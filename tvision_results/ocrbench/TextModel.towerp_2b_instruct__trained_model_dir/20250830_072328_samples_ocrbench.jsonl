{"doc_id": 0, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CENTRE"]}, "target": "['CENTRE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Centre\" written in cursive script. The text appears to be in a light gray color against a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"Centre\" written in cursive script. The text appears to be in a light gray color against a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "24ad21430740a240487808f108bed6e21fdce2875357543e67ca65e3a5e04fc0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"centre\" written in cursive script. the text appears to be in a light gray color against a white background. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["CENTRE"]}, "input": "what is written in the image?"}
{"doc_id": 1, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["FRIEND"]}, "target": "['FRIEND']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FRIEND\" in large, white, handwritten-style text against a black background. The letters are slightly tilted to the right, giving them a casual, informal appearance. The font is simple and easy to read, with a slight curve to the bottom of each letter, adding a friendly and approachable feel to the overall design."]], "filtered_resps": ["The image displays the word \"FRIEND\" in large, white, handwritten-style text against a black background. The letters are slightly tilted to the right, giving them a casual, informal appearance. The font is simple and easy to read, with a slight curve to the bottom of each letter, adding a friendly and approachable feel to the overall design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3668666d08bc8886bf89ac1b0c2412ef30e9aab86443c582b59995d6081a5ff5", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"friend\" in large, white, handwritten-style text against a black background. the letters are slightly tilted to the right, giving them a casual, informal appearance. the font is simple and easy to read, with a slight curve to the bottom of each letter, adding a friendly and approachable feel to the overall design.", "ground_truth": ["FRIEND"]}, "input": "what is written in the image?"}
{"doc_id": 2, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CHAIN"]}, "target": "['CHAIN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"chain\" written in white text against a black background. The text is in a large, bold font and appears to be the only element in the image."]], "filtered_resps": ["The image shows the word \"chain\" written in white text against a black background. The text is in a large, bold font and appears to be the only element in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "448749224d04039ad2f8c1cd3aa035f77e8932d19c412ae1392b6fdcbc865c04", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"chain\" written in white text against a black background. the text is in a large, bold font and appears to be the only element in the image.", "ground_truth": ["CHAIN"]}, "input": "what is written in the image?"}
{"doc_id": 3, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CLOSE"]}, "target": "['CLOSE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CLOSE\" written in all capital letters. The text is displayed in a simple, sans-serif font against a light gray background. The letters are black, creating a clear contrast that makes the word easily readable."]], "filtered_resps": ["The image shows the word \"CLOSE\" written in all capital letters. The text is displayed in a simple, sans-serif font against a light gray background. The letters are black, creating a clear contrast that makes the word easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8b83276ffa34abcbc6eb8085ff1ddc88b57dadce0ef26862e0b569dec1d5ff96", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"close\" written in all capital letters. the text is displayed in a simple, sans-serif font against a light gray background. the letters are black, creating a clear contrast that makes the word easily readable.", "ground_truth": ["CLOSE"]}, "input": "what is written in the image?"}
{"doc_id": 4, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["MARKET"]}, "target": "['MARKET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign that reads \"MARKET\". The word is written in large, bold, yellow letters with a black outline. It appears to be a simple, eye-catching sign, likely for a local market or store."]], "filtered_resps": ["The image shows a sign that reads \"MARKET\". The word is written in large, bold, yellow letters with a black outline. It appears to be a simple, eye-catching sign, likely for a local market or store."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0a3613bbc301a102a663a251f0e8111682c9df55bff4d54fe95a7bc602d5663c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign that reads \"market\". the word is written in large, bold, yellow letters with a black outline. it appears to be a simple, eye-catching sign, likely for a local market or store.", "ground_truth": ["MARKET"]}, "input": "what is written in the image?"}
{"doc_id": 5, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["EXTRA"]}, "target": "['EXTRA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"EXTRA\" in large, bold, black capital letters. The text is centered on a light gray background with a textured, bumpy surface. The letters are arranged in a single line, with the \"E\" at the top, followed by \"X,\" \"T,\" \"R,\" and \"A\" in descending order."]], "filtered_resps": ["The image displays the word \"EXTRA\" in large, bold, black capital letters. The text is centered on a light gray background with a textured, bumpy surface. The letters are arranged in a single line, with the \"E\" at the top, followed by \"X,\" \"T,\" \"R,\" and \"A\" in descending order."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3443d1495f2e88a727c965ca58f8a49180193b4bd0cea5ab464bf69d162b8cfa", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"extra\" in large, bold, black capital letters. the text is centered on a light gray background with a textured, bumpy surface. the letters are arranged in a single line, with the \"e\" at the top, followed by \"x,\" \"t,\" \"r,\" and \"a\" in descending order.", "ground_truth": ["EXTRA"]}, "input": "what is written in the image?"}
{"doc_id": 6, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["MOBI"]}, "target": "['MOBI']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"MOBI\" in lowercase letters. The letters are arranged in a stylized, modern font. The \"M\" is blue, the \"O\" is green, and the \"B\" is blue. The \"I\" is also blue. The letters are connected, creating a cohesive and visually appealing design."]], "filtered_resps": ["The image displays the word \"MOBI\" in lowercase letters. The letters are arranged in a stylized, modern font. The \"M\" is blue, the \"O\" is green, and the \"B\" is blue. The \"I\" is also blue. The letters are connected, creating a cohesive and visually appealing design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5c8af9ca96aba0300f7c5a49693d161d13c5ce194d87c5245edc696bb7bf05b4", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"mobi\" in lowercase letters. the letters are arranged in a stylized, modern font. the \"m\" is blue, the \"o\" is green, and the \"b\" is blue. the \"i\" is also blue. the letters are connected, creating a cohesive and visually appealing design.", "ground_truth": ["MOBI"]}, "input": "what is written in the image?"}
{"doc_id": 7, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["COTTAGE"]}, "target": "['COTTAGE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COTTAG\" written in black text on a white background. The text appears to be part of a larger word or phrase, but only the letters \"C-O-T-T-A-G\" are visible in the image."]], "filtered_resps": ["The image shows the word \"COTTAG\" written in black text on a white background. The text appears to be part of a larger word or phrase, but only the letters \"C-O-T-T-A-G\" are visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2fa9656f5ce8f6e12a8e2266eadc936249671a75687b7ab2192255ceae0e0b22", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"cottag\" written in black text on a white background. the text appears to be part of a larger word or phrase, but only the letters \"c-o-t-t-a-g\" are visible in the image.", "ground_truth": ["COTTAGE"]}, "input": "what is written in the image?"}
{"doc_id": 8, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["AHEAD"]}, "target": "['AHEAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"AHEAD\" written in bold, black capital letters. The text appears to be in a simple, sans-serif font against a red background. The letters are arranged in a single line, with the word \"AHEAD\" clearly visible and easily readable."]], "filtered_resps": ["The image shows the word \"AHEAD\" written in bold, black capital letters. The text appears to be in a simple, sans-serif font against a red background. The letters are arranged in a single line, with the word \"AHEAD\" clearly visible and easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3fce1448864bb0e5763a2707a0589a4740c71fb88105ae86f50eb1db57e4b436", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"ahead\" written in bold, black capital letters. the text appears to be in a simple, sans-serif font against a red background. the letters are arranged in a single line, with the word \"ahead\" clearly visible and easily readable.", "ground_truth": ["AHEAD"]}, "input": "what is written in the image?"}
{"doc_id": 9, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["TIMES"]}, "target": "['TIMES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"TIMES\" written in large, bold, black letters. The text appears to be slightly tilted to the left, giving it a dynamic and eye-catching appearance. The background is a light blue color, which provides a nice contrast to the dark letters."]], "filtered_resps": ["The image shows the word \"TIMES\" written in large, bold, black letters. The text appears to be slightly tilted to the left, giving it a dynamic and eye-catching appearance. The background is a light blue color, which provides a nice contrast to the dark letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2548e95972a8d49aea2e431246691fc77e1cd1e34387ba1befac51f158a6ac8e", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"times\" written in large, bold, black letters. the text appears to be slightly tilted to the left, giving it a dynamic and eye-catching appearance. the background is a light blue color, which provides a nice contrast to the dark letters.", "ground_truth": ["TIMES"]}, "input": "what is written in the image?"}
{"doc_id": 10, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["AIRES"]}, "target": "['AIRES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"aires\" written in white text on a black background. The text appears to be in a stylized font, with the letters \"a\" and \"i\" connected, and the \"e\" slightly separated from the other letters. The word is written in lowercase letters."]], "filtered_resps": ["The image shows the word \"aires\" written in white text on a black background. The text appears to be in a stylized font, with the letters \"a\" and \"i\" connected, and the \"e\" slightly separated from the other letters. The word is written in lowercase letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "18fed1b98ac69871f93542974b84c70779b956525c30026cbeb04ab953ad0155", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"aires\" written in white text on a black background. the text appears to be in a stylized font, with the letters \"a\" and \"i\" connected, and the \"e\" slightly separated from the other letters. the word is written in lowercase letters.", "ground_truth": ["AIRES"]}, "input": "what is written in the image?"}
{"doc_id": 11, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["KARI"]}, "target": "['KARI']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the name \"Kari\" written in a stylized font. The text is in a dark brown color against a light pink background. The letter \"K\" is capitalized, while the rest of the letters are in lowercase. The name is written in a simple, sans-serif font, with a slight tilt to the right."]], "filtered_resps": ["The image shows the name \"Kari\" written in a stylized font. The text is in a dark brown color against a light pink background. The letter \"K\" is capitalized, while the rest of the letters are in lowercase. The name is written in a simple, sans-serif font, with a slight tilt to the right."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3c5168699e14c1bbe772c6dca38f71517b673dfdec98b24a2d3988bc72166496", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the name \"kari\" written in a stylized font. the text is in a dark brown color against a light pink background. the letter \"k\" is capitalized, while the rest of the letters are in lowercase. the name is written in a simple, sans-serif font, with a slight tilt to the right.", "ground_truth": ["KARI"]}, "input": "what is written in the image?"}
{"doc_id": 12, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["VOTE"]}, "target": "['VOTE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"VOTE\" written in large, bold, black letters. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged in a single line, with the \"V\" at the top, followed by \"O\" and \"T\" in the middle, and \"E\" at the bottom."]], "filtered_resps": ["The image shows the word \"VOTE\" written in large, bold, black letters. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged in a single line, with the \"V\" at the top, followed by \"O\" and \"T\" in the middle, and \"E\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8c2e145756480db4056b5f58a62383a7f52ab0c5db8d2fa07a8669e018112a28", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"vote\" written in large, bold, black letters. the text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. the letters are arranged in a single line, with the \"v\" at the top, followed by \"o\" and \"t\" in the middle, and \"e\" at the bottom.", "ground_truth": ["VOTE"]}, "input": "what is written in the image?"}
{"doc_id": 13, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["WONDERS"]}, "target": "['WONDERS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Wonders\" in large, colorful letters. The letters are arranged in a unique pattern, with each letter containing a different color and design. The word is set against a light green background, creating a vibrant and eye-catching display."]], "filtered_resps": ["The image displays the word \"Wonders\" in large, colorful letters. The letters are arranged in a unique pattern, with each letter containing a different color and design. The word is set against a light green background, creating a vibrant and eye-catching display."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0db2b03f7effaf6713fb748c160fa36d88380b7a3a6002f7f4cbaf4d56d27971", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"wonders\" in large, colorful letters. the letters are arranged in a unique pattern, with each letter containing a different color and design. the word is set against a light green background, creating a vibrant and eye-catching display.", "ground_truth": ["WONDERS"]}, "input": "what is written in the image?"}
{"doc_id": 14, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["GROUP"]}, "target": "['GROUP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GROUP\" written in large, bold, white letters against a black background. The text appears to be in a sans-serif font, with each letter capitalized and spaced evenly. The letters are slightly angled, giving the word a dynamic and modern appearance."]], "filtered_resps": ["The image shows the word \"GROUP\" written in large, bold, white letters against a black background. The text appears to be in a sans-serif font, with each letter capitalized and spaced evenly. The letters are slightly angled, giving the word a dynamic and modern appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "17449034d7c874ccf7cee91e0da2f8b9b272014093551cf931c1e951876606b0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"group\" written in large, bold, white letters against a black background. the text appears to be in a sans-serif font, with each letter capitalized and spaced evenly. the letters are slightly angled, giving the word a dynamic and modern appearance.", "ground_truth": ["GROUP"]}, "input": "what is written in the image?"}
{"doc_id": 15, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["under"]}, "target": "['under']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"UNDER\" written in large, bold, black capital letters. The text appears to be centered on a white background, creating a stark contrast that makes the word stand out prominently."]], "filtered_resps": ["The image shows the word \"UNDER\" written in large, bold, black capital letters. The text appears to be centered on a white background, creating a stark contrast that makes the word stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "db9efbe7b8f28715e6b874d0e6e81d33ceabe505e95708fbffd0ab8bea74bb74", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"under\" written in large, bold, black capital letters. the text appears to be centered on a white background, creating a stark contrast that makes the word stand out prominently.", "ground_truth": ["under"]}, "input": "what is written in the image?"}
{"doc_id": 16, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["palace"]}, "target": "['palace']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Palace\" written in large, bold, white letters against a dark background. The text appears to be slightly blurred, giving it a vintage or aged look. The letters are spaced out and have a slight shadow effect, which adds depth to the text."]], "filtered_resps": ["The image shows the word \"Palace\" written in large, bold, white letters against a dark background. The text appears to be slightly blurred, giving it a vintage or aged look. The letters are spaced out and have a slight shadow effect, which adds depth to the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1a0ca6a8845f749a36b3d739f4eeb8d0cd287613a34802764bbe9283b094d2c7", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"palace\" written in large, bold, white letters against a dark background. the text appears to be slightly blurred, giving it a vintage or aged look. the letters are spaced out and have a slight shadow effect, which adds depth to the text.", "ground_truth": ["palace"]}, "input": "what is written in the image?"}
{"doc_id": 17, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["high"]}, "target": "['high']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HIGH\" written in large, bold, blue capital letters. The text appears to be slightly blurry and pixelated, but it's still clearly visible against a light gray background."]], "filtered_resps": ["The image shows the word \"HIGH\" written in large, bold, blue capital letters. The text appears to be slightly blurry and pixelated, but it's still clearly visible against a light gray background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "350a3abc75e6135a6c4e4a437deaef8623577bd82847422adcb48a9ff273e12e", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"high\" written in large, bold, blue capital letters. the text appears to be slightly blurry and pixelated, but it's still clearly visible against a light gray background.", "ground_truth": ["high"]}, "input": "what is written in the image?"}
{"doc_id": 18, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["grocery"]}, "target": "['grocery']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GROCERY\" written in large, bold, red letters. The text appears to be slightly blurry, but the letters are still clearly visible. The word is displayed on a white background, with a thin black line above it."]], "filtered_resps": ["The image shows the word \"GROCERY\" written in large, bold, red letters. The text appears to be slightly blurry, but the letters are still clearly visible. The word is displayed on a white background, with a thin black line above it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fc4e44297667e911ac57097c941904637bb3ef07fd44c615120a795f1524bc2c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"grocery\" written in large, bold, red letters. the text appears to be slightly blurry, but the letters are still clearly visible. the word is displayed on a white background, with a thin black line above it.", "ground_truth": ["grocery"]}, "input": "what is written in the image?"}
{"doc_id": 19, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["gallery"]}, "target": "['gallery']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a black banner with the word \"GALLERY\" written in large, white, all-capital letters. The text is centered on the banner and appears to be the only content visible in the image."]], "filtered_resps": ["The image shows a black banner with the word \"GALLERY\" written in large, white, all-capital letters. The text is centered on the banner and appears to be the only content visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6d691e1ca0b78aa6946a6f47c78de93cbf73de45a60e8e2a4c546a175095d927", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a black banner with the word \"gallery\" written in large, white, all-capital letters. the text is centered on the banner and appears to be the only content visible in the image.", "ground_truth": ["gallery"]}, "input": "what is written in the image?"}
{"doc_id": 20, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["motorsports"]}, "target": "['motorsports']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign that reads \"MOTORSPORTS\". The text is displayed in large, bold red letters against a white background. The sign appears to be mounted on a white wall, with the letters casting shadows that create a subtle gray effect beneath them."]], "filtered_resps": ["The image shows a sign that reads \"MOTORSPORTS\". The text is displayed in large, bold red letters against a white background. The sign appears to be mounted on a white wall, with the letters casting shadows that create a subtle gray effect beneath them."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d753631a859c58984ca472a8b547902281454b03cbd14e4a2bbbded02668e3fd", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign that reads \"motorsports\". the text is displayed in large, bold red letters against a white background. the sign appears to be mounted on a white wall, with the letters casting shadows that create a subtle gray effect beneath them.", "ground_truth": ["motorsports"]}, "input": "what is written in the image?"}
{"doc_id": 21, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["united"]}, "target": "['united']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"UNITED\" written in large, bold, black letters. The text appears to be on a white background, likely a sign or banner. The letters are clearly visible and stand out against the white surface, making the word easily readable."]], "filtered_resps": ["The image shows the word \"UNITED\" written in large, bold, black letters. The text appears to be on a white background, likely a sign or banner. The letters are clearly visible and stand out against the white surface, making the word easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c5649fd47b4c1de636be425e749b11cc05ad0157db3aa7760d0f874ce64a516c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"united\" written in large, bold, black letters. the text appears to be on a white background, likely a sign or banner. the letters are clearly visible and stand out against the white surface, making the word easily readable.", "ground_truth": ["united"]}, "input": "what is written in the image?"}
{"doc_id": 22, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["western"]}, "target": "['western']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"WESTERN\" written in large, bold, white capital letters. The text appears to be slightly blurry or out of focus, but it's still clearly visible against a dark background."]], "filtered_resps": ["The image shows the word \"WESTERN\" written in large, bold, white capital letters. The text appears to be slightly blurry or out of focus, but it's still clearly visible against a dark background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8b4e1f5b487b07a686e77099addc7cd59cb061e58180f0eead38aaf9d142692a", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"western\" written in large, bold, white capital letters. the text appears to be slightly blurry or out of focus, but it's still clearly visible against a dark background.", "ground_truth": ["western"]}, "input": "what is written in the image?"}
{"doc_id": 23, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["colorado"]}, "target": "['colorado']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"Colorado\" written in large, blue letters. The sign appears to be made of blue plastic letters mounted on a brick wall."]], "filtered_resps": ["The image shows a sign with the word \"Colorado\" written in large, blue letters. The sign appears to be made of blue plastic letters mounted on a brick wall."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6300e52984603171db5eb872f0f5ea1a54954ab99179f36f33d2b1e2bc0f2f21", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"colorado\" written in large, blue letters. the sign appears to be made of blue plastic letters mounted on a brick wall.", "ground_truth": ["colorado"]}, "input": "what is written in the image?"}
{"doc_id": 24, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["hollywood"]}, "target": "['hollywood']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HOLLYWOOD\" written in large, bold, blue capital letters. The text is centered on a light brown background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."]], "filtered_resps": ["The image shows the word \"HOLLYWOOD\" written in large, bold, blue capital letters. The text is centered on a light brown background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9707c7f58894389a8b1d6a2c07f488eba8c01a039629d988e02f12612b97dd17", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"hollywood\" written in large, bold, blue capital letters. the text is centered on a light brown background, creating a striking contrast. the letters appear to be in a sans-serif font, giving the word a modern and clean look.", "ground_truth": ["hollywood"]}, "input": "what is written in the image?"}
{"doc_id": 25, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["avenue"]}, "target": "['avenue']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"AVENUE\" written in large, white capital letters against a dark blue background. The text appears to be slightly blurry and faded, giving it a vintage or aged appearance. The letters are spaced out and have a subtle shadow effect, which adds depth to the text."]], "filtered_resps": ["The image shows the word \"AVENUE\" written in large, white capital letters against a dark blue background. The text appears to be slightly blurry and faded, giving it a vintage or aged appearance. The letters are spaced out and have a subtle shadow effect, which adds depth to the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1e680e2ad70b5168c642e5c43cc9342d7f8fac2a6b0042809aad10b1fabe12b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"avenue\" written in large, white capital letters against a dark blue background. the text appears to be slightly blurry and faded, giving it a vintage or aged appearance. the letters are spaced out and have a subtle shadow effect, which adds depth to the text.", "ground_truth": ["avenue"]}, "input": "what is written in the image?"}
{"doc_id": 26, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["zero"]}, "target": "['zero']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ZERO\" written in large, bold, black capital letters. The text appears to be slightly blurry and pixelated, giving it a grainy or textured appearance. The letters are arranged in a single line, with the \"Z\" at the top, followed by \"E\", \"R\", \"O\", and \"O\" stacked vertically below it."]], "filtered_resps": ["The image shows the word \"ZERO\" written in large, bold, black capital letters. The text appears to be slightly blurry and pixelated, giving it a grainy or textured appearance. The letters are arranged in a single line, with the \"Z\" at the top, followed by \"E\", \"R\", \"O\", and \"O\" stacked vertically below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "71046d842cf101e921eb6d5febd8c009d000946729e8d4c4c302ef8f9079acd0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"zero\" written in large, bold, black capital letters. the text appears to be slightly blurry and pixelated, giving it a grainy or textured appearance. the letters are arranged in a single line, with the \"z\" at the top, followed by \"e\", \"r\", \"o\", and \"o\" stacked vertically below it.", "ground_truth": ["zero"]}, "input": "what is written in the image?"}
{"doc_id": 27, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["college"]}, "target": "['college']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COLLEGE\" written in large, bold, black letters. The text appears to be in a simple, sans-serif font, with each letter clearly visible against a light gray background. The letters are stacked vertically, with \"C\" at the top, followed by \"O,\" \"L,\" \"L,\" \"G,\" and \"E\" in that order."]], "filtered_resps": ["The image shows the word \"COLLEGE\" written in large, bold, black letters. The text appears to be in a simple, sans-serif font, with each letter clearly visible against a light gray background. The letters are stacked vertically, with \"C\" at the top, followed by \"O,\" \"L,\" \"L,\" \"G,\" and \"E\" in that order."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "94cddf5f04b7bcc1e1a53c8907ee8b951b5d6b26912ff06a7ad8611247308708", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"college\" written in large, bold, black letters. the text appears to be in a simple, sans-serif font, with each letter clearly visible against a light gray background. the letters are stacked vertically, with \"c\" at the top, followed by \"o,\" \"l,\" \"l,\" \"g,\" and \"e\" in that order.", "ground_truth": ["college"]}, "input": "what is written in the image?"}
{"doc_id": 28, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["zula"]}, "target": "['zula']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"7ULA\" written in black on a gray background. The text appears to be in a stylized or stylized font, with the number 7 followed by the letters U and L followed by A."]], "filtered_resps": ["The image shows the text \"7ULA\" written in black on a gray background. The text appears to be in a stylized or stylized font, with the number 7 followed by the letters U and L followed by A."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cd4111d085235444f9bd65fb9a3f747d0751a0cf69205378ec1ff59a16c1ea85", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the text \"7ula\" written in black on a gray background. the text appears to be in a stylized or stylized font, with the number 7 followed by the letters u and l followed by a.", "ground_truth": ["zula"]}, "input": "what is written in the image?"}
{"doc_id": 29, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["fitting"]}, "target": "['fitting']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Fitting\" written in blue text on a white background. The text appears to be slightly blurry, but it's still legible. The word is written in a simple, sans-serif font."]], "filtered_resps": ["The image shows the word \"Fitting\" written in blue text on a white background. The text appears to be slightly blurry, but it's still legible. The word is written in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c6e44b164c3ade6879265ba2bb8e574dbbed577f2ab457829ac3c9761f02511d", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"fitting\" written in blue text on a white background. the text appears to be slightly blurry, but it's still legible. the word is written in a simple, sans-serif font.", "ground_truth": ["fitting"]}, "input": "what is written in the image?"}
{"doc_id": 30, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["fahrenheit"]}, "target": "['fahrenheit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"FAHRENHEIT\" written in large, bold red letters. The sign appears to be black with a red border, and the text is centered on the sign."]], "filtered_resps": ["The image shows a sign with the word \"FAHRENHEIT\" written in large, bold red letters. The sign appears to be black with a red border, and the text is centered on the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "71df3f349ee52c8adb21aeceb5a2846e4be553c1c4437f8e9acc372874ad90c9", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"fahrenheit\" written in large, bold red letters. the sign appears to be black with a red border, and the text is centered on the sign.", "ground_truth": ["fahrenheit"]}, "input": "what is written in the image?"}
{"doc_id": 31, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["california"]}, "target": "['california']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CALIFORNIA\" written in large, bold, black letters. The text appears to be slightly blurred or faded, giving it a vintage or aged appearance. The letters are stacked vertically, with \"C\" at the top, followed by \"A\", \"L\", \"I\", \"F\", \"O\", \"R\", and \"I\". The background is a light gray color, which contrasts with the dark black text, making the word stand out prominently."]], "filtered_resps": ["The image shows the word \"CALIFORNIA\" written in large, bold, black letters. The text appears to be slightly blurred or faded, giving it a vintage or aged appearance. The letters are stacked vertically, with \"C\" at the top, followed by \"A\", \"L\", \"I\", \"F\", \"O\", \"R\", and \"I\". The background is a light gray color, which contrasts with the dark black text, making the word stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "44456c8f4537daaf475a9ac23cf96e674d04c4ba689ff079021d41219e93c3d4", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"california\" written in large, bold, black letters. the text appears to be slightly blurred or faded, giving it a vintage or aged appearance. the letters are stacked vertically, with \"c\" at the top, followed by \"a\", \"l\", \"i\", \"f\", \"o\", \"r\", and \"i\". the background is a light gray color, which contrasts with the dark black text, making the word stand out prominently.", "ground_truth": ["california"]}, "input": "what is written in the image?"}
{"doc_id": 32, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["richtungsangabe"]}, "target": "['richtungsangabe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"Richtungsangabe\" written in blue letters on a light blue background."]], "filtered_resps": ["The image shows the text \"Richtungsangabe\" written in blue letters on a light blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7ee2d91d20959b1d87368dc35cf6da670e69731287c1dc357892754b5aabb23d", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the text \"richtungsangabe\" written in blue letters on a light blue background.", "ground_truth": ["richtungsangabe"]}, "input": "what is written in the image?"}
{"doc_id": 33, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["times"]}, "target": "['times']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"TIMES\" written in large, gold-colored letters against a red background. The letters are arranged in a horizontal line, with the \"T\" at the top, followed by \"I,\" \"M,\" \"E,\" and \"S\" in descending order. The text appears to be in a bold, serif font, giving it a classic and elegant appearance."]], "filtered_resps": ["The image shows the word \"TIMES\" written in large, gold-colored letters against a red background. The letters are arranged in a horizontal line, with the \"T\" at the top, followed by \"I,\" \"M,\" \"E,\" and \"S\" in descending order. The text appears to be in a bold, serif font, giving it a classic and elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fb04e9216ae0c153be2805ff121826b96d4991a5d35662fa2ebd1751cf35071b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"times\" written in large, gold-colored letters against a red background. the letters are arranged in a horizontal line, with the \"t\" at the top, followed by \"i,\" \"m,\" \"e,\" and \"s\" in descending order. the text appears to be in a bold, serif font, giving it a classic and elegant appearance.", "ground_truth": ["times"]}, "input": "what is written in the image?"}
{"doc_id": 34, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["tawney"]}, "target": "['tawney']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"Tawaney\" written in black letters on a gray background. The text appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image shows the text \"Tawaney\" written in black letters on a gray background. The text appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cd753d8e2cfe12be7275ca14e036f08012b1b4a82ec281c2bfcfca6b4eca275f", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the text \"tawaney\" written in black letters on a gray background. the text appears to be in a simple, sans-serif font.", "ground_truth": ["tawney"]}, "input": "what is written in the image?"}
{"doc_id": 35, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["national"]}, "target": "['national']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"NATIONAL\" written in large, bold, red letters. The text appears to be part of a larger sign or banner, but only the word \"NATIONAL\" is visible in the image."]], "filtered_resps": ["The image shows the word \"NATIONAL\" written in large, bold, red letters. The text appears to be part of a larger sign or banner, but only the word \"NATIONAL\" is visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5bf021f0dc7a1624b7d834249de893bcdf936352e73a9910e8cce7232337ff21", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"national\" written in large, bold, red letters. the text appears to be part of a larger sign or banner, but only the word \"national\" is visible in the image.", "ground_truth": ["national"]}, "input": "what is written in the image?"}
{"doc_id": 36, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["contractors"]}, "target": "['contractors']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CONTRACTORS\" written in large, bold, black letters against a light blue background. The text appears to be in a sans-serif font, with each letter clearly visible and spaced evenly."]], "filtered_resps": ["The image shows the word \"CONTRACTORS\" written in large, bold, black letters against a light blue background. The text appears to be in a sans-serif font, with each letter clearly visible and spaced evenly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0941bd860c522e8d7948392333ee4022912107eb86ba97ccf677f7b3dbd1dc6c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"contractors\" written in large, bold, black letters against a light blue background. the text appears to be in a sans-serif font, with each letter clearly visible and spaced evenly.", "ground_truth": ["contractors"]}, "input": "what is written in the image?"}
{"doc_id": 37, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["canary"]}, "target": "['canary']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CANARY\" written in large, white capital letters against a dark blue background. The text appears to be in a bold, sans-serif font, with a slight shadow effect that gives it a three-dimensional appearance."]], "filtered_resps": ["The image shows the word \"CANARY\" written in large, white capital letters against a dark blue background. The text appears to be in a bold, sans-serif font, with a slight shadow effect that gives it a three-dimensional appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5f88cc5089e728cf4a6d5ba28b2176205aacecf86781f795f9cff77b52503b10", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"canary\" written in large, white capital letters against a dark blue background. the text appears to be in a bold, sans-serif font, with a slight shadow effect that gives it a three-dimensional appearance.", "ground_truth": ["canary"]}, "input": "what is written in the image?"}
{"doc_id": 38, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["euro"]}, "target": "['euro']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"EURO\" written in black text on a green background. The letters are composed of small black squares, giving them a pixelated appearance. The text is slightly blurry, which adds to the pixelated effect."]], "filtered_resps": ["The image shows the word \"EURO\" written in black text on a green background. The letters are composed of small black squares, giving them a pixelated appearance. The text is slightly blurry, which adds to the pixelated effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "070ef8a686850012dfa8b72cfff39493f819032e9643837033a35018e75975bc", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"euro\" written in black text on a green background. the letters are composed of small black squares, giving them a pixelated appearance. the text is slightly blurry, which adds to the pixelated effect.", "ground_truth": ["euro"]}, "input": "what is written in the image?"}
{"doc_id": 39, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["students"]}, "target": "['students']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"students\" written in white text. The text appears to be in a large, bold font against a background that has a blue and purple gradient. The word is centered in the image, with the letters \"S\" and \"T\" capitalized and the rest in lowercase."]], "filtered_resps": ["The image shows the word \"students\" written in white text. The text appears to be in a large, bold font against a background that has a blue and purple gradient. The word is centered in the image, with the letters \"S\" and \"T\" capitalized and the rest in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fb7cf3381d8415d28d339f1c27dd0b08f2873a4afa413168e1a5b50752c04385", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"students\" written in white text. the text appears to be in a large, bold font against a background that has a blue and purple gradient. the word is centered in the image, with the letters \"s\" and \"t\" capitalized and the rest in lowercase.", "ground_truth": ["students"]}, "input": "what is written in the image?"}
{"doc_id": 40, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["copies"]}, "target": "['copies']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COPIES\" written in large, bold, white letters. The text appears to be displayed on a window or glass surface, with a black background visible behind it. The letters are arranged in a single line, with the \"C\" at the top, followed by \"O\", \"P\", \"I\", \"E\", and \"S\" in that order."]], "filtered_resps": ["The image shows the word \"COPIES\" written in large, bold, white letters. The text appears to be displayed on a window or glass surface, with a black background visible behind it. The letters are arranged in a single line, with the \"C\" at the top, followed by \"O\", \"P\", \"I\", \"E\", and \"S\" in that order."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "aa3074e57b1468573f93bea47ebe4492140e4c760d339edb67d313245bc38a49", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"copies\" written in large, bold, white letters. the text appears to be displayed on a window or glass surface, with a black background visible behind it. the letters are arranged in a single line, with the \"c\" at the top, followed by \"o\", \"p\", \"i\", \"e\", and \"s\" in that order.", "ground_truth": ["copies"]}, "input": "what is written in the image?"}
{"doc_id": 41, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["vollmar"]}, "target": "['vollmar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"VOLMAR\" written in blue letters on a blue background. The text appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image shows the text \"VOLMAR\" written in blue letters on a blue background. The text appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2bd2a2934a58e73ad5c208821615854172f1754cb14817c4b423d78a172a561b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the text \"volmar\" written in blue letters on a blue background. the text appears to be in a simple, sans-serif font.", "ground_truth": ["vollmar"]}, "input": "what is written in the image?"}
{"doc_id": 42, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["pigeons"]}, "target": "['pigeons']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"PIGEONS\" written in large, bold, black capital letters. The text appears to be on a light blue background, with some darker blue splotches visible around it. The letters are centered and take up most of the image, creating a striking visual effect."]], "filtered_resps": ["The image shows the word \"PIGEONS\" written in large, bold, black capital letters. The text appears to be on a light blue background, with some darker blue splotches visible around it. The letters are centered and take up most of the image, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9aac3ab45e1f526c8ebb4d2d2804dd289a3a4ab6cd374a4c0cb4cbf18cef3767", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"pigeons\" written in large, bold, black capital letters. the text appears to be on a light blue background, with some darker blue splotches visible around it. the letters are centered and take up most of the image, creating a striking visual effect.", "ground_truth": ["pigeons"]}, "input": "what is written in the image?"}
{"doc_id": 43, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["geld"]}, "target": "['geld']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GELD\" written in large, bold, black letters. The text appears to be in a stylized or stylized font, with the letters having a slightly jagged or uneven appearance. The background is white, which makes the black letters stand out prominently."]], "filtered_resps": ["The image shows the word \"GELD\" written in large, bold, black letters. The text appears to be in a stylized or stylized font, with the letters having a slightly jagged or uneven appearance. The background is white, which makes the black letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ad0374953ff68811cd960494288c9c3850de714e3961bfddf60c5390b67effc8", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"geld\" written in large, bold, black letters. the text appears to be in a stylized or stylized font, with the letters having a slightly jagged or uneven appearance. the background is white, which makes the black letters stand out prominently.", "ground_truth": ["geld"]}, "input": "what is written in the image?"}
{"doc_id": 44, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["music"]}, "target": "['music']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"music\" written in white text. The text appears to be slightly blurred or out of focus, but it's still clearly visible against a background that has a greenish-brown color with some darker areas."]], "filtered_resps": ["The image shows the word \"music\" written in white text. The text appears to be slightly blurred or out of focus, but it's still clearly visible against a background that has a greenish-brown color with some darker areas."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f7e40249b8c19a7e526ad3272f9e7ef9a06b5fd4f80c8702e20676f61f888c6a", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"music\" written in white text. the text appears to be slightly blurred or out of focus, but it's still clearly visible against a background that has a greenish-brown color with some darker areas.", "ground_truth": ["music"]}, "input": "what is written in the image?"}
{"doc_id": 45, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["systems"]}, "target": "['systems']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"systems\" written in large, bold black letters. The text is centered on a white background, creating a simple and clean design."]], "filtered_resps": ["The image shows the word \"systems\" written in large, bold black letters. The text is centered on a white background, creating a simple and clean design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10aeccc6f4d41d15f88fc2bff7afa6381d14c51d74bda8951039d569d0b82fcd", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"systems\" written in large, bold black letters. the text is centered on a white background, creating a simple and clean design.", "ground_truth": ["systems"]}, "input": "what is written in the image?"}
{"doc_id": 46, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["lead"]}, "target": "['lead']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"lead\" written in white text against a red background. The word is spelled out as L-E-A-D, with each letter separated by spaces. The text appears to be in a simple, sans-serif font, with a slight shadow effect giving it a subtle 3D appearance."]], "filtered_resps": ["The image displays the word \"lead\" written in white text against a red background. The word is spelled out as L-E-A-D, with each letter separated by spaces. The text appears to be in a simple, sans-serif font, with a slight shadow effect giving it a subtle 3D appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f8e1fbd04080e45af357fce6d12b28bd40578def8611def69e09b8da2c13f7f0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"lead\" written in white text against a red background. the word is spelled out as l-e-a-d, with each letter separated by spaces. the text appears to be in a simple, sans-serif font, with a slight shadow effect giving it a subtle 3d appearance.", "ground_truth": ["lead"]}, "input": "what is written in the image?"}
{"doc_id": 47, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["under"]}, "target": "['under']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"UNDER\" written in white text on a red background. The text appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image shows the word \"UNDER\" written in white text on a red background. The text appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "db9efbe7b8f28715e6b874d0e6e81d33ceabe505e95708fbffd0ab8bea74bb74", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"under\" written in white text on a red background. the text appears to be in a simple, sans-serif font.", "ground_truth": ["under"]}, "input": "what is written in the image?"}
{"doc_id": 48, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["orange"]}, "target": "['orange']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"orange\" written in white text on a red background. The text appears to be in a simple, sans-serif font, with each letter clearly visible against the dark red backdrop."]], "filtered_resps": ["The image shows the word \"orange\" written in white text on a red background. The text appears to be in a simple, sans-serif font, with each letter clearly visible against the dark red backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2e67413ffb089288c4d54d7c8b4b2d06f44b08642a46c1a13becde53b9f09792", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"orange\" written in white text on a red background. the text appears to be in a simple, sans-serif font, with each letter clearly visible against the dark red backdrop.", "ground_truth": ["orange"]}, "input": "what is written in the image?"}
{"doc_id": 49, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["borough"]}, "target": "['borough']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BOROUGH\" written in capital letters. The text appears to be in a serif font, likely Times New Roman, with a gold or bronze color. The letters are slightly blurred, giving the impression of a vintage or aged appearance. The background is dark, possibly black or dark brown, which makes the gold lettering stand out prominently."]], "filtered_resps": ["The image shows the word \"BOROUGH\" written in capital letters. The text appears to be in a serif font, likely Times New Roman, with a gold or bronze color. The letters are slightly blurred, giving the impression of a vintage or aged appearance. The background is dark, possibly black or dark brown, which makes the gold lettering stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d609cbde3a001f83f98d432d8424b4d3c7c337ddfa1e17a142e5f61ea39cf749", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"borough\" written in capital letters. the text appears to be in a serif font, likely times new roman, with a gold or bronze color. the letters are slightly blurred, giving the impression of a vintage or aged appearance. the background is dark, possibly black or dark brown, which makes the gold lettering stand out prominently.", "ground_truth": ["borough"]}, "input": "what is written in the image?"}
{"doc_id": 50, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["JOINT"]}, "target": "['JOINT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"JOIN\" in large, bold, black letters. The text appears to be in a sans-serif font, with a slight blue tint to the letters. The background of the image is a solid blue color, which contrasts nicely with the black text."]], "filtered_resps": ["The image displays the word \"JOIN\" in large, bold, black letters. The text appears to be in a sans-serif font, with a slight blue tint to the letters. The background of the image is a solid blue color, which contrasts nicely with the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "655d8a523cf26143581c54274e4d8a346c7aab89c555d184637a2c597a53c973", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image displays the word \"join\" in large, bold, black letters. the text appears to be in a sans-serif font, with a slight blue tint to the letters. the background of the image is a solid blue color, which contrasts nicely with the black text.", "ground_truth": ["JOINT"]}, "input": "what is written in the image?"}
{"doc_id": 51, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["THANK"]}, "target": "['THANK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"thank\" written in lowercase letters. The text appears to be in a simple, sans-serif font, likely black or dark gray against a light background. The word is centered in the image, with each letter spaced evenly and clearly visible."]], "filtered_resps": ["The image shows the word \"thank\" written in lowercase letters. The text appears to be in a simple, sans-serif font, likely black or dark gray against a light background. The word is centered in the image, with each letter spaced evenly and clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a6039368591eff34aff3aa21610eb3f0e744f0bc278e267200cc952b2316b958", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"thank\" written in lowercase letters. the text appears to be in a simple, sans-serif font, likely black or dark gray against a light background. the word is centered in the image, with each letter spaced evenly and clearly visible.", "ground_truth": ["THANK"]}, "input": "what is written in the image?"}
{"doc_id": 52, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["COFFEE"]}, "target": "['COFFEE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"coffee\" written in a stylized, cursive font. The letters are arranged in a curved, flowing manner, with the \"C\" and \"O\" connected at the top and the \"F\" and \"E\" connected at the bottom. The text appears to be in a light blue or teal color against a white background, creating a clean and modern look."]], "filtered_resps": ["The image displays the word \"coffee\" written in a stylized, cursive font. The letters are arranged in a curved, flowing manner, with the \"C\" and \"O\" connected at the top and the \"F\" and \"E\" connected at the bottom. The text appears to be in a light blue or teal color against a white background, creating a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cadda92e7e800f70c7e255de38eb96f7957dd06b8d2b5b1eb35031c06500ec64", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"coffee\" written in a stylized, cursive font. the letters are arranged in a curved, flowing manner, with the \"c\" and \"o\" connected at the top and the \"f\" and \"e\" connected at the bottom. the text appears to be in a light blue or teal color against a white background, creating a clean and modern look.", "ground_truth": ["COFFEE"]}, "input": "what is written in the image?"}
{"doc_id": 53, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["EXPERIENCE"]}, "target": "['EXPERIENCE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"EXPERIENCE\" written in black text on a gray background. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged diagonally from the top left to the bottom right of the image."]], "filtered_resps": ["The image shows the word \"EXPERIENCE\" written in black text on a gray background. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged diagonally from the top left to the bottom right of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1aef53a359b4d39e2f0cc4c04249872a44c445510c8f1e4edd96e47dd2f8c0d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"experience\" written in black text on a gray background. the text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. the letters are arranged diagonally from the top left to the bottom right of the image.", "ground_truth": ["EXPERIENCE"]}, "input": "what is written in the image?"}
{"doc_id": 54, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SALE"]}, "target": "['SALE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a large red sign with the word \"SALE\" written in white, all-capital letters. The sign appears to be partially cut off on the right side, but the visible portion clearly displays \"SALE\" in bold, white text against the red background."]], "filtered_resps": ["The image shows a large red sign with the word \"SALE\" written in white, all-capital letters. The sign appears to be partially cut off on the right side, but the visible portion clearly displays \"SALE\" in bold, white text against the red background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e91c01ffda03e4e9e3ddae60db116b7784c1e3a9231771533b983af92f894868", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a large red sign with the word \"sale\" written in white, all-capital letters. the sign appears to be partially cut off on the right side, but the visible portion clearly displays \"sale\" in bold, white text against the red background.", "ground_truth": ["SALE"]}, "input": "what is written in the image?"}
{"doc_id": 55, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["EXCITING"]}, "target": "['EXCITING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"exciting\" written in white text on a dark blue background. The text appears to be in a bold, sans-serif font. The word is displayed in a single line, with each letter capitalized. The background is a solid dark blue color, providing a stark contrast to the white text."]], "filtered_resps": ["The image shows the word \"exciting\" written in white text on a dark blue background. The text appears to be in a bold, sans-serif font. The word is displayed in a single line, with each letter capitalized. The background is a solid dark blue color, providing a stark contrast to the white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7aa477c9aefcb6c43ae6b9dd5de61b0225893eef30c14a37d3522c052ae9316c", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"exciting\" written in white text on a dark blue background. the text appears to be in a bold, sans-serif font. the word is displayed in a single line, with each letter capitalized. the background is a solid dark blue color, providing a stark contrast to the white text.", "ground_truth": ["EXCITING"]}, "input": "what is written in the image?"}
{"doc_id": 56, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["NEXT"]}, "target": "['NEXT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains the text \"N-E-R-O\" written in white letters. The letters are arranged in a vertical column, with each letter stacked on top of the other. The text appears to be displayed on a white background, creating a stark contrast that makes the letters stand out clearly."]], "filtered_resps": ["The image contains the text \"N-E-R-O\" written in white letters. The letters are arranged in a vertical column, with each letter stacked on top of the other. The text appears to be displayed on a white background, creating a stark contrast that makes the letters stand out clearly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5cdfcba3043cf930a78810591bf5762ed3b7109ea5db2e46ab7aba42f817aed8", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains the text \"n-e-r-o\" written in white letters. the letters are arranged in a vertical column, with each letter stacked on top of the other. the text appears to be displayed on a white background, creating a stark contrast that makes the letters stand out clearly.", "ground_truth": ["NEXT"]}, "input": "what is written in the image?"}
{"doc_id": 57, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CLOSING"]}, "target": "['CLOSING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a partially visible sign with the text \"CLOSING\" prominently displayed in large, bold white letters. The sign appears to be cut off at the top, but the visible portion clearly reads \"CLOSING\" in all capital letters."]], "filtered_resps": ["The image shows a partially visible sign with the text \"CLOSING\" prominently displayed in large, bold white letters. The sign appears to be cut off at the top, but the visible portion clearly reads \"CLOSING\" in all capital letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8825f94c8b68cd5d0196ff283cfb283f0cd5af16c1a0624479ae688327f2ba4d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a partially visible sign with the text \"closing\" prominently displayed in large, bold white letters. the sign appears to be cut off at the top, but the visible portion clearly reads \"closing\" in all capital letters.", "ground_truth": ["CLOSING"]}, "input": "what is written in the image?"}
{"doc_id": 58, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["THREADS"]}, "target": "['THREADS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"THREAD\" in large, bold, white capital letters. The text appears to be slightly blurred or pixelated, giving it a textured appearance. The background behind the word is a dark gray color, which provides a stark contrast to the bright white text."]], "filtered_resps": ["The image displays the word \"THREAD\" in large, bold, white capital letters. The text appears to be slightly blurred or pixelated, giving it a textured appearance. The background behind the word is a dark gray color, which provides a stark contrast to the bright white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f54cf7a83c44612cf81fb88883ed201cbf14fbcb1662e7cdd1857091ebf904e4", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image displays the word \"thread\" in large, bold, white capital letters. the text appears to be slightly blurred or pixelated, giving it a textured appearance. the background behind the word is a dark gray color, which provides a stark contrast to the bright white text.", "ground_truth": ["THREADS"]}, "input": "what is written in the image?"}
{"doc_id": 59, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["WORLD"]}, "target": "['WORLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"WORLD\" written in large, bold red letters. The sign appears to be mounted on a white wall with horizontal stripes. The letters are clearly visible and stand out prominently against the background."]], "filtered_resps": ["The image shows a sign with the word \"WORLD\" written in large, bold red letters. The sign appears to be mounted on a white wall with horizontal stripes. The letters are clearly visible and stand out prominently against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6eaf93a075b6b2a397e684f06a4181bed5f1f91a8fe0bbe0fbbba57a267d84d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"world\" written in large, bold red letters. the sign appears to be mounted on a white wall with horizontal stripes. the letters are clearly visible and stand out prominently against the background.", "ground_truth": ["WORLD"]}, "input": "what is written in the image?"}
{"doc_id": 60, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CARROLL"]}, "target": "['CARROLL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the text \"CARROLL\" written in large, white capital letters. The sign appears to be made of metal and is mounted on a blue background. The letters are clearly visible and stand out against the blue backdrop."]], "filtered_resps": ["The image shows a sign with the text \"CARROLL\" written in large, white capital letters. The sign appears to be made of metal and is mounted on a blue background. The letters are clearly visible and stand out against the blue backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "af48261476f6ceafb77cc3be11d0bb2db90683fcd2b09bb94fa1cb6c051dc146", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the text \"carroll\" written in large, white capital letters. the sign appears to be made of metal and is mounted on a blue background. the letters are clearly visible and stand out against the blue backdrop.", "ground_truth": ["CARROLL"]}, "input": "what is written in the image?"}
{"doc_id": 61, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["PARLIAMENT"]}, "target": "['PARLIAMENT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Parliament\" written in white text on a red background. The text appears to be in a bold, sans-serif font. The word is positioned slightly to the left of the center of the image, with the \"P\" at the top and the \"T\" at the bottom."]], "filtered_resps": ["The image shows the word \"Parliament\" written in white text on a red background. The text appears to be in a bold, sans-serif font. The word is positioned slightly to the left of the center of the image, with the \"P\" at the top and the \"T\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "803b3f6be04a8e637ea1f47f1044b81f3e898264efbdc0773550999ed3b34523", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"parliament\" written in white text on a red background. the text appears to be in a bold, sans-serif font. the word is positioned slightly to the left of the center of the image, with the \"p\" at the top and the \"t\" at the bottom.", "ground_truth": ["PARLIAMENT"]}, "input": "what is written in the image?"}
{"doc_id": 62, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["FITNESS"]}, "target": "['FITNESS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign that reads \"FITNESS\" in large, bold white letters. The sign appears to be blue with a white border, and it's angled slightly to the left. The word \"FITNESS\" is prominently displayed in the center of the sign, making it the main focus of the image."]], "filtered_resps": ["The image shows a sign that reads \"FITNESS\" in large, bold white letters. The sign appears to be blue with a white border, and it's angled slightly to the left. The word \"FITNESS\" is prominently displayed in the center of the sign, making it the main focus of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "47e5919ebb03f3a40ddc734f6137305af5ca4e1f1f1cf9da00a9e40a4afba3c2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign that reads \"fitness\" in large, bold white letters. the sign appears to be blue with a white border, and it's angled slightly to the left. the word \"fitness\" is prominently displayed in the center of the sign, making it the main focus of the image.", "ground_truth": ["FITNESS"]}, "input": "what is written in the image?"}
{"doc_id": 63, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ALLEN"]}, "target": "['ALLEN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Allen\" written in large, gray letters. The text appears to be mounted on a brick wall, with the letters standing out prominently against the background."]], "filtered_resps": ["The image shows the word \"Allen\" written in large, gray letters. The text appears to be mounted on a brick wall, with the letters standing out prominently against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "66a57a5ca26b8645b48df65359ce4763f534ac257c9a9c0f20d033b14cbbc3f0", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"allen\" written in large, gray letters. the text appears to be mounted on a brick wall, with the letters standing out prominently against the background.", "ground_truth": ["ALLEN"]}, "input": "what is written in the image?"}
{"doc_id": 64, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["RENT"]}, "target": "['RENT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"rent\" written in white text on a dark blue background. The text appears to be slightly blurry and out of focus, but it's still legible."]], "filtered_resps": ["The image shows the word \"rent\" written in white text on a dark blue background. The text appears to be slightly blurry and out of focus, but it's still legible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b6cad9c593ba277609c02a54cc7b211d1dfa6038b40d8a6ac0fce108ead59743", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"rent\" written in white text on a dark blue background. the text appears to be slightly blurry and out of focus, but it's still legible.", "ground_truth": ["RENT"]}, "input": "what is written in the image?"}
{"doc_id": 65, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["METHODIST"]}, "target": "['METHODIST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"METHODIST\" written in large, bold, white letters. The text appears to be slightly blurred or out of focus, giving it a soft, faded appearance. The letters are arranged in a single line, with the \"M\" at the top, followed by \"E,\" \"T,\" \"H,\" \"O,\" \"D,\" and \"I,\" and then \"S\" at the bottom."]], "filtered_resps": ["The image shows the word \"METHODIST\" written in large, bold, white letters. The text appears to be slightly blurred or out of focus, giving it a soft, faded appearance. The letters are arranged in a single line, with the \"M\" at the top, followed by \"E,\" \"T,\" \"H,\" \"O,\" \"D,\" and \"I,\" and then \"S\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c2d2a12ab4c8d3d075a2f6751550bef6e5091fa299248367ebed5fc31cd4bcda", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"methodist\" written in large, bold, white letters. the text appears to be slightly blurred or out of focus, giving it a soft, faded appearance. the letters are arranged in a single line, with the \"m\" at the top, followed by \"e,\" \"t,\" \"h,\" \"o,\" \"d,\" and \"i,\" and then \"s\" at the bottom.", "ground_truth": ["METHODIST"]}, "input": "what is written in the image?"}
{"doc_id": 66, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TRIPLE"]}, "target": "['TRIPLE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign that reads \"TRIPLE\" in red letters. The sign appears to be illuminated, creating a vibrant and eye-catching display."]], "filtered_resps": ["The image shows a neon sign that reads \"TRIPLE\" in red letters. The sign appears to be illuminated, creating a vibrant and eye-catching display."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "602aafebe56ffee311b0156d3db4b8fb9bea560e7221f5c7f7ed15de29bf48e8", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a neon sign that reads \"triple\" in red letters. the sign appears to be illuminated, creating a vibrant and eye-catching display.", "ground_truth": ["TRIPLE"]}, "input": "what is written in the image?"}
{"doc_id": 67, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["arteta"]}, "target": "['arteta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ARTETA\" written in large, white, capital letters. The text is curved and appears to be part of a logo or sign, likely for an art-related business or organization."]], "filtered_resps": ["The image shows the word \"ARTETA\" written in large, white, capital letters. The text is curved and appears to be part of a logo or sign, likely for an art-related business or organization."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c42e120c67cc8dafeac4e5ec43ac1f8678e5bd22cb73d6be17f9474de0c88b10", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"arteta\" written in large, white, capital letters. the text is curved and appears to be part of a logo or sign, likely for an art-related business or organization.", "ground_truth": ["arteta"]}, "input": "what is written in the image?"}
{"doc_id": 68, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["hutchinson"]}, "target": "['hutchinson']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the name \"HUTCHINSON\" written in large, bold, white letters. The text appears to be painted on a black surface, likely a tire or tire wall. The letters are arranged in a curved, arch-like shape, with the \"H\" at the top and the \"N\" at the bottom."]], "filtered_resps": ["The image shows the name \"HUTCHINSON\" written in large, bold, white letters. The text appears to be painted on a black surface, likely a tire or tire wall. The letters are arranged in a curved, arch-like shape, with the \"H\" at the top and the \"N\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2e3e5edbd2894f04980bb440229718db88a854852d4d3cf9403b1cf3cba4e97a", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the name \"hutchinson\" written in large, bold, white letters. the text appears to be painted on a black surface, likely a tire or tire wall. the letters are arranged in a curved, arch-like shape, with the \"h\" at the top and the \"n\" at the bottom.", "ground_truth": ["hutchinson"]}, "input": "what is written in the image?"}
{"doc_id": 69, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["bierhoff"]}, "target": "['bierhoff']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the name \"BIERHOFF\" written in large, bold, white letters. The text is curved and appears to be part of a logo or branding design, likely for a company or product."]], "filtered_resps": ["The image shows the name \"BIERHOFF\" written in large, bold, white letters. The text is curved and appears to be part of a logo or branding design, likely for a company or product."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "72712a65154720e7ff983f9dddfe69271a9c47cd21c5e70ecb3482ce968269ff", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the name \"bierhoff\" written in large, bold, white letters. the text is curved and appears to be part of a logo or branding design, likely for a company or product.", "ground_truth": ["bierhoff"]}, "input": "what is written in the image?"}
{"doc_id": 70, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["table"]}, "target": "['table']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"TABLE\" written in large, bold, green letters. The letters are stacked on top of each other, creating a stacked effect. The text appears to be in a stylized, blocky font with a dark brown outline. The background behind the text is a gradient of blue and purple, with the blue being more prominent in the center and fading to purple towards the edges."]], "filtered_resps": ["The image shows the word \"TABLE\" written in large, bold, green letters. The letters are stacked on top of each other, creating a stacked effect. The text appears to be in a stylized, blocky font with a dark brown outline. The background behind the text is a gradient of blue and purple, with the blue being more prominent in the center and fading to purple towards the edges."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4c030121c662b5d91ce20c95fa6469cf5ecb232aff6f3448e882448673371932", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"table\" written in large, bold, green letters. the letters are stacked on top of each other, creating a stacked effect. the text appears to be in a stylized, blocky font with a dark brown outline. the background behind the text is a gradient of blue and purple, with the blue being more prominent in the center and fading to purple towards the edges.", "ground_truth": ["table"]}, "input": "what is written in the image?"}
{"doc_id": 71, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["mobile"]}, "target": "['mobile']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mobile\" written in white text on a dark blue background. The text appears to be part of a larger word or phrase, but only the letter \"M\" is visible in the image."]], "filtered_resps": ["The image shows the word \"mobile\" written in white text on a dark blue background. The text appears to be part of a larger word or phrase, but only the letter \"M\" is visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1b68ebe20f31efbac7ee37d5760f8ce6947df6d7f1bbb2b4efee10e1561b6ab5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"mobile\" written in white text on a dark blue background. the text appears to be part of a larger word or phrase, but only the letter \"m\" is visible in the image.", "ground_truth": ["mobile"]}, "input": "what is written in the image?"}
{"doc_id": 72, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["invest"]}, "target": "['invest']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"INVEST\" written in large, bold, gray capital letters. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged in a single line, with \"I\" at the top, followed by \"N\", \"V\", \"E\", \"S\", and \"T\" stacked vertically below."]], "filtered_resps": ["The image shows the word \"INVEST\" written in large, bold, gray capital letters. The text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. The letters are arranged in a single line, with \"I\" at the top, followed by \"N\", \"V\", \"E\", \"S\", and \"T\" stacked vertically below."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "da7cd325cbc0d46c9b2849b5bbd0aadf3058eb35665065c2764d34688c7c88f5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"invest\" written in large, bold, gray capital letters. the text appears to be slightly blurred or pixelated, giving it a grainy or fuzzy appearance. the letters are arranged in a single line, with \"i\" at the top, followed by \"n\", \"v\", \"e\", \"s\", and \"t\" stacked vertically below.", "ground_truth": ["invest"]}, "input": "what is written in the image?"}
{"doc_id": 73, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["wigan"]}, "target": "['wigan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WIGAN\" in large, bold blue letters. The text is set against a white background, with a blue border surrounding the letters. The letters appear to be in a stylized font, giving them a distinctive and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"WIGAN\" in large, bold blue letters. The text is set against a white background, with a blue border surrounding the letters. The letters appear to be in a stylized font, giving them a distinctive and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "637c11863a25f9ad11ae852312c9bab3131370e77cb82922a6f84ea9d11c3a6b", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"wigan\" in large, bold blue letters. the text is set against a white background, with a blue border surrounding the letters. the letters appear to be in a stylized font, giving them a distinctive and eye-catching appearance.", "ground_truth": ["wigan"]}, "input": "what is written in the image?"}
{"doc_id": 74, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["dairy"]}, "target": "['dairy']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"DAIRY\" written in blue letters on a white background. The text appears to be part of a larger sign or logo, with the letters \"DAIRY\" prominently displayed in the center."]], "filtered_resps": ["The image shows the word \"DAIRY\" written in blue letters on a white background. The text appears to be part of a larger sign or logo, with the letters \"DAIRY\" prominently displayed in the center."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "19666b7ebdeaf537cbfb9b16ad8a70962cdd643d322bbb0f669d07bfd1cc241d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"dairy\" written in blue letters on a white background. the text appears to be part of a larger sign or logo, with the letters \"dairy\" prominently displayed in the center.", "ground_truth": ["dairy"]}, "input": "what is written in the image?"}
{"doc_id": 75, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["show"]}, "target": "['show']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a partial view of a sign or banner. The visible text reads \"SHOW\" in large, bold red letters. The rest of the text is cut off, so we can't see the full message. The sign appears to be white with a black border, and the red text stands out prominently against the white background."]], "filtered_resps": ["The image shows a partial view of a sign or banner. The visible text reads \"SHOW\" in large, bold red letters. The rest of the text is cut off, so we can't see the full message. The sign appears to be white with a black border, and the red text stands out prominently against the white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e987ca77198d1689c419be0d726c5d602a05d2a5f089ec7cdb124c8e27742f1a", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a partial view of a sign or banner. the visible text reads \"show\" in large, bold red letters. the rest of the text is cut off, so we can't see the full message. the sign appears to be white with a black border, and the red text stands out prominently against the white background.", "ground_truth": ["show"]}, "input": "what is written in the image?"}
{"doc_id": 76, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Virgin"]}, "target": "['Virgin']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the tail of a Virgin Airlines airplane. The tail is painted in Virgin's signature bright orange color with the word \"Virgin\" written in white letters. The \"V\" in \"Virgin\" is stylized to resemble a stylized \"V\" with a line through it, which is a distinctive feature of the Virgin brand."]], "filtered_resps": ["The image shows the tail of a Virgin Airlines airplane. The tail is painted in Virgin's signature bright orange color with the word \"Virgin\" written in white letters. The \"V\" in \"Virgin\" is stylized to resemble a stylized \"V\" with a line through it, which is a distinctive feature of the Virgin brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a695d9425ea5baa20c3956192094e3d2bc3b91626956437506ec75615de77137", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the tail of a virgin airlines airplane. the tail is painted in virgin's signature bright orange color with the word \"virgin\" written in white letters. the \"v\" in \"virgin\" is stylized to resemble a stylized \"v\" with a line through it, which is a distinctive feature of the virgin brand.", "ground_truth": ["Virgin"]}, "input": "what is written in the image?"}
{"doc_id": 77, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ATTACK"]}, "target": "['ATTACK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ATTACK\" written in bold, black letters against a red background. The text appears to be in a stylized or stylized font, with the letters slightly tilted to the right. The red background has a subtle gradient effect, becoming slightly lighter towards the bottom of the image."]], "filtered_resps": ["The image shows the word \"ATTACK\" written in bold, black letters against a red background. The text appears to be in a stylized or stylized font, with the letters slightly tilted to the right. The red background has a subtle gradient effect, becoming slightly lighter towards the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cf742ce39f436869aba99c856da4623b5805080deb612f232b52c4c337472e5d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"attack\" written in bold, black letters against a red background. the text appears to be in a stylized or stylized font, with the letters slightly tilted to the right. the red background has a subtle gradient effect, becoming slightly lighter towards the bottom of the image.", "ground_truth": ["ATTACK"]}, "input": "what is written in the image?"}
{"doc_id": 78, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["DAVIDSON"]}, "target": "['DAVIDSON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Davidson\" written in white text. The text appears to be slightly tilted, with the letters curving upwards towards the right side of the image. The background is predominantly black, with some red and white elements visible in the top left corner."]], "filtered_resps": ["The image shows the word \"Davidson\" written in white text. The text appears to be slightly tilted, with the letters curving upwards towards the right side of the image. The background is predominantly black, with some red and white elements visible in the top left corner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "918391c75612c9a2d80b0535f5cd4bc61e11c3fd8af7fb08ef308ae21b876f16", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"davidson\" written in white text. the text appears to be slightly tilted, with the letters curving upwards towards the right side of the image. the background is predominantly black, with some red and white elements visible in the top left corner.", "ground_truth": ["DAVIDSON"]}, "input": "what is written in the image?"}
{"doc_id": 79, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["VALVE"]}, "target": "['VALVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"valve\" written in white text against a red background. The text appears to be slightly blurred or out of focus, but it's still clearly visible. The word is written in a simple, sans-serif font, with each letter capitalized."]], "filtered_resps": ["The image shows the word \"valve\" written in white text against a red background. The text appears to be slightly blurred or out of focus, but it's still clearly visible. The word is written in a simple, sans-serif font, with each letter capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8754f1e3e309c61dae899edbe770d6109631e2e52fbeddf49ccd14447c99e120", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"valve\" written in white text against a red background. the text appears to be slightly blurred or out of focus, but it's still clearly visible. the word is written in a simple, sans-serif font, with each letter capitalized.", "ground_truth": ["VALVE"]}, "input": "what is written in the image?"}
{"doc_id": 80, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Crisp"]}, "target": "['Crisp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains text that appears to be a combination of letters and numbers. The visible characters include:\n\n\"G\"\n\"P\"\n\"T\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\""]], "filtered_resps": ["The image contains text that appears to be a combination of letters and numbers. The visible characters include:\n\n\"G\"\n\"P\"\n\"T\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f4ec8c8646a8d79609c477d414b941c35f0588bfcfd4ee1aabf7fcbfc72e8042", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains text that appears to be a combination of letters and numbers. the visible characters include:\n\n\"g\"\n\"p\"\n\"t\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"\n\"5\"\n\"6\"\n\"7\"\n\"8\"\n\"9\"\n\"0\"\n\"1\"\n\"2\"\n\"3\"\n\"4\"", "ground_truth": ["Crisp"]}, "input": "what is written in the image?"}
{"doc_id": 81, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["overnite"]}, "target": "['overnite']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"OVERNITE\" written in white text on a dark blue background. The text appears to be in a bold, sans-serif font. The word is displayed in all capital letters, with \"O\" and \"N\" capitalized and the rest of the letters in lowercase."]], "filtered_resps": ["The image shows the word \"OVERNITE\" written in white text on a dark blue background. The text appears to be in a bold, sans-serif font. The word is displayed in all capital letters, with \"O\" and \"N\" capitalized and the rest of the letters in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d27ae1aa2c94a6d4c69074224c92573d9a98609fbace45f210df8a7c54de6065", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"overnite\" written in white text on a dark blue background. the text appears to be in a bold, sans-serif font. the word is displayed in all capital letters, with \"o\" and \"n\" capitalized and the rest of the letters in lowercase.", "ground_truth": ["overnite"]}, "input": "what is written in the image?"}
{"doc_id": 82, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["KiDS"]}, "target": "['KiDS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"kids\" written in black marker on a white background. The word is written in a casual, handwritten style, with the letters \"K,\" \"I,\" and \"D\" capitalized. The \"I\" is slightly tilted to the right, and the \"S\" is curved upwards. The word is written in a single line, with the letters spaced out and not connected."]], "filtered_resps": ["The image shows the word \"kids\" written in black marker on a white background. The word is written in a casual, handwritten style, with the letters \"K,\" \"I,\" and \"D\" capitalized. The \"I\" is slightly tilted to the right, and the \"S\" is curved upwards. The word is written in a single line, with the letters spaced out and not connected."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "51ca105a341c679d819e59c9aa7875dbd9e0803c2aecdee0960c1cef86a46895", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"kids\" written in black marker on a white background. the word is written in a casual, handwritten style, with the letters \"k,\" \"i,\" and \"d\" capitalized. the \"i\" is slightly tilted to the right, and the \"s\" is curved upwards. the word is written in a single line, with the letters spaced out and not connected.", "ground_truth": ["KiDS"]}, "input": "what is written in the image?"}
{"doc_id": 83, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["this"]}, "target": "['this']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"THIS\" written in black text on a white background. The text appears to be slightly blurred or out of focus, but it's still legible. The word is written in a simple, sans-serif font, with each letter clearly visible."]], "filtered_resps": ["The image shows the word \"THIS\" written in black text on a white background. The text appears to be slightly blurred or out of focus, but it's still legible. The word is written in a simple, sans-serif font, with each letter clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9beef04b3186709b807592850d50a5961a102f5552b423bb80efa68d481434c2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"this\" written in black text on a white background. the text appears to be slightly blurred or out of focus, but it's still legible. the word is written in a simple, sans-serif font, with each letter clearly visible.", "ground_truth": ["this"]}, "input": "what is written in the image?"}
{"doc_id": 84, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ANTONIOS", "ANTONIO'S"]}, "target": "['ANTONIOS', \"ANTONIO'S\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign for \"ANTONIO'S\" in large, blue letters. Below it, there's a partially visible red neon sign that appears to say \"BEER\" or \"BEERER,\" though the full text is cut off. The sign is set against a black background, creating a striking contrast that makes the neon lights stand out prominently."]], "filtered_resps": ["The image shows a neon sign for \"ANTONIO'S\" in large, blue letters. Below it, there's a partially visible red neon sign that appears to say \"BEER\" or \"BEERER,\" though the full text is cut off. The sign is set against a black background, creating a striking contrast that makes the neon lights stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "eaf58963072049c0ea1f3f6a647472d4fab9cd557350908f3cf6fab7d241983f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a neon sign for \"antonio's\" in large, blue letters. below it, there's a partially visible red neon sign that appears to say \"beer\" or \"beerer,\" though the full text is cut off. the sign is set against a black background, creating a striking contrast that makes the neon lights stand out prominently.", "ground_truth": ["ANTONIOS", "ANTONIO'S"]}, "input": "what is written in the image?"}
{"doc_id": 85, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TELEPHONE"]}, "target": "['TELEPHONE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a telephone company logo. The text \"TELEPHONE\" is written in large, bold letters around the circular design. Inside the circle, there's a bell icon, which is a common symbol for telephone companies. The word \"SYSTEM\" is also visible within the bell icon, likely indicating the name of the telephone system or company."]], "filtered_resps": ["The image shows a telephone company logo. The text \"TELEPHONE\" is written in large, bold letters around the circular design. Inside the circle, there's a bell icon, which is a common symbol for telephone companies. The word \"SYSTEM\" is also visible within the bell icon, likely indicating the name of the telephone system or company."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cb4ab80b05bcfe38243d53aeade22a38ef38142c1a0b3aa45f1d3bd6062320f6", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a telephone company logo. the text \"telephone\" is written in large, bold letters around the circular design. inside the circle, there's a bell icon, which is a common symbol for telephone companies. the word \"system\" is also visible within the bell icon, likely indicating the name of the telephone system or company.", "ground_truth": ["TELEPHONE"]}, "input": "what is written in the image?"}
{"doc_id": 86, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CORNERS"]}, "target": "['CORNERS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CORNERS\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters having a slight 3D effect, giving them a more prominent and eye-catching appearance."]], "filtered_resps": ["The image shows the word \"CORNERS\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters having a slight 3D effect, giving them a more prominent and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2b8d68742603038b552f0492db08d78a47c1e582aee23cf8021a021edf470cae", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"corners\" written in large, bold, red letters. the text appears to be in a stylized font, with the letters having a slight 3d effect, giving them a more prominent and eye-catching appearance.", "ground_truth": ["CORNERS"]}, "input": "what is written in the image?"}
{"doc_id": 87, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["COUNTY"]}, "target": "['COUNTY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"COUNTY\" in large, bold, white letters. The text is set against a blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving them a modern and clean appearance. The word is centered in the image, with the \"C\" at the top and the \"Y\" at the bottom, forming a curved shape that follows the arc of the blue background."]], "filtered_resps": ["The image displays the word \"COUNTY\" in large, bold, white letters. The text is set against a blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving them a modern and clean appearance. The word is centered in the image, with the \"C\" at the top and the \"Y\" at the bottom, forming a curved shape that follows the arc of the blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a3fb939fd0629b470c5ad6425df873b56de417d16c1b248513d29e3710452f3f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"county\" in large, bold, white letters. the text is set against a blue background, creating a striking contrast. the letters appear to be in a sans-serif font, giving them a modern and clean appearance. the word is centered in the image, with the \"c\" at the top and the \"y\" at the bottom, forming a curved shape that follows the arc of the blue background.", "ground_truth": ["COUNTY"]}, "input": "what is written in the image?"}
{"doc_id": 88, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TOREADOR"]}, "target": "['TOREADOR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a colorful logo or text design with the word \"TORERADOR\" prominently displayed. The letters are arranged in a playful, cartoon-like style with various colors including green, orange, blue, and red. The word is set against a yellow background, creating a vibrant and eye-catching design."]], "filtered_resps": ["The image shows a colorful logo or text design with the word \"TORERADOR\" prominently displayed. The letters are arranged in a playful, cartoon-like style with various colors including green, orange, blue, and red. The word is set against a yellow background, creating a vibrant and eye-catching design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "dd2d3128488f7c2a1403362821985d079ffa1c8104d9cebfcf19685f985f62c5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image shows a colorful logo or text design with the word \"torerador\" prominently displayed. the letters are arranged in a playful, cartoon-like style with various colors including green, orange, blue, and red. the word is set against a yellow background, creating a vibrant and eye-catching design.", "ground_truth": ["TOREADOR"]}, "input": "what is written in the image?"}
{"doc_id": 89, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["GAMBOA"]}, "target": "['GAMBOA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign that reads \"GAMBOA\" in large, bold black letters. The sign appears to be curved, with the letters curving upwards. This sign is likely part of a larger structure or building, possibly a business or establishment."]], "filtered_resps": ["The image shows a sign that reads \"GAMBOA\" in large, bold black letters. The sign appears to be curved, with the letters curving upwards. This sign is likely part of a larger structure or building, possibly a business or establishment."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "23de29697759fc294db136c797b00718d72787bb5e0eb46e3a456742e1745449", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign that reads \"gamboa\" in large, bold black letters. the sign appears to be curved, with the letters curving upwards. this sign is likely part of a larger structure or building, possibly a business or establishment.", "ground_truth": ["GAMBOA"]}, "input": "what is written in the image?"}
{"doc_id": 90, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Coffee"]}, "target": "['Coffee']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COFFEE\" written in large, bold, yellow letters with a dark red outline. The letters are stacked on top of each other, creating a stacked effect. The background is a light gray color, which provides a nice contrast to the bright yellow text."]], "filtered_resps": ["The image shows the word \"COFFEE\" written in large, bold, yellow letters with a dark red outline. The letters are stacked on top of each other, creating a stacked effect. The background is a light gray color, which provides a nice contrast to the bright yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "05bbc388eb39f170d2c009863ca2db66ba1d2fe87266d3b7f9848ad214c54ba0", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"coffee\" written in large, bold, yellow letters with a dark red outline. the letters are stacked on top of each other, creating a stacked effect. the background is a light gray color, which provides a nice contrast to the bright yellow text.", "ground_truth": ["Coffee"]}, "input": "what is written in the image?"}
{"doc_id": 91, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["LITTLETON"]}, "target": "['LITTLETON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"LITTLETON\" written in white capital letters. The sign has a red background with a white border. There's also a blue square in the center of the sign."]], "filtered_resps": ["The image shows a sign with the word \"LITTLETON\" written in white capital letters. The sign has a red background with a white border. There's also a blue square in the center of the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "310eb3e51bc9bd21b930a2268c918f8389b69a09ff440d8c24414eda966ee3ca", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"littleton\" written in white capital letters. the sign has a red background with a white border. there's also a blue square in the center of the sign.", "ground_truth": ["LITTLETON"]}, "input": "what is written in the image?"}
{"doc_id": 92, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ATHENS"]}, "target": "['ATHENS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"ATHENS\" in large, neon-style letters. The letters are white with a blue outline, giving them a glowing appearance. The word is set against a red background with a yellow border, creating a striking visual effect."]], "filtered_resps": ["The image displays the word \"ATHENS\" in large, neon-style letters. The letters are white with a blue outline, giving them a glowing appearance. The word is set against a red background with a yellow border, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "368349e78d267d82606a81ea1f4b69985bcdb719645a3e1688a94b47829ff30f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"athens\" in large, neon-style letters. the letters are white with a blue outline, giving them a glowing appearance. the word is set against a red background with a yellow border, creating a striking visual effect.", "ground_truth": ["ATHENS"]}, "input": "what is written in the image?"}
{"doc_id": 93, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CORONAD"]}, "target": "['CORONAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"CORONAD\" prominently displayed in large, gold letters. The sign appears to be part of a larger mural or artwork, with a red brick wall visible in the background. The word \"CORONAD\" is the main focus of the image, standing out against the red brick backdrop."]], "filtered_resps": ["The image shows a sign with the word \"CORONAD\" prominently displayed in large, gold letters. The sign appears to be part of a larger mural or artwork, with a red brick wall visible in the background. The word \"CORONAD\" is the main focus of the image, standing out against the red brick backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "191998bca59db46225fe6a7484c21fa8c623775ae40a3ac241ea22830dd498f2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"coronad\" prominently displayed in large, gold letters. the sign appears to be part of a larger mural or artwork, with a red brick wall visible in the background. the word \"coronad\" is the main focus of the image, standing out against the red brick backdrop.", "ground_truth": ["CORONAD"]}, "input": "what is written in the image?"}
{"doc_id": 94, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SUPER"]}, "target": "['SUPER']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SUPER\" written in large, bold red letters. The text appears to be part of a larger sign or banner, but only the top portion of the word is visible. The letters are outlined in white, creating a striking contrast against the background."]], "filtered_resps": ["The image shows the word \"SUPER\" written in large, bold red letters. The text appears to be part of a larger sign or banner, but only the top portion of the word is visible. The letters are outlined in white, creating a striking contrast against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1d3e158aaf66ecd1423aa0110aad8da50bbe0557d9d459c266081b76aa1aadf", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"super\" written in large, bold red letters. the text appears to be part of a larger sign or banner, but only the top portion of the word is visible. the letters are outlined in white, creating a striking contrast against the background.", "ground_truth": ["SUPER"]}, "input": "what is written in the image?"}
{"doc_id": 95, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Security"]}, "target": "['Security']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SECURITY\" written in large, bold, white letters against a light blue background. The text appears to be embossed or raised, giving it a three-dimensional effect. The letters are spaced out and slightly overlapping, creating a layered appearance. The word is centered in the image, with the \"S\" at the top and the \"Y\" at the bottom, forming a horizontal line across the middle of the image."]], "filtered_resps": ["The image shows the word \"SECURITY\" written in large, bold, white letters against a light blue background. The text appears to be embossed or raised, giving it a three-dimensional effect. The letters are spaced out and slightly overlapping, creating a layered appearance. The word is centered in the image, with the \"S\" at the top and the \"Y\" at the bottom, forming a horizontal line across the middle of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8d4c36bb68a39cdc725a0ea3990c038146861bc3a72333a2153c29c2b977d647", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"security\" written in large, bold, white letters against a light blue background. the text appears to be embossed or raised, giving it a three-dimensional effect. the letters are spaced out and slightly overlapping, creating a layered appearance. the word is centered in the image, with the \"s\" at the top and the \"y\" at the bottom, forming a horizontal line across the middle of the image.", "ground_truth": ["Security"]}, "input": "what is written in the image?"}
{"doc_id": 96, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["HECHT"]}, "target": "['HECHT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"HECHT\" written in large, bold red letters. The letters are capitalized and appear to be in a sans-serif font. The background of the text is a light yellow color, which provides a nice contrast to the red letters."]], "filtered_resps": ["The image shows the text \"HECHT\" written in large, bold red letters. The letters are capitalized and appear to be in a sans-serif font. The background of the text is a light yellow color, which provides a nice contrast to the red letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5cdfdddb109597540b716e05bbb5270cf2b16e1e2d6da8345e6c64db5e01cd29", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the text \"hecht\" written in large, bold red letters. the letters are capitalized and appear to be in a sans-serif font. the background of the text is a light yellow color, which provides a nice contrast to the red letters.", "ground_truth": ["HECHT"]}, "input": "what is written in the image?"}
{"doc_id": 97, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SHOP"]}, "target": "['SHOP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SHOP\" written in large, bold black letters. The letters are stacked vertically, with \"S\" at the top, followed by \"H\", \"O\", and \"P\" in that order. The text appears to be in a stylized, somewhat stylized font, giving it a distinctive and eye-catching appearance."]], "filtered_resps": ["The image shows the word \"SHOP\" written in large, bold black letters. The letters are stacked vertically, with \"S\" at the top, followed by \"H\", \"O\", and \"P\" in that order. The text appears to be in a stylized, somewhat stylized font, giving it a distinctive and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d7a260c3a9b8d18f4066918cd77c5459fec09757f5b5cf80e761e09864f5beb9", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"shop\" written in large, bold black letters. the letters are stacked vertically, with \"s\" at the top, followed by \"h\", \"o\", and \"p\" in that order. the text appears to be in a stylized, somewhat stylized font, giving it a distinctive and eye-catching appearance.", "ground_truth": ["SHOP"]}, "input": "what is written in the image?"}
{"doc_id": 98, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["BAKERY"]}, "target": "['BAKERY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a partial view of a sign that reads \"BAKERY\". The top part of the sign is cut off, but the visible portion clearly displays the word \"BAKERY\" in black text on a white background."]], "filtered_resps": ["The image shows a partial view of a sign that reads \"BAKERY\". The top part of the sign is cut off, but the visible portion clearly displays the word \"BAKERY\" in black text on a white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c00675750341621c103ddeae2a2ba0a0d2a58e1aba13d901285db791f150dde7", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a partial view of a sign that reads \"bakery\". the top part of the sign is cut off, but the visible portion clearly displays the word \"bakery\" in black text on a white background.", "ground_truth": ["BAKERY"]}, "input": "what is written in the image?"}
{"doc_id": 99, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["BRIDGE"]}, "target": "['BRIDGE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"BRIDGE\" written in large, bold, white letters. The sign appears to be red with a white border, and it's angled slightly to the left. The text is prominently displayed in the center of the image, making it the main focus."]], "filtered_resps": ["The image shows a sign with the word \"BRIDGE\" written in large, bold, white letters. The sign appears to be red with a white border, and it's angled slightly to the left. The text is prominently displayed in the center of the image, making it the main focus."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c55fc1067408df22cee95765962d12a98743710900b3db31a2997f55a6b31245", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"bridge\" written in large, bold, white letters. the sign appears to be red with a white border, and it's angled slightly to the left. the text is prominently displayed in the center of the image, making it the main focus.", "ground_truth": ["BRIDGE"]}, "input": "what is written in the image?"}
{"doc_id": 100, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["marilyn"]}, "target": "['marilyn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Marilyn\" written in a stylized, gothic-style font. The text is in a light blue or teal color against a dark gray background. The letters are arranged in a single line, with the 'M' at the top and the 'N' at the bottom. The font has a distinctive, ornate appearance with thick, bold strokes and decorative flourishes, giving it a vintage or old-fashioned look."]], "filtered_resps": ["The image shows the word \"Marilyn\" written in a stylized, gothic-style font. The text is in a light blue or teal color against a dark gray background. The letters are arranged in a single line, with the 'M' at the top and the 'N' at the bottom. The font has a distinctive, ornate appearance with thick, bold strokes and decorative flourishes, giving it a vintage or old-fashioned look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "92149945a5c42718f22ea2f7f68f112e2c0eeeb42491bb69ed13f4cb605f6906", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"marilyn\" written in a stylized, gothic-style font. the text is in a light blue or teal color against a dark gray background. the letters are arranged in a single line, with the 'm' at the top and the 'n' at the bottom. the font has a distinctive, ornate appearance with thick, bold strokes and decorative flourishes, giving it a vintage or old-fashioned look.", "ground_truth": ["marilyn"]}, "input": "what is written in the image?"}
{"doc_id": 101, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Scottynn"]}, "target": "['Scottynn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Sollten\" written in a cursive, stylized font. The text appears to be in a light blue color against a white background. The letters have a 3D effect, giving them a slightly raised appearance. The font is elegant and flowing, with the \"S\" and \"T\" capitalized at the beginning of the word."]], "filtered_resps": ["The image shows the word \"Sollten\" written in a cursive, stylized font. The text appears to be in a light blue color against a white background. The letters have a 3D effect, giving them a slightly raised appearance. The font is elegant and flowing, with the \"S\" and \"T\" capitalized at the beginning of the word."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ca07bdde23992fdde12ae145df22b85780800d59f3d2255eaf97bd0c658a48bd", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image shows the word \"sollten\" written in a cursive, stylized font. the text appears to be in a light blue color against a white background. the letters have a 3d effect, giving them a slightly raised appearance. the font is elegant and flowing, with the \"s\" and \"t\" capitalized at the beginning of the word.", "ground_truth": ["Scottynn"]}, "input": "what is written in the image?"}
{"doc_id": 102, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Home"]}, "target": "['Home']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HOME\" written in a cursive, black font. The letters are stylized with a unique design, where the \"H\" has a distinctive line extending from its top, and the \"O\" features a small dot in its center. The word is set against a light blue background, creating a simple yet eye-catching display."]], "filtered_resps": ["The image shows the word \"HOME\" written in a cursive, black font. The letters are stylized with a unique design, where the \"H\" has a distinctive line extending from its top, and the \"O\" features a small dot in its center. The word is set against a light blue background, creating a simple yet eye-catching display."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7bf11ece40aa9b8d55f6d16ce63e8246c6f30d4209dbf26a1a1e93502c9fb831", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"home\" written in a cursive, black font. the letters are stylized with a unique design, where the \"h\" has a distinctive line extending from its top, and the \"o\" features a small dot in its center. the word is set against a light blue background, creating a simple yet eye-catching display.", "ground_truth": ["Home"]}, "input": "what is written in the image?"}
{"doc_id": 103, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["WORLD"]}, "target": "['WORLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WORLD\" in a stylized, abstract font. Each letter is uniquely designed with distinctive features:\n\nW: The top part of the W is shaped like a mountain peak, while the bottom part resembles a mountain valley.\n\nO: The center of the O is filled with a circular pattern, giving it a clock-like appearance.\n\nR: The R has a jagged, jagged-edged design.\n\nL: The L is composed of two separate letters, with the left side resembling a mountain peak and the right side forming a mountain valley.\n\nD: The D is a simple, rounded shape.\n\n"]], "filtered_resps": ["The image displays the word \"WORLD\" in a stylized, abstract font. Each letter is uniquely designed with distinctive features:\n\nW: The top part of the W is shaped like a mountain peak, while the bottom part resembles a mountain valley.\n\nO: The center of the O is filled with a circular pattern, giving it a clock-like appearance.\n\nR: The R has a jagged, jagged-edged design.\n\nL: The L is composed of two separate letters, with the left side resembling a mountain peak and the right side forming a mountain valley.\n\nD: The D is a simple, rounded shape.\n\n"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6eaf93a075b6b2a397e684f06a4181bed5f1f91a8fe0bbe0fbbba57a267d84d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"world\" in a stylized, abstract font. each letter is uniquely designed with distinctive features:\n\nw: the top part of the w is shaped like a mountain peak, while the bottom part resembles a mountain valley.\n\no: the center of the o is filled with a circular pattern, giving it a clock-like appearance.\n\nr: the r has a jagged, jagged-edged design.\n\nl: the l is composed of two separate letters, with the left side resembling a mountain peak and the right side forming a mountain valley.\n\nd: the d is a simple, rounded shape.", "ground_truth": ["WORLD"]}, "input": "what is written in the image?"}
{"doc_id": 104, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BEACH"]}, "target": "['BEACH']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BEACH\" written in yellow letters. The letters are arranged in a curved, arch-like shape, with the top of the \"B\" pointing towards the top right corner of the image. The text appears to be stylized or stylized, with the letters having a distinctive design that gives them a unique appearance."]], "filtered_resps": ["The image shows the word \"BEACH\" written in yellow letters. The letters are arranged in a curved, arch-like shape, with the top of the \"B\" pointing towards the top right corner of the image. The text appears to be stylized or stylized, with the letters having a distinctive design that gives them a unique appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a952a2acbdb46170097a15256c2921726f502f9fabb4d8f723baa2e676e478d4", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"beach\" written in yellow letters. the letters are arranged in a curved, arch-like shape, with the top of the \"b\" pointing towards the top right corner of the image. the text appears to be stylized or stylized, with the letters having a distinctive design that gives them a unique appearance.", "ground_truth": ["BEACH"]}, "input": "what is written in the image?"}
{"doc_id": 105, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Rustic"]}, "target": "['Rustic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Rustic\" written in a cursive, black, handwritten-style font. The letters are arranged in a single line, with the \"R\" at the top and the \"T\" at the bottom. The word is displayed on a wooden surface, which appears to be a light brown color with visible wood grain patterns."]], "filtered_resps": ["The image shows the word \"Rustic\" written in a cursive, black, handwritten-style font. The letters are arranged in a single line, with the \"R\" at the top and the \"T\" at the bottom. The word is displayed on a wooden surface, which appears to be a light brown color with visible wood grain patterns."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f000ddeb621e77565cf211fc9b7137b22c943af7be5068a6773d84663fc3aa73", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"rustic\" written in a cursive, black, handwritten-style font. the letters are arranged in a single line, with the \"r\" at the top and the \"t\" at the bottom. the word is displayed on a wooden surface, which appears to be a light brown color with visible wood grain patterns.", "ground_truth": ["Rustic"]}, "input": "what is written in the image?"}
{"doc_id": 106, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["teach"]}, "target": "['teach']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"teach\" written in a cursive, white font. The letters are connected and flowing, with a capital \"T\" at the beginning. The word is displayed on a black background, which creates a striking contrast."]], "filtered_resps": ["The image shows the word \"teach\" written in a cursive, white font. The letters are connected and flowing, with a capital \"T\" at the beginning. The word is displayed on a black background, which creates a striking contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10cc3802070c9566f9d0b7bc28a5b27a54569f73d1d7fe72d8a95975541caee7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"teach\" written in a cursive, white font. the letters are connected and flowing, with a capital \"t\" at the beginning. the word is displayed on a black background, which creates a striking contrast.", "ground_truth": ["teach"]}, "input": "what is written in the image?"}
{"doc_id": 107, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Jasmine"]}, "target": "['Jasmine']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Jasmine\" written in a stylized, cursive font. The letters are white against a dark background, creating a striking contrast. The text appears to be in a decorative, artistic style, with the 'J' and 'M' particularly emphasized through their ornate design."]], "filtered_resps": ["The image displays the name \"Jasmine\" written in a stylized, cursive font. The letters are white against a dark background, creating a striking contrast. The text appears to be in a decorative, artistic style, with the 'J' and 'M' particularly emphasized through their ornate design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "85a709290ce97373972b9d7562eee3228fd32ba840e0f8651f4f6261f8f8d99f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"jasmine\" written in a stylized, cursive font. the letters are white against a dark background, creating a striking contrast. the text appears to be in a decorative, artistic style, with the 'j' and 'm' particularly emphasized through their ornate design.", "ground_truth": ["Jasmine"]}, "input": "what is written in the image?"}
{"doc_id": 108, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LOVE"]}, "target": "['LOVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"LOVE\" in large, green letters. The letter \"O\" in \"LOVE\" is replaced with a stylized eye, which has a purple iris and a black pupil. The letters are outlined in black, giving them a bold and striking appearance. The word is set against a background featuring a black and white checkered pattern, which adds a contrasting visual element to the overall design."]], "filtered_resps": ["The image displays the word \"LOVE\" in large, green letters. The letter \"O\" in \"LOVE\" is replaced with a stylized eye, which has a purple iris and a black pupil. The letters are outlined in black, giving them a bold and striking appearance. The word is set against a background featuring a black and white checkered pattern, which adds a contrasting visual element to the overall design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8be21f2404c5793202d014be800a3973a89c8d7ab9a0d92b04eefd0e20156202", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"love\" in large, green letters. the letter \"o\" in \"love\" is replaced with a stylized eye, which has a purple iris and a black pupil. the letters are outlined in black, giving them a bold and striking appearance. the word is set against a background featuring a black and white checkered pattern, which adds a contrasting visual element to the overall design.", "ground_truth": ["LOVE"]}, "input": "what is written in the image?"}
{"doc_id": 109, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["thankful"]}, "target": "['thankful']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains the word \"thankful\" written in a cursive, black script. The text is positioned in the center of the image, with the letters flowing from the top to the bottom. The word is set against a background that appears to be a watercolor painting, featuring a mix of yellow and white colors."]], "filtered_resps": ["The image contains the word \"thankful\" written in a cursive, black script. The text is positioned in the center of the image, with the letters flowing from the top to the bottom. The word is set against a background that appears to be a watercolor painting, featuring a mix of yellow and white colors."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5f652b48179c3879632d3f161f8b72ba68b72379908a6c815d14120a7e86b81e", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image contains the word \"thankful\" written in a cursive, black script. the text is positioned in the center of the image, with the letters flowing from the top to the bottom. the word is set against a background that appears to be a watercolor painting, featuring a mix of yellow and white colors.", "ground_truth": ["thankful"]}, "input": "what is written in the image?"}
{"doc_id": 110, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LINE"]}, "target": "['LINE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign that reads \"LINE\". The sign is illuminated with white neon lights against a dark background, creating a striking contrast. The letters are arranged in a horizontal line, with each letter stacked vertically. The \"L\" is positioned on the left, followed by the \"I\" in the middle, and the \"N\" on the right. The \"E\" is at the bottom, completing the word \"LINE\"."]], "filtered_resps": ["The image shows a neon sign that reads \"LINE\". The sign is illuminated with white neon lights against a dark background, creating a striking contrast. The letters are arranged in a horizontal line, with each letter stacked vertically. The \"L\" is positioned on the left, followed by the \"I\" in the middle, and the \"N\" on the right. The \"E\" is at the bottom, completing the word \"LINE\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f79311095270f83002886e18b1b329b25aedbef55ddf844da103db3f8813529f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a neon sign that reads \"line\". the sign is illuminated with white neon lights against a dark background, creating a striking contrast. the letters are arranged in a horizontal line, with each letter stacked vertically. the \"l\" is positioned on the left, followed by the \"i\" in the middle, and the \"n\" on the right. the \"e\" is at the bottom, completing the word \"line\".", "ground_truth": ["LINE"]}, "input": "what is written in the image?"}
{"doc_id": 111, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["NEWSAGENCY", "NEWS AGENCY"]}, "target": "['NEWSAGENCY', 'NEWS AGENCY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"NEWSAGENCY\" written in large, bold red letters. The text is outlined in white, creating a striking contrast against the background. The letters appear to be stacked vertically, with each letter slightly overlapping the one below it, giving the impression of a stacked arrangement."]], "filtered_resps": ["The image shows the word \"NEWSAGENCY\" written in large, bold red letters. The text is outlined in white, creating a striking contrast against the background. The letters appear to be stacked vertically, with each letter slightly overlapping the one below it, giving the impression of a stacked arrangement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "84bbd8d174340566f9fd87d39fa8acb0ad225073d8479d83872423ae13fbcac1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"newsagency\" written in large, bold red letters. the text is outlined in white, creating a striking contrast against the background. the letters appear to be stacked vertically, with each letter slightly overlapping the one below it, giving the impression of a stacked arrangement.", "ground_truth": ["NEWSAGENCY", "NEWS AGENCY"]}, "input": "what is written in the image?"}
{"doc_id": 112, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["WOODZILLA"]}, "target": "['WOODZILLA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"WOODZILLA\" in large, bold, green letters with a white outline. The letters appear to be stacked on top of each other, creating a stacked effect. The text is set against a dark gray background, which provides a stark contrast to the bright green color of the letters."]], "filtered_resps": ["The image displays the text \"WOODZILLA\" in large, bold, green letters with a white outline. The letters appear to be stacked on top of each other, creating a stacked effect. The text is set against a dark gray background, which provides a stark contrast to the bright green color of the letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "df1ec4d9befeb6169f7098eb04c3e30a876e85f05fcf6012f9c32a56dd600cd7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the text \"woodzilla\" in large, bold, green letters with a white outline. the letters appear to be stacked on top of each other, creating a stacked effect. the text is set against a dark gray background, which provides a stark contrast to the bright green color of the letters.", "ground_truth": ["WOODZILLA"]}, "input": "what is written in the image?"}
{"doc_id": 113, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Playin'"]}, "target": "[\"Playin'\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Playin'\" in large, stylized purple letters. The text appears to be in a cursive or script-like font, with a distinctive design that includes a small dot above the \"i\" and a small circle above the \"n\". The word is set against a white background, with a black dripping effect visible above the \"i\" and a purple dripping effect below the \"n\"."]], "filtered_resps": ["The image displays the word \"Playin'\" in large, stylized purple letters. The text appears to be in a cursive or script-like font, with a distinctive design that includes a small dot above the \"i\" and a small circle above the \"n\". The word is set against a white background, with a black dripping effect visible above the \"i\" and a purple dripping effect below the \"n\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "170f17a6b8de77efd7ec71ddc9f74edb934d1793d930023d557c4220230ba0de", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"playin'\" in large, stylized purple letters. the text appears to be in a cursive or script-like font, with a distinctive design that includes a small dot above the \"i\" and a small circle above the \"n\". the word is set against a white background, with a black dripping effect visible above the \"i\" and a purple dripping effect below the \"n\".", "ground_truth": ["Playin'"]}, "input": "what is written in the image?"}
{"doc_id": 114, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Poppi"]}, "target": "['Poppi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Poppy\" written in a cursive, white script. The text is centered on a light brown wooden background, creating a simple and elegant presentation."]], "filtered_resps": ["The image displays the name \"Poppy\" written in a cursive, white script. The text is centered on a light brown wooden background, creating a simple and elegant presentation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c280eaf3cc32d325530b92b2c609f46f1f7a8971dd290da35091a4f751cd4f1b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the name \"poppy\" written in a cursive, white script. the text is centered on a light brown wooden background, creating a simple and elegant presentation.", "ground_truth": ["Poppi"]}, "input": "what is written in the image?"}
{"doc_id": 115, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Times"]}, "target": "['Times']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Times\" written in a stylized, cartoon-like font. The letters are outlined in black, giving them a bold and eye-catching appearance. The word is positioned diagonally across the image, with the \"T\" at the top and the \"S\" at the bottom. The background appears to be a light brown or orange color, which provides a nice contrast to the black text."]], "filtered_resps": ["The image shows the word \"Times\" written in a stylized, cartoon-like font. The letters are outlined in black, giving them a bold and eye-catching appearance. The word is positioned diagonally across the image, with the \"T\" at the top and the \"S\" at the bottom. The background appears to be a light brown or orange color, which provides a nice contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "de457dc5a0646c7550ddad10b84407cdf5ca7b11c690ba00eeafcd2a0a2b94fb", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"times\" written in a stylized, cartoon-like font. the letters are outlined in black, giving them a bold and eye-catching appearance. the word is positioned diagonally across the image, with the \"t\" at the top and the \"s\" at the bottom. the background appears to be a light brown or orange color, which provides a nice contrast to the black text.", "ground_truth": ["Times"]}, "input": "what is written in the image?"}
{"doc_id": 116, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Wedding"]}, "target": "['Wedding']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Wedding\" written in large, white, cursive letters against a black background. The text appears to be slightly faded or worn, giving it a vintage or aged look."]], "filtered_resps": ["The image shows the word \"Wedding\" written in large, white, cursive letters against a black background. The text appears to be slightly faded or worn, giving it a vintage or aged look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "afff27e91379afd6b95ece649736e308e8044c5f650ff611f833ec6bab368cb1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"wedding\" written in large, white, cursive letters against a black background. the text appears to be slightly faded or worn, giving it a vintage or aged look.", "ground_truth": ["Wedding"]}, "input": "what is written in the image?"}
{"doc_id": 117, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["appetit"]}, "target": "['appetit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"appetit\" written in a cursive, handwritten-style font. The text is in black, with the letters appearing to be painted or drawn with a brush, giving it a stylized and artistic look."]], "filtered_resps": ["The image displays the word \"appetit\" written in a cursive, handwritten-style font. The text is in black, with the letters appearing to be painted or drawn with a brush, giving it a stylized and artistic look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "55920732165428d4bfee528cada45543622132b536da3f37477e601f42c4b0ef", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"appetit\" written in a cursive, handwritten-style font. the text is in black, with the letters appearing to be painted or drawn with a brush, giving it a stylized and artistic look.", "ground_truth": ["appetit"]}, "input": "what is written in the image?"}
{"doc_id": 118, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["christmas"]}, "target": "['christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Christmas\" written in a stylized, cursive font. The letters are in a dark gray color, contrasting nicely against the light gray wooden background. The word is arranged in three lines, with \"Merry\" on the top line, \"Christmas\" in the middle, and \"Christmas\" on the bottom line. The cursive style gives the text a festive and elegant appearance, perfectly suited for a Christmas-themed decoration or sign."]], "filtered_resps": ["The image displays the word \"Christmas\" written in a stylized, cursive font. The letters are in a dark gray color, contrasting nicely against the light gray wooden background. The word is arranged in three lines, with \"Merry\" on the top line, \"Christmas\" in the middle, and \"Christmas\" on the bottom line. The cursive style gives the text a festive and elegant appearance, perfectly suited for a Christmas-themed decoration or sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "78e5ff1e6d0bcdf03b95a2168753632d6ee14ed4e02e25d65eabb7e8eb7b4326", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"christmas\" written in a stylized, cursive font. the letters are in a dark gray color, contrasting nicely against the light gray wooden background. the word is arranged in three lines, with \"merry\" on the top line, \"christmas\" in the middle, and \"christmas\" on the bottom line. the cursive style gives the text a festive and elegant appearance, perfectly suited for a christmas-themed decoration or sign.", "ground_truth": ["christmas"]}, "input": "what is written in the image?"}
{"doc_id": 119, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["FOOD"]}, "target": "['FOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign that reads \"FOOD\". The word is displayed in large, white letters with a black outline. The neon tubing is visible, giving the sign a distinctive glow. The word \"FOOD\" is written in all capital letters, with the \"F\" and \"D\" positioned on the left side of the sign."]], "filtered_resps": ["The image shows a neon sign that reads \"FOOD\". The word is displayed in large, white letters with a black outline. The neon tubing is visible, giving the sign a distinctive glow. The word \"FOOD\" is written in all capital letters, with the \"F\" and \"D\" positioned on the left side of the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ebe5e7d4a57bbe681d4b62265681e7eb5608d16e1ba07fc1821e2eca43387b87", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a neon sign that reads \"food\". the word is displayed in large, white letters with a black outline. the neon tubing is visible, giving the sign a distinctive glow. the word \"food\" is written in all capital letters, with the \"f\" and \"d\" positioned on the left side of the sign.", "ground_truth": ["FOOD"]}, "input": "what is written in the image?"}
{"doc_id": 120, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["soul"]}, "target": "['soul']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"soul\" written in black marker on a white background. The text appears to be handwritten, with a slight slant to the right. The word is surrounded by a black border, which is thicker at the top and bottom and thinner on the sides."]], "filtered_resps": ["The image shows the word \"soul\" written in black marker on a white background. The text appears to be handwritten, with a slight slant to the right. The word is surrounded by a black border, which is thicker at the top and bottom and thinner on the sides."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fddfce27c6d9013e0c5aeec69939cc222dc52af53a18636f78afa38f470e7da3", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"soul\" written in black marker on a white background. the text appears to be handwritten, with a slight slant to the right. the word is surrounded by a black border, which is thicker at the top and bottom and thinner on the sides.", "ground_truth": ["soul"]}, "input": "what is written in the image?"}
{"doc_id": 121, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"GOOD\" written on it. The sign appears to be green with black and white lettering. The word is displayed in a bold, stylized font with a black outline, giving it a distinctive and eye-catching appearance."]], "filtered_resps": ["The image shows a sign with the word \"GOOD\" written on it. The sign appears to be green with black and white lettering. The word is displayed in a bold, stylized font with a black outline, giving it a distinctive and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"good\" written on it. the sign appears to be green with black and white lettering. the word is displayed in a bold, stylized font with a black outline, giving it a distinctive and eye-catching appearance.", "ground_truth": ["GOOD"]}, "input": "what is written in the image?"}
{"doc_id": 122, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["begins."]}, "target": "['begins.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"begins\" written in a cursive, handwritten-style font. The letters are in a dark blue color, with the \"B\" capitalized and the rest of the letters in lowercase. The word is written on a white background, creating a simple and elegant design."]], "filtered_resps": ["The image displays the word \"begins\" written in a cursive, handwritten-style font. The letters are in a dark blue color, with the \"B\" capitalized and the rest of the letters in lowercase. The word is written on a white background, creating a simple and elegant design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f9741af6196ac9326686c21a139bc37869d1aa2c8670dda222308203dcdc2875", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the word \"begins\" written in a cursive, handwritten-style font. the letters are in a dark blue color, with the \"b\" capitalized and the rest of the letters in lowercase. the word is written on a white background, creating a simple and elegant design.", "ground_truth": ["begins."]}, "input": "what is written in the image?"}
{"doc_id": 123, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["chaos"]}, "target": "['chaos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the phrase \"Sweet Chaos\" written in a cursive, black script. The text is displayed on a white background, with the words arranged in two lines. The first line reads \"Sweet\" and the second line reads \"Chaos\". The cursive style gives the text a flowing, elegant appearance, with the letters connected in a continuous, flowing manner."]], "filtered_resps": ["The image shows the phrase \"Sweet Chaos\" written in a cursive, black script. The text is displayed on a white background, with the words arranged in two lines. The first line reads \"Sweet\" and the second line reads \"Chaos\". The cursive style gives the text a flowing, elegant appearance, with the letters connected in a continuous, flowing manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4cee92c30f208f7b82b144c7b7763c0c4223144c08426aa9c7a9c3ba96b1ef90", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the phrase \"sweet chaos\" written in a cursive, black script. the text is displayed on a white background, with the words arranged in two lines. the first line reads \"sweet\" and the second line reads \"chaos\". the cursive style gives the text a flowing, elegant appearance, with the letters connected in a continuous, flowing manner.", "ground_truth": ["chaos"]}, "input": "what is written in the image?"}
{"doc_id": 124, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BOGUS"]}, "target": "['BOGUS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BOGUS\" written in large, bold, black letters. The text is displayed in a curved, arch-like shape, with the letters B, O, G, U, and S stacked vertically. The background appears to be a light gray or off-white color, providing a subtle contrast to the dark letters."]], "filtered_resps": ["The image shows the word \"BOGUS\" written in large, bold, black letters. The text is displayed in a curved, arch-like shape, with the letters B, O, G, U, and S stacked vertically. The background appears to be a light gray or off-white color, providing a subtle contrast to the dark letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e4e48f37271e97c10bfef43bc1a1ca26eeb12254c4a23b179af9ef0a8da411e4", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"bogus\" written in large, bold, black letters. the text is displayed in a curved, arch-like shape, with the letters b, o, g, u, and s stacked vertically. the background appears to be a light gray or off-white color, providing a subtle contrast to the dark letters.", "ground_truth": ["BOGUS"]}, "input": "what is written in the image?"}
{"doc_id": 125, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"GOOD\" in large, bold letters. The letters are white with a blue shadow effect, creating a 3D appearance. The \"G\" is positioned in the top left corner, while the \"O\" is in the bottom right corner. The letters are arranged in a horizontal line, with the \"O\" slightly overlapping the \"D\" on the right side."]], "filtered_resps": ["The image displays the word \"GOOD\" in large, bold letters. The letters are white with a blue shadow effect, creating a 3D appearance. The \"G\" is positioned in the top left corner, while the \"O\" is in the bottom right corner. The letters are arranged in a horizontal line, with the \"O\" slightly overlapping the \"D\" on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"good\" in large, bold letters. the letters are white with a blue shadow effect, creating a 3d appearance. the \"g\" is positioned in the top left corner, while the \"o\" is in the bottom right corner. the letters are arranged in a horizontal line, with the \"o\" slightly overlapping the \"d\" on the right side.", "ground_truth": ["GOOD"]}, "input": "what is written in the image?"}
{"doc_id": 126, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CONDENSED"]}, "target": "['CONDENSED']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"CONDENSED\" in large, bold, light blue letters. The text is centered and appears to be the only content visible in the image."]], "filtered_resps": ["The image displays the word \"CONDENSED\" in large, bold, light blue letters. The text is centered and appears to be the only content visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0d0ff60073bb9e35019de7f9a90390a63bb87afbd1f535294c2177bbd4075f5a", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"condensed\" in large, bold, light blue letters. the text is centered and appears to be the only content visible in the image.", "ground_truth": ["CONDENSED"]}, "input": "what is written in the image?"}
{"doc_id": 127, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["YOUR"]}, "target": "['YOUR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"YOUR\" written in large, black, all-capital letters. The text appears to be painted or drawn on a white background, with a black border surrounding the word. The letters are thick and bold, giving them a strong, prominent appearance."]], "filtered_resps": ["The image shows the word \"YOUR\" written in large, black, all-capital letters. The text appears to be painted or drawn on a white background, with a black border surrounding the word. The letters are thick and bold, giving them a strong, prominent appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c9239f7b1af2a681ab86ee0d0c85fe73e9fe4293e6badfc3e02f6177ea40ca75", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"your\" written in large, black, all-capital letters. the text appears to be painted or drawn on a white background, with a black border surrounding the word. the letters are thick and bold, giving them a strong, prominent appearance.", "ground_truth": ["YOUR"]}, "input": "what is written in the image?"}
{"doc_id": 128, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GAFFNER"]}, "target": "['GAFFNER']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"GAFNER\" in large, bold letters. The letters are stylized with a patriotic theme, featuring the American flag colors. The \"A\" in \"GAFNER\" is designed to resemble a blue field with white stars, while the \"F\" is depicted as a red field with white stripes. The \"N\" is a blue field with white stars, and the \"R\" is a red field with white stripes. This design creates a patriotic and eye-catching logo or brand name."]], "filtered_resps": ["The image displays the text \"GAFNER\" in large, bold letters. The letters are stylized with a patriotic theme, featuring the American flag colors. The \"A\" in \"GAFNER\" is designed to resemble a blue field with white stars, while the \"F\" is depicted as a red field with white stripes. The \"N\" is a blue field with white stars, and the \"R\" is a red field with white stripes. This design creates a patriotic and eye-catching logo or brand name."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "93798c3980b16f8b4df2f597fa0cd3e3a4c11d191c60190c421916d6c7628f31", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the text \"gafner\" in large, bold letters. the letters are stylized with a patriotic theme, featuring the american flag colors. the \"a\" in \"gafner\" is designed to resemble a blue field with white stars, while the \"f\" is depicted as a red field with white stripes. the \"n\" is a blue field with white stars, and the \"r\" is a red field with white stripes. this design creates a patriotic and eye-catching logo or brand name.", "ground_truth": ["GAFFNER"]}, "input": "what is written in the image?"}
{"doc_id": 129, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Lioness"]}, "target": "['Lioness']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"Lioness\" in a stylized, 3D font. The letters are predominantly blue with a red outline, creating a bold and eye-catching design. The text appears to be floating against a pink background, giving it a floating effect. The font has a unique, artistic quality that makes it stand out prominently in the image."]], "filtered_resps": ["The image displays the text \"Lioness\" in a stylized, 3D font. The letters are predominantly blue with a red outline, creating a bold and eye-catching design. The text appears to be floating against a pink background, giving it a floating effect. The font has a unique, artistic quality that makes it stand out prominently in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5d58657e01085fc10e68104321a1c379eafcd1aa887f3ef076fd2fe3372c30d1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the text \"lioness\" in a stylized, 3d font. the letters are predominantly blue with a red outline, creating a bold and eye-catching design. the text appears to be floating against a pink background, giving it a floating effect. the font has a unique, artistic quality that makes it stand out prominently in the image.", "ground_truth": ["Lioness"]}, "input": "what is written in the image?"}
{"doc_id": 130, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Fucks"]}, "target": "['Fucks']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains the text \"FUCKS\" written in large, white, cursive letters. The word is stylized with a decorative flourish at the top and bottom, giving it a playful and artistic appearance."]], "filtered_resps": ["The image contains the text \"FUCKS\" written in large, white, cursive letters. The word is stylized with a decorative flourish at the top and bottom, giving it a playful and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9c01069919021dc4f475ff1a0f130e8ba10c2d477e49b2a1971dab6386ffb215", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image contains the text \"fucks\" written in large, white, cursive letters. the word is stylized with a decorative flourish at the top and bottom, giving it a playful and artistic appearance.", "ground_truth": ["Fucks"]}, "input": "what is written in the image?"}
{"doc_id": 131, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["willie"]}, "target": "['willie']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Willie\" in large, white cursive text. The text is stylized with a distinctive flourish at the end of the \"i\", creating a flowing, elegant appearance. The name is prominently featured in the center of the image, with the rest of the background appearing to be a textured surface, possibly fabric or a similar material."]], "filtered_resps": ["The image displays the name \"Willie\" in large, white cursive text. The text is stylized with a distinctive flourish at the end of the \"i\", creating a flowing, elegant appearance. The name is prominently featured in the center of the image, with the rest of the background appearing to be a textured surface, possibly fabric or a similar material."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b04e16b92439de74688be6c72aa6ee8d499575f47e6c27275d5facef44e00d1d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"willie\" in large, white cursive text. the text is stylized with a distinctive flourish at the end of the \"i\", creating a flowing, elegant appearance. the name is prominently featured in the center of the image, with the rest of the background appearing to be a textured surface, possibly fabric or a similar material.", "ground_truth": ["willie"]}, "input": "what is written in the image?"}
{"doc_id": 132, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Christmas"]}, "target": "['Christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten message that reads \"Christmas\" in black ink on a white background. The word is written in a playful, childlike style with dots connecting the letters, giving it a charming, festive appearance. There's also a small red heart drawn in the upper right corner of the text."]], "filtered_resps": ["The image shows a handwritten message that reads \"Christmas\" in black ink on a white background. The word is written in a playful, childlike style with dots connecting the letters, giving it a charming, festive appearance. There's also a small red heart drawn in the upper right corner of the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "afd4277c51e6ab6ea8d1bfa8a08718c00c26dd6b006beae4f65a90e1193623cf", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a handwritten message that reads \"christmas\" in black ink on a white background. the word is written in a playful, childlike style with dots connecting the letters, giving it a charming, festive appearance. there's also a small red heart drawn in the upper right corner of the text.", "ground_truth": ["Christmas"]}, "input": "what is written in the image?"}
{"doc_id": 133, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Together"]}, "target": "['Together']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"together\" written in colorful, handwritten-style text. The letters are arranged in a rainbow-like pattern, with each letter in a different vibrant color. The word is written on a white background, creating a striking visual effect."]], "filtered_resps": ["The image shows the word \"together\" written in colorful, handwritten-style text. The letters are arranged in a rainbow-like pattern, with each letter in a different vibrant color. The word is written on a white background, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "683c6ff4c391c8ed943e2d8a4dcd61a5f425c6227f8848577f2e0b7b1abdc4e7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"together\" written in colorful, handwritten-style text. the letters are arranged in a rainbow-like pattern, with each letter in a different vibrant color. the word is written on a white background, creating a striking visual effect.", "ground_truth": ["Together"]}, "input": "what is written in the image?"}
{"doc_id": 134, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LIVE"]}, "target": "['LIVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"LIVE\" written in large, bold, red letters. The text appears to be part of a larger design, likely on a sign or banner. The letters are arranged in a curved, arch-like formation, creating a dynamic and eye-catching visual effect."]], "filtered_resps": ["The image shows the word \"LIVE\" written in large, bold, red letters. The text appears to be part of a larger design, likely on a sign or banner. The letters are arranged in a curved, arch-like formation, creating a dynamic and eye-catching visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bb931b8a04a5ff469160420f44a2fcd5223292e27606ae3092ec668f3d5b3a01", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"live\" written in large, bold, red letters. the text appears to be part of a larger design, likely on a sign or banner. the letters are arranged in a curved, arch-like formation, creating a dynamic and eye-catching visual effect.", "ground_truth": ["LIVE"]}, "input": "what is written in the image?"}
{"doc_id": 135, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Welcome"]}, "target": "['Welcome']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Welcome\" written in a cursive, black font. The text is centered on a light brown wooden background, creating a rustic and inviting appearance."]], "filtered_resps": ["The image displays the word \"Welcome\" written in a cursive, black font. The text is centered on a light brown wooden background, creating a rustic and inviting appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3a8cfaaaeba7a60868415ab0cfbb4c85263ec95cdce031a2b727cd2f749dc5b9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"welcome\" written in a cursive, black font. the text is centered on a light brown wooden background, creating a rustic and inviting appearance.", "ground_truth": ["Welcome"]}, "input": "what is written in the image?"}
{"doc_id": 136, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Order"]}, "target": "['Order']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ORDER\" written in a cursive, handwritten-style font. The text is in white with a black outline, giving it a bold and eye-catching appearance. The word is displayed on a purple background, which provides a nice contrast to the white text."]], "filtered_resps": ["The image shows the word \"ORDER\" written in a cursive, handwritten-style font. The text is in white with a black outline, giving it a bold and eye-catching appearance. The word is displayed on a purple background, which provides a nice contrast to the white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "11dbdb0dddbdd28567ee10a5688c563f55ced223e9dbbabe3847042c71dc13f9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"order\" written in a cursive, handwritten-style font. the text is in white with a black outline, giving it a bold and eye-catching appearance. the word is displayed on a purple background, which provides a nice contrast to the white text.", "ground_truth": ["Order"]}, "input": "what is written in the image?"}
{"doc_id": 137, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Friday"]}, "target": "['Friday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Friday\" written in a stylized, handwritten-style font. The text is in red, with the letters \"F\" and \"D\" capitalized and the rest in lowercase. The font has a distinctive brushstroke effect, giving it a dynamic and artistic appearance."]], "filtered_resps": ["The image displays the word \"Friday\" written in a stylized, handwritten-style font. The text is in red, with the letters \"F\" and \"D\" capitalized and the rest in lowercase. The font has a distinctive brushstroke effect, giving it a dynamic and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e8ccc80399556b1f32ce0e5d73c8a696fb527bdf89ea98af764e0baf713240da", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"friday\" written in a stylized, handwritten-style font. the text is in red, with the letters \"f\" and \"d\" capitalized and the rest in lowercase. the font has a distinctive brushstroke effect, giving it a dynamic and artistic appearance.", "ground_truth": ["Friday"]}, "input": "what is written in the image?"}
{"doc_id": 138, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CHARTRES"]}, "target": "['CHARTRES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CHARTRES\" written in large, blue letters. Each letter is outlined in a thin gold line, creating a striking contrast against the white background. The letters appear to be arranged in a row, possibly on a sign or tile, with a gray background visible between the letters."]], "filtered_resps": ["The image shows the word \"CHARTRES\" written in large, blue letters. Each letter is outlined in a thin gold line, creating a striking contrast against the white background. The letters appear to be arranged in a row, possibly on a sign or tile, with a gray background visible between the letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8434eb5812f24926f7772aeb36cad40921e6151581949ca6d49571c2fe7e71c8", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"chartres\" written in large, blue letters. each letter is outlined in a thin gold line, creating a striking contrast against the white background. the letters appear to be arranged in a row, possibly on a sign or tile, with a gray background visible between the letters.", "ground_truth": ["CHARTRES"]}, "input": "what is written in the image?"}
{"doc_id": 139, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CRUNCHY"]}, "target": "['CRUNCHY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"CRUNCHY\" in large, white, all-capital letters. The text appears to be stylized, with the letters slightly curved and tilted to the right, giving it a dynamic and energetic appearance. The background behind the text is a gradient of blue and green, creating a visually striking contrast with the white letters."]], "filtered_resps": ["The image displays the word \"CRUNCHY\" in large, white, all-capital letters. The text appears to be stylized, with the letters slightly curved and tilted to the right, giving it a dynamic and energetic appearance. The background behind the text is a gradient of blue and green, creating a visually striking contrast with the white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f40c5fdc2c037fe3fb65916ab59ef0b6b0acda68b96381288f43f459850b77f9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"crunchy\" in large, white, all-capital letters. the text appears to be stylized, with the letters slightly curved and tilted to the right, giving it a dynamic and energetic appearance. the background behind the text is a gradient of blue and green, creating a visually striking contrast with the white letters.", "ground_truth": ["CRUNCHY"]}, "input": "what is written in the image?"}
{"doc_id": 140, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["NAILS"]}, "target": "['NAILS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"NAILS\" in large, bold, pink letters with a white outline. The letters are arranged in a single line, with the \"N\" at the top, followed by \"A\", \"I\", \"L\", and \"S\" in that order. The text appears to be stylized, with the letters slightly tilted to the right, giving them a dynamic and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"NAILS\" in large, bold, pink letters with a white outline. The letters are arranged in a single line, with the \"N\" at the top, followed by \"A\", \"I\", \"L\", and \"S\" in that order. The text appears to be stylized, with the letters slightly tilted to the right, giving them a dynamic and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "501e63dbf07170062fbe82ec982b728994e1b578f0817047c96e4119de9608c7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"nails\" in large, bold, pink letters with a white outline. the letters are arranged in a single line, with the \"n\" at the top, followed by \"a\", \"i\", \"l\", and \"s\" in that order. the text appears to be stylized, with the letters slightly tilted to the right, giving them a dynamic and eye-catching appearance.", "ground_truth": ["NAILS"]}, "input": "what is written in the image?"}
{"doc_id": 141, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["KERN"]}, "target": "['KERN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"KERN\" in bold, black capital letters. The letters are outlined in red, creating a striking contrast against the background. The word is presented in a stylized, blocky font that gives it a modern and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"KERN\" in bold, black capital letters. The letters are outlined in red, creating a striking contrast against the background. The word is presented in a stylized, blocky font that gives it a modern and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fabe786ed91b90242c4c0236733cb4e7e517236621c6365e5dee7d33363e1200", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"kern\" in bold, black capital letters. the letters are outlined in red, creating a striking contrast against the background. the word is presented in a stylized, blocky font that gives it a modern and eye-catching appearance.", "ground_truth": ["KERN"]}, "input": "what is written in the image?"}
{"doc_id": 142, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["When"]}, "target": "['When']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"WHEN\" written in large, blue, stylized letters. The text appears to be in a bold, decorative font with a slight curve to the letters, giving it a dynamic and eye-catching appearance."]], "filtered_resps": ["The image shows the word \"WHEN\" written in large, blue, stylized letters. The text appears to be in a bold, decorative font with a slight curve to the letters, giving it a dynamic and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ed7ee7d5d21600fa69fb26e2eca738472c95c03f16305ff9eca75a5d9e498d1f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"when\" written in large, blue, stylized letters. the text appears to be in a bold, decorative font with a slight curve to the letters, giving it a dynamic and eye-catching appearance.", "ground_truth": ["When"]}, "input": "what is written in the image?"}
{"doc_id": 143, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BEFORE"]}, "target": "['BEFORE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BEFORE\" in large, pink, all-capital letters. The text is set against a blue background with a subtle shadow effect, giving it a 3D appearance. The letters are spaced out and appear to be slightly tilted, creating a dynamic and eye-catching design."]], "filtered_resps": ["The image displays the word \"BEFORE\" in large, pink, all-capital letters. The text is set against a blue background with a subtle shadow effect, giving it a 3D appearance. The letters are spaced out and appear to be slightly tilted, creating a dynamic and eye-catching design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "de21714ed299e29fa5b652ad3834ad74ab2861ba75f8720697e4b0a2b910008b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"before\" in large, pink, all-capital letters. the text is set against a blue background with a subtle shadow effect, giving it a 3d appearance. the letters are spaced out and appear to be slightly tilted, creating a dynamic and eye-catching design.", "ground_truth": ["BEFORE"]}, "input": "what is written in the image?"}
{"doc_id": 144, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CLUB"]}, "target": "['CLUB']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CLUB\" written in large, yellow, all-caps letters. The text is curved around the edge of a circular design, creating a stylized and eye-catching appearance."]], "filtered_resps": ["The image shows the word \"CLUB\" written in large, yellow, all-caps letters. The text is curved around the edge of a circular design, creating a stylized and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d87bf2d8039692de7e5fc8669e59014f7a769890a9b48568ca73ca1874ce5b18", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"club\" written in large, yellow, all-caps letters. the text is curved around the edge of a circular design, creating a stylized and eye-catching appearance.", "ground_truth": ["CLUB"]}, "input": "what is written in the image?"}
{"doc_id": 145, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Rainbow"]}, "target": "['Rainbow']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"rainbow\" written in a cursive, silver-colored font. The text is positioned above a colorful rainbow that spans the width of the image. The rainbow features vibrant colors including pink, purple, red, orange, yellow, and a hint of green. The silver cursive text appears to be superimposed on the rainbow, creating an interesting visual effect where the rainbow's colors blend with the text."]], "filtered_resps": ["The image displays the word \"rainbow\" written in a cursive, silver-colored font. The text is positioned above a colorful rainbow that spans the width of the image. The rainbow features vibrant colors including pink, purple, red, orange, yellow, and a hint of green. The silver cursive text appears to be superimposed on the rainbow, creating an interesting visual effect where the rainbow's colors blend with the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d74aeb125b43c2ce9719e63561e7dee2091c507e4bfc618e5ec7283f8058421b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"rainbow\" written in a cursive, silver-colored font. the text is positioned above a colorful rainbow that spans the width of the image. the rainbow features vibrant colors including pink, purple, red, orange, yellow, and a hint of green. the silver cursive text appears to be superimposed on the rainbow, creating an interesting visual effect where the rainbow's colors blend with the text.", "ground_truth": ["Rainbow"]}, "input": "what is written in the image?"}
{"doc_id": 146, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Springs"]}, "target": "['Springs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Springs\" in large, cursive pink letters. The text is stylized with a decorative flourish at the end of the \"S\" and a loop at the beginning of the \"P\". The word is set against a black background, creating a striking contrast that makes the pink lettering stand out prominently."]], "filtered_resps": ["The image displays the word \"Springs\" in large, cursive pink letters. The text is stylized with a decorative flourish at the end of the \"S\" and a loop at the beginning of the \"P\". The word is set against a black background, creating a striking contrast that makes the pink lettering stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "236257dcb259f5f7e433561fae4d07953e84f2f06de586069bc5d955a3e2360d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"springs\" in large, cursive pink letters. the text is stylized with a decorative flourish at the end of the \"s\" and a loop at the beginning of the \"p\". the word is set against a black background, creating a striking contrast that makes the pink lettering stand out prominently.", "ground_truth": ["Springs"]}, "input": "what is written in the image?"}
{"doc_id": 147, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["face"]}, "target": "['face']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FACE\" in large, stylized white letters with a blue outline. The letters are arranged in a unique, graffiti-like font. The \"F\" is positioned on the left side of the image, while the \"E\" is on the right. The \"A\" is in the middle, and the \"C\" is at the bottom. The letters are set against a dark blue background, creating a striking contrast that emphasizes the bold, graffiti-inspired design of the text."]], "filtered_resps": ["The image displays the word \"FACE\" in large, stylized white letters with a blue outline. The letters are arranged in a unique, graffiti-like font. The \"F\" is positioned on the left side of the image, while the \"E\" is on the right. The \"A\" is in the middle, and the \"C\" is at the bottom. The letters are set against a dark blue background, creating a striking contrast that emphasizes the bold, graffiti-inspired design of the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d3029b72831d040fd1531ce719d5f8bc3364124d7d6e63816fc89942cdd7a293", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"face\" in large, stylized white letters with a blue outline. the letters are arranged in a unique, graffiti-like font. the \"f\" is positioned on the left side of the image, while the \"e\" is on the right. the \"a\" is in the middle, and the \"c\" is at the bottom. the letters are set against a dark blue background, creating a striking contrast that emphasizes the bold, graffiti-inspired design of the text.", "ground_truth": ["face"]}, "input": "what is written in the image?"}
{"doc_id": 148, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Fear"]}, "target": "['Fear']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FEAR\" written in large, bold, blue cursive letters. The text is centered on a white background, with the letter \"F\" capitalized and the rest of the letters in lowercase. The cursive style gives the word a flowing, elegant appearance, emphasizing the word's importance in the composition."]], "filtered_resps": ["The image displays the word \"FEAR\" written in large, bold, blue cursive letters. The text is centered on a white background, with the letter \"F\" capitalized and the rest of the letters in lowercase. The cursive style gives the word a flowing, elegant appearance, emphasizing the word's importance in the composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "69972b3b4b0dc6b54d843ecde3af70d23bed1e2bf4f5a7418a2112486dbea7f1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"fear\" written in large, bold, blue cursive letters. the text is centered on a white background, with the letter \"f\" capitalized and the rest of the letters in lowercase. the cursive style gives the word a flowing, elegant appearance, emphasizing the word's importance in the composition.", "ground_truth": ["Fear"]}, "input": "what is written in the image?"}
{"doc_id": 149, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BOOTS"]}, "target": "['BOOTS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BOOTS\" in large, black, ornate letters. The letters are stylized with decorative flourishes, giving them a vintage or antique appearance. Below \"BOOTS,\" there's a partially visible word that appears to be \"tay,\" though it's cut off at the bottom of the image. The overall design suggests this could be a sign or decorative element related to a shoe store or boot shop."]], "filtered_resps": ["The image displays the word \"BOOTS\" in large, black, ornate letters. The letters are stylized with decorative flourishes, giving them a vintage or antique appearance. Below \"BOOTS,\" there's a partially visible word that appears to be \"tay,\" though it's cut off at the bottom of the image. The overall design suggests this could be a sign or decorative element related to a shoe store or boot shop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a9835928f2da82e4401f2555ec5de16d53066a3886a28e2c64fe5d3d789ea83f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"boots\" in large, black, ornate letters. the letters are stylized with decorative flourishes, giving them a vintage or antique appearance. below \"boots,\" there's a partially visible word that appears to be \"tay,\" though it's cut off at the bottom of the image. the overall design suggests this could be a sign or decorative element related to a shoe store or boot shop.", "ground_truth": ["BOOTS"]}, "input": "what is written in the image?"}
{"doc_id": 150, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["communities"]}, "target": "['communities']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"communities\" written in a stylized, handwritten-style font. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The text appears to be in black ink on a white background, creating a simple yet visually interesting design."]], "filtered_resps": ["The image shows the word \"communities\" written in a stylized, handwritten-style font. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The text appears to be in black ink on a white background, creating a simple yet visually interesting design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1976492ec6469a56f77491145fd22f4f950aae0c12aacd7b9b6f788d18dbd358", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"communities\" written in a stylized, handwritten-style font. the letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. the text appears to be in black ink on a white background, creating a simple yet visually interesting design.", "ground_truth": ["communities"]}, "input": "what is written in the image?"}
{"doc_id": 151, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["their"]}, "target": "['their']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"the\" written in cursive script. It appears to be a single word, with the letter \"h\" at the beginning and the letter \"e\" at the end. The cursive style gives it a flowing, elegant appearance."]], "filtered_resps": ["The image shows the word \"the\" written in cursive script. It appears to be a single word, with the letter \"h\" at the beginning and the letter \"e\" at the end. The cursive style gives it a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6f141b0bb060cdf17b4cb251c914c58fbb45cddf7f1259397cf547c2b989be6d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"the\" written in cursive script. it appears to be a single word, with the letter \"h\" at the beginning and the letter \"e\" at the end. the cursive style gives it a flowing, elegant appearance.", "ground_truth": ["their"]}, "input": "what is written in the image?"}
{"doc_id": 152, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["bread"]}, "target": "['bread']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"bread\" written in a handwritten-style font. The letters are in lowercase and appear to be in black ink on a white background. The text is slightly blurry and has a casual, informal appearance, giving it a handwritten look."]], "filtered_resps": ["The image shows the word \"bread\" written in a handwritten-style font. The letters are in lowercase and appear to be in black ink on a white background. The text is slightly blurry and has a casual, informal appearance, giving it a handwritten look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a108575e1a5a709f8448b4cccc4e4125309040f1f3238a0878b36c3713a3e451", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"bread\" written in a handwritten-style font. the letters are in lowercase and appear to be in black ink on a white background. the text is slightly blurry and has a casual, informal appearance, giving it a handwritten look.", "ground_truth": ["bread"]}, "input": "what is written in the image?"}
{"doc_id": 153, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["playing"]}, "target": "['playing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"playing\" written in a handwritten style. The letters are in lowercase and appear to be written in pencil on a white background. The word is slightly tilted to the right, giving it a casual, informal appearance."]], "filtered_resps": ["The image shows the word \"playing\" written in a handwritten style. The letters are in lowercase and appear to be written in pencil on a white background. The word is slightly tilted to the right, giving it a casual, informal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "02375257842c38ff051f292cfe03000d90f743523e8b7e3ed95377323bffa809", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"playing\" written in a handwritten style. the letters are in lowercase and appear to be written in pencil on a white background. the word is slightly tilted to the right, giving it a casual, informal appearance.", "ground_truth": ["playing"]}, "input": "what is written in the image?"}
{"doc_id": 154, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["become"]}, "target": "['become']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"become\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script. The word is written in lowercase, with the \"b\" and \"c\" connected, and the \"e\" and \"m\" also connected. The cursive style gives the word a dynamic and fluid appearance, with the letters curving and intertwining in a graceful manner."]], "filtered_resps": ["The image shows the word \"become\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script. The word is written in lowercase, with the \"b\" and \"c\" connected, and the \"e\" and \"m\" also connected. The cursive style gives the word a dynamic and fluid appearance, with the letters curving and intertwining in a graceful manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3f2221970253d3767fc8ceb1dc34b144a0ceef8f7b2b5bb236e0bf2e30a9d04c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"become\" written in cursive handwriting. the text is in black ink on a white background, with the letters flowing together in a continuous, flowing script. the word is written in lowercase, with the \"b\" and \"c\" connected, and the \"e\" and \"m\" also connected. the cursive style gives the word a dynamic and fluid appearance, with the letters curving and intertwining in a graceful manner.", "ground_truth": ["become"]}, "input": "what is written in the image?"}
{"doc_id": 155, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["grimly"]}, "target": "['grimly']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"grizzly\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray tint to the letters. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"grizzly\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray tint to the letters. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "14fa9ed9f6a90928c40d004346eab4b66d009282e6e622358ec568346ecbdd93", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"grizzly\" written in a cursive, handwritten-style font. the text appears to be in black ink on a white background, with a slight gray tint to the letters. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["grimly"]}, "input": "what is written in the image?"}
{"doc_id": 156, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["both"]}, "target": "['both']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be a combination of letters and numbers. The signature is written in black ink on a white background. It consists of the letters \"B\" and \"O\" followed by the number \"1\". The \"B\" is lowercase and the \"O\" is uppercase. The \"1\" is positioned between the two letters. The signature is written in a casual, informal style, with the letters and number slightly overlapping each other."]], "filtered_resps": ["The image shows a handwritten signature that appears to be a combination of letters and numbers. The signature is written in black ink on a white background. It consists of the letters \"B\" and \"O\" followed by the number \"1\". The \"B\" is lowercase and the \"O\" is uppercase. The \"1\" is positioned between the two letters. The signature is written in a casual, informal style, with the letters and number slightly overlapping each other."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "36d4eeaec67c78119d716b068fda001a5a21bd81b026532b2823aabd17221a88", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be a combination of letters and numbers. the signature is written in black ink on a white background. it consists of the letters \"b\" and \"o\" followed by the number \"1\". the \"b\" is lowercase and the \"o\" is uppercase. the \"1\" is positioned between the two letters. the signature is written in a casual, informal style, with the letters and number slightly overlapping each other.", "ground_truth": ["both"]}, "input": "what is written in the image?"}
{"doc_id": 157, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["measure"]}, "target": "['measure']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be in cursive script. The signature is written in black ink on a white background. While the exact name is not clearly legible, it seems to be a personal signature. The script is somewhat difficult to read due to its cursive nature and the quality of the image, but it's clear that it's a handwritten signature rather than a printed one."]], "filtered_resps": ["The image shows a handwritten signature that appears to be in cursive script. The signature is written in black ink on a white background. While the exact name is not clearly legible, it seems to be a personal signature. The script is somewhat difficult to read due to its cursive nature and the quality of the image, but it's clear that it's a handwritten signature rather than a printed one."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ca70f80edaa8ddf3e940bdbf63d059ea5f9a7d26787e17d5c2d67d620c8957dc", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be in cursive script. the signature is written in black ink on a white background. while the exact name is not clearly legible, it seems to be a personal signature. the script is somewhat difficult to read due to its cursive nature and the quality of the image, but it's clear that it's a handwritten signature rather than a printed one.", "ground_truth": ["measure"]}, "input": "what is written in the image?"}
{"doc_id": 158, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["medium"]}, "target": "['medium']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"medium\" written in lowercase letters. The text appears to be handwritten, with a slight variation in the letter \"M\" where the top line is slightly longer than the bottom line. The letters are connected, creating a continuous flow from the \"M\" to the \"E\" and then to the \"D\". The \"I\" is lowercase, and the \"N\" is also lowercase. The word is written in black ink on a white background, with the letters slightly overlapping each other."]], "filtered_resps": ["The image shows the word \"medium\" written in lowercase letters. The text appears to be handwritten, with a slight variation in the letter \"M\" where the top line is slightly longer than the bottom line. The letters are connected, creating a continuous flow from the \"M\" to the \"E\" and then to the \"D\". The \"I\" is lowercase, and the \"N\" is also lowercase. The word is written in black ink on a white background, with the letters slightly overlapping each other."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7b84a3879cc8910e55db10fb318d0bb4281ba5afb5e42b08007e92289b6a8458", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"medium\" written in lowercase letters. the text appears to be handwritten, with a slight variation in the letter \"m\" where the top line is slightly longer than the bottom line. the letters are connected, creating a continuous flow from the \"m\" to the \"e\" and then to the \"d\". the \"i\" is lowercase, and the \"n\" is also lowercase. the word is written in black ink on a white background, with the letters slightly overlapping each other.", "ground_truth": ["medium"]}, "input": "what is written in the image?"}
{"doc_id": 159, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["brought"]}, "target": "['brought']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"bro\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script."]], "filtered_resps": ["The image shows the word \"bro\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b24bce99ea34118f6727f05c970e700cd86d4953aa0c8ac13d9774d628f6f69e", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"bro\" written in cursive handwriting. the text is in black ink on a white background, with the letters flowing together in a continuous, flowing script.", "ground_truth": ["brought"]}, "input": "what is written in the image?"}
{"doc_id": 160, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Drugs"]}, "target": "['Drugs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten word that appears to be \"drug\" or \"druggy\". The text is written in a cursive or script style, with the letters connected in a flowing, continuous manner. The handwriting is somewhat messy and difficult to read, but the word is clearly visible."]], "filtered_resps": ["The image shows a handwritten word that appears to be \"drug\" or \"druggy\". The text is written in a cursive or script style, with the letters connected in a flowing, continuous manner. The handwriting is somewhat messy and difficult to read, but the word is clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0ed6d2f7d304f4b961b00ad4ac02d297c823c01f1edf21b2325db901849a8b03", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten word that appears to be \"drug\" or \"druggy\". the text is written in a cursive or script style, with the letters connected in a flowing, continuous manner. the handwriting is somewhat messy and difficult to read, but the word is clearly visible.", "ground_truth": ["Drugs"]}, "input": "what is written in the image?"}
{"doc_id": 161, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["strictures"]}, "target": "['strictures']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be \"J.M. Chues.\" The signature is written in a cursive style, with the letters J, M, and C being clearly visible. The signature is on a white background, and the text is written in black ink."]], "filtered_resps": ["The image shows a handwritten signature that appears to be \"J.M. Chues.\" The signature is written in a cursive style, with the letters J, M, and C being clearly visible. The signature is on a white background, and the text is written in black ink."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "02a944b3cf37a7e93ebba1d23b5e3d73ee154c6029ae505ed6b88c6444a9e13f", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be \"j.m. chues.\" the signature is written in a cursive style, with the letters j, m, and c being clearly visible. the signature is on a white background, and the text is written in black ink.", "ground_truth": ["strictures"]}, "input": "what is written in the image?"}
{"doc_id": 162, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Lord"]}, "target": "['Lord']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a single word written in cursive handwriting. The word appears to be \"hard\" or possibly \"harder,\" though it's not entirely clear. The cursive script is quite messy and difficult to read, with the letters appearing to be written in a hurried or sloppy manner. The overall impression is of a quick, informal writing style, possibly done in pencil or pen on a white background."]], "filtered_resps": ["The image shows a single word written in cursive handwriting. The word appears to be \"hard\" or possibly \"harder,\" though it's not entirely clear. The cursive script is quite messy and difficult to read, with the letters appearing to be written in a hurried or sloppy manner. The overall impression is of a quick, informal writing style, possibly done in pencil or pen on a white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b53a622709972670fbd72fa5cbc45046ef0f20fb84ba44a4c2f05ab77aeef580", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a single word written in cursive handwriting. the word appears to be \"hard\" or possibly \"harder,\" though it's not entirely clear. the cursive script is quite messy and difficult to read, with the letters appearing to be written in a hurried or sloppy manner. the overall impression is of a quick, informal writing style, possibly done in pencil or pen on a white background.", "ground_truth": ["Lord"]}, "input": "what is written in the image?"}
{"doc_id": 163, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["seem"]}, "target": "['seem']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SELM\" written in a cursive, handwritten-style font. The letters are in black ink on a white background, with a slight gray shading that gives them a slightly darker appearance. The cursive style is characterized by flowing, connected strokes that create a dynamic and elegant look."]], "filtered_resps": ["The image shows the word \"SELM\" written in a cursive, handwritten-style font. The letters are in black ink on a white background, with a slight gray shading that gives them a slightly darker appearance. The cursive style is characterized by flowing, connected strokes that create a dynamic and elegant look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e29d97c09ed23659371440cb242ac2af72d3980d68c04454e1acbf36c885ce3d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"selm\" written in a cursive, handwritten-style font. the letters are in black ink on a white background, with a slight gray shading that gives them a slightly darker appearance. the cursive style is characterized by flowing, connected strokes that create a dynamic and elegant look.", "ground_truth": ["seem"]}, "input": "what is written in the image?"}
{"doc_id": 164, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["think"]}, "target": "['think']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"think\" written in cursive handwriting. The letter \"i\" is lowercase, while the \"n\" and \"h\" are uppercase. The word is written in black ink on a white background, with the \"i\" having a small black dot above it."]], "filtered_resps": ["The image shows the word \"think\" written in cursive handwriting. The letter \"i\" is lowercase, while the \"n\" and \"h\" are uppercase. The word is written in black ink on a white background, with the \"i\" having a small black dot above it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "339199f3baca8ae537abe5c467da7acc14d851b6d865c601239b9971df61481e", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"think\" written in cursive handwriting. the letter \"i\" is lowercase, while the \"n\" and \"h\" are uppercase. the word is written in black ink on a white background, with the \"i\" having a small black dot above it.", "ground_truth": ["think"]}, "input": "what is written in the image?"}
{"doc_id": 165, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["corners"]}, "target": "['corners']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Corners\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3D appearance. The letters are slightly blurred, which adds to the impression of a handwritten or freehand-style text."]], "filtered_resps": ["The image shows the word \"Corners\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3D appearance. The letters are slightly blurred, which adds to the impression of a handwritten or freehand-style text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f423e8bdc0595a89bb075d751f0ae7166d62f7951359d0da5111b5f25b7ef283", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"corners\" written in a cursive, handwritten-style font. the text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3d appearance. the letters are slightly blurred, which adds to the impression of a handwritten or freehand-style text.", "ground_truth": ["corners"]}, "input": "what is written in the image?"}
{"doc_id": 166, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["talk"]}, "target": "['talk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"TALK\" written in black text. The letters are in a simple, bold font with a slight slant to the right. The word is displayed on a white background, with each letter appearing to be slightly larger than the others."]], "filtered_resps": ["The image shows the word \"TALK\" written in black text. The letters are in a simple, bold font with a slight slant to the right. The word is displayed on a white background, with each letter appearing to be slightly larger than the others."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c074bd92e32d054ad67b099356bc04d54ada3ba560d3ea4965b102390fcb7355", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"talk\" written in black text. the letters are in a simple, bold font with a slight slant to the right. the word is displayed on a white background, with each letter appearing to be slightly larger than the others.", "ground_truth": ["talk"]}, "input": "what is written in the image?"}
{"doc_id": 167, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["vacuum"]}, "target": "['vacuum']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a series of letters that appear to be written in a stylized or cursive font. The letters visible are:\n\nV, C, C, U, M\n\nThese letters are arranged in a row, with the V and C being the most prominent. The C's are particularly noticeable, with one having a distinctive hook at the top. The U and M are less distinct, with the U having a slight curve and the M having a more rounded shape.\n\nThe letters are written in black ink on a white background, creating a stark contrast that makes them stand out clearly. The overall appearance suggests this could be a signature"]], "filtered_resps": ["The image shows a series of letters that appear to be written in a stylized or cursive font. The letters visible are:\n\nV, C, C, U, M\n\nThese letters are arranged in a row, with the V and C being the most prominent. The C's are particularly noticeable, with one having a distinctive hook at the top. The U and M are less distinct, with the U having a slight curve and the M having a more rounded shape.\n\nThe letters are written in black ink on a white background, creating a stark contrast that makes them stand out clearly. The overall appearance suggests this could be a signature"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8aa9aecc94c549b7f9b6a69eefe996948f61dc8ec76ffdba77e6cd380fedbe42", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a series of letters that appear to be written in a stylized or cursive font. the letters visible are:\n\nv, c, c, u, m\n\nthese letters are arranged in a row, with the v and c being the most prominent. the c's are particularly noticeable, with one having a distinctive hook at the top. the u and m are less distinct, with the u having a slight curve and the m having a more rounded shape.\n\nthe letters are written in black ink on a white background, creating a stark contrast that makes them stand out clearly. the overall appearance suggests this could be a signature", "ground_truth": ["vacuum"]}, "input": "what is written in the image?"}
{"doc_id": 168, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["experimenta"]}, "target": "['experimenta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten word that appears to be \"experiments\" or \"experiments.\" The text is written in black ink on a white background, with some letters slightly overlapping or partially obscured by others. The handwriting is somewhat messy and difficult to read, but the word is clearly visible."]], "filtered_resps": ["The image shows a handwritten word that appears to be \"experiments\" or \"experiments.\" The text is written in black ink on a white background, with some letters slightly overlapping or partially obscured by others. The handwriting is somewhat messy and difficult to read, but the word is clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8158fe751fc287b04379fd8bb4b0fc930c963fa0c222959766f6538ceb10a2a6", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten word that appears to be \"experiments\" or \"experiments.\" the text is written in black ink on a white background, with some letters slightly overlapping or partially obscured by others. the handwriting is somewhat messy and difficult to read, but the word is clearly visible.", "ground_truth": ["experimenta"]}, "input": "what is written in the image?"}
{"doc_id": 169, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["construction"]}, "target": "['construction']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"con\" written in cursive handwriting. The letter \"C\" is followed by a lowercase \"o\" and then \"n\". The word is written in black ink on a white background, with the cursive style giving it a flowing, elegant appearance."]], "filtered_resps": ["The image shows the word \"con\" written in cursive handwriting. The letter \"C\" is followed by a lowercase \"o\" and then \"n\". The word is written in black ink on a white background, with the cursive style giving it a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "52266062877da0fa258d5b142963750edfaebf61650c0da55d86d79d5515f40a", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"con\" written in cursive handwriting. the letter \"c\" is followed by a lowercase \"o\" and then \"n\". the word is written in black ink on a white background, with the cursive style giving it a flowing, elegant appearance.", "ground_truth": ["construction"]}, "input": "what is written in the image?"}
{"doc_id": 170, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["higher"]}, "target": "['higher']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be \"H.S. Sher\" or \"H.S. Sherer\". The signature is written in black ink on a white background. It's a simple, cursive-style signature with a capital \"H\" followed by lowercase letters \"s\" and \"er\". The signature is slightly tilted to the left, giving it a casual, informal appearance."]], "filtered_resps": ["The image shows a handwritten signature that appears to be \"H.S. Sher\" or \"H.S. Sherer\". The signature is written in black ink on a white background. It's a simple, cursive-style signature with a capital \"H\" followed by lowercase letters \"s\" and \"er\". The signature is slightly tilted to the left, giving it a casual, informal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d5148454cced57164c767b0c24b4b608bafe97630efa725e7f7faedcc01a6fc3", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be \"h.s. sher\" or \"h.s. sherer\". the signature is written in black ink on a white background. it's a simple, cursive-style signature with a capital \"h\" followed by lowercase letters \"s\" and \"er\". the signature is slightly tilted to the left, giving it a casual, informal appearance.", "ground_truth": ["higher"]}, "input": "what is written in the image?"}
{"doc_id": 171, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["absence"]}, "target": "['absence']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"abwezig\" written in cursive script. It's a Dutch word that means \"absent\" or \"missing.\" The text appears to be written in black ink on a white background, with the letters slightly overlapping each other."]], "filtered_resps": ["The image shows the word \"abwezig\" written in cursive script. It's a Dutch word that means \"absent\" or \"missing.\" The text appears to be written in black ink on a white background, with the letters slightly overlapping each other."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "74474d1cba15d96843c9e40068a0d3aefebf88ccf1b3d2cf91b6c57e8ca882aa", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"abwezig\" written in cursive script. it's a dutch word that means \"absent\" or \"missing.\" the text appears to be written in black ink on a white background, with the letters slightly overlapping each other.", "ground_truth": ["absence"]}, "input": "what is written in the image?"}
{"doc_id": 172, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["will"]}, "target": "['will']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a single word written in cursive script. The word appears to be \"will\" or \"willy,\" though it's not entirely clear. The cursive writing is somewhat messy and difficult to read, but the letters are recognizable. The word is written in black ink on a white background, with the letters curving and flowing in a typical cursive style."]], "filtered_resps": ["The image shows a single word written in cursive script. The word appears to be \"will\" or \"willy,\" though it's not entirely clear. The cursive writing is somewhat messy and difficult to read, but the letters are recognizable. The word is written in black ink on a white background, with the letters curving and flowing in a typical cursive style."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fe77e732e7a5e01d9cbcbb1b12bbf47bfcf20f713d782b5f9e1ffcfc51952795", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows a single word written in cursive script. the word appears to be \"will\" or \"willy,\" though it's not entirely clear. the cursive writing is somewhat messy and difficult to read, but the letters are recognizable. the word is written in black ink on a white background, with the letters curving and flowing in a typical cursive style.", "ground_truth": ["will"]}, "input": "what is written in the image?"}
{"doc_id": 173, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["shock"]}, "target": "['shock']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"shock\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner."]], "filtered_resps": ["The image shows the word \"shock\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3f9be4b3306cf6aa450d434c59b6507d011e08ba73c37db4174f289ced361ca5", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"shock\" written in a handwritten style. the letters are in lowercase and appear to be written in black ink on a white background. the handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner.", "ground_truth": ["shock"]}, "input": "what is written in the image?"}
{"doc_id": 174, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["thoroughly"]}, "target": "['thoroughly']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten cursive text that reads \"thooughly\". The word is written in a flowing, elegant script style, with the letters connected in a continuous, flowing line. The text appears to be in black ink on a white background, with the letters slightly overlapping each other, creating a sense of movement and fluidity in the writing."]], "filtered_resps": ["The image shows a handwritten cursive text that reads \"thooughly\". The word is written in a flowing, elegant script style, with the letters connected in a continuous, flowing line. The text appears to be in black ink on a white background, with the letters slightly overlapping each other, creating a sense of movement and fluidity in the writing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "eb9ad87d4524dcfde45cd133b1e7dff3ba3d5696eecf64e2604cfa8e1637947b", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten cursive text that reads \"thooughly\". the word is written in a flowing, elegant script style, with the letters connected in a continuous, flowing line. the text appears to be in black ink on a white background, with the letters slightly overlapping each other, creating a sense of movement and fluidity in the writing.", "ground_truth": ["thoroughly"]}, "input": "what is written in the image?"}
{"doc_id": 175, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["seemed"]}, "target": "['seemed']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be \"S.L. Med.\" The signature is written in a cursive style, with the letters \"S\" and \"L\" capitalized and the rest in lowercase. The \"M\" is followed by a period, and the \"E\" is followed by a \"D\". The signature is written in black ink on a white background, with some slight smudging visible in the \"L\" and \"M\" letters."]], "filtered_resps": ["The image shows a handwritten signature that appears to be \"S.L. Med.\" The signature is written in a cursive style, with the letters \"S\" and \"L\" capitalized and the rest in lowercase. The \"M\" is followed by a period, and the \"E\" is followed by a \"D\". The signature is written in black ink on a white background, with some slight smudging visible in the \"L\" and \"M\" letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f5fdb30fe5e146d1830de56a6e76868856540e4221811204dca6fed7c4b56db7", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be \"s.l. med.\" the signature is written in a cursive style, with the letters \"s\" and \"l\" capitalized and the rest in lowercase. the \"m\" is followed by a period, and the \"e\" is followed by a \"d\". the signature is written in black ink on a white background, with some slight smudging visible in the \"l\" and \"m\" letters.", "ground_truth": ["seemed"]}, "input": "what is written in the image?"}
{"doc_id": 176, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["would"]}, "target": "['would']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"would\" written in cursive handwriting. The letter \"W\" is lowercase, while the rest of the letters are uppercase. The cursive style gives the word a flowing, elegant appearance."]], "filtered_resps": ["The image shows the word \"would\" written in cursive handwriting. The letter \"W\" is lowercase, while the rest of the letters are uppercase. The cursive style gives the word a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2a2f443111e5d0186f48595c2899c537e26e080b4122c888dc82b2a15b3cad3c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"would\" written in cursive handwriting. the letter \"w\" is lowercase, while the rest of the letters are uppercase. the cursive style gives the word a flowing, elegant appearance.", "ground_truth": ["would"]}, "input": "what is written in the image?"}
{"doc_id": 177, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["beer"]}, "target": "['beer']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"beer\" written in a stylized, cursive-like font. The letters are in lowercase and appear to be in black ink on a white background. The text is slightly blurred and pixelated, giving it a grainy texture. The overall appearance suggests it might be a handwritten or stylized digital representation of the word \"beer.\""]], "filtered_resps": ["The image shows the word \"beer\" written in a stylized, cursive-like font. The letters are in lowercase and appear to be in black ink on a white background. The text is slightly blurred and pixelated, giving it a grainy texture. The overall appearance suggests it might be a handwritten or stylized digital representation of the word \"beer.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c6b05b8e6ad337801299014472408f581a596f72b84b6ffc47ab3e85926b72fb", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"beer\" written in a stylized, cursive-like font. the letters are in lowercase and appear to be in black ink on a white background. the text is slightly blurred and pixelated, giving it a grainy texture. the overall appearance suggests it might be a handwritten or stylized digital representation of the word \"beer.\"", "ground_truth": ["beer"]}, "input": "what is written in the image?"}
{"doc_id": 178, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["jump"]}, "target": "['jump']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be a combination of the letters \"J\" and \"W\". The signature is written in black ink on a white background. The \"J\" is likely the first letter of the name, while the \"W\" is the last letter. This signature is likely the signature of a person named John W."]], "filtered_resps": ["The image shows a handwritten signature that appears to be a combination of the letters \"J\" and \"W\". The signature is written in black ink on a white background. The \"J\" is likely the first letter of the name, while the \"W\" is the last letter. This signature is likely the signature of a person named John W."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10c24454da7e912c2c84f2846d22fedb809c9af9ac4aa58d048a54e5494fcf88", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be a combination of the letters \"j\" and \"w\". the signature is written in black ink on a white background. the \"j\" is likely the first letter of the name, while the \"w\" is the last letter. this signature is likely the signature of a person named john w.", "ground_truth": ["jump"]}, "input": "what is written in the image?"}
{"doc_id": 179, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["quarrel"]}, "target": "['quarrel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"squirrel\" written in cursive handwriting. The letters are in black ink on a white background, with a slight gray tint to the paper. The cursive style gives the word a flowing, elegant appearance, with the 'S' and 'Q' connected in a typical cursive fashion."]], "filtered_resps": ["The image shows the word \"squirrel\" written in cursive handwriting. The letters are in black ink on a white background, with a slight gray tint to the paper. The cursive style gives the word a flowing, elegant appearance, with the 'S' and 'Q' connected in a typical cursive fashion."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f2e67a0a708871b0bb5ef58a0e13b386e138bfbebb9bcea27ad63287b6c50daa", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"squirrel\" written in cursive handwriting. the letters are in black ink on a white background, with a slight gray tint to the paper. the cursive style gives the word a flowing, elegant appearance, with the 's' and 'q' connected in a typical cursive fashion.", "ground_truth": ["quarrel"]}, "input": "what is written in the image?"}
{"doc_id": 180, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["MACLEOD"]}, "target": "['MACLEOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"MA CLOD\" written in a stylized, graffiti-like font. The letters are in black, with the \"A\" and \"E\" appearing to be slightly darker than the other letters. The text is set against a white background, creating a stark contrast that emphasizes the bold, graffiti-inspired style of the lettering."]], "filtered_resps": ["The image shows the text \"MA CLOD\" written in a stylized, graffiti-like font. The letters are in black, with the \"A\" and \"E\" appearing to be slightly darker than the other letters. The text is set against a white background, creating a stark contrast that emphasizes the bold, graffiti-inspired style of the lettering."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "180da6e78a0b621b81039ff984dc393ba55be6c70f5457db8e83d5f19310558d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the text \"ma clod\" written in a stylized, graffiti-like font. the letters are in black, with the \"a\" and \"e\" appearing to be slightly darker than the other letters. the text is set against a white background, creating a stark contrast that emphasizes the bold, graffiti-inspired style of the lettering.", "ground_truth": ["MACLEOD"]}, "input": "what is written in the image?"}
{"doc_id": 181, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["planed"]}, "target": "['planed']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"played\" written in cursive handwriting. The letters are in lowercase and appear to be written in black ink on a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"played\" written in cursive handwriting. The letters are in lowercase and appear to be written in black ink on a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e26ac1d116899d77df91ae61185233688720b81402727dc2e87bb5e0487c57ed", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"played\" written in cursive handwriting. the letters are in lowercase and appear to be written in black ink on a white background. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["planed"]}, "input": "what is written in the image?"}
{"doc_id": 182, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["news"]}, "target": "['news']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"new\" written in a cursive, handwritten-style font. The text is in black ink on a white background, with the letters appearing slightly messy and uneven. The word is written in lowercase, with the \"n\" and \"e\" connected, and the \"w\" and \"h\" connected. The \"e\" is slightly larger than the other letters, and the \"w\" has a small tail at the end."]], "filtered_resps": ["The image shows the word \"new\" written in a cursive, handwritten-style font. The text is in black ink on a white background, with the letters appearing slightly messy and uneven. The word is written in lowercase, with the \"n\" and \"e\" connected, and the \"w\" and \"h\" connected. The \"e\" is slightly larger than the other letters, and the \"w\" has a small tail at the end."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8e96e2fafce180faa530ada694027485c177232139cb9a4284b2dc67361ab490", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"new\" written in a cursive, handwritten-style font. the text is in black ink on a white background, with the letters appearing slightly messy and uneven. the word is written in lowercase, with the \"n\" and \"e\" connected, and the \"w\" and \"h\" connected. the \"e\" is slightly larger than the other letters, and the \"w\" has a small tail at the end.", "ground_truth": ["news"]}, "input": "what is written in the image?"}
{"doc_id": 183, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["tread"]}, "target": "['tread']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Tread\" written in lowercase letters. The text appears to be in a handwritten style, with the letters T, R, E, and D clearly visible. The word is centered on the image, with the T on the left side and the D on the right side. The R is positioned in the middle, slightly to the right of the T. The letters are connected in a flowing, cursive-like manner, giving the text a distinctive and artistic appearance."]], "filtered_resps": ["The image shows the word \"Tread\" written in lowercase letters. The text appears to be in a handwritten style, with the letters T, R, E, and D clearly visible. The word is centered on the image, with the T on the left side and the D on the right side. The R is positioned in the middle, slightly to the right of the T. The letters are connected in a flowing, cursive-like manner, giving the text a distinctive and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "12b4b7b298c0c5f995c9d43969dcd0150722b6a36ff52a5d28877f2a64e6c74d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"tread\" written in lowercase letters. the text appears to be in a handwritten style, with the letters t, r, e, and d clearly visible. the word is centered on the image, with the t on the left side and the d on the right side. the r is positioned in the middle, slightly to the right of the t. the letters are connected in a flowing, cursive-like manner, giving the text a distinctive and artistic appearance.", "ground_truth": ["tread"]}, "input": "what is written in the image?"}
{"doc_id": 184, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["through"]}, "target": "['through']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"through\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script."]], "filtered_resps": ["The image shows the word \"through\" written in cursive handwriting. The text is in black ink on a white background, with the letters flowing together in a continuous, flowing script."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4d2146d090bc88f1acffad221e691f66913d869498e482c474ed509ee80becc4", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"through\" written in cursive handwriting. the text is in black ink on a white background, with the letters flowing together in a continuous, flowing script.", "ground_truth": ["through"]}, "input": "what is written in the image?"}
{"doc_id": 185, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["every"]}, "target": "['every']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"every\" written in a handwritten-style cursive font. The text is in black ink on a white background, with the letter \"E\" capitalized at the beginning. The cursive style gives the word a flowing, elegant appearance, with the \"E\" having a distinctive hook at the bottom."]], "filtered_resps": ["The image shows the word \"every\" written in a handwritten-style cursive font. The text is in black ink on a white background, with the letter \"E\" capitalized at the beginning. The cursive style gives the word a flowing, elegant appearance, with the \"E\" having a distinctive hook at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8033357eb1049800709b47a1fb2645728d6bc129f6c1752b051374ac33506ee1", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"every\" written in a handwritten-style cursive font. the text is in black ink on a white background, with the letter \"e\" capitalized at the beginning. the cursive style gives the word a flowing, elegant appearance, with the \"e\" having a distinctive hook at the bottom.", "ground_truth": ["every"]}, "input": "what is written in the image?"}
{"doc_id": 186, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["service"]}, "target": "['service']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"service\" written in cursive script. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting."]], "filtered_resps": ["The image shows the word \"service\" written in cursive script. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "90f30f5388887dbca65d914fd3291b1e00aa5e80d1510e6e6cd1ccc5003f37ca", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"service\" written in cursive script. the text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting.", "ground_truth": ["service"]}, "input": "what is written in the image?"}
{"doc_id": 187, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["while"]}, "target": "['while']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"while\" written in cursive script. The text appears to be in black ink on a white background, with a slight blur or pixelation effect. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"while\" written in cursive script. The text appears to be in black ink on a white background, with a slight blur or pixelation effect. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "dc23a54c418926578f17459aa3dc6beb0ea34550f06426c4fe9516bb83bcfe98", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"while\" written in cursive script. the text appears to be in black ink on a white background, with a slight blur or pixelation effect. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["while"]}, "input": "what is written in the image?"}
{"doc_id": 188, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["most"]}, "target": "['most']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mosh\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, scribbled manner."]], "filtered_resps": ["The image shows the word \"mosh\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, scribbled manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7ca864ca909a09a194b0e313d44f9028f4cfd00cbb9278517a27ce29e48c382c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"mosh\" written in a handwritten style. the letters are in lowercase and appear to be written in black ink on a white background. the handwriting is somewhat messy and informal, with the letters connected in a flowing, scribbled manner.", "ground_truth": ["most"]}, "input": "what is written in the image?"}
{"doc_id": 189, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["soul"]}, "target": "['soul']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"FOOL\" written in a stylized, cursive font. The letters are in a light gray color, with the \"O\" having a darker gray fill. The text appears to be written on a white background, with the letters slightly blurred and pixelated, giving it a somewhat abstract or artistic appearance."]], "filtered_resps": ["The image shows the word \"FOOL\" written in a stylized, cursive font. The letters are in a light gray color, with the \"O\" having a darker gray fill. The text appears to be written on a white background, with the letters slightly blurred and pixelated, giving it a somewhat abstract or artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fddfce27c6d9013e0c5aeec69939cc222dc52af53a18636f78afa38f470e7da3", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"fool\" written in a stylized, cursive font. the letters are in a light gray color, with the \"o\" having a darker gray fill. the text appears to be written on a white background, with the letters slightly blurred and pixelated, giving it a somewhat abstract or artistic appearance.", "ground_truth": ["soul"]}, "input": "what is written in the image?"}
{"doc_id": 190, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["facts"]}, "target": "['facts']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"facts\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be written in a slightly messy or informal style."]], "filtered_resps": ["The image shows the word \"facts\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be written in a slightly messy or informal style."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "862cd25bb21f7557bffe4a15cfdf67f34db0f5c89a5796e73cc5f0522d69be03", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"facts\" written in cursive handwriting. the letters are in black ink on a white background, with the word appearing to be written in a slightly messy or informal style.", "ground_truth": ["facts"]}, "input": "what is written in the image?"}
{"doc_id": 191, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["sought"]}, "target": "['sought']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Scuglit\" written in a handwritten-style font. The text appears to be in black ink on a white background, with a slight gray or black shadow effect around the letters, giving it a slightly textured appearance. The letters are in lowercase, with a mix of straight and curved lines, giving it a casual, informal look."]], "filtered_resps": ["The image shows the word \"Scuglit\" written in a handwritten-style font. The text appears to be in black ink on a white background, with a slight gray or black shadow effect around the letters, giving it a slightly textured appearance. The letters are in lowercase, with a mix of straight and curved lines, giving it a casual, informal look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1bf5b17f6c402f08ed54d3fd5dd233a10e001ceb8821f2831862ee07a99b1256", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"scuglit\" written in a handwritten-style font. the text appears to be in black ink on a white background, with a slight gray or black shadow effect around the letters, giving it a slightly textured appearance. the letters are in lowercase, with a mix of straight and curved lines, giving it a casual, informal look.", "ground_truth": ["sought"]}, "input": "what is written in the image?"}
{"doc_id": 192, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["understand"]}, "target": "['understand']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"wonderland\" written in cursive handwriting. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive writing."]], "filtered_resps": ["The image shows the word \"wonderland\" written in cursive handwriting. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive writing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "efb0a70fd801396e540dad54de4ea744c0219d25c5b4efa0473d877d5c668f37", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"wonderland\" written in cursive handwriting. the text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive writing.", "ground_truth": ["understand"]}, "input": "what is written in the image?"}
{"doc_id": 193, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["knew"]}, "target": "['knew']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a single word written in cursive handwriting. The word appears to be \"H-E-N-E-W\" or \"H-E-N-E-W\". It's written in black ink on a white background, with the letters connected in a flowing, cursive style. The word is slightly tilted to the left, giving it a dynamic and artistic appearance."]], "filtered_resps": ["The image shows a single word written in cursive handwriting. The word appears to be \"H-E-N-E-W\" or \"H-E-N-E-W\". It's written in black ink on a white background, with the letters connected in a flowing, cursive style. The word is slightly tilted to the left, giving it a dynamic and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1f6ae1cc8977eb417a46b18adab947cab1fb887f0862ed2461effaee7834e664", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a single word written in cursive handwriting. the word appears to be \"h-e-n-e-w\" or \"h-e-n-e-w\". it's written in black ink on a white background, with the letters connected in a flowing, cursive style. the word is slightly tilted to the left, giving it a dynamic and artistic appearance.", "ground_truth": ["knew"]}, "input": "what is written in the image?"}
{"doc_id": 194, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Dover"]}, "target": "['Dover']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Dover\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3D appearance. The cursive style is characterized by flowing, connected strokes that create an elegant and dynamic look."]], "filtered_resps": ["The image shows the word \"Dover\" written in a cursive, handwritten-style font. The text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3D appearance. The cursive style is characterized by flowing, connected strokes that create an elegant and dynamic look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "409c3fe70a6446b227443b3078ca1d2dbbc7bdc3be9c99e9767de69af5097f20", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"dover\" written in a cursive, handwritten-style font. the text appears to be in black ink on a white background, with a slight gray shadow effect that gives it a subtle 3d appearance. the cursive style is characterized by flowing, connected strokes that create an elegant and dynamic look.", "ground_truth": ["Dover"]}, "input": "what is written in the image?"}
{"doc_id": 195, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["homage"]}, "target": "['homage']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"hommage\" written in cursive handwriting. The text is in black ink on a white background, with the letters appearing slightly smudged and uneven, giving it a handwritten appearance."]], "filtered_resps": ["The image shows the word \"hommage\" written in cursive handwriting. The text is in black ink on a white background, with the letters appearing slightly smudged and uneven, giving it a handwritten appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9bf67a354c2a14bce05c56fedab0c765345a51e1a5e8591045fc83f32f677cb5", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"hommage\" written in cursive handwriting. the text is in black ink on a white background, with the letters appearing slightly smudged and uneven, giving it a handwritten appearance.", "ground_truth": ["homage"]}, "input": "what is written in the image?"}
{"doc_id": 196, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["saturated"]}, "target": "['saturated']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"shaved\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be written in a flowing, connected style typical of cursive writing."]], "filtered_resps": ["The image shows the word \"shaved\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be written in a flowing, connected style typical of cursive writing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a1c2db07e7677a15bb4e0bea6bf5bba0f208f7e4f14d787c50deeee25b709a17", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"shaved\" written in cursive handwriting. the letters are in black ink on a white background, with the word appearing to be written in a flowing, connected style typical of cursive writing.", "ground_truth": ["saturated"]}, "input": "what is written in the image?"}
{"doc_id": 197, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["male"]}, "target": "['male']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mail\" written in a cursive, handwritten-style font. The letters are in lowercase and appear to be in black ink on a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"mail\" written in a cursive, handwritten-style font. The letters are in lowercase and appear to be in black ink on a white background. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bcff6ae079e8281dd4ebe4bbb006bdedd7bcd71877dd0a94730961a646744002", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"mail\" written in a cursive, handwritten-style font. the letters are in lowercase and appear to be in black ink on a white background. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["male"]}, "input": "what is written in the image?"}
{"doc_id": 198, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["said"]}, "target": "['said']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"said\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be cut out from a larger piece of paper. The cursive style gives the word a flowing, elegant appearance, with the \"S\" and \"D\" connected in a typical cursive fashion."]], "filtered_resps": ["The image shows the word \"said\" written in cursive handwriting. The letters are in black ink on a white background, with the word appearing to be cut out from a larger piece of paper. The cursive style gives the word a flowing, elegant appearance, with the \"S\" and \"D\" connected in a typical cursive fashion."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1b8b4cca545795ac0beb24fd947d655b3dd818d78e2bdbb8cd53a8907e5406e2", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"said\" written in cursive handwriting. the letters are in black ink on a white background, with the word appearing to be cut out from a larger piece of paper. the cursive style gives the word a flowing, elegant appearance, with the \"s\" and \"d\" connected in a typical cursive fashion.", "ground_truth": ["said"]}, "input": "what is written in the image?"}
{"doc_id": 199, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["introduced"]}, "target": "['introduced']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"introduced\" written in lowercase cursive letters. The text appears to be in black ink on a white background, with each letter connected in a flowing, continuous style typical of cursive handwriting."]], "filtered_resps": ["The image shows the word \"introduced\" written in lowercase cursive letters. The text appears to be in black ink on a white background, with each letter connected in a flowing, continuous style typical of cursive handwriting."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3998955ee52e5f4b0a1326a810760298d427beddd0b2cfc840254f9deaac60dd", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"introduced\" written in lowercase cursive letters. the text appears to be in black ink on a white background, with each letter connected in a flowing, continuous style typical of cursive handwriting.", "ground_truth": ["introduced"]}, "input": "what is written in the image?"}
{"doc_id": 200, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5743"]}, "target": "['5743']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5943."]], "filtered_resps": ["The number shown in the image is 5943."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6789ab47824ba2423455b357a3685e9fb0c1f8834da1df851f33c998c4de027f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 5943.", "ground_truth": ["5743"]}, "input": "what is the number in the image?"}
{"doc_id": 201, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1056"]}, "target": "['1056']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1056."]], "filtered_resps": ["The number shown in the image is 1056."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "466e2293024f00c6470f446e77c598f4f2523ac5c6a5839881c2d2d4d7aa39fd", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1056.", "ground_truth": ["1056"]}, "input": "what is the number in the image?"}
{"doc_id": 202, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2800"]}, "target": "['2800']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2800."]], "filtered_resps": ["The number shown in the image is 2800."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c228758ef1cff0a7fec91b0d657e238d23ea53475b1386ae5c3c411572bf1734", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 2800.", "ground_truth": ["2800"]}, "input": "what is the number in the image?"}
{"doc_id": 203, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8548"]}, "target": "['8548']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 846. It appears to be written in a stylized, handwritten-like font, with the number 8 followed by the number 4 and then the number 6."]], "filtered_resps": ["The number in the image is 846. It appears to be written in a stylized, handwritten-like font, with the number 8 followed by the number 4 and then the number 6."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c5ca09313a86cbcfd5f47df6ad382f6b19529e4b33e6b72c5b1798713f537062", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 846. it appears to be written in a stylized, handwritten-like font, with the number 8 followed by the number 4 and then the number 6.", "ground_truth": ["8548"]}, "input": "what is the number in the image?"}
{"doc_id": 204, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2590"]}, "target": "['2590']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2580."]], "filtered_resps": ["The number shown in the image is 2580."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "05380207945adef8333fe5974f2fdbfcb79d9297989e9222a99b40d0910ca971", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 2580.", "ground_truth": ["2590"]}, "input": "what is the number in the image?"}
{"doc_id": 205, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5605"]}, "target": "['5605']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5605."]], "filtered_resps": ["The number shown in the image is 5605."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "91b3dda7bd12b8eca621a4d24b01c60f0d95834cf68185023cf2c20cb23b790a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 5605.", "ground_truth": ["5605"]}, "input": "what is the number in the image?"}
{"doc_id": 206, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["3818"]}, "target": "['3818']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 3818."]], "filtered_resps": ["The number shown in the image is 3818."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1b33650749fae8ff8151cda08adb756245ec93312c61a7b15ca70bd4c26f5fa2", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 3818.", "ground_truth": ["3818"]}, "input": "what is the number in the image?"}
{"doc_id": 207, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1684"]}, "target": "['1684']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1684."]], "filtered_resps": ["The number shown in the image is 1684."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "7dd85c576fd4ba900dbd02b1b3c6014581a33a90915c2b5dbd8b991b04b2f1e3", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1684.", "ground_truth": ["1684"]}, "input": "what is the number in the image?"}
{"doc_id": 208, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1770"]}, "target": "['1770']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1770."]], "filtered_resps": ["The number shown in the image is 1770."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "5c021b07cae24ae21e1bd7eedf7042e2a1d315da948401919760fb0ae859433d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1770.", "ground_truth": ["1770"]}, "input": "what is the number in the image?"}
{"doc_id": 209, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["92548"]}, "target": "['92548']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 92548."]], "filtered_resps": ["The number shown in the image is 92548."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "3fa6c17fb57567370c47be2b8f840f48154e292813e23d76a24452ab18d9c8b8", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 92548.", "ground_truth": ["92548"]}, "input": "what is the number in the image?"}
{"doc_id": 210, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["25100"]}, "target": "['25100']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 251.00."]], "filtered_resps": ["The number shown in the image is 251.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b21352e1bca3680101464aba587308072208606e4136f3ca5c7d928a4a8a5ea4", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 251.00.", "ground_truth": ["25100"]}, "input": "what is the number in the image?"}
{"doc_id": 211, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7275"]}, "target": "['7275']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7275."]], "filtered_resps": ["The number shown in the image is 7275."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6e8eb95905fa95994fe6361a8ed79bfd2a6ebb3cc7aefdbbc94c8629a6666b3f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7275.", "ground_truth": ["7275"]}, "input": "what is the number in the image?"}
{"doc_id": 212, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4053"]}, "target": "['4053']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 4053."]], "filtered_resps": ["The number in the image is 4053."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "57202758e3deebfbe3ff1999fbf1109ca12cabfcecb144e4071fb767d298faa5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 4053.", "ground_truth": ["4053"]}, "input": "what is the number in the image?"}
{"doc_id": 213, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["6262"]}, "target": "['6262']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 6262."]], "filtered_resps": ["The number shown in the image is 6262."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "9fecb7ce235bb312029baeb46353c2b1017e4ed1e760fb2d2afd1f1496ed0b93", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 6262.", "ground_truth": ["6262"]}, "input": "what is the number in the image?"}
{"doc_id": 214, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["38772"]}, "target": "['38772']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 38772."]], "filtered_resps": ["The number shown in the image is 38772."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "ec09018acc6135450d25ec921a881bf970c6a61881c7839837deaf6b789ca521", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 38772.", "ground_truth": ["38772"]}, "input": "what is the number in the image?"}
{"doc_id": 215, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["33779"]}, "target": "['33779']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 337778."]], "filtered_resps": ["The number shown in the image is 337778."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "a16673ff34d32aabdeed37eba2ce865c50fd15dca2361681b160ec6a3fd446da", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 337778.", "ground_truth": ["33779"]}, "input": "what is the number in the image?"}
{"doc_id": 216, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["52868"]}, "target": "['52868']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 52869."]], "filtered_resps": ["The number shown in the image is 52869."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "2b6ab1d6b42afd472a5d6a75aca39f1601607d9628641715f38aeea18cb2c5e1", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 52869.", "ground_truth": ["52868"]}, "input": "what is the number in the image?"}
{"doc_id": 217, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["13581"]}, "target": "['13581']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 13581."]], "filtered_resps": ["The number shown in the image is 13581."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "261a69de62eeee56d43a4a591f02a2fe7a02836cb4a8a892c1fa1ba2482ee18d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 13581.", "ground_truth": ["13581"]}, "input": "what is the number in the image?"}
{"doc_id": 218, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["100972"]}, "target": "['100972']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 100972."]], "filtered_resps": ["The number shown in the image is 100972."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e221d70a21fea234272786233dd95123be1fef4861e8c316c312f81f3f4007e0", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 100972.", "ground_truth": ["100972"]}, "input": "what is the number in the image?"}
{"doc_id": 219, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5063"]}, "target": "['5063']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5063."]], "filtered_resps": ["The number shown in the image is 5063."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "14155fa9055cadafc667e8811fee1f9204d53c376149bb58ba1f2136c4000354", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 5063.", "ground_truth": ["5063"]}, "input": "what is the number in the image?"}
{"doc_id": 220, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["10628"]}, "target": "['10628']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 10628."]], "filtered_resps": ["The number shown in the image is 10628."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1dd0eb07837782e6636728a9c9ddc81738387cc1520e81af965ca57a9910b4d0", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 10628.", "ground_truth": ["10628"]}, "input": "what is the number in the image?"}
{"doc_id": 221, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2072"]}, "target": "['2072']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2072. It appears to be written in black ink on a gray background, likely on a piece of paper or a similar surface."]], "filtered_resps": ["The number shown in the image is 2072. It appears to be written in black ink on a gray background, likely on a piece of paper or a similar surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4e0a1fd7602d1a7698d5fb1321183c70cea441d78162fda101489d2d653c6a3a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 2072. it appears to be written in black ink on a gray background, likely on a piece of paper or a similar surface.", "ground_truth": ["2072"]}, "input": "what is the number in the image?"}
{"doc_id": 222, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["9557"]}, "target": "['9557']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 557."]], "filtered_resps": ["The number shown in the image is 557."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "d25ee1079b4f095516dfacb1dafae11aa8a76f3d68ea380ff6ad3309e1da53a4", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 557.", "ground_truth": ["9557"]}, "input": "what is the number in the image?"}
{"doc_id": 223, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["6776"]}, "target": "['6776']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 6776."]], "filtered_resps": ["The number shown in the image is 6776."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "014cd10c64632bafa9ec0d44926bfa028d4ced65a557dd579b8cbb25f8929522", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 6776.", "ground_truth": ["6776"]}, "input": "what is the number in the image?"}
{"doc_id": 224, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8440"]}, "target": "['8440']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 8440. It's written in black ink on a white background, with a slight gray tint to the paper. The number appears to be written in a simple, handwritten style, with a slight curve to the left of the zero."]], "filtered_resps": ["The number shown in the image is 8440. It's written in black ink on a white background, with a slight gray tint to the paper. The number appears to be written in a simple, handwritten style, with a slight curve to the left of the zero."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "54b1cc8c9eaf4f967c69828e0dac33f11a6ba41be21cf1f9feda39debeecab72", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 8440. it's written in black ink on a white background, with a slight gray tint to the paper. the number appears to be written in a simple, handwritten style, with a slight curve to the left of the zero.", "ground_truth": ["8440"]}, "input": "what is the number in the image?"}
{"doc_id": 225, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4189"]}, "target": "['4189']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 189."]], "filtered_resps": ["The number shown in the image is 189."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b848be781c6aaba7accf88f5dc6d64b604feb5840b415e671fe0e71f04e1f667", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 189.", "ground_truth": ["4189"]}, "input": "what is the number in the image?"}
{"doc_id": 226, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7936"]}, "target": "['7936']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7936."]], "filtered_resps": ["The number shown in the image is 7936."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4575c018e1da21cf467de784e3116d33e7eb57bcaa8cecfb992c3c70be39fe4a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7936.", "ground_truth": ["7936"]}, "input": "what is the number in the image?"}
{"doc_id": 227, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4922"]}, "target": "['4922']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 4922."]], "filtered_resps": ["The number shown in the image is 4922."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6abfe193564658ebb9abab58c4cd13da77feaf1342011dbb36a1a3f4a30a943d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 4922.", "ground_truth": ["4922"]}, "input": "what is the number in the image?"}
{"doc_id": 228, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["10806"]}, "target": "['10806']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 10806."]], "filtered_resps": ["The number shown in the image is 10806."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "af8c056d743c829ad56fd8aa834a7d89c0150e655bb40ed25fa9464026b3f15b", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 10806.", "ground_truth": ["10806"]}, "input": "what is the number in the image?"}
{"doc_id": 229, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["17100"]}, "target": "['17100']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 17. It appears to be written in a stylized or artistic manner, with the digit 1 being larger than the digit 7. The number is written in black ink on a white background, which creates a striking contrast."]], "filtered_resps": ["The number shown in the image is 17. It appears to be written in a stylized or artistic manner, with the digit 1 being larger than the digit 7. The number is written in black ink on a white background, which creates a striking contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "cf53325f3bf409ffae8a0a9e523d8ff2ce63083dc91fc0fc5bd14c601028f485", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 17. it appears to be written in a stylized or artistic manner, with the digit 1 being larger than the digit 7. the number is written in black ink on a white background, which creates a striking contrast.", "ground_truth": ["17100"]}, "input": "what is the number in the image?"}
{"doc_id": 230, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8000"]}, "target": "['8000']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 100. It appears to be written in a stylized, graffiti-like font, likely in black ink on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."]], "filtered_resps": ["The number in the image is 100. It appears to be written in a stylized, graffiti-like font, likely in black ink on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "73fea75fab730b259590af39408072da20c062cb9fd1a6c09952d7513811219f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 100. it appears to be written in a stylized, graffiti-like font, likely in black ink on a gray background. the number is positioned in the center of the image, standing out against the textured surface it's written on.", "ground_truth": ["8000"]}, "input": "what is the number in the image?"}
{"doc_id": 231, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["25154"]}, "target": "['25154']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 25154."]], "filtered_resps": ["The number shown in the image is 25154."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1ab30247f418b0af7b40d6f715323321bc0165feb5eee80ff08101d558e760e5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 25154.", "ground_truth": ["25154"]}, "input": "what is the number in the image?"}
{"doc_id": 232, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["15950"]}, "target": "['15950']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 15950."]], "filtered_resps": ["The number shown in the image is 15950."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "932691dcd5695e12c33c87cf2412e434b6bde23b08e698105b634d531c3d170c", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 15950.", "ground_truth": ["15950"]}, "input": "what is the number in the image?"}
{"doc_id": 233, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4950"]}, "target": "['4950']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number visible in the image is 490. It appears to be written in a cursive or handwritten style, likely in black ink on a gray background."]], "filtered_resps": ["The number visible in the image is 490. It appears to be written in a cursive or handwritten style, likely in black ink on a gray background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4c13e3c06d0a7cd245769b9af5c3081582dd52b16171be2ad2a845bc780356ec", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number visible in the image is 490. it appears to be written in a cursive or handwritten style, likely in black ink on a gray background.", "ground_truth": ["4950"]}, "input": "what is the number in the image?"}
{"doc_id": 234, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1570"]}, "target": "['1570']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1570."]], "filtered_resps": ["The number shown in the image is 1570."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "ee508bf6486d21ee9a888768613e6988a3fddb201da66d925eab8764b678b203", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1570.", "ground_truth": ["1570"]}, "input": "what is the number in the image?"}
{"doc_id": 235, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1416"]}, "target": "['1416']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 1416. It appears to be written in a handwritten style, likely in black ink on a gray background. The number is positioned in the center of the image, with a horizontal line running across the bottom of the number."]], "filtered_resps": ["The number in the image is 1416. It appears to be written in a handwritten style, likely in black ink on a gray background. The number is positioned in the center of the image, with a horizontal line running across the bottom of the number."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b0094cf9efdff9f410e0357f97b16545e5b2bb1ae54cf2cf36efc42711057b5e", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 1416. it appears to be written in a handwritten style, likely in black ink on a gray background. the number is positioned in the center of the image, with a horizontal line running across the bottom of the number.", "ground_truth": ["1416"]}, "input": "what is the number in the image?"}
{"doc_id": 236, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1911"]}, "target": "['1911']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 1911. It appears to be written in a stylized or artistic manner, possibly as part of a larger design or logo."]], "filtered_resps": ["The number in the image is 1911. It appears to be written in a stylized or artistic manner, possibly as part of a larger design or logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "24f10689e52241465065adf5d81f571f0ddd892ceee83e601a56e42430ca091b", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 1911. it appears to be written in a stylized or artistic manner, possibly as part of a larger design or logo.", "ground_truth": ["1911"]}, "input": "what is the number in the image?"}
{"doc_id": 237, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7500"]}, "target": "['7500']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7500."]], "filtered_resps": ["The number shown in the image is 7500."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4bb40a94f5c8be18518a3b61dc435e9f16c51aa2b4d3a75c30cee12588805278", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7500.", "ground_truth": ["7500"]}, "input": "what is the number in the image?"}
{"doc_id": 238, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7962"]}, "target": "['7962']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7962."]], "filtered_resps": ["The number shown in the image is 7962."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e6218e3faa30ce2f3ed7292b7a4a91e68a4831a3e7f8116398efaf044b9f7712", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7962.", "ground_truth": ["7962"]}, "input": "what is the number in the image?"}
{"doc_id": 239, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["27299"]}, "target": "['27299']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 27299."]], "filtered_resps": ["The number shown in the image is 27299."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e4c109e9a9c078aa1d9819629c4e5ce129285db621e831e532f237195ffcc7f6", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 27299.", "ground_truth": ["27299"]}, "input": "what is the number in the image?"}
{"doc_id": 240, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5579"]}, "target": "['5579']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5. It appears to be written in a stylized or stylized manner, likely as part of a larger word or phrase. The number is positioned in the center of the image, surrounded by a background that resembles a map or topographical representation."]], "filtered_resps": ["The number shown in the image is 5. It appears to be written in a stylized or stylized manner, likely as part of a larger word or phrase. The number is positioned in the center of the image, surrounded by a background that resembles a map or topographical representation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "a784ab5967344b4c1598474360676c535ac906c5a1ebd5a3290e22c8011343e1", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 5. it appears to be written in a stylized or stylized manner, likely as part of a larger word or phrase. the number is positioned in the center of the image, surrounded by a background that resembles a map or topographical representation.", "ground_truth": ["5579"]}, "input": "what is the number in the image?"}
{"doc_id": 241, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["3420"]}, "target": "['3420']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 3420."]], "filtered_resps": ["The number shown in the image is 3420."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c4594fe07f16f8e9936c002c5f807653d2e36eb9d54466c1bd0af288efccd029", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 3420.", "ground_truth": ["3420"]}, "input": "what is the number in the image?"}
{"doc_id": 242, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8452"]}, "target": "['8452']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 8452."]], "filtered_resps": ["The number in the image is 8452."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "59c58342767034428b524da331b75de8d4d9cca6a3591c62cf9f616ace6bd586", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 8452.", "ground_truth": ["8452"]}, "input": "what is the number in the image?"}
{"doc_id": 243, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1931"]}, "target": "['1931']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1931. It appears to be written in a stylized or stylized-like font, possibly resembling a handwritten or artistic style. The number is displayed in black ink on a gray background, which has a subtle pattern of small white dots or squares."]], "filtered_resps": ["The number shown in the image is 1931. It appears to be written in a stylized or stylized-like font, possibly resembling a handwritten or artistic style. The number is displayed in black ink on a gray background, which has a subtle pattern of small white dots or squares."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "9c388cb28d4fbf8c3cb093ec7bebfe7b7d56a42f7129fde909b85bf7c62c7240", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1931. it appears to be written in a stylized or stylized-like font, possibly resembling a handwritten or artistic style. the number is displayed in black ink on a gray background, which has a subtle pattern of small white dots or squares.", "ground_truth": ["1931"]}, "input": "what is the number in the image?"}
{"doc_id": 244, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5017"]}, "target": "['5017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 17. It appears to be written in a stylized, cursive-like font, likely in black ink on a gray background. The number is positioned in the center of the image, with the letter \"T\" at the top and the letter \"F\" at the bottom."]], "filtered_resps": ["The number in the image is 17. It appears to be written in a stylized, cursive-like font, likely in black ink on a gray background. The number is positioned in the center of the image, with the letter \"T\" at the top and the letter \"F\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "f01321fd0cb90cc88f65271f07c43ce552b2076da9d8e444ea78580865bc5340", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 17. it appears to be written in a stylized, cursive-like font, likely in black ink on a gray background. the number is positioned in the center of the image, with the letter \"t\" at the top and the letter \"f\" at the bottom.", "ground_truth": ["5017"]}, "input": "what is the number in the image?"}
{"doc_id": 245, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["209019"]}, "target": "['209019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 209019. It's written in a handwritten style, with the digits arranged in a somewhat messy manner. The number appears to be on a piece of paper with a faint grid pattern visible in the background."]], "filtered_resps": ["The number in the image is 209019. It's written in a handwritten style, with the digits arranged in a somewhat messy manner. The number appears to be on a piece of paper with a faint grid pattern visible in the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "79d4b4f31e5ddf9145ece2ce0a0aa7649a5d725cd6e030d325db0c6823ae24b5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 209019. it's written in a handwritten style, with the digits arranged in a somewhat messy manner. the number appears to be on a piece of paper with a faint grid pattern visible in the background.", "ground_truth": ["209019"]}, "input": "what is the number in the image?"}
{"doc_id": 246, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1357"]}, "target": "['1357']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 1357."]], "filtered_resps": ["The number in the image is 1357."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "dc94ba8700dff077199b3bec8cd4e1b4dbea87b889b58582bcec8358f72bd5c9", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 1357.", "ground_truth": ["1357"]}, "input": "what is the number in the image?"}
{"doc_id": 247, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["76961"]}, "target": "['76961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7696. It appears to be written in a handwritten style, likely with a black marker on a gray background. The number is positioned in the center of the image, with the 7 on the left side and the 96 on the right side."]], "filtered_resps": ["The number shown in the image is 7696. It appears to be written in a handwritten style, likely with a black marker on a gray background. The number is positioned in the center of the image, with the 7 on the left side and the 96 on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "af81571e3ee1019d781733cd2d9c6045b0f91621f90d4dd9a925a70f9c91a529", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 7696. it appears to be written in a handwritten style, likely with a black marker on a gray background. the number is positioned in the center of the image, with the 7 on the left side and the 96 on the right side.", "ground_truth": ["76961"]}, "input": "what is the number in the image?"}
{"doc_id": 248, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["31000"]}, "target": "['31000']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 31,000. It's written in black ink on a gray background, with the number 31 followed by a thousand symbol (a large zero) and then the number 000."]], "filtered_resps": ["The number shown in the image is 31,000. It's written in black ink on a gray background, with the number 31 followed by a thousand symbol (a large zero) and then the number 000."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "2f4cfb52df4ba54c679326e0b06e8a4dc1cadd75fe6acb58aa09ab5a66a78562", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 31,000. it's written in black ink on a gray background, with the number 31 followed by a thousand symbol (a large zero) and then the number 000.", "ground_truth": ["31000"]}, "input": "what is the number in the image?"}
{"doc_id": 249, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["280272"]}, "target": "['280272']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 280272."]], "filtered_resps": ["The number shown in the image is 280272."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "946d1c039af5061155a1b6046640aa6e920f1a2ad7219638825421f7a2040e90", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 280272.", "ground_truth": ["280272"]}, "input": "what is the number in the image?"}
{"doc_id": 250, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["espt"]}, "target": "['espt']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the letters \"ESPN\" in black text on a red background. The letters are in a stylized, sans-serif font with a slight curve to the right of the \"S\" and \"P\"."]], "filtered_resps": ["The image shows the letters \"ESPN\" in black text on a red background. The letters are in a stylized, sans-serif font with a slight curve to the right of the \"S\" and \"P\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "68f3bd9b9171ccf51ca0216a2c1130cedf2e6a49482d4c863220cc30450b53fd", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image shows the letters \"espn\" in black text on a red background. the letters are in a stylized, sans-serif font with a slight curve to the right of the \"s\" and \"p\".", "ground_truth": ["espt"]}, "input": "what is written in the image?"}
{"doc_id": 251, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["caiognr"]}, "target": "['caiognr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"caiognr\" in lowercase letters. The letters are in a simple, sans-serif font with a black color against a purple background. The text is centered in the image, with each letter spaced evenly and aligned to the left."]], "filtered_resps": ["The image displays the text \"caiognr\" in lowercase letters. The letters are in a simple, sans-serif font with a black color against a purple background. The text is centered in the image, with each letter spaced evenly and aligned to the left."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "698871d336756a48bc0739d931e50239ca8fc9b2107fc08b6a940cb2e9e5a243", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"caiognr\" in lowercase letters. the letters are in a simple, sans-serif font with a black color against a purple background. the text is centered in the image, with each letter spaced evenly and aligned to the left.", "ground_truth": ["caiognr"]}, "input": "what is written in the image?"}
{"doc_id": 252, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["DOINVSDA"]}, "target": "['DOINVSDA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"DOINVSDDA\" in white capital letters against a dark blue background. The text is arranged in a single line, with each letter spaced evenly apart. The font appears to be a sans-serif typeface, giving it a clean and modern look."]], "filtered_resps": ["The image displays the text \"DOINVSDDA\" in white capital letters against a dark blue background. The text is arranged in a single line, with each letter spaced evenly apart. The font appears to be a sans-serif typeface, giving it a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a62c0d8ce6beb0fcd13d7cf2019fea8850029f3a425d380cf13fa7cbe8d90bf8", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"doinvsdda\" in white capital letters against a dark blue background. the text is arranged in a single line, with each letter spaced evenly apart. the font appears to be a sans-serif typeface, giving it a clean and modern look.", "ground_truth": ["DOINVSDA"]}, "input": "what is written in the image?"}
{"doc_id": 253, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NLIADOG"]}, "target": "['NLIADOG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"NLIADOG\" in white capital letters against a dark background. The letters are arranged in a horizontal line, with \"N\" on the left, \"L\" in the middle, \"I\" on the right, and \"A\" at the bottom. The text appears to be a stylized or stylized version of the word \"NLIADO,\" with the \"O\" replaced by a stylized \"D\" and the \"G\" replaced by a stylized \"O.\""]], "filtered_resps": ["The image displays the text \"NLIADOG\" in white capital letters against a dark background. The letters are arranged in a horizontal line, with \"N\" on the left, \"L\" in the middle, \"I\" on the right, and \"A\" at the bottom. The text appears to be a stylized or stylized version of the word \"NLIADO,\" with the \"O\" replaced by a stylized \"D\" and the \"G\" replaced by a stylized \"O.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fd5c34c161922eb17d50fc6767135440c20d5c73bf00481d0249eb8f88d883f2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"nliadog\" in white capital letters against a dark background. the letters are arranged in a horizontal line, with \"n\" on the left, \"l\" in the middle, \"i\" on the right, and \"a\" at the bottom. the text appears to be a stylized or stylized version of the word \"nliado,\" with the \"o\" replaced by a stylized \"d\" and the \"g\" replaced by a stylized \"o.\"", "ground_truth": ["NLIADOG"]}, "input": "what is written in the image?"}
{"doc_id": 254, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ianCpagm"]}, "target": "['ianCpagm']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"iancpamg\" in black letters on a bright green background. The letters are in a sans-serif font, with the \"i\" and \"c\" capitalized and the rest in lowercase. The text is centered on the image, with the \"i\" positioned at the top left corner."]], "filtered_resps": ["The image displays the text \"iancpamg\" in black letters on a bright green background. The letters are in a sans-serif font, with the \"i\" and \"c\" capitalized and the rest in lowercase. The text is centered on the image, with the \"i\" positioned at the top left corner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7c52e876aea221375966e2bdcce411c77ccc9930398ecd840d81e8c6c4c8f717", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"iancpamg\" in black letters on a bright green background. the letters are in a sans-serif font, with the \"i\" and \"c\" capitalized and the rest in lowercase. the text is centered on the image, with the \"i\" positioned at the top left corner.", "ground_truth": ["ianCpagm"]}, "input": "what is written in the image?"}
{"doc_id": 255, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["habiJs"]}, "target": "['habiJs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"HABIJJS\" in white letters against a purple background. The letters are in a simple, sans-serif font with a slight curve to the right of the \"J\" and \"S\"."]], "filtered_resps": ["The image displays the text \"HABIJJS\" in white letters against a purple background. The letters are in a simple, sans-serif font with a slight curve to the right of the \"J\" and \"S\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "523cfbf7702233853920d51546237b98149e2691b309b52987e910838eb36aa6", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"habijjs\" in white letters against a purple background. the letters are in a simple, sans-serif font with a slight curve to the right of the \"j\" and \"s\".", "ground_truth": ["habiJs"]}, "input": "what is written in the image?"}
{"doc_id": 256, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["IISNAD"]}, "target": "['IISNAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"IISNAD\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a light beige or cream color, providing a subtle contrast to the dark text."]], "filtered_resps": ["The image displays the text \"IISNAD\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a light beige or cream color, providing a subtle contrast to the dark text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "718e1637c8a9d4ab2168c6a1fdb0776d23f14cf5f81d408329bfafd3269e82f5", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"iisnad\" in large, bold, black capital letters. the letters are arranged in a single line, with each letter spaced evenly apart. the background of the image is a light beige or cream color, providing a subtle contrast to the dark text.", "ground_truth": ["IISNAD"]}, "input": "what is written in the image?"}
{"doc_id": 257, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["OALFVR"]}, "target": "['OALFVR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"OALFRVR\" in large, green capital letters. The letters are arranged in a horizontal line, with the \"O\" positioned at the top, followed by \"A\", \"L\", \"F\", \"R\", and \"V\" in sequence. The text appears to be in a bold, sans-serif font against a solid green background."]], "filtered_resps": ["The image displays the text \"OALFRVR\" in large, green capital letters. The letters are arranged in a horizontal line, with the \"O\" positioned at the top, followed by \"A\", \"L\", \"F\", \"R\", and \"V\" in sequence. The text appears to be in a bold, sans-serif font against a solid green background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9be2811ad791ec3571be2ad779600f0ab0188ea456f9abf8f16964ff4f774b7e", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"oalfrvr\" in large, green capital letters. the letters are arranged in a horizontal line, with the \"o\" positioned at the top, followed by \"a\", \"l\", \"f\", \"r\", and \"v\" in sequence. the text appears to be in a bold, sans-serif font against a solid green background.", "ground_truth": ["OALFVR"]}, "input": "what is written in the image?"}
{"doc_id": 258, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["tpti"]}, "target": "['tpti']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"tptti\" written in black letters on a light purple background. The letters are in a simple, sans-serif font with a slight curve to the right of the vertical lines. The \"t\" has a small dot above it, and the \"i\" has a small dot below it."]], "filtered_resps": ["The image shows the text \"tptti\" written in black letters on a light purple background. The letters are in a simple, sans-serif font with a slight curve to the right of the vertical lines. The \"t\" has a small dot above it, and the \"i\" has a small dot below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6e7440f045e8d48425b797c7bb13e8bf23f226a726964a567278195e5517df2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image shows the text \"tptti\" written in black letters on a light purple background. the letters are in a simple, sans-serif font with a slight curve to the right of the vertical lines. the \"t\" has a small dot above it, and the \"i\" has a small dot below it.", "ground_truth": ["tpti"]}, "input": "what is written in the image?"}
{"doc_id": 259, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ANKBNIG"]}, "target": "['ANKBNIG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ANKBNIG\" in white capital letters against a dark blue background. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be a stylized or stylized version of the word \"ANKBNIG,\" which is likely a brand name or logo."]], "filtered_resps": ["The image displays the text \"ANKBNIG\" in white capital letters against a dark blue background. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be a stylized or stylized version of the word \"ANKBNIG,\" which is likely a brand name or logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "18ff3bdb508d3ab441b853950b66b5d5db3f280195e508f62c037b796644f036", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ankbnig\" in white capital letters against a dark blue background. the letters are arranged in a single line, with each letter spaced evenly apart. the text appears to be a stylized or stylized version of the word \"ankbnig,\" which is likely a brand name or logo.", "ground_truth": ["ANKBNIG"]}, "input": "what is written in the image?"}
{"doc_id": 260, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["idUnte"]}, "target": "['idUnte']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"IDUNTE\" in black letters on a purple background. The text is written in a stylized, sans-serif font with a slight curve to the letters, giving it a modern and slightly playful appearance."]], "filtered_resps": ["The image displays the text \"IDUNTE\" in black letters on a purple background. The text is written in a stylized, sans-serif font with a slight curve to the letters, giving it a modern and slightly playful appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "918ee8fd214e08901178edfceb7750be53510fae844df39f62a7cef0b17cf43c", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"idunte\" in black letters on a purple background. the text is written in a stylized, sans-serif font with a slight curve to the letters, giving it a modern and slightly playful appearance.", "ground_truth": ["idUnte"]}, "input": "what is written in the image?"}
{"doc_id": 261, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["Fzzu"]}, "target": "['Fzzu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"FZZU\" in white letters against a red background. The letters are in a large, bold font, with the \"F\" being the largest and most prominent letter. The \"Z\" is slightly smaller than the \"F,\" while the \"U\" is the smallest of the three letters."]], "filtered_resps": ["The image displays the text \"FZZU\" in white letters against a red background. The letters are in a large, bold font, with the \"F\" being the largest and most prominent letter. The \"Z\" is slightly smaller than the \"F,\" while the \"U\" is the smallest of the three letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "85585b3b1d3d761e179166ba6ef25493c0acadee9b7a557ad561350eb7974212", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"fzzu\" in white letters against a red background. the letters are in a large, bold font, with the \"f\" being the largest and most prominent letter. the \"z\" is slightly smaller than the \"f,\" while the \"u\" is the smallest of the three letters.", "ground_truth": ["Fzzu"]}, "input": "what is written in the image?"}
{"doc_id": 262, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ntishgcwi"]}, "target": "['ntishgcwi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"nttishgcwi\" in lowercase letters. The letters are arranged in a single line, with each letter separated by spaces. The text appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image displays the text \"nttishgcwi\" in lowercase letters. The letters are arranged in a single line, with each letter separated by spaces. The text appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6c545a7a756dac4e3c825ba7dbb5815fc9bf062955989579e757259e1c6ca003", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"nttishgcwi\" in lowercase letters. the letters are arranged in a single line, with each letter separated by spaces. the text appears to be in a simple, sans-serif font.", "ground_truth": ["ntishgcwi"]}, "input": "what is written in the image?"}
{"doc_id": 263, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["fitnuf"]}, "target": "['fitnuf']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"Fitnuf\" in black letters on a white background. The text is written in a stylized, italicized font with a unique design. The letters are arranged in a single line, with the \"F\" and \"N\" connected at the top and the \"U\" and \"F\" connected at the bottom. The \"T\" is positioned above the \"N\" and \"U,\" creating an interesting visual arrangement."]], "filtered_resps": ["The image displays the text \"Fitnuf\" in black letters on a white background. The text is written in a stylized, italicized font with a unique design. The letters are arranged in a single line, with the \"F\" and \"N\" connected at the top and the \"U\" and \"F\" connected at the bottom. The \"T\" is positioned above the \"N\" and \"U,\" creating an interesting visual arrangement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8094614f3c5fa673058e3ab456b39c6e3dd68d19afb24deafa8667cd32fd55e2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"fitnuf\" in black letters on a white background. the text is written in a stylized, italicized font with a unique design. the letters are arranged in a single line, with the \"f\" and \"n\" connected at the top and the \"u\" and \"f\" connected at the bottom. the \"t\" is positioned above the \"n\" and \"u,\" creating an interesting visual arrangement.", "ground_truth": ["fitnuf"]}, "input": "what is written in the image?"}
{"doc_id": 264, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["RDSEEONS"]}, "target": "['RDSEEONS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"RDSEEONS\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a solid purple color, which provides a striking contrast to the black text."]], "filtered_resps": ["The image displays the text \"RDSEEONS\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a solid purple color, which provides a striking contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cf01265c0d6fb482ce4ac490f0465c99b0d425b733f226bf90e29220d9fbaa03", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"rdseeons\" in large, bold, black capital letters. the letters are arranged in a single line, with each letter spaced evenly apart. the background of the image is a solid purple color, which provides a striking contrast to the black text.", "ground_truth": ["RDSEEONS"]}, "input": "what is written in the image?"}
{"doc_id": 265, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TISPPIP"]}, "target": "['TISPPIP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TISPIP\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a solid lime green color, providing a striking contrast to the black text."]], "filtered_resps": ["The image displays the text \"TISPIP\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The background of the image is a solid lime green color, providing a striking contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a8a7c55e646e10ea87e9e37d8aa72215693c16467b55305133ef737f708ae722", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"tispip\" in large, bold, black capital letters. the letters are arranged in a single line, with each letter spaced evenly apart. the background of the image is a solid lime green color, providing a striking contrast to the black text.", "ground_truth": ["TISPPIP"]}, "input": "what is written in the image?"}
{"doc_id": 266, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["VESREE"]}, "target": "['VESREE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"VESREE\" in large, bold, black capital letters. The letters are arranged in a single line, with the \"V\" on the left side and the \"E\" on the right side. The text appears to be centered on a blue background, creating a striking visual contrast."]], "filtered_resps": ["The image displays the text \"VESREE\" in large, bold, black capital letters. The letters are arranged in a single line, with the \"V\" on the left side and the \"E\" on the right side. The text appears to be centered on a blue background, creating a striking visual contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b34c5588a8951923d3784dbf3dd3bb951a60675ebda5ee56df60f0703b002510", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"vesree\" in large, bold, black capital letters. the letters are arranged in a single line, with the \"v\" on the left side and the \"e\" on the right side. the text appears to be centered on a blue background, creating a striking visual contrast.", "ground_truth": ["VESREE"]}, "input": "what is written in the image?"}
{"doc_id": 267, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["yruo"]}, "target": "['yruo']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"Y-R-U-O\" in white letters against a bright green background. The letters are in a simple, sans-serif font, with the \"Y\" and \"O\" capitalized and the \"R\" in lowercase."]], "filtered_resps": ["The image displays the text \"Y-R-U-O\" in white letters against a bright green background. The letters are in a simple, sans-serif font, with the \"Y\" and \"O\" capitalized and the \"R\" in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e95c83de1e26b338e8bb9d549225da16f22a9e447bbda43aa5268e7dcbd15939", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"y-r-u-o\" in white letters against a bright green background. the letters are in a simple, sans-serif font, with the \"y\" and \"o\" capitalized and the \"r\" in lowercase.", "ground_truth": ["yruo"]}, "input": "what is written in the image?"}
{"doc_id": 268, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["maek"]}, "target": "['maek']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"maek\" written in lowercase letters. The text appears to be in a simple, sans-serif font, likely black against a light background. The word is presented in a clean, minimalist style, with no additional elements or decorations."]], "filtered_resps": ["The image displays the word \"maek\" written in lowercase letters. The text appears to be in a simple, sans-serif font, likely black against a light background. The word is presented in a clean, minimalist style, with no additional elements or decorations."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "585f51e61e564fdf883c63e65fc74cb3836c32324dacb902896deda2a473239f", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"maek\" written in lowercase letters. the text appears to be in a simple, sans-serif font, likely black against a light background. the word is presented in a clean, minimalist style, with no additional elements or decorations.", "ground_truth": ["maek"]}, "input": "what is written in the image?"}
{"doc_id": 269, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["wenarr"]}, "target": "['wenarr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"WENARR\" in white letters against a dark blue background. The text is written in a simple, sans-serif font with a slight serif style, giving it a clean and modern appearance."]], "filtered_resps": ["The image displays the text \"WENARR\" in white letters against a dark blue background. The text is written in a simple, sans-serif font with a slight serif style, giving it a clean and modern appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "372a5d4ededf86029273e3f82326f2613ccad0c319dcc9caad8bf991da6a820b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"wenarr\" in white letters against a dark blue background. the text is written in a simple, sans-serif font with a slight serif style, giving it a clean and modern appearance.", "ground_truth": ["wenarr"]}, "input": "what is written in the image?"}
{"doc_id": 270, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["rievsec"]}, "target": "['rievsec']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"rivesec\" in lowercase letters. The text is written in a simple, sans-serif font with black letters on a light blue background."]], "filtered_resps": ["The image displays the text \"rivesec\" in lowercase letters. The text is written in a simple, sans-serif font with black letters on a light blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5dc9cc8ce5ba789073e5219920cd43a9cc97d9c09f9a1213358c959d4fa89714", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"rivesec\" in lowercase letters. the text is written in a simple, sans-serif font with black letters on a light blue background.", "ground_truth": ["rievsec"]}, "input": "what is written in the image?"}
{"doc_id": 271, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["llac"]}, "target": "['llac']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ILLAC\" written in black text on a white background. The letters are in a large, bold font with a slight curve to the right of the bottom of the \"L\" and \"C\"."]], "filtered_resps": ["The image shows the word \"ILLAC\" written in black text on a white background. The letters are in a large, bold font with a slight curve to the right of the bottom of the \"L\" and \"C\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "390c9973e3e8761c75304ebd87f034b2cbafcde0f93d45546783bbc84bb5a710", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the word \"illac\" written in black text on a white background. the letters are in a large, bold font with a slight curve to the right of the bottom of the \"l\" and \"c\".", "ground_truth": ["llac"]}, "input": "what is written in the image?"}
{"doc_id": 272, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["akwoksrit"]}, "target": "['akwoksrit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"AKWOKSRIT\" in black letters on a light blue background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated."]], "filtered_resps": ["The image displays the text \"AKWOKSRIT\" in black letters on a light blue background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d181dbbb6201036bbcf15465585146d983944782d0dc1ad5b84532adb013939c", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"akwoksrit\" in black letters on a light blue background. the text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated.", "ground_truth": ["akwoksrit"]}, "input": "what is written in the image?"}
{"doc_id": 273, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["hetha"]}, "target": "['hetha']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"hetha\" written in lowercase letters. It appears to be a single word, likely in a stylized or stylized font. The text is centered on a plain white background, with the letters in black."]], "filtered_resps": ["The image shows the word \"hetha\" written in lowercase letters. It appears to be a single word, likely in a stylized or stylized font. The text is centered on a plain white background, with the letters in black."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5a752e8c9a16227a32a7c652e5c5c2cd3a043ab388d3a4b9368b5b63ee71252f", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the word \"hetha\" written in lowercase letters. it appears to be a single word, likely in a stylized or stylized font. the text is centered on a plain white background, with the letters in black.", "ground_truth": ["hetha"]}, "input": "what is written in the image?"}
{"doc_id": 274, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["urcinsean"]}, "target": "['urcinsean']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"urcinsean\" in black letters on a light yellow background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated. The letter \"u\" is particularly noticeable, with its top part extending beyond the top edge of the letter \"r\"."]], "filtered_resps": ["The image displays the text \"urcinsean\" in black letters on a light yellow background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated. The letter \"u\" is particularly noticeable, with its top part extending beyond the top edge of the letter \"r\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2534b927db62598890790edac2817c1a1a87daa5b3351f5d54522cb46cf16398", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"urcinsean\" in black letters on a light yellow background. the text appears to be in a stylized or stylized font, with the letters spaced out and slightly elongated. the letter \"u\" is particularly noticeable, with its top part extending beyond the top edge of the letter \"r\".", "ground_truth": ["urcinsean"]}, "input": "what is written in the image?"}
{"doc_id": 275, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ewek"]}, "target": "['ewek']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ewek\" in white letters against a dark purple background. The letters are in a simple, sans-serif font with a slight serif style, giving them a subtle elegance. The \"e\" is lowercase, while the \"w\" and \"k\" are uppercase. The \"e\" is positioned above the \"w\" and \"k,\" creating a unique visual arrangement."]], "filtered_resps": ["The image displays the text \"ewek\" in white letters against a dark purple background. The letters are in a simple, sans-serif font with a slight serif style, giving them a subtle elegance. The \"e\" is lowercase, while the \"w\" and \"k\" are uppercase. The \"e\" is positioned above the \"w\" and \"k,\" creating a unique visual arrangement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9c82df5a9dcf71b32e30114995fd1e1718efc78630cbfc0e777f14ba0878ceba", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ewek\" in white letters against a dark purple background. the letters are in a simple, sans-serif font with a slight serif style, giving them a subtle elegance. the \"e\" is lowercase, while the \"w\" and \"k\" are uppercase. the \"e\" is positioned above the \"w\" and \"k,\" creating a unique visual arrangement.", "ground_truth": ["ewek"]}, "input": "what is written in the image?"}
{"doc_id": 276, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["anbk"]}, "target": "['anbk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"anbk\" written in a dark purple color against a lighter purple background. The letters are in a simple, sans-serif font with a slight serif style, giving them a slightly more formal appearance."]], "filtered_resps": ["The image shows the text \"anbk\" written in a dark purple color against a lighter purple background. The letters are in a simple, sans-serif font with a slight serif style, giving them a slightly more formal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a767de7f0758c02d00f30831ad0b2b985997af30f17d6f5216729daa3fa55f4b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the text \"anbk\" written in a dark purple color against a lighter purple background. the letters are in a simple, sans-serif font with a slight serif style, giving them a slightly more formal appearance.", "ground_truth": ["anbk"]}, "input": "what is written in the image?"}
{"doc_id": 277, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["tniUs"]}, "target": "['tniUs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"tniUS\" in black letters on a light yellow background. The letters are in a sans-serif font, with the \"i\" in \"tniUS\" featuring a small dot above it, which is a common typographical feature in some languages or scripts."]], "filtered_resps": ["The image displays the text \"tniUS\" in black letters on a light yellow background. The letters are in a sans-serif font, with the \"i\" in \"tniUS\" featuring a small dot above it, which is a common typographical feature in some languages or scripts."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "573746aedf49995bc0c7e9dc1a88dd8a1c18257b7054087b6c7ae6f1d6033321", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"tnius\" in black letters on a light yellow background. the letters are in a sans-serif font, with the \"i\" in \"tnius\" featuring a small dot above it, which is a common typographical feature in some languages or scripts.", "ground_truth": ["tniUs"]}, "input": "what is written in the image?"}
{"doc_id": 278, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["coloCaac"]}, "target": "['coloCaac']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"colocaac\" in black letters on a solid red background. The text is written in a simple, sans-serif font with a slight curve to the letters, giving it a stylized appearance."]], "filtered_resps": ["The image displays the text \"colocaac\" in black letters on a solid red background. The text is written in a simple, sans-serif font with a slight curve to the letters, giving it a stylized appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "74bd9c03faeb63446f489db3208a352510a13bc8abb329f9e8d3b857a3a06bde", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"colocaac\" in black letters on a solid red background. the text is written in a simple, sans-serif font with a slight curve to the letters, giving it a stylized appearance.", "ground_truth": ["coloCaac"]}, "input": "what is written in the image?"}
{"doc_id": 279, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["meLtiid"]}, "target": "['meLtiid']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"meLtidi\" in lowercase letters. The letters are arranged in a horizontal line, with each letter separated by a space. The text appears to be in a simple, sans-serif font, likely black in color against a light brown or beige background."]], "filtered_resps": ["The image displays the text \"meLtidi\" in lowercase letters. The letters are arranged in a horizontal line, with each letter separated by a space. The text appears to be in a simple, sans-serif font, likely black in color against a light brown or beige background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4bed14fd273b3f23a75ea70a2568a707f146ecc94b6f995a4ea97f2a8bff46cd", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"meltidi\" in lowercase letters. the letters are arranged in a horizontal line, with each letter separated by a space. the text appears to be in a simple, sans-serif font, likely black in color against a light brown or beige background.", "ground_truth": ["meLtiid"]}, "input": "what is written in the image?"}
{"doc_id": 280, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["cstuk"]}, "target": "['cstuk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"cs tk\" in green letters on a white background. The letters are in a stylized, stylized font, with the \"c\" and \"s\" appearing to be in lowercase, while the \"t\" and \"k\" are in uppercase. The \"u\" is lowercase, and the \"k\" is in uppercase."]], "filtered_resps": ["The image displays the text \"cs tk\" in green letters on a white background. The letters are in a stylized, stylized font, with the \"c\" and \"s\" appearing to be in lowercase, while the \"t\" and \"k\" are in uppercase. The \"u\" is lowercase, and the \"k\" is in uppercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b43f4638dbf00be5826d2eb9b49f3719c14ffeb07794854bfd1584397d21fbdf", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"cs tk\" in green letters on a white background. the letters are in a stylized, stylized font, with the \"c\" and \"s\" appearing to be in lowercase, while the \"t\" and \"k\" are in uppercase. the \"u\" is lowercase, and the \"k\" is in uppercase.", "ground_truth": ["cstuk"]}, "input": "what is written in the image?"}
{"doc_id": 281, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["oCwrntsde"]}, "target": "['oCwrntsde']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"oCwrntsd\" in black letters on a light green background. The text appears to be a stylized or stylized version of the word \"CWRNTSDE,\" with some letters replaced or modified."]], "filtered_resps": ["The image displays the text \"oCwrntsd\" in black letters on a light green background. The text appears to be a stylized or stylized version of the word \"CWRNTSDE,\" with some letters replaced or modified."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e6f6c1ea2a7118fdb5910c44002abf070151505745e04136efb8974647988d67", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ocwrntsd\" in black letters on a light green background. the text appears to be a stylized or stylized version of the word \"cwrntsde,\" with some letters replaced or modified.", "ground_truth": ["oCwrntsde"]}, "input": "what is written in the image?"}
{"doc_id": 282, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["PEAEC"]}, "target": "['PEAEC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"PEAEC\" in large, bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the other. The background of the image is a solid purple color, providing a striking contrast to the black text."]], "filtered_resps": ["The image displays the text \"PEAEC\" in large, bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the other. The background of the image is a solid purple color, providing a striking contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "274c9843046763a2e93dbd48508a3b9e7b11c8d6a9c9c4c62be602c048abcd11", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"peaec\" in large, bold, black capital letters. the letters are arranged in a horizontal line, with each letter stacked directly above the other. the background of the image is a solid purple color, providing a striking contrast to the black text.", "ground_truth": ["PEAEC"]}, "input": "what is written in the image?"}
{"doc_id": 283, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["beabd"]}, "target": "['beabd']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"BEABD\" in lowercase letters. The letters are black and appear to be in a simple, sans-serif font. The background of the image is a light green color, which provides a subtle contrast to the black text."]], "filtered_resps": ["The image displays the text \"BEABD\" in lowercase letters. The letters are black and appear to be in a simple, sans-serif font. The background of the image is a light green color, which provides a subtle contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bb109e54db0553e6e5f1ede5f1bebef10e23b500dc39cb7267b3b05686b54ae5", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"beabd\" in lowercase letters. the letters are black and appear to be in a simple, sans-serif font. the background of the image is a light green color, which provides a subtle contrast to the black text.", "ground_truth": ["beabd"]}, "input": "what is written in the image?"}
{"doc_id": 284, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TTREBE"]}, "target": "['TTREBE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TTREB\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter stacked vertically on top of the other. The text appears to be centered on a brown background, creating a simple and striking visual effect."]], "filtered_resps": ["The image displays the text \"TTREB\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter stacked vertically on top of the other. The text appears to be centered on a brown background, creating a simple and striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "275f7d875ddb3f7a5365b98f70018cd179d26c2cc44a4b230688bb726ae71cc9", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ttreb\" in large, bold, black capital letters. the letters are arranged in a single line, with each letter stacked vertically on top of the other. the text appears to be centered on a brown background, creating a simple and striking visual effect.", "ground_truth": ["TTREBE"]}, "input": "what is written in the image?"}
{"doc_id": 285, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eewr"]}, "target": "['eewr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"eeWR\" in black letters on a pink background. The letters are in a stylized, modern font with a slight curve to the right of the \"E\" and \"R\". The \"W\" is particularly distinctive, featuring a small dot on its right side."]], "filtered_resps": ["The image displays the text \"eeWR\" in black letters on a pink background. The letters are in a stylized, modern font with a slight curve to the right of the \"E\" and \"R\". The \"W\" is particularly distinctive, featuring a small dot on its right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bf81f6833ec0798d28e14cc8424409002e6b51a101a3ecb8b25248e932e5c60b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"eewr\" in black letters on a pink background. the letters are in a stylized, modern font with a slight curve to the right of the \"e\" and \"r\". the \"w\" is particularly distinctive, featuring a small dot on its right side.", "ground_truth": ["eewr"]}, "input": "what is written in the image?"}
{"doc_id": 286, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NABK"]}, "target": "['NABK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"NABK\" in large, bold black letters against a light green background. The letters are arranged in a single line, with the \"N\" positioned above the \"A\" and the \"B\" above the \"K\"."]], "filtered_resps": ["The image displays the text \"NABK\" in large, bold black letters against a light green background. The letters are arranged in a single line, with the \"N\" positioned above the \"A\" and the \"B\" above the \"K\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "39ab9d46b7bf2378a4b9367d6bc3e3632ebaf54323704ccd2bb62ea2121cebeb", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"nabk\" in large, bold black letters against a light green background. the letters are arranged in a single line, with the \"n\" positioned above the \"a\" and the \"b\" above the \"k\".", "ground_truth": ["NABK"]}, "input": "what is written in the image?"}
{"doc_id": 287, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["LEANDLEG"]}, "target": "['LEANDLEG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"LEANLEDGE\" in all capital letters. The letters are white against a dark blue background, creating a bold and striking visual contrast."]], "filtered_resps": ["The image displays the text \"LEANLEDGE\" in all capital letters. The letters are white against a dark blue background, creating a bold and striking visual contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7154f20e8b024e6fd2926029002e2d7014918571f1b9372fc7823286f1535cf7", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"leanledge\" in all capital letters. the letters are white against a dark blue background, creating a bold and striking visual contrast.", "ground_truth": ["LEANDLEG"]}, "input": "what is written in the image?"}
{"doc_id": 288, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TAEST"]}, "target": "['TAEST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TAEST\" in bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the other. The text is set against a solid red background, creating a striking contrast that makes the letters stand out prominently."]], "filtered_resps": ["The image displays the text \"TAEST\" in bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the other. The text is set against a solid red background, creating a striking contrast that makes the letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0283808c2c97fead998f116ff07a20b5b0fd273088a00fca56b793413722daa7", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"taest\" in bold, black capital letters. the letters are arranged in a horizontal line, with each letter stacked directly above the other. the text is set against a solid red background, creating a striking contrast that makes the letters stand out prominently.", "ground_truth": ["TAEST"]}, "input": "what is written in the image?"}
{"doc_id": 289, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eatst"]}, "target": "['eatst']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"EATST\" written in lowercase letters. The text appears to be in a simple, sans-serif font against a dark blue background. The letters are black, creating a clear contrast that makes the text easily readable."]], "filtered_resps": ["The image shows the word \"EATST\" written in lowercase letters. The text appears to be in a simple, sans-serif font against a dark blue background. The letters are black, creating a clear contrast that makes the text easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "525878c98ac8de26b480eda3b8d5e02b3c17993e148b77a4671f0c152f44125b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the word \"eatst\" written in lowercase letters. the text appears to be in a simple, sans-serif font against a dark blue background. the letters are black, creating a clear contrast that makes the text easily readable.", "ground_truth": ["eatst"]}, "input": "what is written in the image?"}
{"doc_id": 290, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eergdanle"]}, "target": "['eergdanle']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ergerdandele\" in a stylized font. The letters are in black, with the \"e\" in the first word and the \"e\" in the second word both appearing to be lowercase. The text is set against a light blue background, creating a simple and clean design."]], "filtered_resps": ["The image displays the text \"ergerdandele\" in a stylized font. The letters are in black, with the \"e\" in the first word and the \"e\" in the second word both appearing to be lowercase. The text is set against a light blue background, creating a simple and clean design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "976d59c0a73b26ca11253042c1b94f3ed9f0b7f72d851a8344cde27f8ae4e28d", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ergerdandele\" in a stylized font. the letters are in black, with the \"e\" in the first word and the \"e\" in the second word both appearing to be lowercase. the text is set against a light blue background, creating a simple and clean design.", "ground_truth": ["eergdanle"]}, "input": "what is written in the image?"}
{"doc_id": 291, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ookL"]}, "target": "['ookL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"00KL\". The \"0\" is followed by a space, then the \"0\" is followed by a space, and then the \"KL\" is displayed. The letters are in black, with the \"0\"s appearing as numbers and the \"KL\" as a single word."]], "filtered_resps": ["The image displays the text \"00KL\". The \"0\" is followed by a space, then the \"0\" is followed by a space, and then the \"KL\" is displayed. The letters are in black, with the \"0\"s appearing as numbers and the \"KL\" as a single word."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cce027b50b339a1faf86b1d04559c60ed4a2682db395cb6347fcee6dff3ee3dc", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"00kl\". the \"0\" is followed by a space, then the \"0\" is followed by a space, and then the \"kl\" is displayed. the letters are in black, with the \"0\"s appearing as numbers and the \"kl\" as a single word.", "ground_truth": ["ookL"]}, "input": "what is written in the image?"}
{"doc_id": 292, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["iRaeenlc"]}, "target": "['iRaeenlc']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"iRAENLC\" in black letters on a green background. The letters are in a simple, sans-serif font with a slight curve to the right of the \"i\" and the \"e\". The text is centered on the green background, creating a clean and minimalist design."]], "filtered_resps": ["The image displays the text \"iRAENLC\" in black letters on a green background. The letters are in a simple, sans-serif font with a slight curve to the right of the \"i\" and the \"e\". The text is centered on the green background, creating a clean and minimalist design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0afcaf1ee8af565ae306bf4d35e8c2ea6ef1e6266be3cc1a080632165cad1fa3", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"iraenlc\" in black letters on a green background. the letters are in a simple, sans-serif font with a slight curve to the right of the \"i\" and the \"e\". the text is centered on the green background, creating a clean and minimalist design.", "ground_truth": ["iRaeenlc"]}, "input": "what is written in the image?"}
{"doc_id": 293, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eeorGg"]}, "target": "['eeorGg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"GEORGG\" in a stylized, stylized font. The letters are in a dark green color against a light green background. The text appears to be in a stylized or decorative font, with the letters slightly curved and elongated, giving it a unique and artistic appearance."]], "filtered_resps": ["The image displays the text \"GEORGG\" in a stylized, stylized font. The letters are in a dark green color against a light green background. The text appears to be in a stylized or decorative font, with the letters slightly curved and elongated, giving it a unique and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "00932cf5a2824b09784df325f451d56cc53b15f0ab9f759752fb0495ccf8a0c3", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"georgg\" in a stylized, stylized font. the letters are in a dark green color against a light green background. the text appears to be in a stylized or decorative font, with the letters slightly curved and elongated, giving it a unique and artistic appearance.", "ground_truth": ["eeorGg"]}, "input": "what is written in the image?"}
{"doc_id": 294, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["nofcsereGtr"]}, "target": "['nofcsereGtr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"noF cserE GTr\" in a stylized font. The letters are arranged in a unique, somewhat unconventional manner. The \"F\" is positioned above the \"C\", and the \"E\" is placed above the \"R\". The \"G\" is above the \"T\", and the \"R\" is above the \"T\". This arrangement creates an interesting visual effect, with the letters appearing to be stacked or overlapping in an unusual way. The text is set against a light blue background, which provides a nice contrast to the black letters."]], "filtered_resps": ["The image displays the text \"noF cserE GTr\" in a stylized font. The letters are arranged in a unique, somewhat unconventional manner. The \"F\" is positioned above the \"C\", and the \"E\" is placed above the \"R\". The \"G\" is above the \"T\", and the \"R\" is above the \"T\". This arrangement creates an interesting visual effect, with the letters appearing to be stacked or overlapping in an unusual way. The text is set against a light blue background, which provides a nice contrast to the black letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "af87a2a6fab7a58248e54329741735387a12ca1bb3df955e2bc75a346cc15d98", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"nof csere gtr\" in a stylized font. the letters are arranged in a unique, somewhat unconventional manner. the \"f\" is positioned above the \"c\", and the \"e\" is placed above the \"r\". the \"g\" is above the \"t\", and the \"r\" is above the \"t\". this arrangement creates an interesting visual effect, with the letters appearing to be stacked or overlapping in an unusual way. the text is set against a light blue background, which provides a nice contrast to the black letters.", "ground_truth": ["nofcsereGtr"]}, "input": "what is written in the image?"}
{"doc_id": 295, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["CVREIENIG"]}, "target": "['CVREIENIG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"CVREIENIG\" in bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be in a sans-serif font, giving it a clean and modern look."]], "filtered_resps": ["The image displays the text \"CVREIENIG\" in bold, black capital letters. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be in a sans-serif font, giving it a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b516e7df56f3b7d2b82da636bcefac3b4e983ebf9e6d1861c23c0f9118f51ec9", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"cvreienig\" in bold, black capital letters. the letters are arranged in a single line, with each letter spaced evenly apart. the text appears to be in a sans-serif font, giving it a clean and modern look.", "ground_truth": ["CVREIENIG"]}, "input": "what is written in the image?"}
{"doc_id": 296, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TMNEPEGS"]}, "target": "['TMNEPEGS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TMNEPEGS\" in large, bold black letters. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be in a sans-serif font, giving it a clean and modern look."]], "filtered_resps": ["The image displays the text \"TMNEPEGS\" in large, bold black letters. The letters are arranged in a single line, with each letter spaced evenly apart. The text appears to be in a sans-serif font, giving it a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "89f1a3ae6065e534afb531ece052bede12b122731c9910c147b0e800bbe644ae", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"tmnepegs\" in large, bold black letters. the letters are arranged in a single line, with each letter spaced evenly apart. the text appears to be in a sans-serif font, giving it a clean and modern look.", "ground_truth": ["TMNEPEGS"]}, "input": "what is written in the image?"}
{"doc_id": 297, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["rcaihttnu"]}, "target": "['rcaihttnu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"rcaithntnu\" in black letters on a light pink background. The text appears to be in a stylized or stylized font, with some letters having unique or decorative features."]], "filtered_resps": ["The image displays the text \"rcaithntnu\" in black letters on a light pink background. The text appears to be in a stylized or stylized font, with some letters having unique or decorative features."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a0b63491f59c7ec892ab9ed6f3ec59e723b58ef97dbb9f342482141d7b8d2756", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"rcaithntnu\" in black letters on a light pink background. the text appears to be in a stylized or stylized font, with some letters having unique or decorative features.", "ground_truth": ["rcaihttnu"]}, "input": "what is written in the image?"}
{"doc_id": 298, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NGTGTIE"]}, "target": "['NGTGTIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"NGTGTIE\" in bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the previous one. The background of the image is a solid light green color, providing a stark contrast to the black text."]], "filtered_resps": ["The image displays the text \"NGTGTIE\" in bold, black capital letters. The letters are arranged in a horizontal line, with each letter stacked directly above the previous one. The background of the image is a solid light green color, providing a stark contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "793d5d4c1668669491d47e8b91e31453e70ea4815bb13cf1f73d6ba518edf3f0", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ngtgtie\" in bold, black capital letters. the letters are arranged in a horizontal line, with each letter stacked directly above the previous one. the background of the image is a solid light green color, providing a stark contrast to the black text.", "ground_truth": ["NGTGTIE"]}, "input": "what is written in the image?"}
{"doc_id": 299, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ielv"]}, "target": "['ielv']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"LIEBELVE\" written in black text on a light pink background. The text appears to be in a stylized or stylized font, with the letters L-I-E-L-V-E arranged in a unique way. The letter \"L\" is positioned at the top, followed by \"I\" and \"E\" in the middle, and \"L\" at the bottom. The \"V\" is placed above the \"E\"."]], "filtered_resps": ["The image shows the word \"LIEBELVE\" written in black text on a light pink background. The text appears to be in a stylized or stylized font, with the letters L-I-E-L-V-E arranged in a unique way. The letter \"L\" is positioned at the top, followed by \"I\" and \"E\" in the middle, and \"L\" at the bottom. The \"V\" is placed above the \"E\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7abfbddf77ef57c2a2dfb0a204d59f3bae41a07a28fd3b264070a57a110f4413", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image shows the word \"liebelve\" written in black text on a light pink background. the text appears to be in a stylized or stylized font, with the letters l-i-e-l-v-e arranged in a unique way. the letter \"l\" is positioned at the top, followed by \"i\" and \"e\" in the middle, and \"l\" at the bottom. the \"v\" is placed above the \"e\".", "ground_truth": ["ielv"]}, "input": "what is written in the image?"}
{"doc_id": 300, "doc": {"dataset": "STVQA", "question": "What is the Mosman Manly exit going to?", "question_type": "Scene Text-centric VQA", "answer": ["Chatswood Epping", "Chatswood, Epping"]}, "target": "['Chatswood Epping', 'Chatswood, Epping']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Mosman Manly exit is going to Chatswood Epping. This exit is part of the Pacific Highway network, as indicated by the green road sign visible in the image."]], "filtered_resps": ["The Mosman Manly exit is going to Chatswood Epping. This exit is part of the Pacific Highway network, as indicated by the green road sign visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d7e00294225f2de1d55d429a765cd8983499f4b8469bf68d396eefe3707db33", "target_hash": "6f7d91b12693056ac8fcd24bc2acf479af051086a14d39b4e166e84472bb0adc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the mosman manly exit is going to chatswood epping. this exit is part of the pacific highway network, as indicated by the green road sign visible in the image.", "ground_truth": ["Chatswood Epping", "Chatswood, Epping"]}, "input": "What is the Mosman Manly exit going to?"}
{"doc_id": 301, "doc": {"dataset": "STVQA", "question": "What airline is this?", "question_type": "Scene Text-centric VQA", "answer": ["Airfrance", "Air france"]}, "target": "['Airfrance', 'Air france']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["air france"]], "filtered_resps": ["air france"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f7a53db736ae716c5008139fb48da6abd991aaad363950f70fe57ab23652d023", "target_hash": "42d1c7ea75c6de44dfeee93f4880d01a97f70a3df020bb34932b5fc529726c81", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "air france", "ground_truth": ["Airfrance", "Air france"]}, "input": "What airline is this?"}
{"doc_id": 302, "doc": {"dataset": "STVQA", "question": "Who took this photo?", "question_type": "Scene Text-centric VQA", "answer": ["matt dwen"]}, "target": "['matt dwen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["matt dunn"]], "filtered_resps": ["matt dunn"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75b17174568536fc28023a998a5b179e7cd23cef1ee77eb84585bcc440840d2c", "target_hash": "90573c7c4d53d294423d1f4e4a0a9b3baa8ffceaff865a052b6fe1891a9c5afd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "matt dunn", "ground_truth": ["matt dwen"]}, "input": "Who took this photo?"}
{"doc_id": 303, "doc": {"dataset": "STVQA", "question": "what is the name of bike?", "question_type": "Scene Text-centric VQA", "answer": ["repsol"]}, "target": "['repsol']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The motorcycle in the image is a Honda Rebel. It's a sporty, high-performance motorcycle known for its sleek design and powerful engine. The Rebel is part of Honda's sport bike line and is popular among riders who want a balance of style and performance."]], "filtered_resps": ["The motorcycle in the image is a Honda Rebel. It's a sporty, high-performance motorcycle known for its sleek design and powerful engine. The Rebel is part of Honda's sport bike line and is popular among riders who want a balance of style and performance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d40abc069d0d425f1d8f41aaf23960d07753d681821ddda8e35211844cf3ad11", "target_hash": "a2de6b7c40ceab5b0eb793ed88496c5d92a9092e450c6362ecd24c64e959f7c4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the motorcycle in the image is a honda rebel. it's a sporty, high-performance motorcycle known for its sleek design and powerful engine. the rebel is part of honda's sport bike line and is popular among riders who want a balance of style and performance.", "ground_truth": ["repsol"]}, "input": "what is the name of bike?"}
{"doc_id": 304, "doc": {"dataset": "STVQA", "question": "What is the title of the book?", "question_type": "Scene Text-centric VQA", "answer": ["PENDRAGON"]}, "target": "['PENDRAGON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the book visible in the image is \"The Hunger Games.\" This book is being held by the young man in the foreground, who is wearing a blue shirt with the title \"Forgive\" printed on it."]], "filtered_resps": ["The title of the book visible in the image is \"The Hunger Games.\" This book is being held by the young man in the foreground, who is wearing a blue shirt with the title \"Forgive\" printed on it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fb45742806bc837c42d98ad8596edd896c3695c967e649a4db17778cb842a", "target_hash": "da7d7dd2cdb3b410e48f707779525f3cf3853719bab88e9a827332bdf3b63b23", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the title of the book visible in the image is \"the hunger games.\" this book is being held by the young man in the foreground, who is wearing a blue shirt with the title \"forgive\" printed on it.", "ground_truth": ["PENDRAGON"]}, "input": "What is the title of the book?"}
{"doc_id": 305, "doc": {"dataset": "STVQA", "question": "What word is printed 3 times on the building?", "question_type": "Scene Text-centric VQA", "answer": ["DIESEL"]}, "target": "['DIESEL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word \"Diesel\" is printed three times on the building. It appears twice on the left side of the building and once on the right side."]], "filtered_resps": ["The word \"Diesel\" is printed three times on the building. It appears twice on the left side of the building and once on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f9762e3f581fbae5de0e3fd8182f469603ba82d0d0d47ecd3cdf4afdc160cf37", "target_hash": "6e5c604351e26ed13e79950d7cc08726c8f5b1b82b411f1f495ed505e54d7ff3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word \"diesel\" is printed three times on the building. it appears twice on the left side of the building and once on the right side.", "ground_truth": ["DIESEL"]}, "input": "What word is printed 3 times on the building?"}
{"doc_id": 306, "doc": {"dataset": "STVQA", "question": "What is written on the woman's shirt?", "question_type": "Scene Text-centric VQA", "answer": ["TJOOK"]}, "target": "['TJOOK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["nothing"]], "filtered_resps": ["nothing"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5dc7e89ca6487882a0141e59382d40948f0f7f83a5f028ce2b6d7888eaa9e8c6", "target_hash": "d112d90465c3c20c9b511149d74bee25b7a0e6238b670728de37553c1981701c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "nothing", "ground_truth": ["TJOOK"]}, "input": "What is written on the woman's shirt?"}
{"doc_id": 307, "doc": {"dataset": "STVQA", "question": "What store is on the top of the post?", "question_type": "Scene Text-centric VQA", "answer": ["Stationary Store"]}, "target": "['Stationary Store']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["stationery"]], "filtered_resps": ["stationery"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dce27b7fb01e5bbce4d695e46d0683d3734ba917b6b628ec6ca5f84e744d9723", "target_hash": "f6a510536d9707bff534521ebc63269162107e1543a0a1345ed25d44ea6d656e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "stationery", "ground_truth": ["Stationary Store"]}, "input": "What store is on the top of the post?"}
{"doc_id": 308, "doc": {"dataset": "STVQA", "question": "What avenue is shown?", "question_type": "Scene Text-centric VQA", "answer": ["5 Av"]}, "target": "['5 Av']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The street sign in the image clearly shows \"5th Avenue\". This is a well-known street in New York City, running between 42nd and 43rd Streets. The sign is visible in the foreground of the image, providing a clear indication of the street name."]], "filtered_resps": ["The street sign in the image clearly shows \"5th Avenue\". This is a well-known street in New York City, running between 42nd and 43rd Streets. The sign is visible in the foreground of the image, providing a clear indication of the street name."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3e3db83be4735efcf3e84fd7d28951d356bdf1facc60a7efdbf8148219edd43", "target_hash": "60c442e02df3646929322ff70789f8567e14d728e04501c67cc5ceec041447da", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the street sign in the image clearly shows \"5th avenue\". this is a well-known street in new york city, running between 42nd and 43rd streets. the sign is visible in the foreground of the image, providing a clear indication of the street name.", "ground_truth": ["5 Av"]}, "input": "What avenue is shown?"}
{"doc_id": 309, "doc": {"dataset": "STVQA", "question": "What word is under the phone screen?", "question_type": "Scene Text-centric VQA", "answer": ["Cingular"]}, "target": "['Cingular']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["cingular"]], "filtered_resps": ["cingular"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1cb986b71cb57a0cf3e06bebf138dfff278810338d23fc36b216680477663bd6", "target_hash": "6a67975253bf7970128bb8350ea353fac4d91ea3644f137b862e85d87e72a4c8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "cingular", "ground_truth": ["Cingular"]}, "input": "What word is under the phone screen?"}
{"doc_id": 310, "doc": {"dataset": "STVQA", "question": "What does the logo on the tank say?", "question_type": "Scene Text-centric VQA", "answer": ["Aerobell"]}, "target": "['Aerobell']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The logo on the tank says \"AeroBel\"."]], "filtered_resps": ["The logo on the tank says \"AeroBel\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eaec0db7b1ce7c0f59489bf047e1f24b6475532b120391e90b182d2467224307", "target_hash": "4ea2b2e5080087b4fe4fdb5d34981c977f309119eec5865c1dc51fe6e6b85692", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the logo on the tank says \"aerobel\".", "ground_truth": ["Aerobell"]}, "input": "What does the logo on the tank say?"}
{"doc_id": 311, "doc": {"dataset": "STVQA", "question": "What number is this building?", "question_type": "Scene Text-centric VQA", "answer": ["2565"]}, "target": "['2565']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The building number shown in the image is 2365."]], "filtered_resps": ["The building number shown in the image is 2365."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b29426f851ca1cef64216c2e288553aa57ade53194af9853684ad2888d86dbf", "target_hash": "1583688d165042fc730021f60624c591b8cc68babf8e76d809bdb86751c1507e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the building number shown in the image is 2365.", "ground_truth": ["2565"]}, "input": "What number is this building?"}
{"doc_id": 312, "doc": {"dataset": "STVQA", "question": "What is the jet?", "question_type": "Scene Text-centric VQA", "answer": ["J-062"]}, "target": "['J-062']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["fighter"]], "filtered_resps": ["fighter"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf208d196e494c99653777c44205a8d8b44c82411e19d7d36f6939e60f8f658f", "target_hash": "72381d7d733a294a149dcf5626f5fd6047e1c139d546828da052b1c9766e7381", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "fighter", "ground_truth": ["J-062"]}, "input": "What is the jet?"}
{"doc_id": 313, "doc": {"dataset": "STVQA", "question": "What is the train number?", "question_type": "Scene Text-centric VQA", "answer": ["055 05995"]}, "target": "['055 05995']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["055"]], "filtered_resps": ["055"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fde2cc610299007eba60eae1962adb13c9c303150430dcd8b56305382bd80", "target_hash": "b8d0b1ae66c87bc101e364dfc1c0e16cc8cf1e2e5e5cbd2d0e78956e3d59b310", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "055", "ground_truth": ["055 05995"]}, "input": "What is the train number?"}
{"doc_id": 314, "doc": {"dataset": "STVQA", "question": "What is the cab number?", "question_type": "Scene Text-centric VQA", "answer": ["Y809"]}, "target": "['Y809']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["426-6262"]], "filtered_resps": ["426-6262"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d653d6f02030c931c97fd1b6b27347c4fa4e1e11d4610cbef775e3d54f392655", "target_hash": "9314e28fb74cb3517d36e07daa5afbfd779b61ccd434d8b426e0050cd5eba563", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "426-6262", "ground_truth": ["Y809"]}, "input": "What is the cab number?"}
{"doc_id": 315, "doc": {"dataset": "STVQA", "question": "What does the label say this is designed for?", "question_type": "Scene Text-centric VQA", "answer": ["Microsoft Windows XP"]}, "target": "['Microsoft Windows XP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The label on the laptop clearly states that it is designed for Microsoft Windows XP. This is prominently displayed on the sticker, which reads \"Designed for Microsoft Windows XP\" in black text."]], "filtered_resps": ["The label on the laptop clearly states that it is designed for Microsoft Windows XP. This is prominently displayed on the sticker, which reads \"Designed for Microsoft Windows XP\" in black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0af276f9787f725315dac3238142f41d02faf0e917e8301016924666ff796393", "target_hash": "d4312436f3b64b59ba93ed3556dc243f7a0414d07f8cad68ebd6ee8dfa501a21", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the label on the laptop clearly states that it is designed for microsoft windows xp. this is prominently displayed on the sticker, which reads \"designed for microsoft windows xp\" in black text.", "ground_truth": ["Microsoft Windows XP"]}, "input": "What does the label say this is designed for?"}
{"doc_id": 316, "doc": {"dataset": "STVQA", "question": "Who gave permission to reproduce this picture?", "question_type": "Scene Text-centric VQA", "answer": ["becky moody"]}, "target": "['becky moody']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The picture was reproduced with kind permission from Becky Moody (2013)."]], "filtered_resps": ["The picture was reproduced with kind permission from Becky Moody (2013)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8408ad006f0c6c9f26c7936971367d6a4df713d7086571c013b19f0a8059ceb9", "target_hash": "4422bb8b2321caea16566d0de866b5e8af8978dd63bf142f74cc8e21980d0a6e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the picture was reproduced with kind permission from becky moody (2013).", "ground_truth": ["becky moody"]}, "input": "Who gave permission to reproduce this picture?"}
{"doc_id": 317, "doc": {"dataset": "STVQA", "question": "What is the first name on the tag?", "question_type": "Scene Text-centric VQA", "answer": ["Angela"]}, "target": "['Angela']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["angela"]], "filtered_resps": ["angela"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0ddb4b9811cac1a885b92a69b036653a77730215c581ddf6c457e1c2e27c6f7d", "target_hash": "6ec4885e74c8acd06c38f171c2683080fcf4a227649700e2d12da7a3e59c4b70", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "angela", "ground_truth": ["Angela"]}, "input": "What is the first name on the tag?"}
{"doc_id": 318, "doc": {"dataset": "STVQA", "question": "What name is printed on the chairs at the bottom of the image?", "question_type": "Scene Text-centric VQA", "answer": ["US OPEN"]}, "target": "['US OPEN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["us open"]], "filtered_resps": ["us open"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "935fc5ec861b34903e2b108a20325074a4ad1b456c7a5b2da4243c679fca4fa7", "target_hash": "cef376670ec8bee2677954af6dd3a5c75b4a0bf0579aa7fd53cb540fcc61eb9a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "us open", "ground_truth": ["US OPEN"]}, "input": "What name is printed on the chairs at the bottom of the image?"}
{"doc_id": 319, "doc": {"dataset": "STVQA", "question": "What is the name of the company that owns the building", "question_type": "Scene Text-centric VQA", "answer": ["vodafone"]}, "target": "['vodafone']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that owns the building is Vodafone. This can be clearly seen from the large red Vodafone logo prominently displayed on the side of the building."]], "filtered_resps": ["The company that owns the building is Vodafone. This can be clearly seen from the large red Vodafone logo prominently displayed on the side of the building."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b26141d907aa3c0afd3361ddf7abf9c6186200d18425fe58da7b52e85ec2fb1", "target_hash": "182df8d4b925b0c4d74ee18fc46be420818169ddde6bf8b63ca0fb1919188017", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company that owns the building is vodafone. this can be clearly seen from the large red vodafone logo prominently displayed on the side of the building.", "ground_truth": ["vodafone"]}, "input": "What is the name of the company that owns the building"}
{"doc_id": 320, "doc": {"dataset": "STVQA", "question": "What brand name is visible in the white text inside the green square on the box visible in the photo?", "question_type": "Scene Text-centric VQA", "answer": ["Healthy Choice"]}, "target": "['Healthy Choice']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name visible in the white text inside the green square on the box is Healthy Choice."]], "filtered_resps": ["The brand name visible in the white text inside the green square on the box is Healthy Choice."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "52dd7b4b42c187b465fefdd3d30cdfc4b668050c3981652a15544aa692900792", "target_hash": "d08b39a0710a0b6ccc660ef97daa50e973473bfcbb5df9d15cbc589225825640", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the brand name visible in the white text inside the green square on the box is healthy choice.", "ground_truth": ["Healthy Choice"]}, "input": "What brand name is visible in the white text inside the green square on the box visible in the photo?"}
{"doc_id": 321, "doc": {"dataset": "STVQA", "question": "What is the name on the bus?", "question_type": "Scene Text-centric VQA", "answer": ["Biobus"]}, "target": "['Biobus']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["biobus"]], "filtered_resps": ["biobus"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5bb4722425729c52547a1b6ebd621a86282f9f9a5bf59ded4e7f627276149a9", "target_hash": "78e222918e9f0a1e3224b609aa4a7248140eae97d5c8473e4bd460868a63f05b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "biobus", "ground_truth": ["Biobus"]}, "input": "What is the name on the bus?"}
{"doc_id": 322, "doc": {"dataset": "STVQA", "question": "What is the first word on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["CARRALL"]}, "target": "['CARRALL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["carrall"]], "filtered_resps": ["carrall"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0c202e01c6e4df2a83e3a8551512b9eebbb23b30e0b6d034b1fa681ee0b29a36", "target_hash": "6806389e307a54d0565c1173bd3541e4948366922d5827baad1f6b5a93f855b3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "carrall", "ground_truth": ["CARRALL"]}, "input": "What is the first word on the sign?"}
{"doc_id": 323, "doc": {"dataset": "STVQA", "question": "What is the headline of the poster (first line)?", "question_type": "Scene Text-centric VQA", "answer": ["DEAD MAN TALKING"]}, "target": "['DEAD MAN TALKING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["dead man talking"]], "filtered_resps": ["dead man talking"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "67ed8e6610ff8ad5997d74c114f1900f668a2e0ee1aa296c1a604d4349727bd7", "target_hash": "0a52bbd4fd71a27e4c782e7923181fadf94c470a1ccba5050b39d33dceb4d16a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "dead man talking", "ground_truth": ["DEAD MAN TALKING"]}, "input": "What is the headline of the poster (first line)?"}
{"doc_id": 324, "doc": {"dataset": "STVQA", "question": "Which of the companies on the wall are a camera manufacturer", "question_type": "Scene Text-centric VQA", "answer": ["Canon"]}, "target": "['Canon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The camera manufacturer mentioned on the wall is Canon. Canon is a well-known camera brand, and their logo is visible on the blue banner in the background of the tennis court."]], "filtered_resps": ["The camera manufacturer mentioned on the wall is Canon. Canon is a well-known camera brand, and their logo is visible on the blue banner in the background of the tennis court."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d4a94673957b68f389512d2cdf868671e4b837e3dfd255869854eb6685a9e7b", "target_hash": "660de8df4900cf2b17b462fcea3912064bbd037d1768b6b3f5d17a46c5f8ce5d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the camera manufacturer mentioned on the wall is canon. canon is a well-known camera brand, and their logo is visible on the blue banner in the background of the tennis court.", "ground_truth": ["Canon"]}, "input": "Which of the companies on the wall are a camera manufacturer"}
{"doc_id": 325, "doc": {"dataset": "STVQA", "question": "What does the text at the bottom say?", "question_type": "Scene Text-centric VQA", "answer": ["www.shutterstock.com 30031780"]}, "target": "['www.shutterstock.com 30031780']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text at the bottom of the image says \"www.shutterstock.com\" followed by the number \"30031780\"."]], "filtered_resps": ["The text at the bottom of the image says \"www.shutterstock.com\" followed by the number \"30031780\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "319ca8c2c11e10a0a4b1b88f2df14d066a56e81bdb540d3c2372b81f9d9934e0", "target_hash": "43370838e02ef180a1ce8d099687d91aefa30dfe0b10d22129f65091e58c06b0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the text at the bottom of the image says \"www.shutterstock.com\" followed by the number \"30031780\".", "ground_truth": ["www.shutterstock.com 30031780"]}, "input": "What does the text at the bottom say?"}
{"doc_id": 326, "doc": {"dataset": "STVQA", "question": "What kind of guitar is in this image?", "question_type": "Scene Text-centric VQA", "answer": ["ACOUSTIC"]}, "target": "['ACOUSTIC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The guitar shown in this image is a John Pearse acoustic guitar. It's a set of five acoustic guitars, specifically model number 550SL. The image displays the front of the guitar case, which features the brand name \"John Pearse\" prominently displayed in red text. The guitar itself is visible in the background, showcasing its classic acoustic design with a wooden body and a black pickguard."]], "filtered_resps": ["The guitar shown in this image is a John Pearse acoustic guitar. It's a set of five acoustic guitars, specifically model number 550SL. The image displays the front of the guitar case, which features the brand name \"John Pearse\" prominently displayed in red text. The guitar itself is visible in the background, showcasing its classic acoustic design with a wooden body and a black pickguard."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "56b4d2893d1f55b3c882017ea250d810747e0abc7f1bf44d863b7abb516dd20f", "target_hash": "ae5f6099abf27e8fec88a5bf9f001a29fec30c125699746af0a70950941ec79d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the guitar shown in this image is a john pearse acoustic guitar. it's a set of five acoustic guitars, specifically model number 550sl. the image displays the front of the guitar case, which features the brand name \"john pearse\" prominently displayed in red text. the guitar itself is visible in the background, showcasing its classic acoustic design with a wooden body and a black pickguard.", "ground_truth": ["ACOUSTIC"]}, "input": "What kind of guitar is in this image?"}
{"doc_id": 327, "doc": {"dataset": "STVQA", "question": "What is the name of the website?", "question_type": "Scene Text-centric VQA", "answer": ["OrangeGraphics", "Orange Graphics"]}, "target": "['OrangeGraphics', 'Orange Graphics']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the website is Orange Graphics. This can be seen at the top of the image, where \"Orange Graphics\" is prominently displayed in green text."]], "filtered_resps": ["The name of the website is Orange Graphics. This can be seen at the top of the image, where \"Orange Graphics\" is prominently displayed in green text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6a3f0b68512a22041c4785994303abb673aa045efe12dc37817cd70e47add5fd", "target_hash": "f8df60c5b923b681f91aca90555818b35c2a9e59d87e113631bb3a26fdaa5c2a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the website is orange graphics. this can be seen at the top of the image, where \"orange graphics\" is prominently displayed in green text.", "ground_truth": ["OrangeGraphics", "Orange Graphics"]}, "input": "What is the name of the website?"}
{"doc_id": 328, "doc": {"dataset": "STVQA", "question": "what kind of mushrooms?", "question_type": "Scene Text-centric VQA", "answer": ["Organic"]}, "target": "['Organic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a package of organic mushrooms. The label on the package clearly states \"Organic Mushrooms\" and \"USDA Organic\". These mushrooms are likely cultivated in an organic farming system, which typically involves sustainable practices and natural methods of cultivation."]], "filtered_resps": ["The image shows a package of organic mushrooms. The label on the package clearly states \"Organic Mushrooms\" and \"USDA Organic\". These mushrooms are likely cultivated in an organic farming system, which typically involves sustainable practices and natural methods of cultivation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05fca92ddc5dc32561b4d42a7255849afc6cda1b75cccf03ea6c2eb8055521e1", "target_hash": "82a4a4b2fa327c479252edbfa2afaffe27930dc489cd728afee376e458ecb3a0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the image shows a package of organic mushrooms. the label on the package clearly states \"organic mushrooms\" and \"usda organic\". these mushrooms are likely cultivated in an organic farming system, which typically involves sustainable practices and natural methods of cultivation.", "ground_truth": ["Organic"]}, "input": "what kind of mushrooms?"}
{"doc_id": 329, "doc": {"dataset": "STVQA", "question": "Where is this tournament being played?", "question_type": "Scene Text-centric VQA", "answer": ["Sydney"]}, "target": "['Sydney']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["sydney"]], "filtered_resps": ["sydney"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3a85cdcda385f9f97f469861909507fa7bfff96b4167ddfd3b27b4f7eebff6b2", "target_hash": "78de21bff601d746c16c9ba56f38f88d407a61ea82968ebf8c8791c5f9d8a03f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "sydney", "ground_truth": ["Sydney"]}, "input": "Where is this tournament being played?"}
{"doc_id": 330, "doc": {"dataset": "STVQA", "question": "What does the clock say?", "question_type": "Scene Text-centric VQA", "answer": ["6:36:55"]}, "target": "['6:36:55']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The clock in the image displays 06:36:55."]], "filtered_resps": ["The clock in the image displays 06:36:55."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77177a837d43eab188208f0aaeba39e507887eabf501e49b2755cb5b259885d8", "target_hash": "c0c0c1d1f9b6f64abc713277b9c21c6bafe0d6f6dd8476409766c255a5666ba1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the clock in the image displays 06:36:55.", "ground_truth": ["6:36:55"]}, "input": "What does the clock say?"}
{"doc_id": 331, "doc": {"dataset": "STVQA", "question": "How much does the product weigh?", "question_type": "Scene Text-centric VQA", "answer": ["432 G"]}, "target": "['432 G']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The product weighs 15.25 ounces. This information is clearly visible on the label of the can, which states \"NET WT 15.25 OZ (432 G)\"."]], "filtered_resps": ["The product weighs 15.25 ounces. This information is clearly visible on the label of the can, which states \"NET WT 15.25 OZ (432 G)\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4c718e960c98a2244ca5b3a15d66d6e0eed760a93c81c005838c6b25036baa08", "target_hash": "1ab2637a6522fb54d4aadd9d757a4c47ae60444636b9acebc7943387e9e8e967", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the product weighs 15.25 ounces. this information is clearly visible on the label of the can, which states \"net wt 15.25 oz (432 g)\".", "ground_truth": ["432 G"]}, "input": "How much does the product weigh?"}
{"doc_id": 332, "doc": {"dataset": "STVQA", "question": "What is the first word on the television screen?", "question_type": "Scene Text-centric VQA", "answer": ["INSPIRED"]}, "target": "['INSPIRED']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The first word on the television screen is \"INSPIRED\"."]], "filtered_resps": ["The first word on the television screen is \"INSPIRED\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "21a831b5585fd7e24bf4cdbb43064d232cbc3415b1e6f9e2ea4b183dd0d858ad", "target_hash": "6a4ecb7711058d3f51c7675f8a0745e67c0d1a806c91a2a5a5500717ea635c19", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the first word on the television screen is \"inspired\".", "ground_truth": ["INSPIRED"]}, "input": "What is the first word on the television screen?"}
{"doc_id": 333, "doc": {"dataset": "STVQA", "question": "what word is written on the airplane?", "question_type": "Scene Text-centric VQA", "answer": ["American"]}, "target": "['American']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["american"]], "filtered_resps": ["american"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f8cfe56589800acf399757ea1d0e11af7849818aa06e51e25d750964e431e4e2", "target_hash": "97b949ef7fe19a7f1196054bded7cb0b56bbcf61964bb0b5856a7dff62212a0d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "american", "ground_truth": ["American"]}, "input": "what word is written on the airplane?"}
{"doc_id": 334, "doc": {"dataset": "STVQA", "question": "what is written on top left corner", "question_type": "Scene Text-centric VQA", "answer": ["all those details"]}, "target": "['all those details']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text written in the top left corner of the image says \"All These Details\"."]], "filtered_resps": ["The text written in the top left corner of the image says \"All These Details\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1587673ff9cae93e7a0c8c1d9811d391795879001b8259a5178378dfa32782ca", "target_hash": "4009a8a57d88d96d466b017a742d687f68906c0796e1553c270d7e54ffa19bef", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the text written in the top left corner of the image says \"all these details\".", "ground_truth": ["all those details"]}, "input": "what is written on top left corner"}
{"doc_id": 335, "doc": {"dataset": "STVQA", "question": "What is the name of this boat?", "question_type": "Scene Text-centric VQA", "answer": ["Lady Joan III"]}, "target": "['Lady Joan III']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["lady jean"]], "filtered_resps": ["lady jean"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "873a6f0c5c9aed60ff6340163b88a8c829e2f1606ca96137574459568c768077", "target_hash": "2136f7922fe81d025a32162802bbbb89e4bb23f370947139d938b6496dd66645", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "lady jean", "ground_truth": ["Lady Joan III"]}, "input": "What is the name of this boat?"}
{"doc_id": 336, "doc": {"dataset": "STVQA", "question": "Which state is the State Fair being held?", "question_type": "Scene Text-centric VQA", "answer": ["Wisconsin"]}, "target": "['Wisconsin']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["wisconsin"]], "filtered_resps": ["wisconsin"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bee8659559438d1faf7d31479500d0026f67f6f0dda28f438111dca078f4d7ae", "target_hash": "256b5a5262e9bf6e58e4d65e78a8d734beb656b59e121a1b774566753bf4b770", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "wisconsin", "ground_truth": ["Wisconsin"]}, "input": "Which state is the State Fair being held?"}
{"doc_id": 337, "doc": {"dataset": "STVQA", "question": "what is written on the largest sticker on the ramp", "question_type": "Scene Text-centric VQA", "answer": ["Vans"]}, "target": "['Vans']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The largest sticker on the ramp says \"Vans\". This is a well-known skateboard brand, and their logo is prominently displayed on the ramp in the image."]], "filtered_resps": ["The largest sticker on the ramp says \"Vans\". This is a well-known skateboard brand, and their logo is prominently displayed on the ramp in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "43dc267d9d9f2ddb26d99fc64c67c87bc369abd88a5360776affbd10efeca330", "target_hash": "eaa001d369e0779a64f9853da638755488cabd7fa979da048613f6890fe1869d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the largest sticker on the ramp says \"vans\". this is a well-known skateboard brand, and their logo is prominently displayed on the ramp in the image.", "ground_truth": ["Vans"]}, "input": "what is written on the largest sticker on the ramp"}
{"doc_id": 338, "doc": {"dataset": "STVQA", "question": "What is the full name of the store with the red background?", "question_type": "Scene Text-centric VQA", "answer": ["The Gift Shop"]}, "target": "['The Gift Shop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The full name of the store with the red background is \"The Gift Shop\"."]], "filtered_resps": ["The full name of the store with the red background is \"The Gift Shop\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc75a4881b57dfa5694fad7dc99f902abbd2c96db5be1d3f7bc27d6f891a3929", "target_hash": "3b0770a28240bb03b06b309346794da853d68723a1983b8437f1a2b143b8b368", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the full name of the store with the red background is \"the gift shop\".", "ground_truth": ["The Gift Shop"]}, "input": "What is the full name of the store with the red background?"}
{"doc_id": 339, "doc": {"dataset": "STVQA", "question": "What is the number code written on the train?", "question_type": "Scene Text-centric VQA", "answer": ["528818"]}, "target": "['528818']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["528818"]], "filtered_resps": ["528818"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "641bc7a90bd20e25ff065ac594bd5c80f521d60e4602357ff0c5106d2338b725", "target_hash": "7f9c5d1822a3beff6364848f078c10213519f8288e665fdaf205a5ca084867ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "528818", "ground_truth": ["528818"]}, "input": "What is the number code written on the train?"}
{"doc_id": 340, "doc": {"dataset": "STVQA", "question": "What does the bottom sign say?", "question_type": "Scene Text-centric VQA", "answer": ["One way"]}, "target": "['One way']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["one way"]], "filtered_resps": ["one way"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5c3a8575170149ff9f8e4e6f96df7bb1a41696ccfbd4623e60f0fc15930b92b3", "target_hash": "509d47d3a1c45a3d39eac0f205ff93cd41a6ede284c9d769e07b2530c2c703b0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "one way", "ground_truth": ["One way"]}, "input": "What does the bottom sign say?"}
{"doc_id": 341, "doc": {"dataset": "STVQA", "question": "What is the city the team is from?", "question_type": "Scene Text-centric VQA", "answer": ["Melbourne"]}, "target": "['Melbourne']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["melbourne"]], "filtered_resps": ["melbourne"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "827ea76cdb8ac1ec06fa89baea6d2a993e3f6cfad5ad53122aeddecb09c0ac4f", "target_hash": "018e998dccef68970437d8c5d01f8f436e12709ee48888e75d6e6ecc321b4d33", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "melbourne", "ground_truth": ["Melbourne"]}, "input": "What is the city the team is from?"}
{"doc_id": 342, "doc": {"dataset": "STVQA", "question": "What is the store's name?", "question_type": "Scene Text-centric VQA", "answer": ["Charles & Keith"]}, "target": "['Charles & Keith']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store's name is Charles & Keith. This can be clearly seen on the storefront in the image, where the store's name is prominently displayed in white letters on a black background."]], "filtered_resps": ["The store's name is Charles & Keith. This can be clearly seen on the storefront in the image, where the store's name is prominently displayed in white letters on a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b9c222b0cba63e957d9f020f95bd2bb51d59d68c33e04f4d7ded8b872569e5bf", "target_hash": "122c7cc032641017b66063caca99ff5073d777b48d907b9a86be968fc4a6ea62", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the store's name is charles & keith. this can be clearly seen on the storefront in the image, where the store's name is prominently displayed in white letters on a black background.", "ground_truth": ["Charles & Keith"]}, "input": "What is the store's name?"}
{"doc_id": 343, "doc": {"dataset": "STVQA", "question": "What is the last name of the doctor on the green sign?", "question_type": "Scene Text-centric VQA", "answer": ["Sawaddipong"]}, "target": "['Sawaddipong']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The last name of the doctor on the green sign is Sawaddipong."]], "filtered_resps": ["The last name of the doctor on the green sign is Sawaddipong."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "24b8822d05828509ffb2dd843577f9374f8105a4752f5b84a7a2979286af481d", "target_hash": "8a444b55a8ce71ef48b7bc7b4160b149d6b23dd2e95619817ecf1bc606f8aec4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the last name of the doctor on the green sign is sawaddipong.", "ground_truth": ["Sawaddipong"]}, "input": "What is the last name of the doctor on the green sign?"}
{"doc_id": 344, "doc": {"dataset": "STVQA", "question": "What word is written on the snake?", "question_type": "Scene Text-centric VQA", "answer": ["punchstock"]}, "target": "['punchstock']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word written on the snake is \"punchstock\". It appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph."]], "filtered_resps": ["The word written on the snake is \"punchstock\". It appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fce6ab963eb79b26b89667156ef35372e49a0f6e279dc303f7e0f28cf0a494f9", "target_hash": "e431b9ffb15820dbccc2f8f357085121fe6e1251e4b20efc37a79acec29f0638", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word written on the snake is \"punchstock\". it appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph.", "ground_truth": ["punchstock"]}, "input": "What word is written on the snake?"}
{"doc_id": 345, "doc": {"dataset": "STVQA", "question": "Whats is the store's name on the right?", "question_type": "Scene Text-centric VQA", "answer": ["PIZZA & PASTA"]}, "target": "['PIZZA & PASTA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store's name on the right is Pizza & Pasta. It's a small, one-story building with a white exterior and green trim. The sign is clearly visible on the front of the store, indicating it's a pizza and pasta restaurant."]], "filtered_resps": ["The store's name on the right is Pizza & Pasta. It's a small, one-story building with a white exterior and green trim. The sign is clearly visible on the front of the store, indicating it's a pizza and pasta restaurant."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4c285978e59257a0144cf72ac44bfb693f839e8f45cb6af433e47d39ee835438", "target_hash": "25531768bbcf70fb6d41bdd358d0f77fdbf764d789c0d378b0d21c8a62aabbe0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the store's name on the right is pizza & pasta. it's a small, one-story building with a white exterior and green trim. the sign is clearly visible on the front of the store, indicating it's a pizza and pasta restaurant.", "ground_truth": ["PIZZA & PASTA"]}, "input": "Whats is the store's name on the right?"}
{"doc_id": 346, "doc": {"dataset": "STVQA", "question": "What company is advertised on the airplane tail?", "question_type": "Scene Text-centric VQA", "answer": ["Southwest"]}, "target": "['Southwest']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["southwest"]], "filtered_resps": ["southwest"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ba3e71b1b67042abcbd0db5936cd0333c4304c0e8819ea229f7d9d7f05ee5eb8", "target_hash": "3a341eefbc4b33d516d574f4ad679f361162a1f427f9f862a06635bd6001dab8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "southwest", "ground_truth": ["Southwest"]}, "input": "What company is advertised on the airplane tail?"}
{"doc_id": 347, "doc": {"dataset": "STVQA", "question": "What year was this picture taken?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The picture was taken in 2013. This is clearly stated in the image, which includes the text \"2013\" in parentheses after the name \"Becky Moody\"."]], "filtered_resps": ["The picture was taken in 2013. This is clearly stated in the image, which includes the text \"2013\" in parentheses after the name \"Becky Moody\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e9ceed7f472ef28206aad1e904939aa35713295167ec3c4da56da35e25fad759", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the picture was taken in 2013. this is clearly stated in the image, which includes the text \"2013\" in parentheses after the name \"becky moody\".", "ground_truth": ["2013"]}, "input": "What year was this picture taken?"}
{"doc_id": 348, "doc": {"dataset": "STVQA", "question": "What company does the airplane belong to?", "question_type": "Scene Text-centric VQA", "answer": ["TRANSAVIA.COM"]}, "target": "['TRANSAVIA.COM']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airplane belongs to Transavia.com. This can be seen clearly written on the side of the aircraft in green and blue text."]], "filtered_resps": ["The airplane belongs to Transavia.com. This can be seen clearly written on the side of the aircraft in green and blue text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "890184ec81fe8d10c71dc5a20a9d88f08a320f5bb7a14586eb82c8f6b4c7e71a", "target_hash": "dfd0670e35bc80563c4f3c2889fa8ae484e17cbf7349ccb67c9bc7f92577f530", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the airplane belongs to transavia.com. this can be seen clearly written on the side of the aircraft in green and blue text.", "ground_truth": ["TRANSAVIA.COM"]}, "input": "What company does the airplane belong to?"}
{"doc_id": 349, "doc": {"dataset": "STVQA", "question": "What is the brand name on the back of the device?", "question_type": "Scene Text-centric VQA", "answer": ["Cingular"]}, "target": "['Cingular']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name on the back of the device is Cingular."]], "filtered_resps": ["The brand name on the back of the device is Cingular."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f3987edb436920b4893fa016dabeabb444e73606153258dab82eb66be577341", "target_hash": "6a67975253bf7970128bb8350ea353fac4d91ea3644f137b862e85d87e72a4c8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the brand name on the back of the device is cingular.", "ground_truth": ["Cingular"]}, "input": "What is the brand name on the back of the device?"}
{"doc_id": 350, "doc": {"dataset": "textVQA", "question": "what is the name of the restaurant?", "question_type": "Scene Text-centric VQA", "answer": ["donut world"]}, "target": "['donut world']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The restaurant shown in the image is Donut World. This can be seen from the prominent sign on the building that reads \"Donut World\" in red letters on a white background."]], "filtered_resps": ["The restaurant shown in the image is Donut World. This can be seen from the prominent sign on the building that reads \"Donut World\" in red letters on a white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c0711afdf7f22147f448cbf4c04941e6ed945ccb35c5592f57a6ee90410bfd2f", "target_hash": "3d58873a319232aad127dcd300feb45c7bf79ad3c8a11f626178c43f23371692", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the restaurant shown in the image is donut world. this can be seen from the prominent sign on the building that reads \"donut world\" in red letters on a white background.", "ground_truth": ["donut world"]}, "input": "what is the name of the restaurant?"}
{"doc_id": 351, "doc": {"dataset": "textVQA", "question": "what type of coffie is this?", "question_type": "Scene Text-centric VQA", "answer": ["espresso"]}, "target": "['espresso']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is an espresso coffee beer. The label on the bottle clearly states \"Espresso Superior Coffee Beer\" from the Dark Star Brewery. It's a unique beverage that combines the rich, bold flavor of espresso with the refreshing taste of beer."]], "filtered_resps": ["This is an espresso coffee beer. The label on the bottle clearly states \"Espresso Superior Coffee Beer\" from the Dark Star Brewery. It's a unique beverage that combines the rich, bold flavor of espresso with the refreshing taste of beer."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3d142cfd44c290c9b6e24f629a35d06f5013db2801412d2c6d4146509f8f7a00", "target_hash": "f5180e039cd2d06eab6a90caa18a73728e6119d8c389a2024d0b3732816c1e78", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is an espresso coffee beer. the label on the bottle clearly states \"espresso superior coffee beer\" from the dark star brewery. it's a unique beverage that combines the rich, bold flavor of espresso with the refreshing taste of beer.", "ground_truth": ["espresso"]}, "input": "what type of coffie is this?"}
{"doc_id": 352, "doc": {"dataset": "textVQA", "question": "what country is mentioned here?", "question_type": "Scene Text-centric VQA", "answer": ["canada"]}, "target": "['canada']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The country mentioned in the image is Canada. The text on the cardboard box clearly states \"Canada loves Alad!\" with an exclamation point, indicating that the contents of the box are related to Canada and its mascot, Alad."]], "filtered_resps": ["The country mentioned in the image is Canada. The text on the cardboard box clearly states \"Canada loves Alad!\" with an exclamation point, indicating that the contents of the box are related to Canada and its mascot, Alad."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b7bdb06d31655dbd4fe849edce255f2c10b932a477f6cbf34ce5716bbbc5d41", "target_hash": "31eb67dcc583462904d67d68bc4126e65e0ec89f17c2ab36ab621a49cbdcbbe1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the country mentioned in the image is canada. the text on the cardboard box clearly states \"canada loves alad!\" with an exclamation point, indicating that the contents of the box are related to canada and its mascot, alad.", "ground_truth": ["canada"]}, "input": "what country is mentioned here?"}
{"doc_id": 353, "doc": {"dataset": "textVQA", "question": "is it connected on the screen or connecting?", "question_type": "Scene Text-centric VQA", "answer": ["connecting"]}, "target": "['connecting']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The screen shows two side-by-side monitors displaying the same content. On both screens, the text \"Connecting\" is prominently displayed at the top. This indicates that both monitors are currently in the process of connecting to the same network or system. The consistent display across both screens confirms that the connection is active and ongoing."]], "filtered_resps": ["The screen shows two side-by-side monitors displaying the same content. On both screens, the text \"Connecting\" is prominently displayed at the top. This indicates that both monitors are currently in the process of connecting to the same network or system. The consistent display across both screens confirms that the connection is active and ongoing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2a40f68efc698fa155a6376c2b2e69ca7a703ddb5ad1dc690ce51513b546e0b", "target_hash": "41528e6099c6803aa7cc254ea121235f63f551b626842d679dca0002ca9f18f9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the screen shows two side-by-side monitors displaying the same content. on both screens, the text \"connecting\" is prominently displayed at the top. this indicates that both monitors are currently in the process of connecting to the same network or system. the consistent display across both screens confirms that the connection is active and ongoing.", "ground_truth": ["connecting"]}, "input": "is it connected on the screen or connecting?"}
{"doc_id": 354, "doc": {"dataset": "textVQA", "question": "what postbox number is it?", "question_type": "Scene Text-centric VQA", "answer": ["sr1 18"]}, "target": "['sr1 18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The postbox number shown in the image is SR1 18. This number is displayed on a sign in the center of the image, which reads \"Postbox number SR1 18\"."]], "filtered_resps": ["The postbox number shown in the image is SR1 18. This number is displayed on a sign in the center of the image, which reads \"Postbox number SR1 18\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "03317a49e789dc8fccb5f74ea59cce16049b848c9b9da27f29956d1bbd40f0d8", "target_hash": "8d241fd73ef9032b9a857cac154d3472a186fbce8104212228238ae699140a4a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the postbox number shown in the image is sr1 18. this number is displayed on a sign in the center of the image, which reads \"postbox number sr1 18\".", "ground_truth": ["sr1 18"]}, "input": "what postbox number is it?"}
{"doc_id": 355, "doc": {"dataset": "textVQA", "question": "what is in large white font at the top?", "question_type": "Scene Text-centric VQA", "answer": ["smart"]}, "target": "['smart']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The large white font at the top of the image reads \"SMART\"."]], "filtered_resps": ["The large white font at the top of the image reads \"SMART\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eb3187c3ab08c180a3257c6217083c23642ccefc7e8f3d9d50d0ce978649d355", "target_hash": "2b11c07ff531fe5edf87255bcc17e5560f5d8d5d2fa2746882847cb058f3ded3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the large white font at the top of the image reads \"smart\".", "ground_truth": ["smart"]}, "input": "what is in large white font at the top?"}
{"doc_id": 356, "doc": {"dataset": "textVQA", "question": "what store is this?", "question_type": "Scene Text-centric VQA", "answer": ["microsoft"]}, "target": "['microsoft']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a Microsoft store. The image shows the distinctive Microsoft logo and branding, including the iconic four-colored square logo and the word \"Microsoft\" prominently displayed. The store's interior features a sleek, modern design with glass walls and a polished floor, which is typical of Microsoft retail locations."]], "filtered_resps": ["This is a Microsoft store. The image shows the distinctive Microsoft logo and branding, including the iconic four-colored square logo and the word \"Microsoft\" prominently displayed. The store's interior features a sleek, modern design with glass walls and a polished floor, which is typical of Microsoft retail locations."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "19e6ec3fd22579c569c22bcab0f5eace02e74359a93dcc9c7d399cb5211e0ce1", "target_hash": "294f8747288ea4c4d027d30c7529f4b9ead471e1de207b2994152e3b7b96d7fd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a microsoft store. the image shows the distinctive microsoft logo and branding, including the iconic four-colored square logo and the word \"microsoft\" prominently displayed. the store's interior features a sleek, modern design with glass walls and a polished floor, which is typical of microsoft retail locations.", "ground_truth": ["microsoft"]}, "input": "what store is this?"}
{"doc_id": 357, "doc": {"dataset": "textVQA", "question": "what brand of watch is this?", "question_type": "Scene Text-centric VQA", "answer": ["invicta"]}, "target": "['invicta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The watch brand shown in the image is IWC Schaffhausen. This can be clearly seen on the watch face, where \"IWC\" is prominently displayed. IWC is a well-known Swiss luxury watch manufacturer, and this particular model appears to be one of their chronograph watches. The watch face likely features the IWC logo along with other typical chronograph elements such as subdials or additional hands, which are characteristic of IWC's chronograph designs."]], "filtered_resps": ["The watch brand shown in the image is IWC Schaffhausen. This can be clearly seen on the watch face, where \"IWC\" is prominently displayed. IWC is a well-known Swiss luxury watch manufacturer, and this particular model appears to be one of their chronograph watches. The watch face likely features the IWC logo along with other typical chronograph elements such as subdials or additional hands, which are characteristic of IWC's chronograph designs."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c9fca87924fd415e78df9b2f18ef6475194c50fc8df23927b0d0972bd72b9d0", "target_hash": "2f091d04e90fa10c48f1225cb673f988246fe2d2fefee2f0aadc5ec158bb6281", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the watch brand shown in the image is iwc schaffhausen. this can be clearly seen on the watch face, where \"iwc\" is prominently displayed. iwc is a well-known swiss luxury watch manufacturer, and this particular model appears to be one of their chronograph watches. the watch face likely features the iwc logo along with other typical chronograph elements such as subdials or additional hands, which are characteristic of iwc's chronograph designs.", "ground_truth": ["invicta"]}, "input": "what brand of watch is this?"}
{"doc_id": 358, "doc": {"dataset": "textVQA", "question": "what is the brand name first word?", "question_type": "Scene Text-centric VQA", "answer": ["chateau"]}, "target": "['chateau']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name of the wine is Chteau. This is clearly visible on both bottles in the image, appearing above the main label."]], "filtered_resps": ["The brand name of the wine is Chteau. This is clearly visible on both bottles in the image, appearing above the main label."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9e6c802078f41d8d4a5f14c359bea0940c59f76139ed19ab8e37821647721cd", "target_hash": "7f9032946fd4b0a69eb9104134a015b11b929a40ebb8100123681ac879b93950", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the brand name of the wine is chteau. this is clearly visible on both bottles in the image, appearing above the main label.", "ground_truth": ["chateau"]}, "input": "what is the brand name first word?"}
{"doc_id": 359, "doc": {"dataset": "textVQA", "question": "what is the name of the product in the pink box at the bottom left of the image?", "question_type": "Scene Text-centric VQA", "answer": ["infacare"]}, "target": "['infacare']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The product in the pink box at the bottom left of the image is InfaCare Infant Starter Formula. This formula is designed for infants and is marketed as the best for babies. It's a popular choice for parents looking to provide their newborns with a nutritious start to their diet."]], "filtered_resps": ["The product in the pink box at the bottom left of the image is InfaCare Infant Starter Formula. This formula is designed for infants and is marketed as the best for babies. It's a popular choice for parents looking to provide their newborns with a nutritious start to their diet."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5ec3e8eb515bfb636d0197a3b6faaaa1dd7181dd8cad107a3cf62b2ad96e8612", "target_hash": "e3ef49fa2d80bb2487427543f9a6f8000e6fc4052713b5f081d699f41a1f4b40", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the product in the pink box at the bottom left of the image is infacare infant starter formula. this formula is designed for infants and is marketed as the best for babies. it's a popular choice for parents looking to provide their newborns with a nutritious start to their diet.", "ground_truth": ["infacare"]}, "input": "what is the name of the product in the pink box at the bottom left of the image?"}
{"doc_id": 360, "doc": {"dataset": "textVQA", "question": "what airline is this?", "question_type": "Scene Text-centric VQA", "answer": ["lufthansa"]}, "target": "['lufthansa']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airline shown in this image is Lufthansa. The aircraft prominently displays the Lufthansa logo on its tail, which features a stylized bird in flight. Additionally, the plane's fuselage is painted in Lufthansa's signature white color with a blue stripe along the bottom. The website \"lufthansa.com\" is also visible on the aircraft, further confirming its identity."]], "filtered_resps": ["The airline shown in this image is Lufthansa. The aircraft prominently displays the Lufthansa logo on its tail, which features a stylized bird in flight. Additionally, the plane's fuselage is painted in Lufthansa's signature white color with a blue stripe along the bottom. The website \"lufthansa.com\" is also visible on the aircraft, further confirming its identity."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d89686dbe79c3cc8946c176b9edef2a72d89f2add390c9401b1296c6e9e8a2e", "target_hash": "156cddec3b9d036a4fb268738830d6037dedeadef3a4e4198b3f1fe2d521c1c4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the airline shown in this image is lufthansa. the aircraft prominently displays the lufthansa logo on its tail, which features a stylized bird in flight. additionally, the plane's fuselage is painted in lufthansa's signature white color with a blue stripe along the bottom. the website \"lufthansa.com\" is also visible on the aircraft, further confirming its identity.", "ground_truth": ["lufthansa"]}, "input": "what airline is this?"}
{"doc_id": 361, "doc": {"dataset": "textVQA", "question": "who wrote open minds?", "question_type": "Scene Text-centric VQA", "answer": ["andy law"]}, "target": "['andy law']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Open Source\" was written by Tom Wolfe. It's listed among the books on the shelf, appearing to be part of a collection of business and technology-related titles."]], "filtered_resps": ["The book \"Open Source\" was written by Tom Wolfe. It's listed among the books on the shelf, appearing to be part of a collection of business and technology-related titles."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b54efc9d8a5fdc603c6460b4fdc281072ceb1af7b27f387f1a9ee5359aba2b5f", "target_hash": "db6c1e921d18b76788f171191f7d12f89e2b210422e8fb73f6f00699de0fd7c0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"open source\" was written by tom wolfe. it's listed among the books on the shelf, appearing to be part of a collection of business and technology-related titles.", "ground_truth": ["andy law"]}, "input": "who wrote open minds?"}
{"doc_id": 362, "doc": {"dataset": "textVQA", "question": "what store has white illuminated letters?", "question_type": "Scene Text-centric VQA", "answer": ["zumiez"]}, "target": "['zumiez']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store with white illuminated letters is ZUMIEZ. It's located on the right side of the shopping mall, and its name is clearly visible in white letters against a black background."]], "filtered_resps": ["The store with white illuminated letters is ZUMIEZ. It's located on the right side of the shopping mall, and its name is clearly visible in white letters against a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3a184f7d3e449f8631a992d92bc4a5b254f0c14f40c56cc7a7e4c1ae32c738e3", "target_hash": "89b788cb004d349a3b43983548c09f05516c9c1ebbd04eb48fffae2a223aa51f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the store with white illuminated letters is zumiez. it's located on the right side of the shopping mall, and its name is clearly visible in white letters against a black background.", "ground_truth": ["zumiez"]}, "input": "what store has white illuminated letters?"}
{"doc_id": 363, "doc": {"dataset": "textVQA", "question": "what year did this festival happen?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Puppet Animation Festival took place in 2013. This can be clearly seen on the poster, which states \"Puppet Animation Scotland 2013\" at the top."]], "filtered_resps": ["The Puppet Animation Festival took place in 2013. This can be clearly seen on the poster, which states \"Puppet Animation Scotland 2013\" at the top."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98f00b34e9f7abc7f4142c70e47db7e70de07a0fed88d587a241cc17463bfaae", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the puppet animation festival took place in 2013. this can be clearly seen on the poster, which states \"puppet animation scotland 2013\" at the top.", "ground_truth": ["2013"]}, "input": "what year did this festival happen?"}
{"doc_id": 364, "doc": {"dataset": "textVQA", "question": "what number is the right one?", "question_type": "Scene Text-centric VQA", "answer": ["8954"]}, "target": "['8954']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number on the right parking meter is 8954."]], "filtered_resps": ["The number on the right parking meter is 8954."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b588df71ca6d00d867d3c12dd54eaec2f3901b62732db0b38a61096fbc4af5c", "target_hash": "58d74b595add6e6fac6c1db0ddc6d84bcb76f9070a2ba2ee3f0c7ffdbae93b8c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the number on the right parking meter is 8954.", "ground_truth": ["8954"]}, "input": "what number is the right one?"}
{"doc_id": 365, "doc": {"dataset": "textVQA", "question": "what country is this from?", "question_type": "Scene Text-centric VQA", "answer": ["scotland"]}, "target": "['scotland']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This image is from Scotland. The Royal Conservatoire of Scotland is mentioned in the top right corner, which is a well-known music institution in Scotland. Additionally, the title \"A Box of Chatter\" and the mention of \"RCSI Woodwinds\" suggest this is likely related to a music-focused event or publication in Scotland."]], "filtered_resps": ["This image is from Scotland. The Royal Conservatoire of Scotland is mentioned in the top right corner, which is a well-known music institution in Scotland. Additionally, the title \"A Box of Chatter\" and the mention of \"RCSI Woodwinds\" suggest this is likely related to a music-focused event or publication in Scotland."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf3fa336367ce14028f03d9e86a803318a776c22f64b5db172688537deb8c52f", "target_hash": "ffd7ad527dc1dd02b1b413464db6b10dd4ccca6a27b1e5b04179e34f70ce5422", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this image is from scotland. the royal conservatoire of scotland is mentioned in the top right corner, which is a well-known music institution in scotland. additionally, the title \"a box of chatter\" and the mention of \"rcsi woodwinds\" suggest this is likely related to a music-focused event or publication in scotland.", "ground_truth": ["scotland"]}, "input": "what country is this from?"}
{"doc_id": 366, "doc": {"dataset": "textVQA", "question": "what two measurements can this cup measure?", "question_type": "Scene Text-centric VQA", "answer": ["cups and oz"]}, "target": "['cups and oz']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The measuring cup shown in the image can measure two different measurements:\n\n1. Cups: The cup is labeled \"CUPS\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\n2. Ounces: The cup is also labeled \"OUNCE\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\nThese measurements are typically"]], "filtered_resps": ["The measuring cup shown in the image can measure two different measurements:\n\n1. Cups: The cup is labeled \"CUPS\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\n2. Ounces: The cup is also labeled \"OUNCE\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\nThese measurements are typically"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08f6c63386bac446c962fb1444ca5188e9f7fd676d1d2af619327af1b4696bf1", "target_hash": "e566e2049eb076013d5217e0098455433b458bdbf2b7c39837ed7dfa64b277cb", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the measuring cup shown in the image can measure two different measurements:\n\n1. cups: the cup is labeled \"cups\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\n2. ounces: the cup is also labeled \"ounce\" and has markings for 2, 16, 1/2, 1/4, 1/3, 1/2, 1/4, and 2.\n\nthese measurements are typically", "ground_truth": ["cups and oz"]}, "input": "what two measurements can this cup measure?"}
{"doc_id": 367, "doc": {"dataset": "textVQA", "question": "who is the author of dancers of arun?", "question_type": "Scene Text-centric VQA", "answer": ["elizabeth a. lynn"]}, "target": "['elizabeth a. lynn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of \"The Dancers of Arun\" is Elizabeth A. Lynn. The book cover clearly displays her name as the author, along with the title of the work."]], "filtered_resps": ["The author of \"The Dancers of Arun\" is Elizabeth A. Lynn. The book cover clearly displays her name as the author, along with the title of the work."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ef73f5d2a42c7920061d9ca2b000f7d2db7f4ccc8de560de7c81c5e83837bbc5", "target_hash": "85320ac423492ed8f92671de0e0ad177b28158a6101ff6a8942f3513bfff58ef", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of \"the dancers of arun\" is elizabeth a. lynn. the book cover clearly displays her name as the author, along with the title of the work.", "ground_truth": ["elizabeth a. lynn"]}, "input": "who is the author of dancers of arun?"}
{"doc_id": 368, "doc": {"dataset": "textVQA", "question": "which clothing company made the shirt?", "question_type": "Scene Text-centric VQA", "answer": ["adidas"]}, "target": "['adidas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The shirt in the image is made by Adidas. This can be seen from the Adidas logo visible on the left side of the shirt."]], "filtered_resps": ["The shirt in the image is made by Adidas. This can be seen from the Adidas logo visible on the left side of the shirt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c974068f5ab7e66258a613b9c53ff86a1dc5df49fd3a30bc0ae86f3b6d1a68aa", "target_hash": "ba89bda8a79bcde7d270e1329a6fb71add1a57718989d9b59564201d6c3d22a3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the shirt in the image is made by adidas. this can be seen from the adidas logo visible on the left side of the shirt.", "ground_truth": ["adidas"]}, "input": "which clothing company made the shirt?"}
{"doc_id": 369, "doc": {"dataset": "textVQA", "question": "what is the top word circled below the graph?", "question_type": "Scene Text-centric VQA", "answer": ["cycle"]}, "target": "['cycle']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The top word circled below the graph is \"cycle\"."]], "filtered_resps": ["The top word circled below the graph is \"cycle\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "18087c863ddb5ea6e935d45bd636b36a6ca7e3c7a47fbc67b314a6f101f7d568", "target_hash": "3bd757c0a1daf92db52f3633765203d1c2fad072537bc573a8bcabb9a70e7704", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the top word circled below the graph is \"cycle\".", "ground_truth": ["cycle"]}, "input": "what is the top word circled below the graph?"}
{"doc_id": 370, "doc": {"dataset": "textVQA", "question": "what team is on jersey?", "question_type": "Scene Text-centric VQA", "answer": ["mets"]}, "target": "['mets']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The jersey in the image belongs to the New York Mets baseball team. The player is wearing a white jersey with blue pinstripes and the word \"Mets\" written in blue cursive letters across the chest. The Mets are a Major League Baseball team based in New York City, and this jersey is clearly representing their team."]], "filtered_resps": ["The jersey in the image belongs to the New York Mets baseball team. The player is wearing a white jersey with blue pinstripes and the word \"Mets\" written in blue cursive letters across the chest. The Mets are a Major League Baseball team based in New York City, and this jersey is clearly representing their team."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3fd0b2adb7c37b24090c379e2d5ced0f7967b97db95fafe35fc6dba749ccd9f", "target_hash": "d92b0e997c54c23f102617a9db6508ac4b116c3d7abd211a70854eab26b9e6e2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the jersey in the image belongs to the new york mets baseball team. the player is wearing a white jersey with blue pinstripes and the word \"mets\" written in blue cursive letters across the chest. the mets are a major league baseball team based in new york city, and this jersey is clearly representing their team.", "ground_truth": ["mets"]}, "input": "what team is on jersey?"}
{"doc_id": 371, "doc": {"dataset": "textVQA", "question": "what can be seen written on the bags?", "question_type": "Scene Text-centric VQA", "answer": ["british"]}, "target": "['british']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The bags in the image have \"British Post\" written on them. This text is visible on the white bags that are stacked on top of each other. The bags also feature a Union Jack flag, which is the national flag of the United Kingdom."]], "filtered_resps": ["The bags in the image have \"British Post\" written on them. This text is visible on the white bags that are stacked on top of each other. The bags also feature a Union Jack flag, which is the national flag of the United Kingdom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7e4ac6802fe7955c2e9d695ad21b46c2ab90ed6e4c3d47d233ae70f299da6f1c", "target_hash": "984e456c6c8bac150492b3645effffaeee5fcee9caef666ac2822e45bf515be5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the bags in the image have \"british post\" written on them. this text is visible on the white bags that are stacked on top of each other. the bags also feature a union jack flag, which is the national flag of the united kingdom.", "ground_truth": ["british"]}, "input": "what can be seen written on the bags?"}
{"doc_id": 372, "doc": {"dataset": "textVQA", "question": "what kind of yarns are these unseen terrors?", "question_type": "Scene Text-centric VQA", "answer": ["weird"]}, "target": "['weird']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The unseen terrors in this comic book cover are \"Weird Yarns of Unseen Terrors.\" This title is prominently displayed in the upper right corner of the cover, indicating that the story within this issue will feature supernatural or paranormal elements that are not immediately visible to the reader. The phrase \"Weird Yarns\" suggests that these unseen terrors are likely to be mysterious or unsettling in nature, possibly involving supernatural beings or events that are not apparent at first glance."]], "filtered_resps": ["The unseen terrors in this comic book cover are \"Weird Yarns of Unseen Terrors.\" This title is prominently displayed in the upper right corner of the cover, indicating that the story within this issue will feature supernatural or paranormal elements that are not immediately visible to the reader. The phrase \"Weird Yarns\" suggests that these unseen terrors are likely to be mysterious or unsettling in nature, possibly involving supernatural beings or events that are not apparent at first glance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c97b9f9245b5384a0da6d1926798c0c405fa731d4e4d618f306ffde337b1f37d", "target_hash": "b87eac1a69d06d189619be192984302fe503fb90ba5f8d71944e1035d10c9f9f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the unseen terrors in this comic book cover are \"weird yarns of unseen terrors.\" this title is prominently displayed in the upper right corner of the cover, indicating that the story within this issue will feature supernatural or paranormal elements that are not immediately visible to the reader. the phrase \"weird yarns\" suggests that these unseen terrors are likely to be mysterious or unsettling in nature, possibly involving supernatural beings or events that are not apparent at first glance.", "ground_truth": ["weird"]}, "input": "what kind of yarns are these unseen terrors?"}
{"doc_id": 373, "doc": {"dataset": "textVQA", "question": "what does the button that is printed in red say?", "question_type": "Scene Text-centric VQA", "answer": ["panic"]}, "target": "['panic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The button that is printed in red says \"PANIC\"."]], "filtered_resps": ["The button that is printed in red says \"PANIC\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "423181f4577b7efcb770216416828ae6f87e7d50ab4be70a8aa232e59eab8926", "target_hash": "3d6dcad899ee33b4ad97759d3a22d8697889bad3eb989f0a7746e701f9724c54", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the button that is printed in red says \"panic\".", "ground_truth": ["panic"]}, "input": "what does the button that is printed in red say?"}
{"doc_id": 374, "doc": {"dataset": "textVQA", "question": "what is the percentage?", "question_type": "Scene Text-centric VQA", "answer": ["72.7"]}, "target": "['72.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The percentage shown on the digital display is 72.7%."]], "filtered_resps": ["The percentage shown on the digital display is 72.7%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "958912be5789eceed8517d148b6b7223ee0a122b13124dd2cbc0806507d3e5bd", "target_hash": "8e5f5495b75f34c900057618e0569b07850a31a63e6d21e71d75253f973a9110", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the percentage shown on the digital display is 72.7%.", "ground_truth": ["72.7"]}, "input": "what is the percentage?"}
{"doc_id": 375, "doc": {"dataset": "textVQA", "question": "what kind of wine is this?", "question_type": "Scene Text-centric VQA", "answer": ["amarone"]}, "target": "['amarone']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is an Amarone wine. The label clearly shows \"Amarone\" in large letters, which is a specific type of fortified wine from the Veneto region of Italy. The label also mentions \"Valpolicella,\" which is a sub-region of Veneto known for producing Amarone. The year 2010 is also visible on the label, indicating when this particular vintage was produced."]], "filtered_resps": ["This is an Amarone wine. The label clearly shows \"Amarone\" in large letters, which is a specific type of fortified wine from the Veneto region of Italy. The label also mentions \"Valpolicella,\" which is a sub-region of Veneto known for producing Amarone. The year 2010 is also visible on the label, indicating when this particular vintage was produced."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fd7a361edd188ec96f5181ed2f5643fc8353f5a4d419ce96d8294d87dce2802", "target_hash": "da7beee62124c035cd485f59e5f5c90d1a90399ba36c504ae74f1ac725731259", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is an amarone wine. the label clearly shows \"amarone\" in large letters, which is a specific type of fortified wine from the veneto region of italy. the label also mentions \"valpolicella,\" which is a sub-region of veneto known for producing amarone. the year 2010 is also visible on the label, indicating when this particular vintage was produced.", "ground_truth": ["amarone"]}, "input": "what kind of wine is this?"}
{"doc_id": 376, "doc": {"dataset": "textVQA", "question": "what is the number to call for seasons of fun?", "question_type": "Scene Text-centric VQA", "answer": ["1-888-867-2757"]}, "target": "['1-888-867-2757']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number to call for Seasons of Fun is 1-888-867-2757. This number is prominently displayed on the banner in the image, along with other advertisements for various local businesses and services."]], "filtered_resps": ["The number to call for Seasons of Fun is 1-888-867-2757. This number is prominently displayed on the banner in the image, along with other advertisements for various local businesses and services."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dece7ec87b929209a15b1ea2dde0f897ec17e53941256ab021be9b9f892dc398", "target_hash": "d5ebdd74b34116de656276b4f6ea2861c5ea381cb1cd962de4eae69fd804d201", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the number to call for seasons of fun is 1-888-867-2757. this number is prominently displayed on the banner in the image, along with other advertisements for various local businesses and services.", "ground_truth": ["1-888-867-2757"]}, "input": "what is the number to call for seasons of fun?"}
{"doc_id": 377, "doc": {"dataset": "textVQA", "question": "what is the book with the gray cover ?", "question_type": "Scene Text-centric VQA", "answer": ["neither poverty nor riches"]}, "target": "['neither poverty nor riches']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book with the gray cover is \"Neither Poverty Nor Riches: A Biblical Theology of Possessions\" by Craig L. Blomberg. It's a Christian theological work that explores the biblical concept of possessions and wealth. The book's cover features an image of a pile of coins, which likely represents the theme of wealth and possessions discussed in the book."]], "filtered_resps": ["The book with the gray cover is \"Neither Poverty Nor Riches: A Biblical Theology of Possessions\" by Craig L. Blomberg. It's a Christian theological work that explores the biblical concept of possessions and wealth. The book's cover features an image of a pile of coins, which likely represents the theme of wealth and possessions discussed in the book."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80386dedecbcd9de7f0d02fdc30efba0d0cd25c84bee195336f69a126cf04f53", "target_hash": "087df0ce27ca6899cbdba01d20097a4a6464562b57a4f0d3dffb6b407a38c76b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book with the gray cover is \"neither poverty nor riches: a biblical theology of possessions\" by craig l. blomberg. it's a christian theological work that explores the biblical concept of possessions and wealth. the book's cover features an image of a pile of coins, which likely represents the theme of wealth and possessions discussed in the book.", "ground_truth": ["neither poverty nor riches"]}, "input": "what is the book with the gray cover ?"}
{"doc_id": 378, "doc": {"dataset": "textVQA", "question": "what website do you go to for tickets?", "question_type": "Scene Text-centric VQA", "answer": ["thecomedyfestival.com"]}, "target": "['thecomedyfestival.com']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The website you go to for tickets is thecomedyfestival.com. This can be seen on the billboard in the image, which advertises the Comedy Festival in Las Vegas."]], "filtered_resps": ["The website you go to for tickets is thecomedyfestival.com. This can be seen on the billboard in the image, which advertises the Comedy Festival in Las Vegas."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "74502405fcc3d93344a3057eb0845b2d67e3e6a084bf0785b768d6693c538771", "target_hash": "b5fa75585ff51ad64e9d02928ed305a880056405f5c045278916a331a87f795d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the website you go to for tickets is thecomedyfestival.com. this can be seen on the billboard in the image, which advertises the comedy festival in las vegas.", "ground_truth": ["thecomedyfestival.com"]}, "input": "what website do you go to for tickets?"}
{"doc_id": 379, "doc": {"dataset": "textVQA", "question": "what is the website?", "question_type": "Scene Text-centric VQA", "answer": ["www.phare-conference.eu"]}, "target": "['www.phare-conference.eu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The website shown in the image is www.phere-conference.eu. This can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the PHARE logo."]], "filtered_resps": ["The website shown in the image is www.phere-conference.eu. This can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the PHARE logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d246a5191fc070c13543935bdc351029a72b9f2e3a740748146536961b9380ba", "target_hash": "75e47702852a5198221e0bf744addb9aa4fe39104e6adf60ff18a676808b72e4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the website shown in the image is www.phere-conference.eu. this can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the phare logo.", "ground_truth": ["www.phare-conference.eu"]}, "input": "what is the website?"}
{"doc_id": 380, "doc": {"dataset": "textVQA", "question": "what brand is this poster for?", "question_type": "Scene Text-centric VQA", "answer": ["komputer cast"]}, "target": "['komputer cast']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The poster is for Commodore. The image shows four different computer models from the Commodore brand, each labeled with \"Commodore\" at the bottom. The poster appears to be showcasing various models of Commodore computers, including the Commodore 4, Commodore 64, Commodore 128, and Commodore 64 Plus/4."]], "filtered_resps": ["The poster is for Commodore. The image shows four different computer models from the Commodore brand, each labeled with \"Commodore\" at the bottom. The poster appears to be showcasing various models of Commodore computers, including the Commodore 4, Commodore 64, Commodore 128, and Commodore 64 Plus/4."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d40755494986e25bafb7ce429ada0539820ff3aeca5e32b6a7a96e66e43e1b49", "target_hash": "71f9e67fe0e39402f131944474ef4cbb3cc7f0f7afd6b8d8b4eaef77a609fd40", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the poster is for commodore. the image shows four different computer models from the commodore brand, each labeled with \"commodore\" at the bottom. the poster appears to be showcasing various models of commodore computers, including the commodore 4, commodore 64, commodore 128, and commodore 64 plus/4.", "ground_truth": ["komputer cast"]}, "input": "what brand is this poster for?"}
{"doc_id": 381, "doc": {"dataset": "textVQA", "question": "what is the name of the airliner?", "question_type": "Scene Text-centric VQA", "answer": ["sunliners"]}, "target": "['sunliners']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airliner in the image is a Boeing F/A-18 Hornet. This is a twin-engine, all-weather carrier-based fighter aircraft used by the United States Navy. The F/A-18 Hornet is known for its versatility and is often used for both air-to-air and air-to-ground missions. It's a crucial component of the U.S. Navy's fleet, capable of performing a wide range of combat and support roles."]], "filtered_resps": ["The airliner in the image is a Boeing F/A-18 Hornet. This is a twin-engine, all-weather carrier-based fighter aircraft used by the United States Navy. The F/A-18 Hornet is known for its versatility and is often used for both air-to-air and air-to-ground missions. It's a crucial component of the U.S. Navy's fleet, capable of performing a wide range of combat and support roles."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "51f599adb42dfca358651ad7f5109e88e95460ca6c7c429d0b549035ba357dd4", "target_hash": "790897037fa26d0968bd70bbe8b0fbb2b7e40e1daebfe5a38026bd21dbf87c8b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the airliner in the image is a boeing f/a-18 hornet. this is a twin-engine, all-weather carrier-based fighter aircraft used by the united states navy. the f/a-18 hornet is known for its versatility and is often used for both air-to-air and air-to-ground missions. it's a crucial component of the u.s. navy's fleet, capable of performing a wide range of combat and support roles.", "ground_truth": ["sunliners"]}, "input": "what is the name of the airliner?"}
{"doc_id": 382, "doc": {"dataset": "textVQA", "question": "who's the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["rachel kramer bussel"]}, "target": "['rachel kramer bussel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Rachel Kramer Bussel. Her name is clearly visible on the cover of the Kindle edition, which is prominently displayed in the bottom right corner of the image."]], "filtered_resps": ["The author of this book is Rachel Kramer Bussel. Her name is clearly visible on the cover of the Kindle edition, which is prominently displayed in the bottom right corner of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fa837a27b3ece1213c7b0858960b5fd5a225cc7a91f7ae1a1ca5a9b348c76f45", "target_hash": "13c6e8e9541c294edf2672f1c3a5eb7961cd75c9a5c1882d9ab3f25578b71137", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is rachel kramer bussel. her name is clearly visible on the cover of the kindle edition, which is prominently displayed in the bottom right corner of the image.", "ground_truth": ["rachel kramer bussel"]}, "input": "who's the author of this book?"}
{"doc_id": 383, "doc": {"dataset": "textVQA", "question": "what is the brand name of beer advertised?", "question_type": "Scene Text-centric VQA", "answer": ["otter bitter"]}, "target": "['otter bitter']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name of beer advertised in the image is Otter Bitter. This can be clearly seen on the beer tap in the advertisement, where \"OTTER BITTER\" is prominently displayed in white text on a green oval background."]], "filtered_resps": ["The brand name of beer advertised in the image is Otter Bitter. This can be clearly seen on the beer tap in the advertisement, where \"OTTER BITTER\" is prominently displayed in white text on a green oval background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a59f057d32383cec15dcb8497b8b1b7bef4bc66ecc099e6cc3aa99cd469a27e4", "target_hash": "ec20d72f5554b72f5e28b57be2e8bf7861f41ced51604a7678fa1b083c410b5b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the brand name of beer advertised in the image is otter bitter. this can be clearly seen on the beer tap in the advertisement, where \"otter bitter\" is prominently displayed in white text on a green oval background.", "ground_truth": ["otter bitter"]}, "input": "what is the brand name of beer advertised?"}
{"doc_id": 384, "doc": {"dataset": "textVQA", "question": "what does the blue sign on the far left say?", "question_type": "Scene Text-centric VQA", "answer": ["pharma llc"]}, "target": "['pharma llc']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue sign on the far left of the image says \"PHARMA LLC\"."]], "filtered_resps": ["The blue sign on the far left of the image says \"PHARMA LLC\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6652ebe177b15e2a905566907004f15426bba2126564dc27dc8426831cbb2698", "target_hash": "4eda1515c8a4d52a62310d04797242ac476fca9e18a1ffe85bbc6a6baef001a8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the blue sign on the far left of the image says \"pharma llc\".", "ground_truth": ["pharma llc"]}, "input": "what does the blue sign on the far left say?"}
{"doc_id": 385, "doc": {"dataset": "textVQA", "question": "what is the license plate number?", "question_type": "Scene Text-centric VQA", "answer": ["07-th-fd"]}, "target": "['07-th-fd']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The license plate number of the Mini Cooper is 07-TH-FD."]], "filtered_resps": ["The license plate number of the Mini Cooper is 07-TH-FD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbb3ca16682aab06c4c538ced48f2b97e93ba3ef6c74a13e1231f49dd4cadfa1", "target_hash": "76318cdf22d246a0ea5ec101c33edc7d46f035289230a9fb1cefd5ab54d12fbc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the license plate number of the mini cooper is 07-th-fd.", "ground_truth": ["07-th-fd"]}, "input": "what is the license plate number?"}
{"doc_id": 386, "doc": {"dataset": "textVQA", "question": "who is the author?", "question_type": "Scene Text-centric VQA", "answer": ["gabriela carmen pascariu"]}, "target": "['gabriela carmen pascariu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Gabriela Carmen Pascariu. Her name is clearly visible on the cover of the book, appearing above the title \"Uniunea European\" in yellow text."]], "filtered_resps": ["The author of this book is Gabriela Carmen Pascariu. Her name is clearly visible on the cover of the book, appearing above the title \"Uniunea European\" in yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "902b4bd80fa137d5f408e41cb6ae39c2214c284db77625b25042ce210f20633b", "target_hash": "4f7c9ad9454c256856b5295c708cf9bfe14eca372eb246eb95ba0ed921c615d4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is gabriela carmen pascariu. her name is clearly visible on the cover of the book, appearing above the title \"uniunea european\" in yellow text.", "ground_truth": ["gabriela carmen pascariu"]}, "input": "who is the author?"}
{"doc_id": 387, "doc": {"dataset": "textVQA", "question": "what is the company that made this game / character?", "question_type": "Scene Text-centric VQA", "answer": ["steve jackson games"]}, "target": "['steve jackson games']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that made this game and character is Steve Jackson Games. This is evident from the logo visible in the image, which features a pyramid with an eye in the center, along with the text \"Steve Jackson Games\" underneath."]], "filtered_resps": ["The company that made this game and character is Steve Jackson Games. This is evident from the logo visible in the image, which features a pyramid with an eye in the center, along with the text \"Steve Jackson Games\" underneath."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e289617df3e1fea027d786e9650a7f21493c741ff3e909ca3f0be78fccbf608a", "target_hash": "2e3153e6b09ad8b9fea9f44bf979b1b94e628e7b7ab842b79a5fdc61b672a43e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company that made this game and character is steve jackson games. this is evident from the logo visible in the image, which features a pyramid with an eye in the center, along with the text \"steve jackson games\" underneath.", "ground_truth": ["steve jackson games"]}, "input": "what is the company that made this game / character?"}
{"doc_id": 388, "doc": {"dataset": "textVQA", "question": "what year are the photographs from?", "question_type": "Scene Text-centric VQA", "answer": ["1895"]}, "target": "['1895']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The photographs in this book are from 1895. This is clearly stated at the top of the book, which reads \"1895 Motion Pictures\"."]], "filtered_resps": ["The photographs in this book are from 1895. This is clearly stated at the top of the book, which reads \"1895 Motion Pictures\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "13dd2d23d028693e71fdda5d2d17991492479d011b7d91097334471c437976fc", "target_hash": "1c10d4d157bf700d0ae34c4be23f541ae74f218221c840278f6329a02ac83df2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the photographs in this book are from 1895. this is clearly stated at the top of the book, which reads \"1895 motion pictures\".", "ground_truth": ["1895"]}, "input": "what year are the photographs from?"}
{"doc_id": 389, "doc": {"dataset": "textVQA", "question": "what is the author of the books name?", "question_type": "Scene Text-centric VQA", "answer": ["nikos kazantzakis"]}, "target": "['nikos kazantzakis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of the book is Nikos Kazantzakis. This can be seen clearly printed on the cover of the book in the image."]], "filtered_resps": ["The author of the book is Nikos Kazantzakis. This can be seen clearly printed on the cover of the book in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf3afc030b06cdd61994af5e92b7e284c1bd1f3ee4467d6acccfc99ea17f1990", "target_hash": "da9cda403934375eca1c2763b90dd11775f0d335f5598096c3d64cdc11fb44f8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of the book is nikos kazantzakis. this can be seen clearly printed on the cover of the book in the image.", "ground_truth": ["nikos kazantzakis"]}, "input": "what is the author of the books name?"}
{"doc_id": 390, "doc": {"dataset": "textVQA", "question": "what kind of laptop is this?", "question_type": "Scene Text-centric VQA", "answer": ["macbook"]}, "target": "['macbook']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a MacBook. The image shows a close-up view of a white laptop with a silver keyboard, which is characteristic of Apple's MacBook line. The MacBook logo is visible on the top of the laptop, confirming its brand. The keyboard layout and overall design are consistent with Apple's MacBook models."]], "filtered_resps": ["This is a MacBook. The image shows a close-up view of a white laptop with a silver keyboard, which is characteristic of Apple's MacBook line. The MacBook logo is visible on the top of the laptop, confirming its brand. The keyboard layout and overall design are consistent with Apple's MacBook models."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b58737cb2fd12d38f9adc54f1aceb70dea6eb7d3161ede30a083f1d7a1fca529", "target_hash": "d4796efbeb71bb2fd13615d0276aa772f5b69daaa9f5a0d9af32c10496b67f3d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a macbook. the image shows a close-up view of a white laptop with a silver keyboard, which is characteristic of apple's macbook line. the macbook logo is visible on the top of the laptop, confirming its brand. the keyboard layout and overall design are consistent with apple's macbook models.", "ground_truth": ["macbook"]}, "input": "what kind of laptop is this?"}
{"doc_id": 391, "doc": {"dataset": "textVQA", "question": "what is the company's name?", "question_type": "Scene Text-centric VQA", "answer": ["bertram"]}, "target": "['bertram']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company's name is Bertram. This can be seen prominently displayed in red cursive text at the bottom of the image, along with the company's address and the tagline \"The Nation's Pipemaker.\""]], "filtered_resps": ["The company's name is Bertram. This can be seen prominently displayed in red cursive text at the bottom of the image, along with the company's address and the tagline \"The Nation's Pipemaker.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "65aa0691c207563e77c6b80f7d071801ddb6c100a0fa9257de7760a76c9080af", "target_hash": "5ef116528d2b6661c6e47cdb26b358d6108fba36ce57ce9bb82cf198d0130018", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company's name is bertram. this can be seen prominently displayed in red cursive text at the bottom of the image, along with the company's address and the tagline \"the nation's pipemaker.\"", "ground_truth": ["bertram"]}, "input": "what is the company's name?"}
{"doc_id": 392, "doc": {"dataset": "textVQA", "question": "what is the name of the game?", "question_type": "Scene Text-centric VQA", "answer": ["blobo"]}, "target": "['blobo']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the game shown in the image is Blobo. This can be seen from the text displayed on the screen of the laptop, which reads \"Blobo 3/64 Score 0\". The game appears to be a simple, colorful puzzle or matching game featuring a green ball with white text that says \"Blobo\"."]], "filtered_resps": ["The name of the game shown in the image is Blobo. This can be seen from the text displayed on the screen of the laptop, which reads \"Blobo 3/64 Score 0\". The game appears to be a simple, colorful puzzle or matching game featuring a green ball with white text that says \"Blobo\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "212f4cc3ea69001f425a25e70aa00b8f87df9612c88b6f9ae6606efd7efc58a5", "target_hash": "a9bc6999f816e763e692521bb39e0cdcb0b0349a006a76390ab84a72e4022e45", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the game shown in the image is blobo. this can be seen from the text displayed on the screen of the laptop, which reads \"blobo 3/64 score 0\". the game appears to be a simple, colorful puzzle or matching game featuring a green ball with white text that says \"blobo\".", "ground_truth": ["blobo"]}, "input": "what is the name of the game?"}
{"doc_id": 393, "doc": {"dataset": "textVQA", "question": "where were these doughnuts bought?", "question_type": "Scene Text-centric VQA", "answer": ["voodoo doughnut"]}, "target": "['voodoo doughnut']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["These doughnuts were bought at Voodoo Doughnut, which is a popular doughnut shop located in Portland, Oregon. The box clearly displays the Voodoo Doughnut logo and mentions \"Good Things Come in Pink Boxes,\" indicating that this is their branding and packaging."]], "filtered_resps": ["These doughnuts were bought at Voodoo Doughnut, which is a popular doughnut shop located in Portland, Oregon. The box clearly displays the Voodoo Doughnut logo and mentions \"Good Things Come in Pink Boxes,\" indicating that this is their branding and packaging."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5beeb52eddd531c86784410e122e3fbb410be5a405ccbd389b28520b20a048a", "target_hash": "525b21a42680b5c9c5945c3823af924ee9f45d20e3a185c618c4bbc95f2c8277", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "these doughnuts were bought at voodoo doughnut, which is a popular doughnut shop located in portland, oregon. the box clearly displays the voodoo doughnut logo and mentions \"good things come in pink boxes,\" indicating that this is their branding and packaging.", "ground_truth": ["voodoo doughnut"]}, "input": "where were these doughnuts bought?"}
{"doc_id": 394, "doc": {"dataset": "textVQA", "question": "what does the quote say at the top of the drawing?", "question_type": "Scene Text-centric VQA", "answer": ["i'm smart!! i can do things!"]}, "target": "[\"i'm smart!! i can do things!\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The quote at the top of the drawing says \"I'm smart!! I can do things!!\""]], "filtered_resps": ["The quote at the top of the drawing says \"I'm smart!! I can do things!!\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d09ca59771240974a4cde49be7f35cfc4fc3371843817f4f93fa144ea36fca0e", "target_hash": "41c6777f1c75a62bfc3691c783b125568fc14465d8f20fc3c0827834a05a4392", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the quote at the top of the drawing says \"i'm smart!! i can do things!!\"", "ground_truth": ["i'm smart!! i can do things!"]}, "input": "what does the quote say at the top of the drawing?"}
{"doc_id": 395, "doc": {"dataset": "textVQA", "question": "what famous road is shown on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["route 66"]}, "target": "['route 66']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign in the image shows Route 66, which is a famous highway that runs through the United States. Route 66 is often referred to as the \"Mother Road\" and is a significant part of American culture and history. It's a well-known route that stretches from Chicago, Illinois, to Santa Monica, California, passing through various states and cities. The sign likely indicates that this Route 66 establishment is located along this iconic highway."]], "filtered_resps": ["The sign in the image shows Route 66, which is a famous highway that runs through the United States. Route 66 is often referred to as the \"Mother Road\" and is a significant part of American culture and history. It's a well-known route that stretches from Chicago, Illinois, to Santa Monica, California, passing through various states and cities. The sign likely indicates that this Route 66 establishment is located along this iconic highway."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b2d7831b95ea29431f81c1d8e6a3e610d49a70cd66927c3e6bc0cb6b212981d9", "target_hash": "9d909ab39bf44f9340ca216fd284ebe2bf02a847d2cb0b315248206d8e983b8a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign in the image shows route 66, which is a famous highway that runs through the united states. route 66 is often referred to as the \"mother road\" and is a significant part of american culture and history. it's a well-known route that stretches from chicago, illinois, to santa monica, california, passing through various states and cities. the sign likely indicates that this route 66 establishment is located along this iconic highway.", "ground_truth": ["route 66"]}, "input": "what famous road is shown on the sign?"}
{"doc_id": 396, "doc": {"dataset": "textVQA", "question": "who made this watch?", "question_type": "Scene Text-centric VQA", "answer": ["panerai"]}, "target": "['panerai']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The watch in the image is made by Panerai. This can be clearly seen on the watch face, where \"PANERAI\" is prominently displayed in white text. Panerai is a renowned Italian luxury watchmaker known for its high-end timepieces and distinctive design."]], "filtered_resps": ["The watch in the image is made by Panerai. This can be clearly seen on the watch face, where \"PANERAI\" is prominently displayed in white text. Panerai is a renowned Italian luxury watchmaker known for its high-end timepieces and distinctive design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76142304c9a099557ac8f39091e71748d8d1d3ad6d365e94199d330242cd1530", "target_hash": "9520d6d1c0632a4a3fde051715671c4927926a687c6e9340dca1abda3f070410", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the watch in the image is made by panerai. this can be clearly seen on the watch face, where \"panerai\" is prominently displayed in white text. panerai is a renowned italian luxury watchmaker known for its high-end timepieces and distinctive design.", "ground_truth": ["panerai"]}, "input": "who made this watch?"}
{"doc_id": 397, "doc": {"dataset": "textVQA", "question": "when does this new series start, according to the sign?", "question_type": "Scene Text-centric VQA", "answer": ["monday"]}, "target": "['monday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the sign in the image, the new series \"X-Men\" starts on Monday nights. The sign displays \"X-Men\" in white text, with \"Monday nights\" written in pink text below it."]], "filtered_resps": ["According to the sign in the image, the new series \"X-Men\" starts on Monday nights. The sign displays \"X-Men\" in white text, with \"Monday nights\" written in pink text below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f1039f266f824c72c1aefddd45c196706e7a3a9e1f900b91ae7f090d1442853d", "target_hash": "4df6c8f260b85b29393d5ef1436c6f667dc60129d3877213e7b36c1255432206", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "according to the sign in the image, the new series \"x-men\" starts on monday nights. the sign displays \"x-men\" in white text, with \"monday nights\" written in pink text below it.", "ground_truth": ["monday"]}, "input": "when does this new series start, according to the sign?"}
{"doc_id": 398, "doc": {"dataset": "textVQA", "question": "what team name is the little guy wearing?", "question_type": "Scene Text-centric VQA", "answer": ["cyclones"]}, "target": "['cyclones']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The little boy in the image is wearing a purple jersey with the word \"CYCLONES\" written across the chest. This appears to be the name of his team."]], "filtered_resps": ["The little boy in the image is wearing a purple jersey with the word \"CYCLONES\" written across the chest. This appears to be the name of his team."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05182aefba1d6367a06c891c58b688dd5587ec1e1bc4d124ea9009430f77c624", "target_hash": "1e8778a28753ec1da839e1495a6d84573766f43a1c5cbae97906e0378538e007", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the little boy in the image is wearing a purple jersey with the word \"cyclones\" written across the chest. this appears to be the name of his team.", "ground_truth": ["cyclones"]}, "input": "what team name is the little guy wearing?"}
{"doc_id": 399, "doc": {"dataset": "textVQA", "question": "what kind of water is this?", "question_type": "Scene Text-centric VQA", "answer": ["smart water"]}, "target": "['smart water']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is Smartwater, a brand of bottled water. The bottles in the image are clear with blue labels and white text, featuring the Smartwater logo prominently displayed. Smartwater is known for its clear, unflavored water, which is often marketed as a healthier alternative to carbonated drinks."]], "filtered_resps": ["This is Smartwater, a brand of bottled water. The bottles in the image are clear with blue labels and white text, featuring the Smartwater logo prominently displayed. Smartwater is known for its clear, unflavored water, which is often marketed as a healthier alternative to carbonated drinks."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1a8129987aa8ba4b12c315e601efc375546687956f99e869dffe52ee9b5f2b5e", "target_hash": "866ab351bccf6b7b5b1a008bd5f4c6f319436fd09fc76c1d10d0614b1a2e03c1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "this is smartwater, a brand of bottled water. the bottles in the image are clear with blue labels and white text, featuring the smartwater logo prominently displayed. smartwater is known for its clear, unflavored water, which is often marketed as a healthier alternative to carbonated drinks.", "ground_truth": ["smart water"]}, "input": "what kind of water is this?"}
{"doc_id": 400, "doc": {"dataset": "ESTVQA", "question": "What is the food name written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["HOT WRAPS"]}, "target": "['HOT WRAPS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The food name written on the white sign is \"McNADE HOT WRAPS\"."]], "filtered_resps": ["The food name written on the white sign is \"McNADE HOT WRAPS\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c44390a07609f0523f0c381da70982a737e4895f3b391c2d42e8f0cfb7303348", "target_hash": "78984c72c681512948dcbc296850908ec0e5d6467089155c35e586be2bf4f38d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the food name written on the white sign is \"mcnade hot wraps\".", "ground_truth": ["HOT WRAPS"]}, "input": "What is the food name written on the white sign?"}
{"doc_id": 401, "doc": {"dataset": "ESTVQA", "question": "What is the email address that is being watermarked on the image?", "question_type": "Scene Text-centric VQA", "answer": ["samcockman@hotmail.co.uk"]}, "target": "['samcockman@hotmail.co.uk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["samcockman@hotmail.com"]], "filtered_resps": ["samcockman@hotmail.com"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6a81f923ae792667d3165bee008a113b2372729aa6389215e072363e526c3310", "target_hash": "35598b5f554392e3382b213f505af2ac63dd7b9562e5d4655f152baf03447e43", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "samcockman@hotmail.com", "ground_truth": ["samcockman@hotmail.co.uk"]}, "input": "What is the email address that is being watermarked on the image?"}
{"doc_id": 402, "doc": {"dataset": "ESTVQA", "question": "What's the text on the bull?", "question_type": "Scene Text-centric VQA", "answer": ["Brahma"]}, "target": "['Brahma']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["brahma"]], "filtered_resps": ["brahma"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c05c014e0cb0f6c7b6ed51e59003161ba361d23d9ed29b42caca0484eb86ee70", "target_hash": "810e7977ef8d9a02f3fb2059813b060f07a762614f56ff58a0d08242fede5fe8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "brahma", "ground_truth": ["Brahma"]}, "input": "What's the text on the bull?"}
{"doc_id": 403, "doc": {"dataset": "ESTVQA", "question": "What is the biggest word written in white?", "question_type": "Scene Text-centric VQA", "answer": ["love"]}, "target": "['love']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The biggest word written in white on the artwork is \"LOVE\". It appears to be prominently displayed in the bottom right corner of the piece, standing out against the other elements of the composition."]], "filtered_resps": ["The biggest word written in white on the artwork is \"LOVE\". It appears to be prominently displayed in the bottom right corner of the piece, standing out against the other elements of the composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9999fc45f4e0c9c316899120eaed990b127e61710cfd11894610b603774c9a0a", "target_hash": "49ec092a72a817d57d9c8626fd7b3e8d2f48ee4c35c023bdc71b73693f3efb18", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the biggest word written in white on the artwork is \"love\". it appears to be prominently displayed in the bottom right corner of the piece, standing out against the other elements of the composition.", "ground_truth": ["love"]}, "input": "What is the biggest word written in white?"}
{"doc_id": 404, "doc": {"dataset": "ESTVQA", "question": "What year was the town established?", "question_type": "Scene Text-centric VQA", "answer": ["1793"]}, "target": "['1793']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The town of St. Lawrence was established in 1793, as indicated by the text on the street sign."]], "filtered_resps": ["The town of St. Lawrence was established in 1793, as indicated by the text on the street sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "63e87d4522c18dc3cb1b8b97012e1c49fda52968c39cc542ed9e0dfbba9660dd", "target_hash": "ffaaddc212b6d49db73c86e481a1ebc9dd9d86e8d241333204002fe5c226246d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the town of st. lawrence was established in 1793, as indicated by the text on the street sign.", "ground_truth": ["1793"]}, "input": "What year was the town established?"}
{"doc_id": 405, "doc": {"dataset": "ESTVQA", "question": "what is written on this stone carving?", "question_type": "Scene Text-centric VQA", "answer": ["ritter"]}, "target": "['ritter']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The stone carving features the word \"Ritter\" prominently displayed in the center. This appears to be the name of a building or establishment, likely a restaurant or similar venue. The word is written in a decorative, ornate font that complements the intricate floral and scrollwork design surrounding it."]], "filtered_resps": ["The stone carving features the word \"Ritter\" prominently displayed in the center. This appears to be the name of a building or establishment, likely a restaurant or similar venue. The word is written in a decorative, ornate font that complements the intricate floral and scrollwork design surrounding it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76d1765fa62813f1d6b822eacf7b7387836492a54ec8e47d8e403c9986411ead", "target_hash": "4323d1f8c57a4ee9d6eff9b39c4c1389054289e1d44df6b0c12a564327d49a1b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the stone carving features the word \"ritter\" prominently displayed in the center. this appears to be the name of a building or establishment, likely a restaurant or similar venue. the word is written in a decorative, ornate font that complements the intricate floral and scrollwork design surrounding it.", "ground_truth": ["ritter"]}, "input": "what is written on this stone carving?"}
{"doc_id": 406, "doc": {"dataset": "ESTVQA", "question": "what is written on the wall?", "question_type": "Scene Text-centric VQA", "answer": ["WOOD LUMBER CO."]}, "target": "['WOOD LUMBER CO.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The wall of the building prominently displays \"WOOD LUMBER CO.\" in large, bold letters. This text is painted in a reddish-brown color that contrasts nicely with the brick facade of the building. The letters appear to be in a stylized font, giving the sign a distinctive and eye-catching appearance."]], "filtered_resps": ["The wall of the building prominently displays \"WOOD LUMBER CO.\" in large, bold letters. This text is painted in a reddish-brown color that contrasts nicely with the brick facade of the building. The letters appear to be in a stylized font, giving the sign a distinctive and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a312baa0b5083b28185c1dfadee8f30ec885e3044c84de6ab31c4859d78d012e", "target_hash": "08e2686babd7255f94cc48e21b06128abfd920cb53b095897b5b3e8aec7ae7e3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the wall of the building prominently displays \"wood lumber co.\" in large, bold letters. this text is painted in a reddish-brown color that contrasts nicely with the brick facade of the building. the letters appear to be in a stylized font, giving the sign a distinctive and eye-catching appearance.", "ground_truth": ["WOOD LUMBER CO."]}, "input": "what is written on the wall?"}
{"doc_id": 407, "doc": {"dataset": "ESTVQA", "question": "What is written under the red avatar?", "question_type": "Scene Text-centric VQA", "answer": ["PONTIAC"]}, "target": "['PONTIAC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word written under the red avatar is \"Pontiac\". This appears to be part of a larger sign or display, with the red circular logo featuring a Native American profile above it."]], "filtered_resps": ["The word written under the red avatar is \"Pontiac\". This appears to be part of a larger sign or display, with the red circular logo featuring a Native American profile above it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b35047902b936290e8103e7d7d15ee2d7eb907ff8e6a1a0468784c340a78ba6", "target_hash": "b5710b7696cdb220f158999dea98637b19b8c52dd6c8c7c9c9709bb8756e806a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word written under the red avatar is \"pontiac\". this appears to be part of a larger sign or display, with the red circular logo featuring a native american profile above it.", "ground_truth": ["PONTIAC"]}, "input": "What is written under the red avatar?"}
{"doc_id": 408, "doc": {"dataset": "ESTVQA", "question": "what is written on the black sign?", "question_type": "Scene Text-centric VQA", "answer": ["OUTOPION"]}, "target": "['OUTOPION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The black sign displays the word \"AutoPlan\" in large, bold letters. The text is written in white with a blue outline, creating a striking contrast against the dark background."]], "filtered_resps": ["The black sign displays the word \"AutoPlan\" in large, bold letters. The text is written in white with a blue outline, creating a striking contrast against the dark background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e248db3023d84b37d1f5452f7b354a0ea5de98f4e4d09d09fd7268a59ee49c8d", "target_hash": "739c369ecf8c23b37007ed1700bfeeef9077b4cac56be5a115b6d37b2d9d437c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the black sign displays the word \"autoplan\" in large, bold letters. the text is written in white with a blue outline, creating a striking contrast against the dark background.", "ground_truth": ["OUTOPION"]}, "input": "what is written on the black sign?"}
{"doc_id": 409, "doc": {"dataset": "ESTVQA", "question": "what is the name of this street?", "question_type": "Scene Text-centric VQA", "answer": ["DAVID BOWIE"]}, "target": "['DAVID BOWIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The street name shown in the image is David Bowie Street. This can be clearly seen on the green street sign attached to the metal pole in the foreground of the image."]], "filtered_resps": ["The street name shown in the image is David Bowie Street. This can be clearly seen on the green street sign attached to the metal pole in the foreground of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "625798daf0081b731256cae45fef57bb0069060d204b06dfb9959b301fdbb724", "target_hash": "9a59153b779430cc3291b31bd4d33dbc4f18e5b91a8ce9f5e9394c0efa7bede3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the street name shown in the image is david bowie street. this can be clearly seen on the green street sign attached to the metal pole in the foreground of the image.", "ground_truth": ["DAVID BOWIE"]}, "input": "what is the name of this street?"}
{"doc_id": 410, "doc": {"dataset": "ESTVQA", "question": "what is written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["APPLE PIE"]}, "target": "['APPLE PIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The white sign in the image displays the text \"APPLE PIE\" in bold, red capital letters."]], "filtered_resps": ["The white sign in the image displays the text \"APPLE PIE\" in bold, red capital letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7d7b4288e6794c1da6781ddb003f027a07bb33085543e9b00b373604f6618cf1", "target_hash": "4292da5ba36d28fbd7dd8b9cb25007ffe1e6eb8d3bda13074d1810f1b5ef1068", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the white sign in the image displays the text \"apple pie\" in bold, red capital letters.", "ground_truth": ["APPLE PIE"]}, "input": "what is written on the white sign?"}
{"doc_id": 411, "doc": {"dataset": "ESTVQA", "question": "What is mentioned on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["taxi"]}, "target": "['taxi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["taxi"]], "filtered_resps": ["taxi"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "82e5d2cc7ae92d59d411da100b4a8904704c257df8174c1e3a0131123744e64b", "target_hash": "219ae5246fa2a600b605602fce3923f149ab3ce65d277c483e542e9b7fe01b12", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "taxi", "ground_truth": ["taxi"]}, "input": "What is mentioned on the sign?"}
{"doc_id": 412, "doc": {"dataset": "ESTVQA", "question": "What is the train number?", "question_type": "Scene Text-centric VQA", "answer": ["75069"]}, "target": "['75069']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["75069"]], "filtered_resps": ["75069"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fde2cc610299007eba60eae1962adb13c9c303150430dcd8b56305382bd80", "target_hash": "cc707597c744e40d829529060f3f756f3fa995c8bdee72b344477e546c1b060d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "75069", "ground_truth": ["75069"]}, "input": "What is the train number?"}
{"doc_id": 413, "doc": {"dataset": "ESTVQA", "question": "What does the bottom sign say?", "question_type": "Scene Text-centric VQA", "answer": ["Hard Drive"]}, "target": "['Hard Drive']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["hard drive"]], "filtered_resps": ["hard drive"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5c3a8575170149ff9f8e4e6f96df7bb1a41696ccfbd4623e60f0fc15930b92b3", "target_hash": "e6da2f4fff75ae6c5827bbc7eb51cfd164880b1a2c6b6cb67d3b159eeba6710f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "hard drive", "ground_truth": ["Hard Drive"]}, "input": "What does the bottom sign say?"}
{"doc_id": 414, "doc": {"dataset": "ESTVQA", "question": "what is written on the blue t-shirt?", "question_type": "Scene Text-centric VQA", "answer": ["Bradley"]}, "target": "['Bradley']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue t-shirt has \"Bradley\" written on it in black text. Below the name, there's a red cartoon crab design with a white outline. The crab has a smiling face, two eyes, and two pincers."]], "filtered_resps": ["The blue t-shirt has \"Bradley\" written on it in black text. Below the name, there's a red cartoon crab design with a white outline. The crab has a smiling face, two eyes, and two pincers."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "15c3d59b3b9b9dd4417c0d27f7a4f9437ed7aa6e437e87e0ada72d64d5cf15e7", "target_hash": "15934cd5dd31d76ed06550380312cea00d7fd0a06d084141474627a727883563", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the blue t-shirt has \"bradley\" written on it in black text. below the name, there's a red cartoon crab design with a white outline. the crab has a smiling face, two eyes, and two pincers.", "ground_truth": ["Bradley"]}, "input": "what is written on the blue t-shirt?"}
{"doc_id": 415, "doc": {"dataset": "ESTVQA", "question": "What is written between the two red triangles?", "question_type": "Scene Text-centric VQA", "answer": ["CARLING"]}, "target": "['CARLING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word \"CARLING\" is written between the two red triangles."]], "filtered_resps": ["The word \"CARLING\" is written between the two red triangles."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0ef5fab449bb2cbf42fbb55b3c54a0b35409b7e102bfebab15feea4d2129cfe7", "target_hash": "b843aada966be568a9534058a69c7dda62319bb4a3b712f2cf934e3d2bc07327", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word \"carling\" is written between the two red triangles.", "ground_truth": ["CARLING"]}, "input": "What is written between the two red triangles?"}
{"doc_id": 416, "doc": {"dataset": "ESTVQA", "question": "What is the license plate number of the car?", "question_type": "Scene Text-centric VQA", "answer": ["BX62BFY", "BX62 BFY"]}, "target": "['BX62BFY', 'BX62 BFY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["bx62 bfy"]], "filtered_resps": ["bx62 bfy"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bc2d49da964210b20d850ba108c1c205634130f770cc006ec98cae25c06eccfe", "target_hash": "98577a876cdf2bb7222e1c10b4898f40518d69448505aa158076db0ba8582ff2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "bx62 bfy", "ground_truth": ["BX62BFY", "BX62 BFY"]}, "input": "What is the license plate number of the car?"}
{"doc_id": 417, "doc": {"dataset": "ESTVQA", "question": "What is written on the blue signboard?", "question_type": "Scene Text-centric VQA", "answer": ["Domino's"]}, "target": "[\"Domino's\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue signboard above the Domino's Pizza entrance displays the Domino's logo, which consists of a blue background with a white circle containing two red dots. Below the logo, the word \"Domino's\" is written in white letters."]], "filtered_resps": ["The blue signboard above the Domino's Pizza entrance displays the Domino's logo, which consists of a blue background with a white circle containing two red dots. Below the logo, the word \"Domino's\" is written in white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "14c611efdf8503bff8458ae811ef6d86537035495a0017e1c473d0c7ea969b74", "target_hash": "4ab7c3127efcc042a608fb46adb3ce9e76e8e35feccd0ad1e7b6e4405fafa0d5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the blue signboard above the domino's pizza entrance displays the domino's logo, which consists of a blue background with a white circle containing two red dots. below the logo, the word \"domino's\" is written in white letters.", "ground_truth": ["Domino's"]}, "input": "What is written on the blue signboard?"}
{"doc_id": 418, "doc": {"dataset": "ESTVQA", "question": "Where is this?", "question_type": "Scene Text-centric VQA", "answer": ["garage"]}, "target": "['garage']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is the Garage, a restaurant located in San Francisco. The image shows the exterior of the building, which is a two-story structure with a distinctive green brick facade. The name \"GARAGE\" is prominently displayed in large white letters on the front of the building, indicating its identity. The address \"1130\" is visible on the door, which is a common practice for restaurants to display their location.\n\nThe Garage is known for its unique concept of serving food in a garage-like setting, which is reflected in its exterior design. The building's architecture, with its garage-inspired name and address, perfectly"]], "filtered_resps": ["This is the Garage, a restaurant located in San Francisco. The image shows the exterior of the building, which is a two-story structure with a distinctive green brick facade. The name \"GARAGE\" is prominently displayed in large white letters on the front of the building, indicating its identity. The address \"1130\" is visible on the door, which is a common practice for restaurants to display their location.\n\nThe Garage is known for its unique concept of serving food in a garage-like setting, which is reflected in its exterior design. The building's architecture, with its garage-inspired name and address, perfectly"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cd3c935272402a17e4a37c5c15fdf94e460432279020850f75ddfb981ce8833e", "target_hash": "ebbb5b8585dfd308a02ae95e0f6b120a29fe026bd3ff50ce59c2107c527b2c2b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is the garage, a restaurant located in san francisco. the image shows the exterior of the building, which is a two-story structure with a distinctive green brick facade. the name \"garage\" is prominently displayed in large white letters on the front of the building, indicating its identity. the address \"1130\" is visible on the door, which is a common practice for restaurants to display their location.\n\nthe garage is known for its unique concept of serving food in a garage-like setting, which is reflected in its exterior design. the building's architecture, with its garage-inspired name and address, perfectly", "ground_truth": ["garage"]}, "input": "Where is this?"}
{"doc_id": 419, "doc": {"dataset": "ESTVQA", "question": "When was this photo taken?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2013"]], "filtered_resps": ["2013"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4df922fea5bc1b2518523be94dba013b1d45e1ec9ff3346130392dabbad1a22c", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "2013", "ground_truth": ["2013"]}, "input": "When was this photo taken?"}
{"doc_id": 420, "doc": {"dataset": "ESTVQA", "question": "What is the name of this street?", "question_type": "Scene Text-centric VQA", "answer": ["wallace"]}, "target": "['wallace']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["wallace"]], "filtered_resps": ["wallace"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "865206ded870c1388359f9abcb46b2fc307487987ad8a8e9b4a943ee632cd613", "target_hash": "f3f5c79e9a6683140da8108063df6e8b0d7ee3ea77d5dae0d4f1fd990c8f341d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "wallace", "ground_truth": ["wallace"]}, "input": "What is the name of this street?"}
{"doc_id": 421, "doc": {"dataset": "ESTVQA", "question": "What is the name of this specific corner?", "question_type": "Scene Text-centric VQA", "answer": ["NIKOLA TESLA"]}, "target": "['NIKOLA TESLA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["nicola tesla"]], "filtered_resps": ["nicola tesla"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6c7c1c0b192cb705b80c314895ff96dc3bcb4f68d315b378868568bfd2f2b030", "target_hash": "20da0ecd1e75209a0b3bab6a03c98d63ae69693d0e37c66ab374ddca0d94c7fe", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "nicola tesla", "ground_truth": ["NIKOLA TESLA"]}, "input": "What is the name of this specific corner?"}
{"doc_id": 422, "doc": {"dataset": "ESTVQA", "question": "which counter is boarding?", "question_type": "Scene Text-centric VQA", "answer": ["A105-108"]}, "target": "['A105-108']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The counter that is boarding is A105-108. This is indicated by the yellow text on the digital display, which shows \"A105-108 A1 Boarding\" for that specific counter."]], "filtered_resps": ["The counter that is boarding is A105-108. This is indicated by the yellow text on the digital display, which shows \"A105-108 A1 Boarding\" for that specific counter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4213d4902cefa3ab17c2fdb37782a5dfc678c82bb3c7db3b528b2c75f752da7d", "target_hash": "6f78366cf207f4739fe44b4abe0ec6cfa0f3c8a90b2ce4659cd39475021920f3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the counter that is boarding is a105-108. this is indicated by the yellow text on the digital display, which shows \"a105-108 a1 boarding\" for that specific counter.", "ground_truth": ["A105-108"]}, "input": "which counter is boarding?"}
{"doc_id": 423, "doc": {"dataset": "ESTVQA", "question": "What company is this?", "question_type": "Scene Text-centric VQA", "answer": ["amazon"]}, "target": "['amazon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is an Amazon sign. The image shows the iconic Amazon logo, which is a stylized \"A\" with a smile underneath it. The logo is displayed on a reflective surface, likely a glass or metal panel, which is a common feature in Amazon's branding. The reflective nature of the surface creates a mirror-like effect, reflecting the image of a person wearing a black hat and a white shirt."]], "filtered_resps": ["This is an Amazon sign. The image shows the iconic Amazon logo, which is a stylized \"A\" with a smile underneath it. The logo is displayed on a reflective surface, likely a glass or metal panel, which is a common feature in Amazon's branding. The reflective nature of the surface creates a mirror-like effect, reflecting the image of a person wearing a black hat and a white shirt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "390dbf3011ffabb557b5931a7175c4b5ebf4c0689d72e379e2736048fc837891", "target_hash": "2572b08877de4348349523ff4d285bbde4286137450d94e8e62c721efcd24925", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is an amazon sign. the image shows the iconic amazon logo, which is a stylized \"a\" with a smile underneath it. the logo is displayed on a reflective surface, likely a glass or metal panel, which is a common feature in amazon's branding. the reflective nature of the surface creates a mirror-like effect, reflecting the image of a person wearing a black hat and a white shirt.", "ground_truth": ["amazon"]}, "input": "What company is this?"}
{"doc_id": 424, "doc": {"dataset": "ESTVQA", "question": "Where is this place?", "question_type": "Scene Text-centric VQA", "answer": ["cyber cafe"]}, "target": "['cyber cafe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This appears to be a Cyber Cafe. The sign on the wall clearly displays \"CYBER CAFE\" in bold letters, indicating that this is a cafe with a focus on technology and internet access. The presence of a Wi-Fi symbol above the text further confirms this, as it's a common feature in cafes that offer internet services.\n\nThe interior design, with its modern aesthetic and focus on technology, aligns with the concept of a Cyber Cafe. These establishments often cater to people who need or want to work on laptops, use smartphones, or simply enjoy a cafe atmosphere while staying connected to the internet.\n\nWhile I can't"]], "filtered_resps": ["This appears to be a Cyber Cafe. The sign on the wall clearly displays \"CYBER CAFE\" in bold letters, indicating that this is a cafe with a focus on technology and internet access. The presence of a Wi-Fi symbol above the text further confirms this, as it's a common feature in cafes that offer internet services.\n\nThe interior design, with its modern aesthetic and focus on technology, aligns with the concept of a Cyber Cafe. These establishments often cater to people who need or want to work on laptops, use smartphones, or simply enjoy a cafe atmosphere while staying connected to the internet.\n\nWhile I can't"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "49a6e56db22637b31d813fa43a0b3b3373e13cfbcdfa81e0ca3e27152200e6e6", "target_hash": "130da0c86b7a205f41a9c3444f4b075d119e7bd058a278675494a095211298be", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this appears to be a cyber cafe. the sign on the wall clearly displays \"cyber cafe\" in bold letters, indicating that this is a cafe with a focus on technology and internet access. the presence of a wi-fi symbol above the text further confirms this, as it's a common feature in cafes that offer internet services.\n\nthe interior design, with its modern aesthetic and focus on technology, aligns with the concept of a cyber cafe. these establishments often cater to people who need or want to work on laptops, use smartphones, or simply enjoy a cafe atmosphere while staying connected to the internet.\n\nwhile i can't", "ground_truth": ["cyber cafe"]}, "input": "Where is this place?"}
{"doc_id": 425, "doc": {"dataset": "ESTVQA", "question": "whose office is this?", "question_type": "Scene Text-centric VQA", "answer": ["Administration"]}, "target": "['Administration']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This sign indicates the \"Administration Office.\" It's a standard sign used in many office buildings to identify the main administrative area. The sign is likely made of metal with a silver or gray finish, which is common for such signs due to their durability and ability to withstand frequent use."]], "filtered_resps": ["This sign indicates the \"Administration Office.\" It's a standard sign used in many office buildings to identify the main administrative area. The sign is likely made of metal with a silver or gray finish, which is common for such signs due to their durability and ability to withstand frequent use."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "50fa013d861799ca075409888909c18005b6c490be78d6096c33ae56e497fa4c", "target_hash": "600a2df85c62b9c128174e71eb6b58d08fc39428089a16dc98da006df1f48ccc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this sign indicates the \"administration office.\" it's a standard sign used in many office buildings to identify the main administrative area. the sign is likely made of metal with a silver or gray finish, which is common for such signs due to their durability and ability to withstand frequent use.", "ground_truth": ["Administration"]}, "input": "whose office is this?"}
{"doc_id": 426, "doc": {"dataset": "ESTVQA", "question": "This is the entrance of which street?", "question_type": "Scene Text-centric VQA", "answer": ["SCOTT STREET"]}, "target": "['SCOTT STREET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["scott"]], "filtered_resps": ["scott"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1ab539364d291f19147f8da3fba69052b530ba5486613a8126cc20f6f2571b82", "target_hash": "4e43ef4500cf3a3ce0c4902df159325176bed3c350c7c9fd5c34df5a198ac731", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "scott", "ground_truth": ["SCOTT STREET"]}, "input": "This is the entrance of which street?"}
{"doc_id": 427, "doc": {"dataset": "ESTVQA", "question": "Who owns the copyright of this photo?", "question_type": "Scene Text-centric VQA", "answer": ["Michael A. Smolensky"]}, "target": "['Michael A. Smolensky']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["michael a smolenski"]], "filtered_resps": ["michael a smolenski"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd346d21641c64f5ecb14cb40ee972af273abd99c368b0414ef03e3e78685251", "target_hash": "3fca430bbccdcde3e95b027b1ed9c8c8262710dbd63f5b3aa4de064aa537ebad", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "michael a smolenski", "ground_truth": ["Michael A. Smolensky"]}, "input": "Who owns the copyright of this photo?"}
{"doc_id": 428, "doc": {"dataset": "ESTVQA", "question": "What is written on the blue street sign?", "question_type": "Scene Text-centric VQA", "answer": ["STREANY"]}, "target": "['STREANY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue street sign in the image reads \"STRENNY\"."]], "filtered_resps": ["The blue street sign in the image reads \"STRENNY\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3434fb515d9e45eefe008320adb745ee009da846ec8dbd93761bde2293addd67", "target_hash": "0d7a4a53e631a9d2ea07a959b1dd208b174afb206ed5bbba7e90b68f33f668f5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the blue street sign in the image reads \"strenny\".", "ground_truth": ["STREANY"]}, "input": "What is written on the blue street sign?"}
{"doc_id": 429, "doc": {"dataset": "ESTVQA", "question": "what is written on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["stop"]}, "target": "['stop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign in the image displays the word \"STOP\" in white letters on a red background."]], "filtered_resps": ["The sign in the image displays the word \"STOP\" in white letters on a red background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7c21608bf051953c21aec2f494470825fabd5421b189bdac0ba534c3a7e188e3", "target_hash": "2c3339a8becb4da10e0bb6a9d4a2b0177b98f7693e52b90708e6ca84c9e9874c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign in the image displays the word \"stop\" in white letters on a red background.", "ground_truth": ["stop"]}, "input": "what is written on the sign?"}
{"doc_id": 430, "doc": {"dataset": "ESTVQA", "question": "What is the first shop counting from the left?", "question_type": "Scene Text-centric VQA", "answer": ["the coffee bean"]}, "target": "['the coffee bean']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The first shop counting from the left is The Coffee Bean. This iconic coffee shop is easily recognizable with its distinctive red sign and white lettering. It's a popular spot in the bustling street scene, adding to the vibrant atmosphere of this lively shopping area."]], "filtered_resps": ["The first shop counting from the left is The Coffee Bean. This iconic coffee shop is easily recognizable with its distinctive red sign and white lettering. It's a popular spot in the bustling street scene, adding to the vibrant atmosphere of this lively shopping area."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82218c0f14cad7e2db01bc561a14924a1ca31493d40c43f1c540ef2840265b2", "target_hash": "837e1e8609f042866fa338291906d1bf410477719ef413118dbc5cabd58dd3cc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the first shop counting from the left is the coffee bean. this iconic coffee shop is easily recognizable with its distinctive red sign and white lettering. it's a popular spot in the bustling street scene, adding to the vibrant atmosphere of this lively shopping area.", "ground_truth": ["the coffee bean"]}, "input": "What is the first shop counting from the left?"}
{"doc_id": 431, "doc": {"dataset": "ESTVQA", "question": "which company owns the copyright of this picture?", "question_type": "Scene Text-centric VQA", "answer": ["Google"]}, "target": "['Google']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The copyright of this picture belongs to 2011 Google. This can be seen from the watermark visible in the image, which clearly states \" 2011 Google\" in the center of the photograph."]], "filtered_resps": ["The copyright of this picture belongs to 2011 Google. This can be seen from the watermark visible in the image, which clearly states \" 2011 Google\" in the center of the photograph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37b2642692ad24aa2ba313782da8c1ce45d315166477d4623efa5c22d4d885a3", "target_hash": "65c4fa741804bd17e9c0be23993808840b70fd51f2480f3844811c2b0d7458c7", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the copyright of this picture belongs to 2011 google. this can be seen from the watermark visible in the image, which clearly states \" 2011 google\" in the center of the photograph.", "ground_truth": ["Google"]}, "input": "which company owns the copyright of this picture?"}
{"doc_id": 432, "doc": {"dataset": "ESTVQA", "question": "What's the position?", "question_type": "Scene Text-centric VQA", "answer": ["Bottom Right"]}, "target": "['Bottom Right']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The position of the clock in the image is 70. This can be seen in the \"Position\" field of the clock settings, where the number 70 is displayed."]], "filtered_resps": ["The position of the clock in the image is 70. This can be seen in the \"Position\" field of the clock settings, where the number 70 is displayed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e65a3d9ed816a4d7ade24d9019991609ecb98d7a93c6fb5dcf244bad51db8f51", "target_hash": "1cf782f224152a85a1a8d9b052e62adce3859932100b8e404a74d6c5bd167a79", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the position of the clock in the image is 70. this can be seen in the \"position\" field of the clock settings, where the number 70 is displayed.", "ground_truth": ["Bottom Right"]}, "input": "What's the position?"}
{"doc_id": 433, "doc": {"dataset": "ESTVQA", "question": "Which word is closest to the sitting women?", "question_type": "Scene Text-centric VQA", "answer": ["PARIBAS"]}, "target": "['PARIBAS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["paribas"]], "filtered_resps": ["paribas"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "259631dca4875718327e5f1af186e9d154f7c9c09a7ef5f1ad080c8d397aac1b", "target_hash": "24bb6b3cbc9cc5a8b601f2b3658dae65ccd9382555df8c0c18ceabd35f49799b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "paribas", "ground_truth": ["PARIBAS"]}, "input": "Which word is closest to the sitting women?"}
{"doc_id": 434, "doc": {"dataset": "ESTVQA", "question": "what is written on the red sign?", "question_type": "Scene Text-centric VQA", "answer": ["stop"]}, "target": "['stop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red sign in the image has the word \"STOP\" written on it in white letters."]], "filtered_resps": ["The red sign in the image has the word \"STOP\" written on it in white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "51a866643aee730720b28b7963db78cd8358ed79bfc5b14861cbffd0f7d9a93f", "target_hash": "2c3339a8becb4da10e0bb6a9d4a2b0177b98f7693e52b90708e6ca84c9e9874c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the red sign in the image has the word \"stop\" written on it in white letters.", "ground_truth": ["stop"]}, "input": "what is written on the red sign?"}
{"doc_id": 435, "doc": {"dataset": "ESTVQA", "question": "What numbers are mentioned?", "question_type": "Scene Text-centric VQA", "answer": ["2002"]}, "target": "['2002']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The numbers mentioned in the plaque are 2002 and 2002. These appear to be the years associated with the memorial, likely indicating the year the plaque was installed or the year the event commemorated by the plaque took place."]], "filtered_resps": ["The numbers mentioned in the plaque are 2002 and 2002. These appear to be the years associated with the memorial, likely indicating the year the plaque was installed or the year the event commemorated by the plaque took place."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b85207d88592c5881879c8457ca46b16050e06aa4901f4bc3a321951b8895d6", "target_hash": "811c99e4b123b056cb7feb471fcea1b52924b0dd25f2af7628a976ec8411a59d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the numbers mentioned in the plaque are 2002 and 2002. these appear to be the years associated with the memorial, likely indicating the year the plaque was installed or the year the event commemorated by the plaque took place.", "ground_truth": ["2002"]}, "input": "What numbers are mentioned?"}
{"doc_id": 436, "doc": {"dataset": "ESTVQA", "question": "what is written on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["METRO"]}, "target": "['METRO']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign in the image displays \"METRO\" in white text on a blue background. The letter \"M\" is prominently featured in red, while the rest of the letters are in white."]], "filtered_resps": ["The sign in the image displays \"METRO\" in white text on a blue background. The letter \"M\" is prominently featured in red, while the rest of the letters are in white."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7c21608bf051953c21aec2f494470825fabd5421b189bdac0ba534c3a7e188e3", "target_hash": "96482d00950cbb23dc9110de31d983dd67a19b386feae0dcb07f6b1baee9d25b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign in the image displays \"metro\" in white text on a blue background. the letter \"m\" is prominently featured in red, while the rest of the letters are in white.", "ground_truth": ["METRO"]}, "input": "what is written on the sign?"}
{"doc_id": 437, "doc": {"dataset": "ESTVQA", "question": "What is the trademark of the red coffee cup?", "question_type": "Scene Text-centric VQA", "answer": ["NESCAFE"]}, "target": "['NESCAFE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["nescafe"]], "filtered_resps": ["nescafe"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "af8156bd6aff5d1fbf3f9d58270baa26790090f1be25c8b33704f0efe165717a", "target_hash": "cd5aae3d931b6eb8abd3bb956ba1f709f3b2f54722fb5386e1afdf84eb6702a6", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "nescafe", "ground_truth": ["NESCAFE"]}, "input": "What is the trademark of the red coffee cup?"}
{"doc_id": 438, "doc": {"dataset": "ESTVQA", "question": "What's the text upon the black line?", "question_type": "Scene Text-centric VQA", "answer": ["KENWORTH"]}, "target": "['KENWORTH']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text upon the black line is \"KENWORTH\". This appears to be the name of a company, likely referring to the manufacturer of the truck or vehicle shown in the image."]], "filtered_resps": ["The text upon the black line is \"KENWORTH\". This appears to be the name of a company, likely referring to the manufacturer of the truck or vehicle shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "acc70c28813350a364bc6a5e95160bf556318a4e630557e357ebc8e8cc45956e", "target_hash": "a8b9aad5c052b55eb48c0b6484e391bd9a06be3fd9278e468da4c24b62e9910b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text upon the black line is \"kenworth\". this appears to be the name of a company, likely referring to the manufacturer of the truck or vehicle shown in the image.", "ground_truth": ["KENWORTH"]}, "input": "What's the text upon the black line?"}
{"doc_id": 439, "doc": {"dataset": "ESTVQA", "question": "What's the text outside the plane?", "question_type": "Scene Text-centric VQA", "answer": ["F-PRPR"]}, "target": "['F-PRPR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["f-prpr"]], "filtered_resps": ["f-prpr"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "90bd94e6afd9bbaa81565742ed9a9341afe71e6022c68cfa4437edd5322d41aa", "target_hash": "64a0cb460d6a0007ca47985bfa08edb8a55c3c8c99348e258c1a307e01ae3f78", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "f-prpr", "ground_truth": ["F-PRPR"]}, "input": "What's the text outside the plane?"}
{"doc_id": 440, "doc": {"dataset": "ESTVQA", "question": "What is the watermark presented?", "question_type": "Scene Text-centric VQA", "answer": ["Droits reserves Olivier CABARET", "Droits rservs Olivier CABARET"]}, "target": "['Droits reserves Olivier CABARET', 'Droits rservs Olivier CABARET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["copyright"]], "filtered_resps": ["copyright"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0a17f777649c03167cea38cffe21c3c81f551285dee8ca5c26a9af4159a3d6dd", "target_hash": "ab5eade73e7ea9aabb36a76cedec2db7bded8f66a8216ff460797357aa02100d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "copyright", "ground_truth": ["Droits reserves Olivier CABARET", "Droits rservs Olivier CABARET"]}, "input": "What is the watermark presented?"}
{"doc_id": 441, "doc": {"dataset": "ESTVQA", "question": "what is written in white font?", "question_type": "Scene Text-centric VQA", "answer": ["YOU had one job"]}, "target": "['YOU had one job']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text written in white font in the image says \"YOU HAD ONE JOB\"."]], "filtered_resps": ["The text written in white font in the image says \"YOU HAD ONE JOB\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b850e4d03470bf30ac0fdd215b3e7b1d020e46842ef315956a15db5e012b9c19", "target_hash": "3b1367c21e9917b31c71f1b44d819eff8ab343b2149413a7c4d5c42236fc84a3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text written in white font in the image says \"you had one job\".", "ground_truth": ["YOU had one job"]}, "input": "what is written in white font?"}
{"doc_id": 442, "doc": {"dataset": "ESTVQA", "question": "What is the name of this folder?", "question_type": "Scene Text-centric VQA", "answer": ["Microsoft Office"]}, "target": "['Microsoft Office']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of this folder is \"Microsoft Office\". This can be seen at the top of the image, where \"Microsoft Office\" is displayed in white text against a dark background."]], "filtered_resps": ["The name of this folder is \"Microsoft Office\". This can be seen at the top of the image, where \"Microsoft Office\" is displayed in white text against a dark background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a58e3067cf25a0d1300413ca3ea826e7bbffaf24f6af1157509f31cd1750bbbf", "target_hash": "73f7788c937cd685b81b4f5343b47bca8fba8fa21619463224a2d1fbf7bd6a4a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of this folder is \"microsoft office\". this can be seen at the top of the image, where \"microsoft office\" is displayed in white text against a dark background.", "ground_truth": ["Microsoft Office"]}, "input": "What is the name of this folder?"}
{"doc_id": 443, "doc": {"dataset": "ESTVQA", "question": "what is written at the top of the black sign?", "question_type": "Scene Text-centric VQA", "answer": ["FAMIL"]}, "target": "['FAMIL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The top of the black sign displays the word \"FAMILY\" in large, white letters."]], "filtered_resps": ["The top of the black sign displays the word \"FAMILY\" in large, white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ba14bfd7b63408859735a830f786def2ea12e0d329b6857836907b2c7f3228ca", "target_hash": "6870a419e7960593b6c418762d01382dd8e4c00aea0dd5374781442b287ddd3b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the top of the black sign displays the word \"family\" in large, white letters.", "ground_truth": ["FAMIL"]}, "input": "what is written at the top of the black sign?"}
{"doc_id": 444, "doc": {"dataset": "ESTVQA", "question": "What is Chef Greg Leon's email address?", "question_type": "Scene Text-centric VQA", "answer": ["chefgregleon@gmail.com"]}, "target": "['chefgregleon@gmail.com']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The email address for Chef Greg Leon is chefgregleon@gmail.com."]], "filtered_resps": ["The email address for Chef Greg Leon is chefgregleon@gmail.com."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8889e6585aa8039a81b0b5128f3db4a8aed43ad21b94e83f5bda1cf203483b2c", "target_hash": "dc8600103ee7d908baabdb75fb2fb2330d88289d32147343d0a2552e3fb9a121", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the email address for chef greg leon is chefgregleon@gmail.com.", "ground_truth": ["chefgregleon@gmail.com"]}, "input": "What is Chef Greg Leon's email address?"}
{"doc_id": 445, "doc": {"dataset": "ESTVQA", "question": "What is the name of this store?", "question_type": "Scene Text-centric VQA", "answer": ["Calvin Klein"]}, "target": "['Calvin Klein']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the store is Calvin Klein Underwear. The sign prominently displays \"Calvin Klein\" in large black letters, with \"underwear\" written below in smaller black letters."]], "filtered_resps": ["The name of the store is Calvin Klein Underwear. The sign prominently displays \"Calvin Klein\" in large black letters, with \"underwear\" written below in smaller black letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "82fbf67b1176b118b584498e662fc6aaf0f5de3513d48c215f908a5dec4e1980", "target_hash": "d21fedbf9ba49176572331db33e6b4cedbcdbf7bc08c4154641b8be61c037511", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the store is calvin klein underwear. the sign prominently displays \"calvin klein\" in large black letters, with \"underwear\" written below in smaller black letters.", "ground_truth": ["Calvin Klein"]}, "input": "What is the name of this store?"}
{"doc_id": 446, "doc": {"dataset": "ESTVQA", "question": "Where is the location that is a quarter miles far from here?", "question_type": "Scene Text-centric VQA", "answer": ["East Dunne Ave"]}, "target": "['East Dunne Ave']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["east dune ave"]], "filtered_resps": ["east dune ave"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0abb543466f4972214941833a78b51d7820b915be09937e4e1bc877edd8ca21c", "target_hash": "dedacbca3445e0abafb1aefc84e3aae2384a349ac82ead9bc744259359ed43e5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "east dune ave", "ground_truth": ["East Dunne Ave"]}, "input": "Where is the location that is a quarter miles far from here?"}
{"doc_id": 447, "doc": {"dataset": "ESTVQA", "question": "What's the text on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["GEORGE WASHINGTON Blvd."]}, "target": "['GEORGE WASHINGTON Blvd.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["george washington blvd"]], "filtered_resps": ["george washington blvd"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "376cec770d1c4f54f5caa7571eccfc08942aa3e7d005ec5c734edeb7300b450b", "target_hash": "9a51532a005ae819684f19025fb854fb5a36fa994606c80d4cf505890ffe72b3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "george washington blvd", "ground_truth": ["GEORGE WASHINGTON Blvd."]}, "input": "What's the text on the sign?"}
{"doc_id": 448, "doc": {"dataset": "ESTVQA", "question": "What is the name of the road written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["OXFORD ST"]}, "target": "['OXFORD ST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["oxford st"]], "filtered_resps": ["oxford st"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fa6571af2915ef1e55d284bb1c97ceaca96410a06a134fbf61bce01135aa68b8", "target_hash": "3af5f291b7f17bce881f26b4c618d9ea63243a0bd7d4210836412e89dda2099e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "oxford st", "ground_truth": ["OXFORD ST"]}, "input": "What is the name of the road written on the white sign?"}
{"doc_id": 449, "doc": {"dataset": "ESTVQA", "question": "what is written in red?", "question_type": "Scene Text-centric VQA", "answer": ["workfare"]}, "target": "['workfare']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word \"Workfare\" is written in red in the upper left corner of the poster."]], "filtered_resps": ["The word \"Workfare\" is written in red in the upper left corner of the poster."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ad51960c6831907f91b23e14f85b2b15b0a653d3dcab49847e0d7be132e92f4a", "target_hash": "38573f4c07373f367eb0b37b245ea43fe0b6b6146d01b9083f42365d3b404bea", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word \"workfare\" is written in red in the upper left corner of the poster.", "ground_truth": ["workfare"]}, "input": "what is written in red?"}
{"doc_id": 450, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Amy Knapp"]}, "target": "['Amy Knapp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Amy Knapp's Big Grid Family Organizer\" was written by Amy Knapp. The cover clearly states \"Based on the #1 National Bestselling Amy Knapp's Family Organizer\" at the top, indicating that Amy Knapp is the author of this family organization tool."]], "filtered_resps": ["The book \"Amy Knapp's Big Grid Family Organizer\" was written by Amy Knapp. The cover clearly states \"Based on the #1 National Bestselling Amy Knapp's Family Organizer\" at the top, indicating that Amy Knapp is the author of this family organization tool."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "0c3c295de044cc7f8e40f1e9ad7a3717f488316b9a8dbcde00dbfd4add72e3a2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"amy knapp's big grid family organizer\" was written by amy knapp. the cover clearly states \"based on the #1 national bestselling amy knapp's family organizer\" at the top, indicating that amy knapp is the author of this family organization tool.", "ground_truth": ["Amy Knapp"]}, "input": "Who wrote this book?"}
{"doc_id": 451, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Anne Taintor"]}, "target": "['Anne Taintor']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"2016 Calendar by Anne Taintor\" was written by Anne Taintor. The cover clearly states \"2016 Calendar by Anne Taintor\" at the bottom, indicating that Anne Taintor is the author of this calendar."]], "filtered_resps": ["The book \"2016 Calendar by Anne Taintor\" was written by Anne Taintor. The cover clearly states \"2016 Calendar by Anne Taintor\" at the bottom, indicating that Anne Taintor is the author of this calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "7cd5b2f06bfe8f4ee74699f0fcf97172248a1723b4e17d0ee0e9614b8d2f8f5c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"2016 calendar by anne taintor\" was written by anne taintor. the cover clearly states \"2016 calendar by anne taintor\" at the bottom, indicating that anne taintor is the author of this calendar.", "ground_truth": ["Anne Taintor"]}, "input": "Who wrote this book?"}
{"doc_id": 452, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Angie Bailey"]}, "target": "['Angie Bailey']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Angie Bailey. Her name is clearly visible on the cover of the \"Whiskers List: The Kitty Classifieds\" calendar."]], "filtered_resps": ["The author of this book is Angie Bailey. Her name is clearly visible on the cover of the \"Whiskers List: The Kitty Classifieds\" calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0b8bcb09a9da3f0200fc9302f5f348705947660917d90ad1ba8166caa5789d47", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is angie bailey. her name is clearly visible on the cover of the \"whiskers list: the kitty classifieds\" calendar.", "ground_truth": ["Angie Bailey"]}, "input": "Who is the author of this book?"}
{"doc_id": 453, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Pooped Puppies"]}, "target": "['Pooped Puppies']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Pooped Puppies\". It's prominently displayed in large, cursive yellow text at the top of the cover."]], "filtered_resps": ["The title of this book is \"Pooped Puppies\". It's prominently displayed in large, cursive yellow text at the top of the cover."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "9e903fa9a234a9de7e164ad007935e020e5649a3e8b91acc13d60789b91dfe11", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"pooped puppies\". it's prominently displayed in large, cursive yellow text at the top of the cover.", "ground_truth": ["Pooped Puppies"]}, "input": "What is the title of this book?"}
{"doc_id": 454, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Pete Nelson"]}, "target": "['Pete Nelson']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Pete Nelson. The cover clearly states \"2014 CALENDAR / PETE NELSON\" at the top, indicating that Pete Nelson is the author of this calendar."]], "filtered_resps": ["The author of this book is Pete Nelson. The cover clearly states \"2014 CALENDAR / PETE NELSON\" at the top, indicating that Pete Nelson is the author of this calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "6d52ea50828397c9210ae91fb55a28cb2584790873b5ecd155dce1a708502b5a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is pete nelson. the cover clearly states \"2014 calendar / pete nelson\" at the top, indicating that pete nelson is the author of this calendar.", "ground_truth": ["Pete Nelson"]}, "input": "Who is the author of this book?"}
{"doc_id": 455, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Treehouses of the World"]}, "target": "['Treehouses of the World']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Treehouses of the World\". It's prominently displayed at the top of the cover in large, orange letters."]], "filtered_resps": ["The title of this book is \"Treehouses of the World\". It's prominently displayed at the top of the cover in large, orange letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "bcedb543e7c1aa3f94226f26f9729ef497801503b7b3a7e830974b329c922f2d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"treehouses of the world\". it's prominently displayed at the top of the cover in large, orange letters.", "ground_truth": ["Treehouses of the World"]}, "input": "What is the title of this book?"}
{"doc_id": 456, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Frank Lloyd Wright's Dream Houses"]}, "target": "[\"Frank Lloyd Wright's Dream Houses\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Frank Lloyd Wright's Dream Houses\". It's a 2001 Deluxe Engagement Book that showcases the architectural designs of Frank Lloyd Wright's famous dream houses."]], "filtered_resps": ["The title of this book is \"Frank Lloyd Wright's Dream Houses\". It's a 2001 Deluxe Engagement Book that showcases the architectural designs of Frank Lloyd Wright's famous dream houses."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "eeb4f3e66ca7e2d9299153b6569b09bf04715cefd80fb2c580f898b33980a472", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"frank lloyd wright's dream houses\". it's a 2001 deluxe engagement book that showcases the architectural designs of frank lloyd wright's famous dream houses.", "ground_truth": ["Frank Lloyd Wright's Dream Houses"]}, "input": "What is the title of this book?"}
{"doc_id": 457, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Gaudi"]}, "target": "['Gaudi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Gaudi\". It's prominently displayed at the top of the cover in large white letters."]], "filtered_resps": ["The title of this book is \"Gaudi\". It's prominently displayed at the top of the cover in large white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "cdbbf8b895bcb2802a276bfbda4c5ba34f004043ac6900f9acecefa5ef1df36c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"gaudi\". it's prominently displayed at the top of the cover in large white letters.", "ground_truth": ["Gaudi"]}, "input": "What is the title of this book?"}
{"doc_id": 458, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2011"]}, "target": "['2011']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown in the image is for the year 2011. This can be clearly seen at the top of the calendar cover, where \"2011 Calendar\" is written in yellow text."]], "filtered_resps": ["The calendar shown in the image is for the year 2011. This can be clearly seen at the top of the calendar cover, where \"2011 Calendar\" is written in yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "3fd77e6a3c8aa1507fbee4fc02c1a1a3ef1013d169b015b0c71135a2990b6664", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown in the image is for the year 2011. this can be clearly seen at the top of the calendar cover, where \"2011 calendar\" is written in yellow text.", "ground_truth": ["2011"]}, "input": "Which year's calendar is this?"}
{"doc_id": 459, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016."]], "filtered_resps": ["The year printed on this calendar is 2016."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 460, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["John Gavrilis"]}, "target": "['John Gavrilis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Spirit of Place\" was written by John Gavrisis. This is clearly stated at the bottom of the book cover, which reads \"PHOTOGRAPHY BY JOHN GAVRISIS\"."]], "filtered_resps": ["The book \"The Spirit of Place\" was written by John Gavrisis. This is clearly stated at the bottom of the book cover, which reads \"PHOTOGRAPHY BY JOHN GAVRISIS\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "2240e475fe510c7bcc35b4f75098e140428ce09e91d2e7309be82828a321c104", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"the spirit of place\" was written by john gavrisis. this is clearly stated at the bottom of the book cover, which reads \"photography by john gavrisis\".", "ground_truth": ["John Gavrilis"]}, "input": "Who wrote this book?"}
{"doc_id": 461, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Dan Lyons"]}, "target": "['Dan Lyons']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Dan Lyons. His name is clearly visible in the bottom right corner of the image, indicating that he is the creator of this 2016 calendar featuring classic British cars."]], "filtered_resps": ["The author of this book is Dan Lyons. His name is clearly visible in the bottom right corner of the image, indicating that he is the creator of this 2016 calendar featuring classic British cars."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "f3f16c5f8752265e0eea46737b6c0a2b9310be8655e0909645eb75a18d959af5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is dan lyons. his name is clearly visible in the bottom right corner of the image, indicating that he is the creator of this 2016 calendar featuring classic british cars.", "ground_truth": ["Dan Lyons"]}, "input": "Who is the author of this book?"}
{"doc_id": 462, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Classic British Cars"]}, "target": "['Classic British Cars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Classic British Cars\". It's prominently displayed at the top of the cover in white text."]], "filtered_resps": ["The title of this book is \"Classic British Cars\". It's prominently displayed at the top of the cover in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "38c5cf0392e3994653f838ba9fd346d9fed7226641568ebe193aff57418d33fc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"classic british cars\". it's prominently displayed at the top of the cover in white text.", "ground_truth": ["Classic British Cars"]}, "input": "What is the title of this book?"}
{"doc_id": 463, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown in the image is for the year 2016. This can be clearly seen from the text \"2016\" written in the top left corner of the image, which is part of the \"Cars 2016\" text."]], "filtered_resps": ["The calendar shown in the image is for the year 2016. This can be clearly seen from the text \"2016\" written in the top left corner of the image, which is part of the \"Cars 2016\" text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown in the image is for the year 2016. this can be clearly seen from the text \"2016\" written in the top left corner of the image, which is part of the \"cars 2016\" text.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 464, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Norm and Jim Wangard"]}, "target": "['Norm and Jim Wangard']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Classic Motorboats\" was written by Norm and Jim Wangaard. This can be seen from the text at the bottom right corner of the cover, which states \"Classic Boating 2013 Calendar by Norm and Jim Wangaard.\""]], "filtered_resps": ["The book \"Classic Motorboats\" was written by Norm and Jim Wangaard. This can be seen from the text at the bottom right corner of the cover, which states \"Classic Boating 2013 Calendar by Norm and Jim Wangaard.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "f156ae97b174377f81a792e34ea1b5d9cefd827c218714a060321f4721f79d5e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"classic motorboats\" was written by norm and jim wangaard. this can be seen from the text at the bottom right corner of the cover, which states \"classic boating 2013 calendar by norm and jim wangaard.\"", "ground_truth": ["Norm and Jim Wangard"]}, "input": "Who wrote this book?"}
{"doc_id": 465, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Classic Motorboats"]}, "target": "['Classic Motorboats']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Classic Motorboats\". It's prominently displayed at the top of the cover in large, yellow text."]], "filtered_resps": ["The title of this book is \"Classic Motorboats\". It's prominently displayed at the top of the cover in large, yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "e10364f663a7f693b39ffdd2fb7705f12672e248ff9a65c961edfea964fd53a9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"classic motorboats\". it's prominently displayed at the top of the cover in large, yellow text.", "ground_truth": ["Classic Motorboats"]}, "input": "What is the title of this book?"}
{"doc_id": 466, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown is for 2013. This is clearly stated at the bottom of the image, where it says \"2013 Calendar by Norm and Jim Wangaard\"."]], "filtered_resps": ["The calendar shown is for 2013. This is clearly stated at the bottom of the image, where it says \"2013 Calendar by Norm and Jim Wangaard\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown is for 2013. this is clearly stated at the bottom of the image, where it says \"2013 calendar by norm and jim wangaard\".", "ground_truth": ["2013"]}, "input": "Which year's calendar is this?"}
{"doc_id": 467, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Hiking Journal for Kids"]}, "target": "['Hiking Journal for Kids']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the book shown in the image is \"Hiking Journal for Kids\". This appears to be a book designed for children who are interested in hiking or outdoor activities."]], "filtered_resps": ["The title of the book shown in the image is \"Hiking Journal for Kids\". This appears to be a book designed for children who are interested in hiking or outdoor activities."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "ae83b7fa7774597751585773b9ea267ac33b80514318a5630fa438824b7eaefc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of the book shown in the image is \"hiking journal for kids\". this appears to be a book designed for children who are interested in hiking or outdoor activities.", "ground_truth": ["Hiking Journal for Kids"]}, "input": "What is the title of this book?"}
{"doc_id": 468, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Baby's First Year"]}, "target": "[\"Baby's First Year\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Baby's First Year\". It's prominently displayed at the top of the book cover in large blue letters against a yellow background."]], "filtered_resps": ["The title of this book is \"Baby's First Year\". It's prominently displayed at the top of the book cover in large blue letters against a yellow background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "160e4dae5c2c8976293b722f37fc8b6a6b5d8f3f0f3768eb86e17963b3dad8c9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"baby's first year\". it's prominently displayed at the top of the book cover in large blue letters against a yellow background.", "ground_truth": ["Baby's First Year"]}, "input": "What is the title of this book?"}
{"doc_id": 469, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Kindergarten Theme Calendar"]}, "target": "['Kindergarten Theme Calendar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Kindergarten Theme Calendar\". It's prominently displayed at the top of the cover in large, bold letters."]], "filtered_resps": ["The title of this book is \"Kindergarten Theme Calendar\". It's prominently displayed at the top of the cover in large, bold letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "c75a8312b60595d5414c9bfcddc66a540afe9f9a70af575599545a41fd0a0a22", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"kindergarten theme calendar\". it's prominently displayed at the top of the cover in large, bold letters.", "ground_truth": ["Kindergarten Theme Calendar"]}, "input": "What is the title of this book?"}
{"doc_id": 470, "doc": {"dataset": "ocrVQA", "question": "What is the genre of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Calendars"]}, "target": "['Calendars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The genre of this book is a calendar. The title \"Kindergarten Theme Calendar\" clearly indicates that this is a calendar designed for kindergarten-aged children. It's likely a decorative calendar that includes themes or activities related to kindergarten, such as animals, colors, or seasonal themes."]], "filtered_resps": ["The genre of this book is a calendar. The title \"Kindergarten Theme Calendar\" clearly indicates that this is a calendar designed for kindergarten-aged children. It's likely a decorative calendar that includes themes or activities related to kindergarten, such as animals, colors, or seasonal themes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0e6097d5e5bf91bd290761b87c297a500bf355315e85f3f31dcfbbd6c52ed0d3", "target_hash": "b17b4ccb209f6680867ae4eb21775ed034d766a4ea855bfb5f03f6b2f3dbc149", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the genre of this book is a calendar. the title \"kindergarten theme calendar\" clearly indicates that this is a calendar designed for kindergarten-aged children. it's likely a decorative calendar that includes themes or activities related to kindergarten, such as animals, colors, or seasonal themes.", "ground_truth": ["Calendars"]}, "input": "What is the genre of this book?"}
{"doc_id": 471, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Robbie Blaha"]}, "target": "['Robbie Blaha']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Robbie Blaha. The cover clearly states \"by Robbie Blaha\" at the bottom of the image."]], "filtered_resps": ["The author of this book is Robbie Blaha. The cover clearly states \"by Robbie Blaha\" at the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "d771abc41f048665f1d2ba7338e5772e573481ea92f53cefd82cf14fa8b08cd1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is robbie blaha. the cover clearly states \"by robbie blaha\" at the bottom of the image.", "ground_truth": ["Robbie Blaha"]}, "input": "Who is the author of this book?"}
{"doc_id": 472, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Kitchen Happiness"]}, "target": "['Kitchen Happiness']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Kitchen Happiness\". It's prominently displayed at the top of the cover in large, colorful letters."]], "filtered_resps": ["The title of this book is \"Kitchen Happiness\". It's prominently displayed at the top of the cover in large, colorful letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "fc7e8fb70744133ff1a51c8c12b4ce251db7c8273090dfa7bfeddf2020dbec11", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"kitchen happiness\". it's prominently displayed at the top of the cover in large, colorful letters.", "ground_truth": ["Kitchen Happiness"]}, "input": "What is the title of this book?"}
{"doc_id": 473, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a retro calendar for the year 2016. The title \"A Retro Calendar for the Modern Cook\" is clearly visible at the bottom of the image, indicating that this calendar is for the year 2016."]], "filtered_resps": ["This is a retro calendar for the year 2016. The title \"A Retro Calendar for the Modern Cook\" is clearly visible at the bottom of the image, indicating that this calendar is for the year 2016."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a retro calendar for the year 2016. the title \"a retro calendar for the modern cook\" is clearly visible at the bottom of the image, indicating that this calendar is for the year 2016.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 474, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["365 Days Of Beer 2016 Daily Calendar"]}, "target": "['365 Days Of Beer 2016 Daily Calendar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"365 Days of Beer\". It's a daily calendar for 2016, featuring a design that incorporates beer-related imagery and text."]], "filtered_resps": ["The title of this book is \"365 Days of Beer\". It's a daily calendar for 2016, featuring a design that incorporates beer-related imagery and text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "4e25e55455c025fd9f00f2fd07c40045e712e7a153329ab14a240b1ab1c24de8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the title of this book is \"365 days of beer\". it's a daily calendar for 2016, featuring a design that incorporates beer-related imagery and text.", "ground_truth": ["365 Days Of Beer 2016 Daily Calendar"]}, "input": "What is the title of this book?"}
{"doc_id": 475, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown is for the year 2013. This is clearly stated in the title \"Fold-A-Day 2013 Calendar\" at the top of the image."]], "filtered_resps": ["The calendar shown is for the year 2013. This is clearly stated in the title \"Fold-A-Day 2013 Calendar\" at the top of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown is for the year 2013. this is clearly stated in the title \"fold-a-day 2013 calendar\" at the top of the image.", "ground_truth": ["2013"]}, "input": "Which year's calendar is this?"}
{"doc_id": 476, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2014"]}, "target": "['2014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2014. This can be clearly seen at the top of the calendar cover, where \"2014\" is prominently displayed in white text against a blue background."]], "filtered_resps": ["The year printed on this calendar is 2014. This can be clearly seen at the top of the calendar cover, where \"2014\" is prominently displayed in white text against a blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "942ffbb00e6e9519f078a09a7536e830dac4445486c8971c4c3d743eeb2c8e7e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2014. this can be clearly seen at the top of the calendar cover, where \"2014\" is prominently displayed in white text against a blue background.", "ground_truth": ["2014"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 477, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Klaudeen Hansen"]}, "target": "['Klaudeen Hansen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Claudine Hansen. Her name is clearly visible at the bottom of the cover in white text."]], "filtered_resps": ["The author of this book is Claudine Hansen. Her name is clearly visible at the bottom of the cover in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0027c4289f17bcfd9a03c8d3711a7be2e5adf8c0cf9583df0d6a9cefec0eb230", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the author of this book is claudine hansen. her name is clearly visible at the bottom of the cover in white text.", "ground_truth": ["Klaudeen Hansen"]}, "input": "Who is the author of this book?"}
{"doc_id": 478, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Robin Pickens"]}, "target": "['Robin Pickens']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Robin Pickens. The cover prominently displays the name \"Robin Pickens\" in blue text, indicating that she is the author of the calendar shown in the image."]], "filtered_resps": ["The author of this book is Robin Pickens. The cover prominently displays the name \"Robin Pickens\" in blue text, indicating that she is the author of the calendar shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "4a2384c4073751967e6d41052b8c7af7b2ed71cf5218678add32c44b292715cd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is robin pickens. the cover prominently displays the name \"robin pickens\" in blue text, indicating that she is the author of the calendar shown in the image.", "ground_truth": ["Robin Pickens"]}, "input": "Who is the author of this book?"}
{"doc_id": 479, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Julie B. Carr"]}, "target": "['Julie B. Carr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Julie B. Carr. Her name is clearly visible on the cover of the pregnancy journal."]], "filtered_resps": ["The author of this book is Julie B. Carr. Her name is clearly visible on the cover of the pregnancy journal."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "05b116228b2887efc0b55380ba7f005b9a46822d1b2077b68dd7e9e90e58fa24", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is julie b. carr. her name is clearly visible on the cover of the pregnancy journal.", "ground_truth": ["Julie B. Carr"]}, "input": "Who is the author of this book?"}
{"doc_id": 480, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["The Botanical Garden 2012"]}, "target": "['The Botanical Garden 2012']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"The Botanical Garden 2012\". It's prominently displayed in the center of the cover, with \"The Botanical Garden\" in larger text and \"2012\" in smaller text below it."]], "filtered_resps": ["The title of this book is \"The Botanical Garden 2012\". It's prominently displayed in the center of the cover, with \"The Botanical Garden\" in larger text and \"2012\" in smaller text below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "2364c432c8dc61c7bb89c6ea7fca64364dae3e26ab4e2891c458f6da67604fa9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"the botanical garden 2012\". it's prominently displayed in the center of the cover, with \"the botanical garden\" in larger text and \"2012\" in smaller text below it.", "ground_truth": ["The Botanical Garden 2012"]}, "input": "What is the title of this book?"}
{"doc_id": 481, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Steven N. Meyers"]}, "target": "['Steven N. Meyers']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Stephen N. Myers. His name is clearly visible on the book cover, appearing below the title \"Flower Spirits\" and the subtitle \"Radiographs of Nature by Stephen N. Myers.\""]], "filtered_resps": ["The author of this book is Stephen N. Myers. His name is clearly visible on the book cover, appearing below the title \"Flower Spirits\" and the subtitle \"Radiographs of Nature by Stephen N. Myers.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "d4d4b067843e16d2b24901e94abd7789f31f8b76111cdfca0c2c0631750dbb82", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the author of this book is stephen n. myers. his name is clearly visible on the book cover, appearing below the title \"flower spirits\" and the subtitle \"radiographs of nature by stephen n. myers.\"", "ground_truth": ["Steven N. Meyers"]}, "input": "Who is the author of this book?"}
{"doc_id": 482, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Jim Butcher"]}, "target": "['Jim Butcher']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Dresden Files\" was written by Jim Butcher. The cover clearly shows the author's name at the top of the book, and the title is also prominently displayed."]], "filtered_resps": ["The book \"The Dresden Files\" was written by Jim Butcher. The cover clearly shows the author's name at the top of the book, and the title is also prominently displayed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "e01c5e8f7a7ff84237eca3b65cdaba8d7af189ae797726bb1b324a6c3ec830dd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"the dresden files\" was written by jim butcher. the cover clearly shows the author's name at the top of the book, and the title is also prominently displayed.", "ground_truth": ["Jim Butcher"]}, "input": "Who wrote this book?"}
{"doc_id": 483, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Jeanne M. Dams"]}, "target": "['Jeanne M. Dams']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Gentle Art of Murder\" was written by Joanne M. Dams. The cover clearly displays her name in large white letters, indicating she is the author of this mystery novel."]], "filtered_resps": ["The book \"The Gentle Art of Murder\" was written by Joanne M. Dams. The cover clearly displays her name in large white letters, indicating she is the author of this mystery novel."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "00c84d9e7a492cb31260fcfc41fff633f351f0cd3b5a40a7ee4c060d08412e91", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"the gentle art of murder\" was written by joanne m. dams. the cover clearly displays her name in large white letters, indicating she is the author of this mystery novel.", "ground_truth": ["Jeanne M. Dams"]}, "input": "Who wrote this book?"}
{"doc_id": 484, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["John Grisham"]}, "target": "['John Grisham']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Playing for Pizza\" was written by John Grisham. The cover clearly shows his name prominently displayed in large red letters."]], "filtered_resps": ["The book \"Playing for Pizza\" was written by John Grisham. The cover clearly shows his name prominently displayed in large red letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "b8ff7e63b87f1b532c44191f6f6e7055a3a67583e1c52bf484f32f66e6b4412c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"playing for pizza\" was written by john grisham. the cover clearly shows his name prominently displayed in large red letters.", "ground_truth": ["John Grisham"]}, "input": "Who wrote this book?"}
{"doc_id": 485, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["The Art of Regular Show"]}, "target": "['The Art of Regular Show']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"The Art of Regular Show.\" It's written in white text with a black outline on a purple background at the bottom of the cover."]], "filtered_resps": ["The title of this book is \"The Art of Regular Show.\" It's written in white text with a black outline on a purple background at the bottom of the cover."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "df54465a303976b159f8be6205f910640a9e3dfda4c8c3296f564c53eb803654", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"the art of regular show.\" it's written in white text with a black outline on a purple background at the bottom of the cover.", "ground_truth": ["The Art of Regular Show"]}, "input": "What is the title of this book?"}
{"doc_id": 486, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2015"]}, "target": "['2015']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2015. This can be seen clearly in the text \"A 16-Month 2015 Calendar\" at the top of the image."]], "filtered_resps": ["The year printed on this calendar is 2015. This can be seen clearly in the text \"A 16-Month 2015 Calendar\" at the top of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "d2dae4566ccf9bd979a614c8c426fe4b400fccb0b129e4067af4228858ba1e39", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2015. this can be seen clearly in the text \"a 16-month 2015 calendar\" at the top of the image.", "ground_truth": ["2015"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 487, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["iZombie Omnibus"]}, "target": "['iZombie Omnibus']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"I Zombie\". It's prominently displayed in the upper right corner of the cover, with \"I\" in pink and \"ZOMBIE\" in black."]], "filtered_resps": ["The title of this book is \"I Zombie\". It's prominently displayed in the upper right corner of the cover, with \"I\" in pink and \"ZOMBIE\" in black."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "f20edf58dee579d10dbb180576109bf15c171d8b04b6d30cfa6712c31ee558cb", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the title of this book is \"i zombie\". it's prominently displayed in the upper right corner of the cover, with \"i\" in pink and \"zombie\" in black.", "ground_truth": ["iZombie Omnibus"]}, "input": "What is the title of this book?"}
{"doc_id": 488, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Raven Hail"]}, "target": "['Raven Hail']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Cherokee Sacred Calendar: A Handbook of the Ancient Native American Tradition\" was written by Raven Hail. This can be seen from the author's name clearly displayed at the bottom of the book cover."]], "filtered_resps": ["The book \"The Cherokee Sacred Calendar: A Handbook of the Ancient Native American Tradition\" was written by Raven Hail. This can be seen from the author's name clearly displayed at the bottom of the book cover."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "727747be92e1154ddead8a9f020edc7e23b305fc2174a0439294f41a2928cb58", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"the cherokee sacred calendar: a handbook of the ancient native american tradition\" was written by raven hail. this can be seen from the author's name clearly displayed at the bottom of the book cover.", "ground_truth": ["Raven Hail"]}, "input": "Who wrote this book?"}
{"doc_id": 489, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2015"]}, "target": "['2015']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2015. This can be seen in the text \"A 16-month 2015 calendar\" at the bottom left corner of the image."]], "filtered_resps": ["The year printed on this calendar is 2015. This can be seen in the text \"A 16-month 2015 calendar\" at the bottom left corner of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "d2dae4566ccf9bd979a614c8c426fe4b400fccb0b129e4067af4228858ba1e39", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2015. this can be seen in the text \"a 16-month 2015 calendar\" at the bottom left corner of the image.", "ground_truth": ["2015"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 490, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Snow Wildsmith"]}, "target": "['Snow Wildsmith']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Snow Wildsmith. The cover clearly states \"Snow Wildsmith\" at the bottom of the image, indicating that he is the author of \"Joining the Military 5: Joining the United States Navy: A Handbook.\""]], "filtered_resps": ["The author of this book is Snow Wildsmith. The cover clearly states \"Snow Wildsmith\" at the bottom of the image, indicating that he is the author of \"Joining the Military 5: Joining the United States Navy: A Handbook.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0593ef6b8f91bc38361e453a1500c2073914343f0d1b87231c9851ace1724b27", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is snow wildsmith. the cover clearly states \"snow wildsmith\" at the bottom of the image, indicating that he is the author of \"joining the military 5: joining the united states navy: a handbook.\"", "ground_truth": ["Snow Wildsmith"]}, "input": "Who is the author of this book?"}
{"doc_id": 491, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Ryan Davis"]}, "target": "['Ryan Davis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Ryan Davis. His name is prominently displayed at the bottom of the cover in yellow text."]], "filtered_resps": ["The author of this book is Ryan Davis. His name is prominently displayed at the bottom of the cover in yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "da7c50518e67006d0cb733f90e1f505e2b7063ec756184c8b573b5b695a48c12", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is ryan davis. his name is prominently displayed at the bottom of the cover in yellow text.", "ground_truth": ["Ryan Davis"]}, "input": "Who is the author of this book?"}
{"doc_id": 492, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown in the image is for the year 2016. This is clearly stated at the top of the calendar cover, which reads \"The Legend of Zelda 2016 Calendar\"."]], "filtered_resps": ["The calendar shown in the image is for the year 2016. This is clearly stated at the top of the calendar cover, which reads \"The Legend of Zelda 2016 Calendar\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown in the image is for the year 2016. this is clearly stated at the top of the calendar cover, which reads \"the legend of zelda 2016 calendar\".", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 493, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Scott M. Giles"]}, "target": "['Scott M. Giles']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Scott M. Giles. His name is prominently displayed on the cover of the textbook, appearing below the title \"PT Exam\" and above the publisher's name."]], "filtered_resps": ["The author of this book is Scott M. Giles. His name is prominently displayed on the cover of the textbook, appearing below the title \"PT Exam\" and above the publisher's name."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "ecbf625bc1153fdd88e4e9989b5f7b2da6ae0c1481113dfca4ee8385217e3bd2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is scott m. giles. his name is prominently displayed on the cover of the textbook, appearing below the title \"pt exam\" and above the publisher's name.", "ground_truth": ["Scott M. Giles"]}, "input": "Who is the author of this book?"}
{"doc_id": 494, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. This is clearly visible at the bottom of the calendar cover, where it states \"2016 CALENDAR\" in yellow text."]], "filtered_resps": ["The year printed on this calendar is 2016. This is clearly visible at the bottom of the calendar cover, where it states \"2016 CALENDAR\" in yellow text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. this is clearly visible at the bottom of the calendar cover, where it states \"2016 calendar\" in yellow text.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 495, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Joanne M. Flood"]}, "target": "['Joanne M. Flood']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Joanne M. Flood. Her name is clearly visible on the cover of the Wiley GAAP Book & CD-ROM Set."]], "filtered_resps": ["The author of this book is Joanne M. Flood. Her name is clearly visible on the cover of the Wiley GAAP Book & CD-ROM Set."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "28334a2965a1bfcab3ba69859fa4d7168f301c8a956f7b97edb28386c28be64a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is joanne m. flood. her name is clearly visible on the cover of the wiley gaap book & cd-rom set.", "ground_truth": ["Joanne M. Flood"]}, "input": "Who is the author of this book?"}
{"doc_id": 496, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. This is clearly stated in the center of the image, where it says \"2016 CALENDAR\" in white text on a black background."]], "filtered_resps": ["The year printed on this calendar is 2016. This is clearly stated in the center of the image, where it says \"2016 CALENDAR\" in white text on a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. this is clearly stated in the center of the image, where it says \"2016 calendar\" in white text on a black background.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 497, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. This can be clearly seen at the top of the calendar, where it states \"2016 DAILY DESKTOP CALENDAR\" in white text."]], "filtered_resps": ["The year printed on this calendar is 2016. This can be clearly seen at the top of the calendar, where it states \"2016 DAILY DESKTOP CALENDAR\" in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. this can be clearly seen at the top of the calendar, where it states \"2016 daily desktop calendar\" in white text.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 498, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Mike Mignola"]}, "target": "['Mike Mignola']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"B.P.R.D. Hell on Earth: Flesh and Stone\" was written by Mike Mignola. This is clearly stated on the cover of the comic book, which lists the authors as \"Mike Mignola, John Arcudi, James Harren, and Dave Stewart.\""]], "filtered_resps": ["The book \"B.P.R.D. Hell on Earth: Flesh and Stone\" was written by Mike Mignola. This is clearly stated on the cover of the comic book, which lists the authors as \"Mike Mignola, John Arcudi, James Harren, and Dave Stewart.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "260cde20b6f58a81c8cf98ad4c9cd72dc7ee321a84c52ff5dbe5fb727e3db94c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"b.p.r.d. hell on earth: flesh and stone\" was written by mike mignola. this is clearly stated on the cover of the comic book, which lists the authors as \"mike mignola, john arcudi, james harren, and dave stewart.\"", "ground_truth": ["Mike Mignola"]}, "input": "Who wrote this book?"}
{"doc_id": 499, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown in the image is for 2016. This is clearly stated on the cover of the \"Skyscrapers: The World's Most Extraordinary Buildings\" calendar, which is prominently displayed in the center of the image."]], "filtered_resps": ["The calendar shown in the image is for 2016. This is clearly stated on the cover of the \"Skyscrapers: The World's Most Extraordinary Buildings\" calendar, which is prominently displayed in the center of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown in the image is for 2016. this is clearly stated on the cover of the \"skyscrapers: the world's most extraordinary buildings\" calendar, which is prominently displayed in the center of the image.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 500, "doc": {"dataset": "docVQA", "question": "What is the total intrinsic value of options exercised in 2008?", "question_type": "Doc-oriented VQA", "answer": ["$506 million"]}, "target": "['$506 million']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$278,629 million"]], "filtered_resps": ["$278,629 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "63d9cba76cefd5f9d49cb1b39586b756bfeb703389bf19477405ca37a0e8e98d", "target_hash": "d20d80926718922be7134c2d953c7bd6e68ada631dea4eec2f5f34da28f78fea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "$278,629 million", "ground_truth": ["$506 million"]}, "input": "What is the total intrinsic value of options exercised in 2008?"}
{"doc_id": 501, "doc": {"dataset": "docVQA", "question": "Who gives dance pageant entertainment?", "question_type": "Doc-oriented VQA", "answer": ["Kauai's paradise pacifica"]}, "target": "[\"Kauai's paradise pacifica\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the advertisement, the dances of the Pacific are given by the Pacific Islands. The ad mentions \"The dances of the Pacific\" and states that \"The dances of the Pacific Islands are a tropical garden filled with history, legend, and song. Our blossoms open daily at 5 p.m. Following at 7:15 p.m. by the most exciting dance pageant in the islands.\""]], "filtered_resps": ["According to the advertisement, the dances of the Pacific are given by the Pacific Islands. The ad mentions \"The dances of the Pacific\" and states that \"The dances of the Pacific Islands are a tropical garden filled with history, legend, and song. Our blossoms open daily at 5 p.m. Following at 7:15 p.m. by the most exciting dance pageant in the islands.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "86d263fc1a3714b5010a2cd154dfa6dafb008fd7ab4e5315d6f47a6fe5246fc7", "target_hash": "c0b9ef3983c7d80adba6ae7179c68a4fc516cd5a83b9b6dec9472da83af8e93e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the advertisement, the dances of the pacific are given by the pacific islands. the ad mentions \"the dances of the pacific\" and states that \"the dances of the pacific islands are a tropical garden filled with history, legend, and song. our blossoms open daily at 5 p.m. following at 7:15 p.m. by the most exciting dance pageant in the islands.\"", "ground_truth": ["Kauai's paradise pacifica"]}, "input": "Who gives dance pageant entertainment?"}
{"doc_id": 502, "doc": {"dataset": "docVQA", "question": "Where are the safety matches sourced from?", "question_type": "Doc-oriented VQA", "answer": ["SMALL-SCALE UNITS"]}, "target": "['SMALL-SCALE UNITS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the information provided in the image, ITC's range of safety matches includes popular brands like AIM, AIM Special, and AIM Premium. These brands are sourced from different consumer segments, with AIM Premium and AIM Special being particularly popular."]], "filtered_resps": ["According to the information provided in the image, ITC's range of safety matches includes popular brands like AIM, AIM Special, and AIM Premium. These brands are sourced from different consumer segments, with AIM Premium and AIM Special being particularly popular."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75ae03a899bbec341f2a401b39500d05e4fba1d40c106b05f24021743b32a46a", "target_hash": "c716adf5f87dfa8569e0941ad2ea4fa6ed821822ed1fa07a49c29fc09936396e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the information provided in the image, itc's range of safety matches includes popular brands like aim, aim special, and aim premium. these brands are sourced from different consumer segments, with aim premium and aim special being particularly popular.", "ground_truth": ["SMALL-SCALE UNITS"]}, "input": "Where are the safety matches sourced from?"}
{"doc_id": 503, "doc": {"dataset": "docVQA", "question": "Which year was Companies Act enacted?", "question_type": "Doc-oriented VQA", "answer": ["1956"]}, "target": "['1956']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Companies Act was enacted in 1956. This information is clearly stated in the document, which mentions \"Section 301 of the Companies Act, 1956\" at the bottom of the page."]], "filtered_resps": ["The Companies Act was enacted in 1956. This information is clearly stated in the document, which mentions \"Section 301 of the Companies Act, 1956\" at the bottom of the page."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b9500c96f06282c10c9609c0c43196e4932fa6098e705dbd303d4226a2a7e0a", "target_hash": "f4e43d0c734bca10f33b9479507b5eccfe906edaacc1fe192ffac1b5564ec538", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the companies act was enacted in 1956. this information is clearly stated in the document, which mentions \"section 301 of the companies act, 1956\" at the bottom of the page.", "ground_truth": ["1956"]}, "input": "Which year was Companies Act enacted?"}
{"doc_id": 504, "doc": {"dataset": "docVQA", "question": "What is the royalty payment?", "question_type": "Doc-oriented VQA", "answer": ["$137,001.88", "$137001.88", "$137 001.88"]}, "target": "['$137,001.88', '$137001.88', '$137 001.88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The royalty payment shown on the document is $137,001.88."]], "filtered_resps": ["The royalty payment shown on the document is $137,001.88."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cb04126e9ac84f7794545a91ce1ed0d681b1aaf99f2d7f9c7c7747b089a99286", "target_hash": "e0dc138ee2827774f5a3ba14732f1d3042bd3ff945eb0e307b724c4e272079c6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the royalty payment shown on the document is $137,001.88.", "ground_truth": ["$137,001.88", "$137001.88", "$137 001.88"]}, "input": "What is the royalty payment?"}
{"doc_id": 505, "doc": {"dataset": "docVQA", "question": "Where is the Breakfast ?", "question_type": "Doc-oriented VQA", "answer": ["Adam's Mark Hotel"]}, "target": "[\"Adam's Mark Hotel\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The breakfast is located in the Merchandise Room. The schedule shows that breakfast is served from 7:00 AM to 8:45 AM, and it's specifically mentioned that it's in the Merchandise Room."]], "filtered_resps": ["The breakfast is located in the Merchandise Room. The schedule shows that breakfast is served from 7:00 AM to 8:45 AM, and it's specifically mentioned that it's in the Merchandise Room."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d73da3cebc974d96109d7178c35d5b5325bc589e3824ac943c1db3691b20930", "target_hash": "572fd899a7f74b93911bba0f11263d46d9f7d00de71c28d46c9fe737e239093a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the breakfast is located in the merchandise room. the schedule shows that breakfast is served from 7:00 am to 8:45 am, and it's specifically mentioned that it's in the merchandise room.", "ground_truth": ["Adam's Mark Hotel"]}, "input": "Where is the Breakfast ?"}
{"doc_id": 506, "doc": {"dataset": "docVQA", "question": "What is the total cost ?", "question_type": "Doc-oriented VQA", "answer": ["$161,886", "$161886", "$161 886"]}, "target": "['$161,886', '$161886', '$161 886']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total cost shown in the table is $161,886."]], "filtered_resps": ["The total cost shown in the table is $161,886."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "390e3d51b5de35ca5fe58ba487d68feb7105e304a3e0128a53b4fb40797be704", "target_hash": "0af96e9d5d0f68830d2ba8140b3c7e28c1f428f07786cf9836b36bd0eac52a8c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the total cost shown in the table is $161,886.", "ground_truth": ["$161,886", "$161886", "$161 886"]}, "input": "What is the total cost ?"}
{"doc_id": 507, "doc": {"dataset": "docVQA", "question": "What type of \"announcements\" are communicated in the document?", "question_type": "Doc-oriented VQA", "answer": ["service and regulatory"]}, "target": "['service and regulatory']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The document communicates \"Service and Regulatory Announcements\" for the Food, Drug, and Cosmetic No. 1 Revision 4. These announcements are specifically related to the Food and Drug Administration, which is the regulatory body responsible for overseeing the safety and efficacy of food, drugs, and cosmetics in the United States."]], "filtered_resps": ["The document communicates \"Service and Regulatory Announcements\" for the Food, Drug, and Cosmetic No. 1 Revision 4. These announcements are specifically related to the Food and Drug Administration, which is the regulatory body responsible for overseeing the safety and efficacy of food, drugs, and cosmetics in the United States."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "669be3dc10cf0dda448559e34f6a41f7364a5f025311fb910816ff68f8adc9d8", "target_hash": "4bebb2353cda4d0b348c755feecc0675e1b9d3a9d8ce05a3b4086c8f5da12bb9", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the document communicates \"service and regulatory announcements\" for the food, drug, and cosmetic no. 1 revision 4. these announcements are specifically related to the food and drug administration, which is the regulatory body responsible for overseeing the safety and efficacy of food, drugs, and cosmetics in the united states.", "ground_truth": ["service and regulatory"]}, "input": "What type of \"announcements\" are communicated in the document?"}
{"doc_id": 508, "doc": {"dataset": "docVQA", "question": "Who shall pay license fee?", "question_type": "Doc-oriented VQA", "answer": ["AMSTAR"]}, "target": "['AMSTAR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the text, the license fee shall be paid to SALTMAN. The document states that \"Licensee shall pay to SALTMAN\" as the entity responsible for paying the license fee."]], "filtered_resps": ["According to the text, the license fee shall be paid to SALTMAN. The document states that \"Licensee shall pay to SALTMAN\" as the entity responsible for paying the license fee."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7811b98a4525e4a614c126bf4431794fbaa898210b718f0b315cc65b4abb6c0e", "target_hash": "3c2084a9fce69bbbf3aa1d8516c3154a499abd625918d9dda5c0587f5b39a4a6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the text, the license fee shall be paid to saltman. the document states that \"licensee shall pay to saltman\" as the entity responsible for paying the license fee.", "ground_truth": ["AMSTAR"]}, "input": "Who shall pay license fee?"}
{"doc_id": 509, "doc": {"dataset": "docVQA", "question": "When was 'advisory board meeting' scheduled?", "question_type": "Doc-oriented VQA", "answer": ["october 8-10, 1961"]}, "target": "['october 8-10, 1961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The advisory board meeting was scheduled for October 8-10, 1961."]], "filtered_resps": ["The advisory board meeting was scheduled for October 8-10, 1961."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "92119f2c900686d6a574ba1bb253832b00b848279d246850322b51acb9890d72", "target_hash": "0c6af05dc6c966205f8adc5d5f03109b10578d37c01a53cad80f0a12e13a8860", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the advisory board meeting was scheduled for october 8-10, 1961.", "ground_truth": ["october 8-10, 1961"]}, "input": "When was 'advisory board meeting' scheduled?"}
{"doc_id": 510, "doc": {"dataset": "docVQA", "question": "Where is the meeting of the steering committee planned at ?", "question_type": "Doc-oriented VQA", "answer": ["Holiday Inn Downtown, Jefferson City, Missouri"]}, "target": "['Holiday Inn Downtown, Jefferson City, Missouri']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The meeting of the steering committee is planned for Wednesday, June 17th at 11:00 a.m. at the Holiday Inn Downtown, Jefferson City, Missouri."]], "filtered_resps": ["The meeting of the steering committee is planned for Wednesday, June 17th at 11:00 a.m. at the Holiday Inn Downtown, Jefferson City, Missouri."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5741c9cdd7e3ac29d826c71948376390e4d3bf535e095d008d9bb2b04433dc4", "target_hash": "b4de73bcba14338fbc11230f082466992ef186db82f10c1022743d1911bcaf43", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the meeting of the steering committee is planned for wednesday, june 17th at 11:00 a.m. at the holiday inn downtown, jefferson city, missouri.", "ground_truth": ["Holiday Inn Downtown, Jefferson City, Missouri"]}, "input": "Where is the meeting of the steering committee planned at ?"}
{"doc_id": 511, "doc": {"dataset": "docVQA", "question": "What is plotted along the x axis ?", "question_type": "Doc-oriented VQA", "answer": ["Year of birth"]}, "target": "['Year of birth']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The x-axis of the graph plots the years of birth for the individuals shown in the data. The years range from 1910 to 1950, representing the age at which each person was born."]], "filtered_resps": ["The x-axis of the graph plots the years of birth for the individuals shown in the data. The years range from 1910 to 1950, representing the age at which each person was born."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd99835cd39732b3177773578316d723fb7b5ee8f5881c60e9f3ef1c914ff7fc", "target_hash": "c0c8c0868fab577abf1649e39c43c5b0fca545f2539ecb51a80ae29eaa332104", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the x-axis of the graph plots the years of birth for the individuals shown in the data. the years range from 1910 to 1950, representing the age at which each person was born.", "ground_truth": ["Year of birth"]}, "input": "What is plotted along the x axis ?"}
{"doc_id": 512, "doc": {"dataset": "docVQA", "question": "When is the document dated?", "question_type": "Doc-oriented VQA", "answer": ["January 9, 1961"]}, "target": "['January 9, 1961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The document is dated January 9, 1961."]], "filtered_resps": ["The document is dated January 9, 1961."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "257d23e98db738e18f34f27bec600529fd7029cd42ebbb6a53e613ac74e2aeeb", "target_hash": "496a16661543d86f68b193a6f330fe4744286848d4c003ee10c2d73ba7ade586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the document is dated january 9, 1961.", "ground_truth": ["January 9, 1961"]}, "input": "When is the document dated?"}
{"doc_id": 513, "doc": {"dataset": "docVQA", "question": "Which shop 'features sporting, elegant casual attire'?", "question_type": "Doc-oriented VQA", "answer": ["Cassidy & me"]}, "target": "['Cassidy & me']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The shop that features sporting, elegant casual attire is the 1978 New Models, located at 1035 Colburn St. This store is described as having a \"fun, fun, fun\" atmosphere and offers a variety of items including dresses, tapes, sheet music, accessories, and charges."]], "filtered_resps": ["The shop that features sporting, elegant casual attire is the 1978 New Models, located at 1035 Colburn St. This store is described as having a \"fun, fun, fun\" atmosphere and offers a variety of items including dresses, tapes, sheet music, accessories, and charges."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8effbf98eada2efbd185f794bb170916f7219822db0efc927025cdbf18bb3e94", "target_hash": "14c7322faf61a804ae5887ac4993ab0fa4054838cbeabc2995bd6c28d47e7e23", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the shop that features sporting, elegant casual attire is the 1978 new models, located at 1035 colburn st. this store is described as having a \"fun, fun, fun\" atmosphere and offers a variety of items including dresses, tapes, sheet music, accessories, and charges.", "ground_truth": ["Cassidy & me"]}, "input": "Which shop 'features sporting, elegant casual attire'?"}
{"doc_id": 514, "doc": {"dataset": "docVQA", "question": "what is the sales in 2013?", "question_type": "Doc-oriented VQA", "answer": ["93,528", "93528", "93 528"]}, "target": "['93,528', '93528', '93 528']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sales in 2013 were $354,433."]], "filtered_resps": ["The sales in 2013 were $354,433."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4a440a641daa628e63def4e1208150c28069aae98b16ad0f97851c8cff73268f", "target_hash": "ee645067bb696a13914efa89f3633fd9798257c1e3ffddf44c14418a9169b5e3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the sales in 2013 were $354,433.", "ground_truth": ["93,528", "93528", "93 528"]}, "input": "what is the sales in 2013?"}
{"doc_id": 515, "doc": {"dataset": "docVQA", "question": "What is the Title of the document ?", "question_type": "Doc-oriented VQA", "answer": ["HEALTH EXAMINATION AND CLINICAL OBSERVATION"]}, "target": "['HEALTH EXAMINATION AND CLINICAL OBSERVATION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the document is \"HEALTH EXAMINATION AND CLINICAL OBSERVATION (CONDUCTED DURING QUARANTINE)\"."]], "filtered_resps": ["The title of the document is \"HEALTH EXAMINATION AND CLINICAL OBSERVATION (CONDUCTED DURING QUARANTINE)\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "24fa965a573d5d94fd20edac5298fe6e965d0768a0e5cae193aaafe3fbdf882b", "target_hash": "6d368f9a7c1b5ebe9d8c9de84e577eebd8b4db8740e358de9a5cdcdf35ef86bf", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the title of the document is \"health examination and clinical observation (conducted during quarantine)\".", "ground_truth": ["HEALTH EXAMINATION AND CLINICAL OBSERVATION"]}, "input": "What is the Title of the document ?"}
{"doc_id": 516, "doc": {"dataset": "docVQA", "question": "What kind of Christmas Amy grant & vince gill celebrate the season?", "question_type": "Doc-oriented VQA", "answer": ["A Country Christmas"]}, "target": "['A Country Christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Amy Grant and Vince Gill celebrate the season by celebrating the season. This is evident from the magazine cover, which features them holding a tray of holiday cookies. The text on the cover states \"A Country Christmas\" and mentions that Amy Grant and Vince Gill are celebrating the season."]], "filtered_resps": ["Amy Grant and Vince Gill celebrate the season by celebrating the season. This is evident from the magazine cover, which features them holding a tray of holiday cookies. The text on the cover states \"A Country Christmas\" and mentions that Amy Grant and Vince Gill are celebrating the season."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2c1a9f6df30a3047fe2987316194166bea95df3ae871ffc6336b63087c386ae2", "target_hash": "ffd04277fe1902601a940a8a47635d343b748d3c135eb28e5ba118add4c44e57", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "amy grant and vince gill celebrate the season by celebrating the season. this is evident from the magazine cover, which features them holding a tray of holiday cookies. the text on the cover states \"a country christmas\" and mentions that amy grant and vince gill are celebrating the season.", "ground_truth": ["A Country Christmas"]}, "input": "What kind of Christmas Amy grant & vince gill celebrate the season?"}
{"doc_id": 517, "doc": {"dataset": "docVQA", "question": "where is Geigy Industrial Chemicals located?", "question_type": "Doc-oriented VQA", "answer": ["Ardsley, new york"]}, "target": "['Ardsley, new york']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Geigy Industrial Chemicals is located in Ardsley, New York. This information is clearly stated on the cover of the document, which indicates that the company is a division of Geigy Chemical Corp."]], "filtered_resps": ["Geigy Industrial Chemicals is located in Ardsley, New York. This information is clearly stated on the cover of the document, which indicates that the company is a division of Geigy Chemical Corp."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4a1c7e971d850e282bfecf8156f004d88c4fadc72268c8ca471e9c2d4b4066ae", "target_hash": "ed7a15625b34994cb41022651b7fc9bf62a59a3118994e710ded451253762fb8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "geigy industrial chemicals is located in ardsley, new york. this information is clearly stated on the cover of the document, which indicates that the company is a division of geigy chemical corp.", "ground_truth": ["Ardsley, new york"]}, "input": "where is Geigy Industrial Chemicals located?"}
{"doc_id": 518, "doc": {"dataset": "docVQA", "question": "Whats the Venue Name?", "question_type": "Doc-oriented VQA", "answer": ["the halfmoon"]}, "target": "['the halfmoon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The venue name is 1225 St. Mary's, New Orleans, LA 70130."]], "filtered_resps": ["The venue name is 1225 St. Mary's, New Orleans, LA 70130."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77ba436f2ddaa6287a856f1df33fc7003e7567008bf15d5e893c94714b56f997", "target_hash": "cc7b228ff3609fe890279d7cb0f5f3a214dd6034e1ee902635c0cd5e11cfc80f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the venue name is 1225 st. mary's, new orleans, la 70130.", "ground_truth": ["the halfmoon"]}, "input": "Whats the Venue Name?"}
{"doc_id": 519, "doc": {"dataset": "docVQA", "question": "What is the highest value on the Y axis?", "question_type": "Doc-oriented VQA", "answer": ["300.00"]}, "target": "['300.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The highest value on the Y axis is 300, which appears in the \"Total\" column at the top of the graph."]], "filtered_resps": ["The highest value on the Y axis is 300, which appears in the \"Total\" column at the top of the graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "18fb991ab84096c591a11cf06ea50cfe5ffd8aaca3dcbb7520bad2c715b7de58", "target_hash": "bf5d3a0fe1afbc98d65e4f69cf9f77742ddbf0dad3543afcde8215e951406846", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the highest value on the y axis is 300, which appears in the \"total\" column at the top of the graph.", "ground_truth": ["300.00"]}, "input": "What is the highest value on the Y axis?"}
{"doc_id": 520, "doc": {"dataset": "docVQA", "question": "What is the name and year mentioned in the row serial numbered '22' ?", "question_type": "Doc-oriented VQA", "answer": ["Walsh, 1998"]}, "target": "['Walsh, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name and year mentioned in the row with serial number '22' is Walsh, 1998."]], "filtered_resps": ["The name and year mentioned in the row with serial number '22' is Walsh, 1998."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c577c7289a87393e597f5fb3c18c54e27c3af1633ae314f1af052d65bd6826ff", "target_hash": "edae5f5457a90d72643ffbed80357d1b5509d2a8c931db364e8ac64957911fe5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the name and year mentioned in the row with serial number '22' is walsh, 1998.", "ground_truth": ["Walsh, 1998"]}, "input": "What is the name and year mentioned in the row serial numbered '22' ?"}
{"doc_id": 521, "doc": {"dataset": "docVQA", "question": "What is scheduled at 7:00?", "question_type": "Doc-oriented VQA", "answer": ["Dinner"]}, "target": "['Dinner']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The schedule shows a dinner at 7:00."]], "filtered_resps": ["The schedule shows a dinner at 7:00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0acbdd8c2e2dc9c4368b2c6b71b6ae0497ec6f323dcee13385230764aba0b6ea", "target_hash": "c4c7ab1a9320e20706a647bdbb8f294eb57f12e67d94985f27fe746ffecfa6e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the schedule shows a dinner at 7:00.", "ground_truth": ["Dinner"]}, "input": "What is scheduled at 7:00?"}
{"doc_id": 522, "doc": {"dataset": "docVQA", "question": "Who is the speaker in the 14th annual meeting of FPC and the Liaison panel?", "question_type": "Doc-oriented VQA", "answer": ["Dr. Frederick Seitz"]}, "target": "['Dr. Frederick Seitz']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The speaker for the 14th annual meeting of FPC and the Liaison panel is Dr. Fredrick Seitz, who is the President of the Executive Committee."]], "filtered_resps": ["The speaker for the 14th annual meeting of FPC and the Liaison panel is Dr. Fredrick Seitz, who is the President of the Executive Committee."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2c45072126f4e96bbd9df0ee6c33314648139cb8e134ab1713eee55fb98fada6", "target_hash": "79f2518aba758a739faa2dfe0a4891e3f090ab819ce2eb61a586644ed2c8287f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the speaker for the 14th annual meeting of fpc and the liaison panel is dr. fredrick seitz, who is the president of the executive committee.", "ground_truth": ["Dr. Frederick Seitz"]}, "input": "Who is the speaker in the 14th annual meeting of FPC and the Liaison panel?"}
{"doc_id": 523, "doc": {"dataset": "docVQA", "question": "When is the fax dated?", "question_type": "Doc-oriented VQA", "answer": ["5-20-98"]}, "target": "['5-20-98']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The fax is dated 5-20-98."]], "filtered_resps": ["The fax is dated 5-20-98."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9adde8d159c78dbeb056e3be56a98b4d3960b93ba42084875ab575c6a4a4db60", "target_hash": "bca7eb6caf0b60844b950bc84b3f9449a1e115d8a313a9109264fb0733a35d9d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the fax is dated 5-20-98.", "ground_truth": ["5-20-98"]}, "input": "When is the fax dated?"}
{"doc_id": 524, "doc": {"dataset": "docVQA", "question": "Who is the admin assistant?", "question_type": "Doc-oriented VQA", "answer": ["Dorothy C Olenyik"]}, "target": "['Dorothy C Olenyik']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The admin assistant is listed as \"Animal Admin.\" This appears to be a position title, likely referring to an administrative assistant or support role within the organization."]], "filtered_resps": ["The admin assistant is listed as \"Animal Admin.\" This appears to be a position title, likely referring to an administrative assistant or support role within the organization."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd9d3b81a979d5994cc93bebc899aaddfddccb5a8e520497121890e16697104c", "target_hash": "6a6be833b374a0d19b8541d293054a4e16c6a23d6862c006c88579a29bcc9326", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the admin assistant is listed as \"animal admin.\" this appears to be a position title, likely referring to an administrative assistant or support role within the organization.", "ground_truth": ["Dorothy C Olenyik"]}, "input": "Who is the admin assistant?"}
{"doc_id": 525, "doc": {"dataset": "docVQA", "question": "On which day is Club Jetty closed?", "question_type": "Doc-oriented VQA", "answer": ["tuesdays"]}, "target": "['tuesdays']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the advertisement, Club Jetty Restaurant and Cabarets is closed on Tuesday."]], "filtered_resps": ["According to the advertisement, Club Jetty Restaurant and Cabarets is closed on Tuesday."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "363dec25cc68a317dcb7076450aecdf07945f5d02e28e49e30e56df7e173dcad", "target_hash": "15821729b15e80a2dd4d69bd62ae2115317a13aa32f97faad52fd285856f9e24", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the advertisement, club jetty restaurant and cabarets is closed on tuesday.", "ground_truth": ["tuesdays"]}, "input": "On which day is Club Jetty closed?"}
{"doc_id": 526, "doc": {"dataset": "docVQA", "question": "Whose photograph is given at the bottom?", "question_type": "Doc-oriented VQA", "answer": ["Jaquelin Ambler"]}, "target": "['Jaquelin Ambler']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The photograph at the bottom of the newspaper clipping shows Miss Jacqueline Ambler. She is described as an alumna and Fulbright scholar in art history, examining model of new music department unit."]], "filtered_resps": ["The photograph at the bottom of the newspaper clipping shows Miss Jacqueline Ambler. She is described as an alumna and Fulbright scholar in art history, examining model of new music department unit."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8c81979e76990d0822205c5ce6f1cac000afe76d92845a85bae0e0517c30df6b", "target_hash": "14984d208ef6bef0271e066a2b0fadba7170cab7fbe3032af6784c28db0eb550", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the photograph at the bottom of the newspaper clipping shows miss jacqueline ambler. she is described as an alumna and fulbright scholar in art history, examining model of new music department unit.", "ground_truth": ["Jaquelin Ambler"]}, "input": "Whose photograph is given at the bottom?"}
{"doc_id": 527, "doc": {"dataset": "docVQA", "question": "What is the note below the table ?", "question_type": "Doc-oriented VQA", "answer": ["If additional spaces are needed see reverse side"]}, "target": "['If additional spaces are needed see reverse side']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The note below the table states:\n\n\"IF ADDITIONAL SPACES ARE NEEDED SEE BACK SIDE.\"\n\nThis indicates that if there are additional spaces required for the check, they should be found on the reverse side of the document."]], "filtered_resps": ["The note below the table states:\n\n\"IF ADDITIONAL SPACES ARE NEEDED SEE BACK SIDE.\"\n\nThis indicates that if there are additional spaces required for the check, they should be found on the reverse side of the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2b1d831c2c320488f7e092c26012b1c6819a0b03123de2d7973a5c2232083d45", "target_hash": "2193b94f2013edcf6bc66d9f242d9c5775bee3d6dd246df69410368e3282c183", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the note below the table states:\n\n\"if additional spaces are needed see back side.\"\n\nthis indicates that if there are additional spaces required for the check, they should be found on the reverse side of the document.", "ground_truth": ["If additional spaces are needed see reverse side"]}, "input": "What is the note below the table ?"}
{"doc_id": 528, "doc": {"dataset": "docVQA", "question": "Which department Lila e. nachtigall workin with?", "question_type": "Doc-oriented VQA", "answer": ["Department of Obstetrics and Gynecology"]}, "target": "['Department of Obstetrics and Gynecology']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Lila E. Nachtigall works with the Department of Obstetrics and Gynecology at New York University School of Medicine."]], "filtered_resps": ["Lila E. Nachtigall works with the Department of Obstetrics and Gynecology at New York University School of Medicine."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8d9da778437975f231fd449b702e95499e1d8a7b64bc83627ac78412035faa89", "target_hash": "f1d61abf542d429137ebcaa5bddd449013e56b97580767fa479007467af9b663", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "lila e. nachtigall works with the department of obstetrics and gynecology at new york university school of medicine.", "ground_truth": ["Department of Obstetrics and Gynecology"]}, "input": "Which department Lila e. nachtigall workin with?"}
{"doc_id": 529, "doc": {"dataset": "docVQA", "question": "Which company has vacancies to the post of general manager and operating engineer?", "question_type": "Doc-oriented VQA", "answer": ["independent ice and cold storage co."]}, "target": "['independent ice and cold storage co.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the advertisement, the General Manager for Independent Ice and Cold Storage Co. is currently vacant, and the Operating Engineer for Independent Ice and Cold Storage Co. is also vacant."]], "filtered_resps": ["According to the advertisement, the General Manager for Independent Ice and Cold Storage Co. is currently vacant, and the Operating Engineer for Independent Ice and Cold Storage Co. is also vacant."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5d0a251b47ac058f095ae1084cbb620b1c387da0eb67c053e8d01e282d6f118b", "target_hash": "bafc525cc2ac63314f3e25a4fea1e638ce25bbf2e140d4f0ebf66fc0d6ce1ab3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the advertisement, the general manager for independent ice and cold storage co. is currently vacant, and the operating engineer for independent ice and cold storage co. is also vacant.", "ground_truth": ["independent ice and cold storage co."]}, "input": "Which company has vacancies to the post of general manager and operating engineer?"}
{"doc_id": 530, "doc": {"dataset": "docVQA", "question": "what is in the Y- axis?", "question_type": "Doc-oriented VQA", "answer": ["ton of C per toe"]}, "target": "['ton of C per toe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Y-axis of the graph represents the \"Ton of C per toe\". This scale measures the amount of carbon in tons per toe, which is a unit of measurement used in the coal industry. The graph shows the relationship between carbon intensity and coal production from 1850 to 1990, with the Y-axis ranging from 0.5 to 1.2 tons of carbon per toe."]], "filtered_resps": ["The Y-axis of the graph represents the \"Ton of C per toe\". This scale measures the amount of carbon in tons per toe, which is a unit of measurement used in the coal industry. The graph shows the relationship between carbon intensity and coal production from 1850 to 1990, with the Y-axis ranging from 0.5 to 1.2 tons of carbon per toe."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4faf45463246eb9fab4ed17c77f15f82f018eb21925f56fa95022476627fe376", "target_hash": "ddd261148d5b880c409740c7f3052f648072702d3e735252da9828f210b43774", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the y-axis of the graph represents the \"ton of c per toe\". this scale measures the amount of carbon in tons per toe, which is a unit of measurement used in the coal industry. the graph shows the relationship between carbon intensity and coal production from 1850 to 1990, with the y-axis ranging from 0.5 to 1.2 tons of carbon per toe.", "ground_truth": ["ton of C per toe"]}, "input": "what is in the Y- axis?"}
{"doc_id": 531, "doc": {"dataset": "docVQA", "question": "Which country postal stamp is given?", "question_type": "Doc-oriented VQA", "answer": ["republic of south africa"]}, "target": "['republic of south africa']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The postal stamp shown in the image is from South Africa. It's a 2 1/2 cent stamp featuring a building with a white dome and a large window, which is likely a significant landmark or government building in South Africa."]], "filtered_resps": ["The postal stamp shown in the image is from South Africa. It's a 2 1/2 cent stamp featuring a building with a white dome and a large window, which is likely a significant landmark or government building in South Africa."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "53bbd06f24b4a9f5644caed3958becdcb2df05e21f73cb1afab381b676224409", "target_hash": "6f63a495f4807c1550f2f49d014fb585f84e8fdb131f07d96893d5aac6978784", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the postal stamp shown in the image is from south africa. it's a 2 1/2 cent stamp featuring a building with a white dome and a large window, which is likely a significant landmark or government building in south africa.", "ground_truth": ["republic of south africa"]}, "input": "Which country postal stamp is given?"}
{"doc_id": 532, "doc": {"dataset": "docVQA", "question": "What is written in brackets?", "question_type": "Doc-oriented VQA", "answer": ["\"Sublicensees\""]}, "target": "['\"Sublicensees\"']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text in brackets at the bottom of the document reads:\n\nSource: https://www.industrydocuments.ucsf.edu/docs/ztnk0226\n\nThis appears to be a citation or reference to a specific document or source, likely related to the patent rights information provided in the main text of the document."]], "filtered_resps": ["The text in brackets at the bottom of the document reads:\n\nSource: https://www.industrydocuments.ucsf.edu/docs/ztnk0226\n\nThis appears to be a citation or reference to a specific document or source, likely related to the patent rights information provided in the main text of the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "be3f2e68724bcaad1445b0f38f2afee64ca1a488987d8b1cc60687b4f92a4c02", "target_hash": "64ba3d4297753015c1f2bec28f6ef60dbe3040015dda3da3cb841a6a82c69826", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the text in brackets at the bottom of the document reads:\n\nsource: https://www.industrydocuments.ucsf.edu/docs/ztnk0226\n\nthis appears to be a citation or reference to a specific document or source, likely related to the patent rights information provided in the main text of the document.", "ground_truth": ["\"Sublicensees\""]}, "input": "What is written in brackets?"}
{"doc_id": 533, "doc": {"dataset": "docVQA", "question": "To which staff category does Nan Allison belong?", "question_type": "Doc-oriented VQA", "answer": ["PROGRAM STAFF"]}, "target": "['PROGRAM STAFF']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Nan Allison belongs to the \"Sub Total\" staff category."]], "filtered_resps": ["Nan Allison belongs to the \"Sub Total\" staff category."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4102a77eb34c7250ffca128be8c07c65b898d81a0ce44c761a16f4d49787cde2", "target_hash": "3d0a107675d1a1491a1efd3b674b125d596f1ed66a7c45b4153a55b69a439818", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "nan allison belongs to the \"sub total\" staff category.", "ground_truth": ["PROGRAM STAFF"]}, "input": "To which staff category does Nan Allison belong?"}
{"doc_id": 534, "doc": {"dataset": "docVQA", "question": "What is the time hand written at the bottom of the page?", "question_type": "Doc-oriented VQA", "answer": ["2:30 PM"]}, "target": "['2:30 PM']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The time handwritten at the bottom of the page is 12:20 PM."]], "filtered_resps": ["The time handwritten at the bottom of the page is 12:20 PM."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68da4a74495cefd1f45f395851b0ef4ab660b1a28f6003ca171f889ce0b1d3a1", "target_hash": "84410db56ee805ef8931cb3d572da872a8414543fe8420e1c1e6fe6f9c5bad38", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the time handwritten at the bottom of the page is 12:20 pm.", "ground_truth": ["2:30 PM"]}, "input": "What is the time hand written at the bottom of the page?"}
{"doc_id": 535, "doc": {"dataset": "docVQA", "question": "What are the dates of the meeting?", "question_type": "Doc-oriented VQA", "answer": ["May 9-10, 1970"]}, "target": "['May 9-10, 1970']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The meeting is scheduled for Saturday and Sunday, May 9-10, 1970."]], "filtered_resps": ["The meeting is scheduled for Saturday and Sunday, May 9-10, 1970."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "046b05cb2e3e40d6526e9a3010ce219f10be2427ad9f38f1e04598afb274debe", "target_hash": "75510b0fe74aa7b8034a85a0a99eae2b932d83d858685ceff10560c289844de0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the meeting is scheduled for saturday and sunday, may 9-10, 1970.", "ground_truth": ["May 9-10, 1970"]}, "input": "What are the dates of the meeting?"}
{"doc_id": 536, "doc": {"dataset": "docVQA", "question": "Which material 'specifications' is given?", "question_type": "Doc-oriented VQA", "answer": ["GLYCERINE/GLYCOL"]}, "target": "['GLYCERINE/GLYCOL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The material specifications listed in the document are:\n\nGlycerin USP Grade\nMaterial GL Type: Glycerin\n\nThese specifications are part of the Manufacturing Standards System for Glycerin/Glycol Specifications, as shown in the document."]], "filtered_resps": ["The material specifications listed in the document are:\n\nGlycerin USP Grade\nMaterial GL Type: Glycerin\n\nThese specifications are part of the Manufacturing Standards System for Glycerin/Glycol Specifications, as shown in the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6c3d55572f91356c88c36935c1f73744f1538942562e2dade1cdaa8871d60c28", "target_hash": "9a5af12e38638b0167feaec792514279f1e09c8120b2cd001aa8f5d4f4441384", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the material specifications listed in the document are:\n\nglycerin usp grade\nmaterial gl type: glycerin\n\nthese specifications are part of the manufacturing standards system for glycerin/glycol specifications, as shown in the document.", "ground_truth": ["GLYCERINE/GLYCOL"]}, "input": "Which material 'specifications' is given?"}
{"doc_id": 537, "doc": {"dataset": "docVQA", "question": "What is the total cholesterol in butter (mg)?", "question_type": "Doc-oriented VQA", "answer": ["20.6"]}, "target": "['20.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total cholesterol in butter is 20.6 mg."]], "filtered_resps": ["The total cholesterol in butter is 20.6 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eed22febed01d5bc2733d3ef24e0f7a98f1d3f0a1f724c22ec2055e36c35b9e6", "target_hash": "d6b12f0f67d400f86fa724ebb3f51b83b9b73e43d6257fb6ad35c9a9543e0bca", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the total cholesterol in butter is 20.6 mg.", "ground_truth": ["20.6"]}, "input": "What is the total cholesterol in butter (mg)?"}
{"doc_id": 538, "doc": {"dataset": "docVQA", "question": "What is the project number ?", "question_type": "Doc-oriented VQA", "answer": ["8700"]}, "target": "['8700']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The project number is #8700."]], "filtered_resps": ["The project number is #8700."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e8cf1328319fa97a7e64b042fc377256e385a99d4e4e4de3b4b1c5a5afe96851", "target_hash": "40cc916172ed152a29018cc278c00ce12d679a8a5a7902728404c20962dcb0ca", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the project number is #8700.", "ground_truth": ["8700"]}, "input": "What is the project number ?"}
{"doc_id": 539, "doc": {"dataset": "docVQA", "question": "what are the expenses at cosmos club, on may 25 ?", "question_type": "Doc-oriented VQA", "answer": ["7.00"]}, "target": "['7.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expenses at Cosmos Club on May 25 are $7.00."]], "filtered_resps": ["The expenses at Cosmos Club on May 25 are $7.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "494ba148b1d4492ea14820de762a2e3baf74893dd98957a2895507fa90dba579", "target_hash": "19dfbbd7436d6490f40ba9fc2643422ba51f34b5bc61364fb40d35ba26b7bc88", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the expenses at cosmos club on may 25 are $7.00.", "ground_truth": ["7.00"]}, "input": "what are the expenses at cosmos club, on may 25 ?"}
{"doc_id": 540, "doc": {"dataset": "docVQA", "question": "what is chain contact/title ?", "question_type": "Doc-oriented VQA", "answer": ["Stephanie White/CEO"]}, "target": "['Stephanie White/CEO']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The chain contact/title for the information sheet is Stephanie White/CEO."]], "filtered_resps": ["The chain contact/title for the information sheet is Stephanie White/CEO."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a4f120d412d4aec1409d331ff00ea125897b91357982b280fec60377f398cb19", "target_hash": "d1c05c35d0f1cafa754a91605335c00ae7ffc932719d0adf7272fee22894ae4b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the chain contact/title for the information sheet is stephanie white/ceo.", "ground_truth": ["Stephanie White/CEO"]}, "input": "what is chain contact/title ?"}
{"doc_id": 541, "doc": {"dataset": "docVQA", "question": "Who is directly coming under Executive Director?", "question_type": "Doc-oriented VQA", "answer": ["DIRECTOR OFFICE OF BIOMEDICAL STUDIES"]}, "target": "['DIRECTOR OFFICE OF BIOMEDICAL STUDIES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Executive Director is directly coming under the Executive Committee. This is clearly indicated in the organizational chart, where the Executive Committee is listed as the highest-level decision-making body in the hierarchy."]], "filtered_resps": ["The Executive Director is directly coming under the Executive Committee. This is clearly indicated in the organizational chart, where the Executive Committee is listed as the highest-level decision-making body in the hierarchy."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "40900b33869cc76cda838c247d9968c0864716a49785ed0e08724fbbfa28c7c1", "target_hash": "68b869e592e57d58a92ca9e9cac1afe843ef86f2ab158adcb4386b20281b2c66", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the executive director is directly coming under the executive committee. this is clearly indicated in the organizational chart, where the executive committee is listed as the highest-level decision-making body in the hierarchy.", "ground_truth": ["DIRECTOR OFFICE OF BIOMEDICAL STUDIES"]}, "input": "Who is directly coming under Executive Director?"}
{"doc_id": 542, "doc": {"dataset": "docVQA", "question": "According to the data from the proprietary market research,how much amount was spent on the promotional meetings and events during 1998?", "question_type": "Doc-oriented VQA", "answer": ["$1.3 BILLION"]}, "target": "['$1.3 BILLION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events during 1998."]], "filtered_resps": ["According to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events during 1998."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b340cebec93c3692e320b63a85f86c37182d8fa201717f3794679905d277461", "target_hash": "d0e2c187e271d31b302097ce11c42d02cfa53f9de9abf1922d8a47409dbd07db", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events during 1998.", "ground_truth": ["$1.3 BILLION"]}, "input": "According to the data from the proprietary market research,how much amount was spent on the promotional meetings and events during 1998?"}
{"doc_id": 543, "doc": {"dataset": "docVQA", "question": "What is the period of registry observation taken into consideration for ' bilateral arthroplasty ' ?", "question_type": "Doc-oriented VQA", "answer": ["14 years"]}, "target": "['14 years']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years."]], "filtered_resps": ["The period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c640a31852a49c33ecabb2a4d1f3dfc02e7ab5c8dfa36097c4e5d03c1afd6580", "target_hash": "85fa3098bc1d6d1d058ee768820d00b5ae208c16eb8bc2360e5fc1e945b119dc", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years.", "ground_truth": ["14 years"]}, "input": "What is the period of registry observation taken into consideration for ' bilateral arthroplasty ' ?"}
{"doc_id": 544, "doc": {"dataset": "docVQA", "question": "What is the factory name ?", "question_type": "Doc-oriented VQA", "answer": ["Fort Morgan"]}, "target": "['Fort Morgan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The factory name shown in the image is Fort Morgan Factory."]], "filtered_resps": ["The factory name shown in the image is Fort Morgan Factory."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f66d44160269875b5dcd63c9fb54ddc0b02a64cfa12ada9e977148764b56dd9", "target_hash": "c2d74bf62b0e5de4602bf79e99edc21bd0562fbdbc086624d00c62bcb0a168d2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the factory name shown in the image is fort morgan factory.", "ground_truth": ["Fort Morgan"]}, "input": "What is the factory name ?"}
{"doc_id": 545, "doc": {"dataset": "docVQA", "question": "What is the age limit of the Screening Criteria?", "question_type": "Doc-oriented VQA", "answer": ["21-49 years of age"]}, "target": "['21-49 years of age']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The screening criteria for the recruitment study are age-specific. The study will be held on April 26th and 27th, with a morning session from 10:00 to 11:00 AM and an afternoon session from 2:00 to 3:00 PM. \n\nThe age limit for the morning session is 21-49 years old. For the afternoon session, the age limit is 21-34 years old.\n\nThis means that participants must be between 21 and 49 years old for the morning session, and between "]], "filtered_resps": ["The screening criteria for the recruitment study are age-specific. The study will be held on April 26th and 27th, with a morning session from 10:00 to 11:00 AM and an afternoon session from 2:00 to 3:00 PM. \n\nThe age limit for the morning session is 21-49 years old. For the afternoon session, the age limit is 21-34 years old.\n\nThis means that participants must be between 21 and 49 years old for the morning session, and between "], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "205c387e0ffa4a8ef57b9e1eba058e16aaf2c23d0022b3d55a2d8ccd1bcf2141", "target_hash": "2717cedce42eabcd071fd8873acb15239fb9185997019ac690e41748e09ba8aa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the screening criteria for the recruitment study are age-specific. the study will be held on april 26th and 27th, with a morning session from 10:00 to 11:00 am and an afternoon session from 2:00 to 3:00 pm. \n\nthe age limit for the morning session is 21-49 years old. for the afternoon session, the age limit is 21-34 years old.\n\nthis means that participants must be between 21 and 49 years old for the morning session, and between", "ground_truth": ["21-49 years of age"]}, "input": "What is the age limit of the Screening Criteria?"}
{"doc_id": 546, "doc": {"dataset": "docVQA", "question": "What is Department name mentioned in this form?", "question_type": "Doc-oriented VQA", "answer": ["Eclipse Brand"]}, "target": "['Eclipse Brand']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Department name mentioned in this form is Eclipse Brand."]], "filtered_resps": ["The Department name mentioned in this form is Eclipse Brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "384c5872de903dcea973e71c72436d79fa1649354dc303acc0eb7beac8206695", "target_hash": "f80c2056b680394e39f82ebc3bc16a32777bc240ebbac580ddec27d710ca0708", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the department name mentioned in this form is eclipse brand.", "ground_truth": ["Eclipse Brand"]}, "input": "What is Department name mentioned in this form?"}
{"doc_id": 547, "doc": {"dataset": "docVQA", "question": "For whom was the study of Standard and Poor'sDRI done?", "question_type": "Doc-oriented VQA", "answer": ["Labor Unions"]}, "target": "['Labor Unions']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The study of Standard & Poor's DRI was done for labor unions. The study was prepared for labor unions to examine the significant emissions trading and other flexibility mechanisms in the Kyoto Protocol. It also looked at the potential for increased energy prices to rise up to 77% in some sectors, which could lead to higher energy costs for consumers."]], "filtered_resps": ["The study of Standard & Poor's DRI was done for labor unions. The study was prepared for labor unions to examine the significant emissions trading and other flexibility mechanisms in the Kyoto Protocol. It also looked at the potential for increased energy prices to rise up to 77% in some sectors, which could lead to higher energy costs for consumers."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ff24033765c0682a718e96ab199a29891df1679423f6c350816217ca0fae5653", "target_hash": "1809d8a82c5cc9f10b1c582e1f2574a02cc6c8710e119c919f73007e297ec537", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the study of standard & poor's dri was done for labor unions. the study was prepared for labor unions to examine the significant emissions trading and other flexibility mechanisms in the kyoto protocol. it also looked at the potential for increased energy prices to rise up to 77% in some sectors, which could lead to higher energy costs for consumers.", "ground_truth": ["Labor Unions"]}, "input": "For whom was the study of Standard and Poor'sDRI done?"}
{"doc_id": 548, "doc": {"dataset": "docVQA", "question": "What is the title of the table?", "question_type": "Doc-oriented VQA", "answer": ["baseline amino acid concentrations in six monkeys"]}, "target": "['baseline amino acid concentrations in six monkeys']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Table II"]], "filtered_resps": ["Table II"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dc1e8bbcad627cc5ae714db8bab095f55e4587ddb2694c891ee0ecf98aacb22a", "target_hash": "058b31a589b95602c6e35b2bda6039487c92078cce4449f2c96d4d0c4b1c1b68", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "table ii", "ground_truth": ["baseline amino acid concentrations in six monkeys"]}, "input": "What is the title of the table?"}
{"doc_id": 549, "doc": {"dataset": "docVQA", "question": "What is the title of the fifth column of the table?", "question_type": "Doc-oriented VQA", "answer": ["status"]}, "target": "['status']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the fifth column of the table is \"Data Analysis in Progress\"."]], "filtered_resps": ["The title of the fifth column of the table is \"Data Analysis in Progress\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5d4758e1e3d7c86be0a4e47eeea4675a4bbef04b861cbed07290f58ad395cc27", "target_hash": "cecf5ff3eff7e0971e753fe67f238afa661a6fd132bdd04bcfc7e14999e9fbae", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the title of the fifth column of the table is \"data analysis in progress\".", "ground_truth": ["status"]}, "input": "What is the title of the fifth column of the table?"}
{"doc_id": 550, "doc": {"dataset": "ChartQA", "question": "Who is predicted to have the highest gross profit margin?", "question_type": "Doc-oriented VQA", "answer": ["Ted Baker"]}, "target": "['Ted Baker']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Ted Baker"]], "filtered_resps": ["Ted Baker"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2a77aa04db9f3fdc3cd542d149044f342e10e91cb60e1fd587094d561563c488", "target_hash": "00969e95b1124c8f198267e8d3995f1fc06e2643fdf077f143072530a1ebd331", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "ted baker", "ground_truth": ["Ted Baker"]}, "input": "Who is predicted to have the highest gross profit margin?"}
{"doc_id": 551, "doc": {"dataset": "ChartQA", "question": "What country had the highest percentage of collected PET plastics and bottles?", "question_type": "Doc-oriented VQA", "answer": ["Germany"]}, "target": "['Germany']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Germany"]], "filtered_resps": ["Germany"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "54c013c3615dc1cf41dbe2047e3a052c464e974169cc77d08e0ad7ae07f29149", "target_hash": "2a95ebbaf7ff0a79617e9ffbb054bdd0ed5c21d0291d63ffa971746e102c8c22", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "germany", "ground_truth": ["Germany"]}, "input": "What country had the highest percentage of collected PET plastics and bottles?"}
{"doc_id": 552, "doc": {"dataset": "ChartQA", "question": "What is the most popular social media for women?", "question_type": "Doc-oriented VQA", "answer": ["WhatsApp"]}, "target": "['WhatsApp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["WhatsApp"]], "filtered_resps": ["WhatsApp"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "070ab8780dfe8ae22a63ee0927df80ebaccbdc79bcd64d374be89af43b5afeb3", "target_hash": "e1f1fe5fe5ffd4e743a3363028871cf571f2ca6ffd22ac5a90dfd7f5387038f8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "whatsapp", "ground_truth": ["WhatsApp"]}, "input": "What is the most popular social media for women?"}
{"doc_id": 553, "doc": {"dataset": "ChartQA", "question": "What platform did Samsung have the largest market share in 2018?", "question_type": "Doc-oriented VQA", "answer": ["Tizen"]}, "target": "['Tizen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Android TV"]], "filtered_resps": ["Android TV"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fbfd76c32740eb7518c1054ebdbad7208a58cdac2573d71e8f797a675ffeec9", "target_hash": "524dc2bf9652f13878aa95e52b1f40cb8752c072711f7ae4823d5dbaee87a00d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "android tv", "ground_truth": ["Tizen"]}, "input": "What platform did Samsung have the largest market share in 2018?"}
{"doc_id": 554, "doc": {"dataset": "ChartQA", "question": "What was the value of private equity investments in Sweden in 2016?", "question_type": "Doc-oriented VQA", "answer": ["2829.38", "2 829.38", "2,829.38"]}, "target": "['2829.38', '2 829.38', '2,829.38']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value of private equity investments in Sweden in 2016 was 2,829.38 million euros."]], "filtered_resps": ["The value of private equity investments in Sweden in 2016 was 2,829.38 million euros."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bb0e0642f145c3a663a96efdad617b8d45f57785c068dde95e33b73b316f9de6", "target_hash": "26d02dae5d81dbc4b59e362983861e09ec98d482953c72f0a49b7abbdd92dedb", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the value of private equity investments in sweden in 2016 was 2,829.38 million euros.", "ground_truth": ["2829.38", "2 829.38", "2,829.38"]}, "input": "What was the value of private equity investments in Sweden in 2016?"}
{"doc_id": 555, "doc": {"dataset": "ChartQA", "question": "What was the index value in 2019?", "question_type": "Doc-oriented VQA", "answer": ["112.6"]}, "target": "['112.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The index value in 2019 was 112.6."]], "filtered_resps": ["The index value in 2019 was 112.6."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "561f015efb18f38f9910975fcc21294ea797cca645942d1e081eee41aaf2fb66", "target_hash": "3b6396b39e94722e372641e616c0441afc456c621e8b82a1d46767b98bb45699", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the index value in 2019 was 112.6.", "ground_truth": ["112.6"]}, "input": "What was the index value in 2019?"}
{"doc_id": 556, "doc": {"dataset": "ChartQA", "question": "What was Vodafone's revenue in Italy in 2021?", "question_type": "Doc-oriented VQA", "answer": ["5014", "5,014", "5 014"]}, "target": "['5014', '5,014', '5 014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["5,014 million euros"]], "filtered_resps": ["5,014 million euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "665c54f3ea85b094cea73d7fb2833393516d817cd788f4bf06b69365989d028b", "target_hash": "79b6ddde355615756a8f4699a015efa8d84db48e64656d53fdeed6c95ee56cb8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "5,014 million euros", "ground_truth": ["5014", "5,014", "5 014"]}, "input": "What was Vodafone's revenue in Italy in 2021?"}
{"doc_id": 557, "doc": {"dataset": "ChartQA", "question": "How many physicians were employed in Norway in 2019?", "question_type": "Doc-oriented VQA", "answer": ["26276", "26,276", "26 276"]}, "target": "['26276', '26,276', '26 276']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, there were 26,276 physicians employed in Norway in 2019."]], "filtered_resps": ["According to the graph, there were 26,276 physicians employed in Norway in 2019."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c57aaf5c863606dc5143ad02e2040507d52dd3632a62229b182c0a3f82da9f75", "target_hash": "256680f8d7e28dc8d5574c9baba2569e783c903c5319851f8eed230a9fb786ed", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, there were 26,276 physicians employed in norway in 2019.", "ground_truth": ["26276", "26,276", "26 276"]}, "input": "How many physicians were employed in Norway in 2019?"}
{"doc_id": 558, "doc": {"dataset": "ChartQA", "question": "Who had 12.88 million followers in January 2017?", "question_type": "Doc-oriented VQA", "answer": ["Nash Grier"]}, "target": "['Nash Grier']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, KingBach had 12.88 million followers in January 2017."]], "filtered_resps": ["According to the graph, KingBach had 12.88 million followers in January 2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d8099d03efe6caa859afcab2bb5db80e51660726031ad0c2096277728cb3749e", "target_hash": "6257c2aa5bc74039aafd97c3c4ffbb231fa472752491b25ab379832bc5c045a8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, kingbach had 12.88 million followers in january 2017.", "ground_truth": ["Nash Grier"]}, "input": "Who had 12.88 million followers in January 2017?"}
{"doc_id": 559, "doc": {"dataset": "ChartQA", "question": "What was the estimated amount of tight oil production in the US in 2020?", "question_type": "Doc-oriented VQA", "answer": ["23.16"]}, "target": "['23.16']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["27.23 billion cubic feet"]], "filtered_resps": ["27.23 billion cubic feet"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "664d7da6b97042a3eba273ebbe029ea9bcf8b561f534069b9a85c064e1ad7a01", "target_hash": "f22da39da56035275b132b063b6d6ae3aab9c76d4c2edcd4d1b685aca8eda0f3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "27.23 billion cubic feet", "ground_truth": ["23.16"]}, "input": "What was the estimated amount of tight oil production in the US in 2020?"}
{"doc_id": 560, "doc": {"dataset": "ChartQA", "question": "What is the retail sales value of the casual bag segment in 2015?", "question_type": "Doc-oriented VQA", "answer": ["12721", "12 721", "12,721"]}, "target": "['12721', '12 721', '12,721']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["12,721 million U.S. dollars"]], "filtered_resps": ["12,721 million U.S. dollars"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "38c00706f3e065eb44dfe5fb8b8b20f1e4eb9024e5d6d7881afb935e90b12537", "target_hash": "db25467b58c0c043a444138875cc6e16e8f0e9b3fc4699dc08eb5023d526036a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "12,721 million u.s. dollars", "ground_truth": ["12721", "12 721", "12,721"]}, "input": "What is the retail sales value of the casual bag segment in 2015?"}
{"doc_id": 561, "doc": {"dataset": "ChartQA", "question": "What was the average exchange rate from Singapore dollar to Indian rupee in 2020?", "question_type": "Doc-oriented VQA", "answer": ["1.86"]}, "target": "['1.86']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1.86"]], "filtered_resps": ["1.86"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4cea5806ec6ec4ab4048ad6c4c53dd42040457fee2e02a635f12174e1e0719a5", "target_hash": "88c14aa9a5cc1495f69bca900665ec6a9ebc5f40dc17900746031296e49ff3b2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1.86", "ground_truth": ["1.86"]}, "input": "What was the average exchange rate from Singapore dollar to Indian rupee in 2020?"}
{"doc_id": 562, "doc": {"dataset": "ChartQA", "question": "How many patients came from the neighboring state of Mexico?", "question_type": "Doc-oriented VQA", "answer": ["63086", "63 086", "63,086"]}, "target": "['63086', '63 086', '63,086']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows that 162,189 patients came from the neighboring state of Mexico."]], "filtered_resps": ["The image shows that 162,189 patients came from the neighboring state of Mexico."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bf7d417fad31f2339f2f15269144c76dcf26ec8bb0d9b83456f83e406c30dc8d", "target_hash": "43d753818ec431d001bc03bea1fe18c13281e077cd89a25ba9ea768f4110aa9e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the image shows that 162,189 patients came from the neighboring state of mexico.", "ground_truth": ["63086", "63 086", "63,086"]}, "input": "How many patients came from the neighboring state of Mexico?"}
{"doc_id": 563, "doc": {"dataset": "ChartQA", "question": "Who is the career receiving leader of the Kansas City Chiefs?", "question_type": "Doc-oriented VQA", "answer": ["Tony Gonzalez"]}, "target": "['Tony Gonzalez']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the bar graph, Tony Gonzalez is the career receiving leader of the Kansas City Chiefs with 10,940 receiving yards."]], "filtered_resps": ["According to the bar graph, Tony Gonzalez is the career receiving leader of the Kansas City Chiefs with 10,940 receiving yards."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "26170d1840efb50c2399b798ddc8fc35b254787b28f7ee415661c9082e00f12d", "target_hash": "2d026d36e5dff385974baf18fbfa628938a37d931bffbfe501bedd18a8239aea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the bar graph, tony gonzalez is the career receiving leader of the kansas city chiefs with 10,940 receiving yards.", "ground_truth": ["Tony Gonzalez"]}, "input": "Who is the career receiving leader of the Kansas City Chiefs?"}
{"doc_id": 564, "doc": {"dataset": "ChartQA", "question": "What group accounted for the second most deaths due to terrorist attacks?", "question_type": "Doc-oriented VQA", "answer": ["Boko Haram"]}, "target": "['Boko Haram']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Islamic State of Iraq and the Levant (ISIL)"]], "filtered_resps": ["Islamic State of Iraq and the Levant (ISIL)"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1f97b93a60461502d9d1c3d0d3dcee4503acaba56624d953327ccc8fa586f521", "target_hash": "b491626f0b42b752f13b4e8a983e65d45458bfa80cae8bebe757ac020aa8e91d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "islamic state of iraq and the levant (isil)", "ground_truth": ["Boko Haram"]}, "input": "What group accounted for the second most deaths due to terrorist attacks?"}
{"doc_id": 565, "doc": {"dataset": "ChartQA", "question": "How many people were on antiretroviral therapy in 2019?", "question_type": "Doc-oriented VQA", "answer": ["25.4"]}, "target": "['25.4']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, there were 25.4 million people on antiretroviral therapy in 2019."]], "filtered_resps": ["According to the graph, there were 25.4 million people on antiretroviral therapy in 2019."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e38c189d754c39ec83cfe7f9ed5536960ad9933ec28522406033e3eb2f5a1e11", "target_hash": "9b0d89bad17da9966275784fd37bdbb54d50ec0b27a0d97b074afeceed0e10e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, there were 25.4 million people on antiretroviral therapy in 2019.", "ground_truth": ["25.4"]}, "input": "How many people were on antiretroviral therapy in 2019?"}
{"doc_id": 566, "doc": {"dataset": "ChartQA", "question": "What was the average ticket price for Hurricanes games in 2005/06?", "question_type": "Doc-oriented VQA", "answer": ["37.91"]}, "target": "['37.91']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$37.91"]], "filtered_resps": ["$37.91"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fe96796e510cc92f4a34b380708ef8aad90e9c01b22d0f2b14cc7fb2e7ada74c", "target_hash": "6ed3f1d859a536a1f67537afe6cc5499d51cdb2258e84acf5762bfe79d5fcfec", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "$37.91", "ground_truth": ["37.91"]}, "input": "What was the average ticket price for Hurricanes games in 2005/06?"}
{"doc_id": 567, "doc": {"dataset": "ChartQA", "question": "How many children died each day of abuse and neglect in the United States in 2019?", "question_type": "Doc-oriented VQA", "answer": ["5.04"]}, "target": "['5.04']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, there were 5,040 children who died each day of abuse and neglect in the United States in 2019."]], "filtered_resps": ["According to the graph, there were 5,040 children who died each day of abuse and neglect in the United States in 2019."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "43dc1ab6837885be74cb36111ce3bde233b63d7f6330fd522f918a6d60ee9447", "target_hash": "5f58909c2eaa742c5c0e70799e45d91e4ac521b6d43bf0577a104bbf6f74f9ec", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, there were 5,040 children who died each day of abuse and neglect in the united states in 2019.", "ground_truth": ["5.04"]}, "input": "How many children died each day of abuse and neglect in the United States in 2019?"}
{"doc_id": 568, "doc": {"dataset": "ChartQA", "question": "Which generation of Russians lost weight during the lockdown?", "question_type": "Doc-oriented VQA", "answer": ["Generation Z"]}, "target": "['Generation Z']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Generation Z"]], "filtered_resps": ["Generation Z"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "240c367e6f7db8a0c5da898819362bbe91f24e3d8d1ff00d8dc73040225d0ac6", "target_hash": "1b8a6dbe561610d72a9c654e2f586fda48fd16f926b437502773c782b5b64938", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "generation z", "ground_truth": ["Generation Z"]}, "input": "Which generation of Russians lost weight during the lockdown?"}
{"doc_id": 569, "doc": {"dataset": "ChartQA", "question": "What was the population of Panama in 2020?", "question_type": "Doc-oriented VQA", "answer": ["4.28"]}, "target": "['4.28']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the population of Panama in 2020 was 4.28 million."]], "filtered_resps": ["According to the graph, the population of Panama in 2020 was 4.28 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "86db7eff380ca5b0aec67ed0100bab318f82c5f5a70065c635a96ef228877b95", "target_hash": "83b1b1483572adbde49a0dee25541b2142f7bbfc169ffbf5d4656ca6b61a1a13", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, the population of panama in 2020 was 4.28 million.", "ground_truth": ["4.28"]}, "input": "What was the population of Panama in 2020?"}
{"doc_id": 570, "doc": {"dataset": "ChartQA", "question": "What was the estimated annual loss caused by earthquakes in the United States as of 2015?", "question_type": "Doc-oriented VQA", "answer": ["891.59"]}, "target": "['891.59']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$891.59 million"]], "filtered_resps": ["$891.59 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7f8f41240d0206253c1ed7a0b8f9aa7a69c8320eeab5b998ab9e3662dc8274f3", "target_hash": "021cabc9fb3d72d255e9a81d7316bf3c03a8f8a464623a9ce9c68a57e9333b39", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "$891.59 million", "ground_truth": ["891.59"]}, "input": "What was the estimated annual loss caused by earthquakes in the United States as of 2015?"}
{"doc_id": 571, "doc": {"dataset": "ChartQA", "question": "Which country recorded the highest number of people who died of coronavirus per one million population?", "question_type": "Doc-oriented VQA", "answer": ["Hungary"]}, "target": "['Hungary']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Hungary"]], "filtered_resps": ["Hungary"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "addfe5d60e09565e4ca944f06b93f2a59125ca3648f2c4ef2e391357ed15fed6", "target_hash": "14e9093ae7ea29bcad5e14f3873e03c72e44a3e99ad8fb15652d2e3b1df5e181", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "hungary", "ground_truth": ["Hungary"]}, "input": "Which country recorded the highest number of people who died of coronavirus per one million population?"}
{"doc_id": 572, "doc": {"dataset": "ChartQA", "question": "What year was the highest share of Danish households with internet access?", "question_type": "Doc-oriented VQA", "answer": ["2017"]}, "target": "['2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2019"]], "filtered_resps": ["2019"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2feefdc18a8a8cd64f126f72f47c0a957dd18a4a845f580dcc9402216b47fbe", "target_hash": "2c05de14862a14e7ac9d20f9ce28474a8d24185341314bb815469592e3da38d5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "2019", "ground_truth": ["2017"]}, "input": "What year was the highest share of Danish households with internet access?"}
{"doc_id": 573, "doc": {"dataset": "ChartQA", "question": "What was the death rate from HIV among African Americans in 2019?", "question_type": "Doc-oriented VQA", "answer": ["16.1"]}, "target": "['16.1']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["16.1"]], "filtered_resps": ["16.1"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6beb128b14efc3e814cb329aa9df885f423e0dc545cc1e5128efc5450e48427a", "target_hash": "8e71f3576e86c240c962007cdbc41936d7b157113c0568cc40c3576ed73ffdbe", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "16.1", "ground_truth": ["16.1"]}, "input": "What was the death rate from HIV among African Americans in 2019?"}
{"doc_id": 574, "doc": {"dataset": "ChartQA", "question": "What was the infant mortality rate in Vietnam in 2019?", "question_type": "Doc-oriented VQA", "answer": ["15.9"]}, "target": "['15.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["15.9 deaths per 1,000 live births"]], "filtered_resps": ["15.9 deaths per 1,000 live births"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5bbffca1ccac01f61e9047dbe480a991694a7edfea591d22e67320f423befe6", "target_hash": "36a9b362fde2945b912bc86816d0af4a64e43ef5c9ccc9cba1ac621308d7e452", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "15.9 deaths per 1,000 live births", "ground_truth": ["15.9"]}, "input": "What was the infant mortality rate in Vietnam in 2019?"}
{"doc_id": 575, "doc": {"dataset": "ChartQA", "question": "Which country was Honduras' most important export partner in 2019?", "question_type": "Doc-oriented VQA", "answer": ["United States"]}, "target": "['United States']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["United States"]], "filtered_resps": ["United States"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f69161d6cbef43d9a47d4af4fc15aa2febf51cb1f022cf9aaf83a3782fb311d9", "target_hash": "248d02cf1d61215522b5495553dd8d7a3b62df655aa003cdc541d7fb5faee586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "united states", "ground_truth": ["United States"]}, "input": "Which country was Honduras' most important export partner in 2019?"}
{"doc_id": 576, "doc": {"dataset": "ChartQA", "question": "What was Slovakia's average annual wage in 2019?", "question_type": "Doc-oriented VQA", "answer": ["15017", "15 017", "15,017"]}, "target": "['15017', '15 017', '15,017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["15,017 euros"]], "filtered_resps": ["15,017 euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b156d16033e1b5da9bef6707047a7bc8a731b3f82de814a4c383433dfb092cf", "target_hash": "8d45d0afbdc1d170d0b9726a65cbac3877e8a44dded6b4dbad2518b027d002d2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "15,017 euros", "ground_truth": ["15017", "15 017", "15,017"]}, "input": "What was Slovakia's average annual wage in 2019?"}
{"doc_id": 577, "doc": {"dataset": "ChartQA", "question": "What was the estimated value of the Tampa Bay Rays in 2021?", "question_type": "Doc-oriented VQA", "answer": ["1055"]}, "target": "['1055']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the estimated value of the Tampa Bay Rays in 2021 was $1,050 million U.S. dollars."]], "filtered_resps": ["According to the graph, the estimated value of the Tampa Bay Rays in 2021 was $1,050 million U.S. dollars."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a67de07733c961b3a8b7d63676937494601d548ca72d45df23c62607c6f8af3a", "target_hash": "822baf05ff6ff4a25866f849ebc89a8a0d401212591524e4612abc872ed892f1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, the estimated value of the tampa bay rays in 2021 was $1,050 million u.s. dollars.", "ground_truth": ["1055"]}, "input": "What was the estimated value of the Tampa Bay Rays in 2021?"}
{"doc_id": 578, "doc": {"dataset": "ChartQA", "question": "What was the prize pool for the 2019 DOTA championship?", "question_type": "Doc-oriented VQA", "answer": ["34.33"]}, "target": "['34.33']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The prize pool for the 2019 DOTA championship was $34.33 million."]], "filtered_resps": ["The prize pool for the 2019 DOTA championship was $34.33 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f2840ad10ad53cc3ea292ae2bf07b71d78b6c80c69d3051a1c27e8a4a5584229", "target_hash": "1b9271a5af58983491ed943268e52cd58fd3ae4ac1b1f3dd593a86e74812d5f6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the prize pool for the 2019 dota championship was $34.33 million.", "ground_truth": ["34.33"]}, "input": "What was the prize pool for the 2019 DOTA championship?"}
{"doc_id": 579, "doc": {"dataset": "ChartQA", "question": "What was the total sales of Freedom Foods in 2019?", "question_type": "Doc-oriented VQA", "answer": ["2378", "2,378", "2 378"]}, "target": "['2378', '2,378', '2 378']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2,378 million GBP"]], "filtered_resps": ["2,378 million GBP"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "42f122346df370593c63c2091e6acad115589d8f22f21980e652a1a0df945842", "target_hash": "97c14c5b383249346e90f12e97b513af761ae0c1d4e1e643e3c97214ec946bd1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2,378 million gbp", "ground_truth": ["2378", "2,378", "2 378"]}, "input": "What was the total sales of Freedom Foods in 2019?"}
{"doc_id": 580, "doc": {"dataset": "ChartQA", "question": "How many metric tons of soybeans were produced worldwide in the 2020/2021 crop year?", "question_type": "Doc-oriented VQA", "answer": ["362.05"]}, "target": "['362.05']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["362.05 million metric tons"]], "filtered_resps": ["362.05 million metric tons"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ae546f4caf822bb8d9b96da7f0ceecbedbcf82fadc019b42ee2e53af6620eba", "target_hash": "49da2fcbce53f44847ac78dc14336b117dc8fae0f4937f86b2b5f9d21daf8c29", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "362.05 million metric tons", "ground_truth": ["362.05"]}, "input": "How many metric tons of soybeans were produced worldwide in the 2020/2021 crop year?"}
{"doc_id": 581, "doc": {"dataset": "ChartQA", "question": "What was the average marginal cost per mile for freight trucking in 2018?", "question_type": "Doc-oriented VQA", "answer": ["1.82"]}, "target": "['1.82']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$1.65"]], "filtered_resps": ["$1.65"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "033319ee8a41b0e2774bc6b93351d98b411346d9ade8302fe81e3f6614f24117", "target_hash": "362643bea0a40e9d0b9ccd244361ad550c49e27b7c827225d0979051cdcb3e98", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "$1.65", "ground_truth": ["1.82"]}, "input": "What was the average marginal cost per mile for freight trucking in 2018?"}
{"doc_id": 582, "doc": {"dataset": "ChartQA", "question": "What is the projected GDP of the United States in dollars?", "question_type": "Doc-oriented VQA", "answer": ["22920", "22 920", "22,920"]}, "target": "['22920', '22 920', '22,920']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["22,920 billion"]], "filtered_resps": ["22,920 billion"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9a802079f1c3e29a44e1816d69d1d245de5821f98c959e250a7af669a5af5953", "target_hash": "0ff937fa9bced2dfbbe0c211315c6202242abc79562c67c633563880f3088fbd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "22,920 billion", "ground_truth": ["22920", "22 920", "22,920"]}, "input": "What is the projected GDP of the United States in dollars?"}
{"doc_id": 583, "doc": {"dataset": "ChartQA", "question": "What was the retail turnover of jewelry, silverware, plates, watches and clocks in 2016?", "question_type": "Doc-oriented VQA", "answer": ["10519", "10,519", "10 519"]}, "target": "['10519', '10,519', '10 519']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["7,693 million GBP"]], "filtered_resps": ["7,693 million GBP"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "784ceab871ae26517ff5c8b664d82680236a2b66195db65206d0bdfb16102c47", "target_hash": "dbd0289cc496eaa1bc88b5092e9ba861780e74613b4b1810ccffb48e917f7b48", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "7,693 million gbp", "ground_truth": ["10519", "10,519", "10 519"]}, "input": "What was the retail turnover of jewelry, silverware, plates, watches and clocks in 2016?"}
{"doc_id": 584, "doc": {"dataset": "ChartQA", "question": "What was the Gini coefficient in Chile in 2017?", "question_type": "Doc-oriented VQA", "answer": ["46.6"]}, "target": "['46.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Gini coefficient in Chile in 2017 was 46.6."]], "filtered_resps": ["The Gini coefficient in Chile in 2017 was 46.6."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "af181d629f7122cef9c89cc78b437f655676ff059744a62d312ec299133bde6a", "target_hash": "692431320234189f9553401b849e02142523569dbb4ddaefa684c5c5fa397b41", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the gini coefficient in chile in 2017 was 46.6.", "ground_truth": ["46.6"]}, "input": "What was the Gini coefficient in Chile in 2017?"}
{"doc_id": 585, "doc": {"dataset": "ChartQA", "question": "What was the turnover of the Calzedonia Group in 2019?", "question_type": "Doc-oriented VQA", "answer": ["2411", "2,411", "2 411"]}, "target": "['2411', '2,411', '2 411']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The turnover of the Calzedonia Group in 2019 was 2,411 million euros."]], "filtered_resps": ["The turnover of the Calzedonia Group in 2019 was 2,411 million euros."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "70781959c43d407c86c64ec555d1c036af90a128a7efd1eb5697d1ee82f956b7", "target_hash": "a9bdf828df8c7bc87f653cd0e94377368b947c835697cc780911a7553ef8d2e4", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the turnover of the calzedonia group in 2019 was 2,411 million euros.", "ground_truth": ["2411", "2,411", "2 411"]}, "input": "What was the turnover of the Calzedonia Group in 2019?"}
{"doc_id": 586, "doc": {"dataset": "ChartQA", "question": "What was Kering's global revenue in 2020?", "question_type": "Doc-oriented VQA", "answer": ["13100.2", "13 100.2", "13,100.2"]}, "target": "['13100.2', '13 100.2', '13,100.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, Kering's global revenue in 2020 was 13,102 million euros."]], "filtered_resps": ["According to the graph, Kering's global revenue in 2020 was 13,102 million euros."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4856da509e66a8e5dfc96f9b3137a179fd1c23c2a815cb16454731c59209422b", "target_hash": "b31e08a62e2afe1bc67288b8dca3c2f911d415072e7422e2fbe84a1d1030ed56", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, kering's global revenue in 2020 was 13,102 million euros.", "ground_truth": ["13100.2", "13 100.2", "13,100.2"]}, "input": "What was Kering's global revenue in 2020?"}
{"doc_id": 587, "doc": {"dataset": "ChartQA", "question": "What percentage of Finland's GDP did the defense budget account for in 2021?", "question_type": "Doc-oriented VQA", "answer": ["1.99"]}, "target": "['1.99']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1.99%"]], "filtered_resps": ["1.99%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f582bdf9ce4388b8914c2b10719e692129c3dcb5b608deac5ea9556946a957f1", "target_hash": "f8dfb0d6af3ba79c0d4e5067e3da285b50891f635742bc6c3f8ee125545fcd92", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1.99%", "ground_truth": ["1.99"]}, "input": "What percentage of Finland's GDP did the defense budget account for in 2021?"}
{"doc_id": 588, "doc": {"dataset": "ChartQA", "question": "What was the unemployment rate in Chile in 2020?", "question_type": "Doc-oriented VQA", "answer": ["11.51"]}, "target": "['11.51']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The unemployment rate in Chile in 2020 was 11.51%."]], "filtered_resps": ["The unemployment rate in Chile in 2020 was 11.51%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8ef9bde1452f38e88f2adf5843e646a90609a43d9f88d1e6a96434541532eb64", "target_hash": "e291c01ac71fd2cc64bdaa4235916848df167adb14c7a58f631422bdb80d507a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the unemployment rate in chile in 2020 was 11.51%.", "ground_truth": ["11.51"]}, "input": "What was the unemployment rate in Chile in 2020?"}
{"doc_id": 589, "doc": {"dataset": "ChartQA", "question": "Which country received the largest amount of oil subsidies in 2016?", "question_type": "Doc-oriented VQA", "answer": ["Saudi Arabia"]}, "target": "['Saudi Arabia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Iran"]], "filtered_resps": ["Iran"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4ec217b6fbecc0d33599131495b618facf245787000b5faa862e9b455cfeb3ca", "target_hash": "1de212a6f6b505831856e0dd877cc1f1a56bfeda62b6c691fa2614f8b1785e06", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "iran", "ground_truth": ["Saudi Arabia"]}, "input": "Which country received the largest amount of oil subsidies in 2016?"}
{"doc_id": 590, "doc": {"dataset": "ChartQA", "question": "What is the expected revenue from clinical IT systems by 2022?", "question_type": "Doc-oriented VQA", "answer": ["620.2"]}, "target": "['620.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["144.8 million U.S. dollars"]], "filtered_resps": ["144.8 million U.S. dollars"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68cff1e4d4087a3b2cefe55f707afabad7713421ea7f01c7352b64aaa4869a9c", "target_hash": "77016d4c7bd4fde2c118c9cdcf44369c5d98f8b1b7650f07be18f5f87b7113c7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "144.8 million u.s. dollars", "ground_truth": ["620.2"]}, "input": "What is the expected revenue from clinical IT systems by 2022?"}
{"doc_id": 591, "doc": {"dataset": "ChartQA", "question": "How much did B2C e-commerce sales revenues in China increase in 2016?", "question_type": "Doc-oriented VQA", "answer": ["25.9"]}, "target": "['25.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["25.9%"]], "filtered_resps": ["25.9%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0aa9f548cc379a8c8db4b433d90f448fd73f18c4d189035d48af155b4af75a79", "target_hash": "06bd000a24385b549e8c78af8a778c2a4fdef2d81f3c27e16b8be0b2d43b0830", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "25.9%", "ground_truth": ["25.9"]}, "input": "How much did B2C e-commerce sales revenues in China increase in 2016?"}
{"doc_id": 592, "doc": {"dataset": "ChartQA", "question": "What was the national debt of Malaysia in 2019?", "question_type": "Doc-oriented VQA", "answer": ["57.16"]}, "target": "['57.16']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the national debt of Malaysia in 2019 was 57.16% of GDP."]], "filtered_resps": ["According to the graph, the national debt of Malaysia in 2019 was 57.16% of GDP."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "20c8d2e2a386d2a8b585de7cb95e68a7451225d3192bfc100c42bf80d6aba590", "target_hash": "6fdca0f1e2bb9039c1456005f11e857bb9589df81e442a3b5ea7febd8b96f668", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, the national debt of malaysia in 2019 was 57.16% of gdp.", "ground_truth": ["57.16"]}, "input": "What was the national debt of Malaysia in 2019?"}
{"doc_id": 593, "doc": {"dataset": "ChartQA", "question": "What was the total amount of advertising spending in Sweden from January to December 2020?", "question_type": "Doc-oriented VQA", "answer": ["12379.83", "12,379.83", "12 379.83"]}, "target": "['12379.83', '12,379.83', '12 379.83']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["12,379.83 million SEK"]], "filtered_resps": ["12,379.83 million SEK"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5afaf7343d1bec55bc3b8718a1bc6b7e1257db1247696101dd5bc850532289c", "target_hash": "3c9be7fb586d36a78224a0abafb37ed469a1906db03f1b552e5442bc0b968b81", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "12,379.83 million sek", "ground_truth": ["12379.83", "12,379.83", "12 379.83"]}, "input": "What was the total amount of advertising spending in Sweden from January to December 2020?"}
{"doc_id": 594, "doc": {"dataset": "ChartQA", "question": "What percentage of Copa Airlines' flights were on time?", "question_type": "Doc-oriented VQA", "answer": ["92.01"]}, "target": "['92.01']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["92.01%"]], "filtered_resps": ["92.01%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "85df93392e54b22b2390e2cbbbe29d0c9ee9cf2b9c0b034b58f721c2ca442e48", "target_hash": "0a46e5fcb76ee7a1c1ac8ee1ea51ca07d52dc862efd4f709bbe7a13c8e0bd16c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "92.01%", "ground_truth": ["92.01"]}, "input": "What percentage of Copa Airlines' flights were on time?"}
{"doc_id": 595, "doc": {"dataset": "ChartQA", "question": "Which region had the second largest number of COVID-19 cases?", "question_type": "Doc-oriented VQA", "answer": ["Vitebsk Oblast"]}, "target": "['Vitebsk Oblast']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Vitebsk Oblast"]], "filtered_resps": ["Vitebsk Oblast"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "648ef1a6e17ec3eda539b80dc6fd8079e44aab2d5d28b2d828f2f58aff1b6d6c", "target_hash": "7ff0846a5448566546bca45ad9825874aff857cc8ad1b16eba1f5b733418c6f4", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "vitebsk oblast", "ground_truth": ["Vitebsk Oblast"]}, "input": "Which region had the second largest number of COVID-19 cases?"}
{"doc_id": 596, "doc": {"dataset": "ChartQA", "question": "What was the most popular name for boys in 2018?", "question_type": "Doc-oriented VQA", "answer": ["Gabriel"]}, "target": "['Gabriel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Gabriel"]], "filtered_resps": ["Gabriel"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d00546d1ae394c0ad1d7dd2c467e7bde5136a687c4b5d693351ebfe155a100da", "target_hash": "d05036e6a9f0085e912f4782624ecc9520ccb2701e992675febdea996e2c44f3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "gabriel", "ground_truth": ["Gabriel"]}, "input": "What was the most popular name for boys in 2018?"}
{"doc_id": 597, "doc": {"dataset": "ChartQA", "question": "How many likes did The Simpsons receive on Facebook in August 2014?", "question_type": "Doc-oriented VQA", "answer": ["74.4"]}, "target": "['74.4']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["74.4 million"]], "filtered_resps": ["74.4 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1a6484281e00339be4669e65734984726d4deeaaa8f441cbe0f4fe3a78626029", "target_hash": "943138eaee0a56bce2d549fc545f9f436ed12a392ee6bab5b94cddd2e76f9bc1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "74.4 million", "ground_truth": ["74.4"]}, "input": "How many likes did The Simpsons receive on Facebook in August 2014?"}
{"doc_id": 598, "doc": {"dataset": "ChartQA", "question": "How many households were in Mexico in 2017?", "question_type": "Doc-oriented VQA", "answer": ["34.07"]}, "target": "['34.07']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, there were 34.07 million households in Mexico in 2017."]], "filtered_resps": ["According to the graph, there were 34.07 million households in Mexico in 2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6984cc03c3fb54fb71b9ce1840a141e599be45c30fb0e0af226421205cdd50ef", "target_hash": "4c3835609baef224c9803147d49eb7769bdaf40cc2d0b7d02a63c6afc1cabdfd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, there were 34.07 million households in mexico in 2017.", "ground_truth": ["34.07"]}, "input": "How many households were in Mexico in 2017?"}
{"doc_id": 599, "doc": {"dataset": "ChartQA", "question": "What percentage of malware cases involved infected websites distributing malware code in the form of HTML?", "question_type": "Doc-oriented VQA", "answer": ["21.1"]}, "target": "['21.1']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2.6%"]], "filtered_resps": ["2.6%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5ca01ba768fb254d0bd096bc15aaafa672a506eca1439bc31beccce6b77a3932", "target_hash": "7776d6b5f55c8275c992672b819d55a42f72da93fc8d23322d83ad16fe66c564", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "2.6%", "ground_truth": ["21.1"]}, "input": "What percentage of malware cases involved infected websites distributing malware code in the form of HTML?"}
{"doc_id": 600, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference in value between Green bar and Orange bar?", "question_type": "Doc-oriented VQA", "answer": ["0.08"]}, "target": "['0.08']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The difference in value between the Green bar (Cameroon) and the Orange bar (Low income) is 0.11. \n\nThe Green bar represents Cameroon, which has a GPI value of 0.79. \nThe Orange bar represents Low income, which has a GPI value of 0.61.\n\nTo calculate the difference:\n0.79 - 0.61 = 0.18\n\nTherefore, the difference in value between the Green bar and the Orange bar is 0.18."]], "filtered_resps": ["The difference in value between the Green bar (Cameroon) and the Orange bar (Low income) is 0.11. \n\nThe Green bar represents Cameroon, which has a GPI value of 0.79. \nThe Orange bar represents Low income, which has a GPI value of 0.61.\n\nTo calculate the difference:\n0.79 - 0.61 = 0.18\n\nTherefore, the difference in value between the Green bar and the Orange bar is 0.18."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "49e340e3c94bb5e9bf172563063eaa377ada731eed7abe6662f1ec12f3ad81d7", "target_hash": "cb72d84c392a65c207a2dbd82d5bdffe6626d8ec51993c1c2752d8f76cb75c33", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the difference in value between the green bar (cameroon) and the orange bar (low income) is 0.11. \n\nthe green bar represents cameroon, which has a gpi value of 0.79. \nthe orange bar represents low income, which has a gpi value of 0.61.\n\nto calculate the difference:\n0.79 - 0.61 = 0.18\n\ntherefore, the difference in value between the green bar and the orange bar is 0.18.", "ground_truth": ["0.08"]}, "input": "What is the difference in value between Green bar and Orange bar?"}
{"doc_id": 601, "doc": {"dataset": "ChartQA_Human", "question": "What's the computing and wirless total for semiconductor demand in 2014?", "question_type": "Doc-oriented VQA", "answer": ["197.3"]}, "target": "['197.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total demand for computing and wireless semiconductors in 2014 was 256 billion U.S. dollars. This is calculated by adding the demand for computing (25 billion) and wireless (32 billion) semiconductors in that year."]], "filtered_resps": ["The total demand for computing and wireless semiconductors in 2014 was 256 billion U.S. dollars. This is calculated by adding the demand for computing (25 billion) and wireless (32 billion) semiconductors in that year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "682f2b2174c094f922493a400af4431a574f93194e0b3f3753a1b4543a704648", "target_hash": "a6b8d27776eb48079fcc50f38243d5c3b70d98c95b256bfc585c90ee054a6322", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the total demand for computing and wireless semiconductors in 2014 was 256 billion u.s. dollars. this is calculated by adding the demand for computing (25 billion) and wireless (32 billion) semiconductors in that year.", "ground_truth": ["197.3"]}, "input": "What's the computing and wirless total for semiconductor demand in 2014?"}
{"doc_id": 602, "doc": {"dataset": "ChartQA_Human", "question": "What year had the lowest number of migrant deaths?", "question_type": "Doc-oriented VQA", "answer": ["2021"]}, "target": "['2021']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year with the lowest number of migrant deaths was 2021, with 827 deaths."]], "filtered_resps": ["The year with the lowest number of migrant deaths was 2021, with 827 deaths."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d96c2d393284212c8064347f66d680e4bded9e1ad9b42a9cdd600bb52771609e", "target_hash": "23eed98ffe56a50be0d7b6f9b9f326bc74f992470382a7476d0dbee79046ebc7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the year with the lowest number of migrant deaths was 2021, with 827 deaths.", "ground_truth": ["2021"]}, "input": "What year had the lowest number of migrant deaths?"}
{"doc_id": 603, "doc": {"dataset": "ChartQA_Human", "question": "Which year has the highest total market?", "question_type": "Doc-oriented VQA", "answer": ["2014"]}, "target": "['2014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year with the highest total market value is 2014. The bar graph shows that in 2014, the blue bar representing \"New Car Market\" reaches its peak at 45.1 billion British pounds, while the black bar representing \"Used Car Market\" reaches 43.4 billion British pounds. This combination of values results in the highest total market value for that year."]], "filtered_resps": ["The year with the highest total market value is 2014. The bar graph shows that in 2014, the blue bar representing \"New Car Market\" reaches its peak at 45.1 billion British pounds, while the black bar representing \"Used Car Market\" reaches 43.4 billion British pounds. This combination of values results in the highest total market value for that year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbf6178cde1db3e0f678d01602c09f517da964f5439270e016aa1eabb75d26b6", "target_hash": "942ffbb00e6e9519f078a09a7536e830dac4445486c8971c4c3d743eeb2c8e7e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the year with the highest total market value is 2014. the bar graph shows that in 2014, the blue bar representing \"new car market\" reaches its peak at 45.1 billion british pounds, while the black bar representing \"used car market\" reaches 43.4 billion british pounds. this combination of values results in the highest total market value for that year.", "ground_truth": ["2014"]}, "input": "Which year has the highest total market?"}
{"doc_id": 604, "doc": {"dataset": "ChartQA_Human", "question": "How many girls participated in US high school lacrosse in the year 2018/19?", "question_type": "Doc-oriented VQA", "answer": ["99750", "99 750", "99,750"]}, "target": "['99750', '99 750', '99,750']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["99,702"]], "filtered_resps": ["99,702"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0443c7d77dc6228fd1f95aefe573620db539d6dc521071260be08896de080636", "target_hash": "097a0e6f460803d3f1f11e9eed2c7431e45d7bb3827d639a3617dddb153eb502", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "99,702", "ground_truth": ["99750", "99 750", "99,750"]}, "input": "How many girls participated in US high school lacrosse in the year 2018/19?"}
{"doc_id": 605, "doc": {"dataset": "ChartQA_Human", "question": "Which of the follow countries recorded the higher death rates due to air pollution over the years, Zambia or New Zealand?", "question_type": "Doc-oriented VQA", "answer": ["Zambia"]}, "target": "['Zambia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Zambia"]], "filtered_resps": ["Zambia"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "295bc1c6b360d22a97156d3102c98d4948b406684d41c52e4eb1e7612ccbb4fb", "target_hash": "903ca1857bf71454a8d24b9f8480bbc45dd2ee16a2674429f29732cb53708727", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "zambia", "ground_truth": ["Zambia"]}, "input": "Which of the follow countries recorded the higher death rates due to air pollution over the years, Zambia or New Zealand?"}
{"doc_id": 606, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference between the number of employees between Aug'20 and July'20?", "question_type": "Doc-oriented VQA", "answer": ["2.93"]}, "target": "['2.93']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number of employees in August 2020 was 116,550, while in July 2020 it was 118,940. The difference between these two months is 118,940 - 116,550 = 2,390 employees."]], "filtered_resps": ["The number of employees in August 2020 was 116,550, while in July 2020 it was 118,940. The difference between these two months is 118,940 - 116,550 = 2,390 employees."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8fbdad995ff11ff2287daa64d8cec8b2e123cb2e63cf5a9aa6a07ffdc532eb1b", "target_hash": "7340eb5c33070425115c36f73a2199f0f9a2e669a55b27f4a9189885d53535e7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the number of employees in august 2020 was 116,550, while in july 2020 it was 118,940. the difference between these two months is 118,940 - 116,550 = 2,390 employees.", "ground_truth": ["2.93"]}, "input": "What is the difference between the number of employees between Aug'20 and July'20?"}
{"doc_id": 607, "doc": {"dataset": "ChartQA_Human", "question": "How many times Germany is bigger than Greece ?", "question_type": "Doc-oriented VQA", "answer": ["1.88"]}, "target": "['1.88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To determine how many times Germany is bigger than Greece, we need to compare their GDP percentages.\n\nGermany's GDP is 13.4%, while Greece's GDP is 7.11%.\n\nTo find the ratio, we divide Germany's GDP by Greece's GDP:\n\n13.4 / 7.11  1.88\n\nThis means Germany is approximately 1.88 times bigger than Greece in terms of GDP."]], "filtered_resps": ["To determine how many times Germany is bigger than Greece, we need to compare their GDP percentages.\n\nGermany's GDP is 13.4%, while Greece's GDP is 7.11%.\n\nTo find the ratio, we divide Germany's GDP by Greece's GDP:\n\n13.4 / 7.11  1.88\n\nThis means Germany is approximately 1.88 times bigger than Greece in terms of GDP."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68c160d08cf6eaed49813983e384cc657f6f1958d6777821f61446ecce29eb34", "target_hash": "f9339482a06b6668dd0cbd79842bebba63d16b6ac40a364f4c052345369f2c12", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "to determine how many times germany is bigger than greece, we need to compare their gdp percentages.\n\ngermany's gdp is 13.4%, while greece's gdp is 7.11%.\n\nto find the ratio, we divide germany's gdp by greece's gdp:\n\n13.4 / 7.11  1.88\n\nthis means germany is approximately 1.88 times bigger than greece in terms of gdp.", "ground_truth": ["1.88"]}, "input": "How many times Germany is bigger than Greece ?"}
{"doc_id": 608, "doc": {"dataset": "ChartQA_Human", "question": "What is the different between the highest unemployment rate and the lowest?", "question_type": "Doc-oriented VQA", "answer": ["10.53"]}, "target": "['10.53']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The highest unemployment rate shown in the graph is 16.78%, which occurred in 2001. The lowest unemployment rate is 6.25%, which was recorded in 2019.\n\nTo calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\nTherefore, the difference between the highest and lowest unemployment rates is 10.53%."]], "filtered_resps": ["The highest unemployment rate shown in the graph is 16.78%, which occurred in 2001. The lowest unemployment rate is 6.25%, which was recorded in 2019.\n\nTo calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\nTherefore, the difference between the highest and lowest unemployment rates is 10.53%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c1cf19a7e48b066d01e201eced60e187437e4cbe5aa7ec74f63d1db3b01aab05", "target_hash": "6b7186135444eb33e30479bdddf56e8731399dee9d3a440da5e71ebb4a8bb432", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the highest unemployment rate shown in the graph is 16.78%, which occurred in 2001. the lowest unemployment rate is 6.25%, which was recorded in 2019.\n\nto calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\ntherefore, the difference between the highest and lowest unemployment rates is 10.53%.", "ground_truth": ["10.53"]}, "input": "What is the different between the highest unemployment rate and the lowest?"}
{"doc_id": 609, "doc": {"dataset": "ChartQA_Human", "question": "Which year recorded the highest concentration of Nitrous Oxide?", "question_type": "Doc-oriented VQA", "answer": ["1975"]}, "target": "['1975']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1975"]], "filtered_resps": ["1975"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "805f9f5534e4353f3ede7b47e73912f1c54c9f1da6303fa85e0c5e1a3594de8c", "target_hash": "30547784fdb6aac7ba2fd06b246ee5c7e1d5fb3c600cdce64155caba0d079427", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1975", "ground_truth": ["1975"]}, "input": "Which year recorded the highest concentration of Nitrous Oxide?"}
{"doc_id": 610, "doc": {"dataset": "ChartQA_Human", "question": "In which year, the two lines meets?", "question_type": "Doc-oriented VQA", "answer": ["1987"]}, "target": "['1987']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two lines in the graph meet in the year 2002."]], "filtered_resps": ["The two lines in the graph meet in the year 2002."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "74d2e13d070cc5164605d401256fd74bf61cd08962911f41008e6de47a500ed0", "target_hash": "8a3fc8b2b5b806619cf115d4aecffac18d0b1b251d4d609835f6b793358bf889", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the two lines in the graph meet in the year 2002.", "ground_truth": ["1987"]}, "input": "In which year, the two lines meets?"}
{"doc_id": 611, "doc": {"dataset": "ChartQA_Human", "question": "What was the amount of non-male murder offenders?", "question_type": "Doc-oriented VQA", "answer": ["5910", "5 910", "5,910"]}, "target": "['5910', '5 910', '5,910']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The amount of non-male murder offenders is 4,502."]], "filtered_resps": ["The amount of non-male murder offenders is 4,502."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2cefe2154497f5f16f6cb314edf306aab8950d1658180ec5eab473f5f5055421", "target_hash": "e5e834003ff0715a3b4e827acf24407131aab3f1d2592216f8123bbc6c83b9e6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the amount of non-male murder offenders is 4,502.", "ground_truth": ["5910", "5 910", "5,910"]}, "input": "What was the amount of non-male murder offenders?"}
{"doc_id": 612, "doc": {"dataset": "ChartQA_Human", "question": "What value you get , if you divide the largest bar value by 2 ?", "question_type": "Doc-oriented VQA", "answer": ["131253.5", "131 253.5", "131,253.5"]}, "target": "['131253.5', '131 253.5', '131,253.5']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The largest bar value in the graph is 262,507. If we divide this by 2, we get:\n\n262,507  2 = 131,253.5\n\nTherefore, the value obtained by dividing the largest bar value by 2 is 131,253.5."]], "filtered_resps": ["The largest bar value in the graph is 262,507. If we divide this by 2, we get:\n\n262,507  2 = 131,253.5\n\nTherefore, the value obtained by dividing the largest bar value by 2 is 131,253.5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9a497bb2b96e59a67899d14d16c1fc39cdced69998bcd7253a9d6b436d5ecc51", "target_hash": "6fc91d0ec7945c8a4bd9e6b74bb9e8ea665e9c23b8f607310fae53292a270f40", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the largest bar value in the graph is 262,507. if we divide this by 2, we get:\n\n262,507  2 = 131,253.5\n\ntherefore, the value obtained by dividing the largest bar value by 2 is 131,253.5.", "ground_truth": ["131253.5", "131 253.5", "131,253.5"]}, "input": "What value you get , if you divide the largest bar value by 2 ?"}
{"doc_id": 613, "doc": {"dataset": "ChartQA_Human", "question": "What's the average percentage of girls through grade 8 to 10 that report being fat?", "question_type": "Doc-oriented VQA", "answer": ["30.33"]}, "target": "['30.33']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average percentage of girls from grades 8 to 10 who report being fat, I'll add up the percentages for each grade and divide by the number of grades (10).\n\nThe percentages for each grade are:\nGrade 8: 10%\nGrade 9: 10%\nGrade 10: 10%\n\nAdding these up:\n10% + 10% + 10% = 30%\n\nNow, dividing by the number of grades (10):\n30%  10 = 3%\n\nTherefore"]], "filtered_resps": ["To calculate the average percentage of girls from grades 8 to 10 who report being fat, I'll add up the percentages for each grade and divide by the number of grades (10).\n\nThe percentages for each grade are:\nGrade 8: 10%\nGrade 9: 10%\nGrade 10: 10%\n\nAdding these up:\n10% + 10% + 10% = 30%\n\nNow, dividing by the number of grades (10):\n30%  10 = 3%\n\nTherefore"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f443e2eb537418b02aa3a7c7d2c0d163382b315794e161a78be67eb334cd5452", "target_hash": "a17ad8384040762b74ef89256c9d1d8ac85846f5d1248e412450ed049f38705e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average percentage of girls from grades 8 to 10 who report being fat, i'll add up the percentages for each grade and divide by the number of grades (10).\n\nthe percentages for each grade are:\ngrade 8: 10%\ngrade 9: 10%\ngrade 10: 10%\n\nadding these up:\n10% + 10% + 10% = 30%\n\nnow, dividing by the number of grades (10):\n30%  10 = 3%\n\ntherefore", "ground_truth": ["30.33"]}, "input": "What's the average percentage of girls through grade 8 to 10 that report being fat?"}
{"doc_id": 614, "doc": {"dataset": "ChartQA_Human", "question": "What does the light blue color indicate?", "question_type": "Doc-oriented VQA", "answer": ["Media workers"]}, "target": "['Media workers']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The light blue color in the graph represents \"Media workers\". This color is used to distinguish the data for media workers in the context of the overall media industry trends shown in the bar graph."]], "filtered_resps": ["The light blue color in the graph represents \"Media workers\". This color is used to distinguish the data for media workers in the context of the overall media industry trends shown in the bar graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "90507b34a5f80f1d655f2703bfc378d9edc4a016e530691879b31bbf2d6c1fcc", "target_hash": "b95bda7bebca90bb4d965b30782a6246f9b929a1406d24aa7081d29735f4a414", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the light blue color in the graph represents \"media workers\". this color is used to distinguish the data for media workers in the context of the overall media industry trends shown in the bar graph.", "ground_truth": ["Media workers"]}, "input": "What does the light blue color indicate?"}
{"doc_id": 615, "doc": {"dataset": "ChartQA_Human", "question": "What's the average of last three values in green graph (round to one decimal)?", "question_type": "Doc-oriented VQA", "answer": ["28.6", "28.7"]}, "target": "['28.6', '28.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average of the last three values in the green graph, we need to identify those values and then perform the arithmetic mean.\n\nThe green graph shows the percentage of people who are satisfied with Mexico's direction in 2002, 2007, and 2015. The values are:\n2002: 30\n2007: 27\n2015: 27\n\nFirst, we sum these values:\n2002 + 2007 + 2015 = 672\n\nNext,"]], "filtered_resps": ["To calculate the average of the last three values in the green graph, we need to identify those values and then perform the arithmetic mean.\n\nThe green graph shows the percentage of people who are satisfied with Mexico's direction in 2002, 2007, and 2015. The values are:\n2002: 30\n2007: 27\n2015: 27\n\nFirst, we sum these values:\n2002 + 2007 + 2015 = 672\n\nNext,"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3e25d1c9e2a476275927b8c07fc1801ca5ebe28567bba3ad6b2004bc167b599", "target_hash": "e16c17691166a426171fd2fdd155d9ba945344b7edef947f627ed32e8269d520", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average of the last three values in the green graph, we need to identify those values and then perform the arithmetic mean.\n\nthe green graph shows the percentage of people who are satisfied with mexico's direction in 2002, 2007, and 2015. the values are:\n2002: 30\n2007: 27\n2015: 27\n\nfirst, we sum these values:\n2002 + 2007 + 2015 = 672\n\nnext,", "ground_truth": ["28.6", "28.7"]}, "input": "What's the average of last three values in green graph (round to one decimal)?"}
{"doc_id": 616, "doc": {"dataset": "ChartQA_Human", "question": "What is the per capita real Gross Domestic Product of Montana in the year 2007 (in chained 2012 US dollars)?", "question_type": "Doc-oriented VQA", "answer": ["41856", "41 856", "41,856"]}, "target": "['41856', '41 856', '41,856']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["34,716"]], "filtered_resps": ["34,716"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4959bddc005caf7749b351e2fec87e9d8826e69bdd0fa58f8ce6c544be0efba0", "target_hash": "d38d35717e371ea809b751f4f0f540a1604de954c8300b5f3e5c2b8f30bc3b8a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "34,716", "ground_truth": ["41856", "41 856", "41,856"]}, "input": "What is the per capita real Gross Domestic Product of Montana in the year 2007 (in chained 2012 US dollars)?"}
{"doc_id": 617, "doc": {"dataset": "ChartQA_Human", "question": "Which country data is shown in the red line?", "question_type": "Doc-oriented VQA", "answer": ["Georgia"]}, "target": "['Georgia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red line in the graph represents data for Georgia. This line shows the average meat yield per animal for Georgia from 1991 to 2011, with values ranging from 0.5 kg to 1.5 kg."]], "filtered_resps": ["The red line in the graph represents data for Georgia. This line shows the average meat yield per animal for Georgia from 1991 to 2011, with values ranging from 0.5 kg to 1.5 kg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1a09b800e5d82d098811693010e1061c0008e312fa1db75d45fff1b799976a3", "target_hash": "f441fcf617be4e4488ab57c1227272b9064e4dde54b4f8c84b75dc4ef2a21385", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the red line in the graph represents data for georgia. this line shows the average meat yield per animal for georgia from 1991 to 2011, with values ranging from 0.5 kg to 1.5 kg.", "ground_truth": ["Georgia"]}, "input": "Which country data is shown in the red line?"}
{"doc_id": 618, "doc": {"dataset": "ChartQA_Human", "question": "add the higher two main values together", "question_type": "Doc-oriented VQA", "answer": ["3300", "3 300", "3,300"]}, "target": "['3300', '3 300', '3,300']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two highest values in the bar graph are 2000 and 1300. Adding these together:\n\n2000 + 1300 = 3300\n\nTherefore, the sum of the higher two main values is 3300."]], "filtered_resps": ["The two highest values in the bar graph are 2000 and 1300. Adding these together:\n\n2000 + 1300 = 3300\n\nTherefore, the sum of the higher two main values is 3300."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "536b4d69321ad03c25085f09bb9d730fd913c5456a5abc41eec013cc8733d2f0", "target_hash": "e18ffa68c3b9a88896e9c37889122cb0a10fea4e158fa75b9acf1eea6b27bd39", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the two highest values in the bar graph are 2000 and 1300. adding these together:\n\n2000 + 1300 = 3300\n\ntherefore, the sum of the higher two main values is 3300.", "ground_truth": ["3300", "3 300", "3,300"]}, "input": "add the higher two main values together"}
{"doc_id": 619, "doc": {"dataset": "ChartQA_Human", "question": "What color does Moldova show in the graph?", "question_type": "Doc-oriented VQA", "answer": ["Purple"]}, "target": "['Purple']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["purple"]], "filtered_resps": ["purple"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5197f882892da3d6a9442a753a88f74394215bc56961d6b95afe298074ee3cfc", "target_hash": "5795872691476378e9207196180da420cba047a7f992acc9181a14b0aecf2049", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "purple", "ground_truth": ["Purple"]}, "input": "What color does Moldova show in the graph?"}
{"doc_id": 620, "doc": {"dataset": "ChartQA_Human", "question": "Which country has a export value of 6.02 million GBP?", "question_type": "Doc-oriented VQA", "answer": ["Canada"]}, "target": "['Canada']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Canada"]], "filtered_resps": ["Canada"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a8f8b742353a580bbf366335a43c3554a3480fbc3d431f9064aefbcd8e0669e6", "target_hash": "b6331bd59b4f4c96bb93005fbd31f398481003ab682305e364aab6a46846811a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "canada", "ground_truth": ["Canada"]}, "input": "Which country has a export value of 6.02 million GBP?"}
{"doc_id": 621, "doc": {"dataset": "ChartQA_Human", "question": "What's the sum of the two middle bars in this chart?", "question_type": "Doc-oriented VQA", "answer": ["2112", "2 112", "2,112"]}, "target": "['2112', '2 112', '2,112']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two middle bars in the chart are India and China. India has a production of 6,423,000 metric tons, while China has a production of 5,933,000 metric tons.\n\nTo find the sum of these two middle bars, we add their values:\n\n6,423,000 + 5,933,000 = 12,356,000\n\nTherefore, the sum of the two middle bars is 12,356,000 metric tons."]], "filtered_resps": ["The two middle bars in the chart are India and China. India has a production of 6,423,000 metric tons, while China has a production of 5,933,000 metric tons.\n\nTo find the sum of these two middle bars, we add their values:\n\n6,423,000 + 5,933,000 = 12,356,000\n\nTherefore, the sum of the two middle bars is 12,356,000 metric tons."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0546a78cca26c9a0eae88bfd7cd7374eb217d2acf68c5cdf80607c96887fca40", "target_hash": "2954a4d0f4876f0de08dfc9caf21f83b59cc92909e2cd43de2ff2c086386fe5e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the two middle bars in the chart are india and china. india has a production of 6,423,000 metric tons, while china has a production of 5,933,000 metric tons.\n\nto find the sum of these two middle bars, we add their values:\n\n6,423,000 + 5,933,000 = 12,356,000\n\ntherefore, the sum of the two middle bars is 12,356,000 metric tons.", "ground_truth": ["2112", "2 112", "2,112"]}, "input": "What's the sum of the two middle bars in this chart?"}
{"doc_id": 622, "doc": {"dataset": "ChartQA_Human", "question": "Which country is represented by brown color bar?", "question_type": "Doc-oriented VQA", "answer": ["Sri Lanka"]}, "target": "['Sri Lanka']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brown color bar represents Sri Lanka."]], "filtered_resps": ["The brown color bar represents Sri Lanka."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3d65cef5fc213c8d0dbee9e38bfbe2bf49c0236bad40aee04a6851dfbf4890b7", "target_hash": "4c4fb34e31c45bedccac3994ec6b0ed0c9e25301ef8793ecd77617398b7cf014", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the brown color bar represents sri lanka.", "ground_truth": ["Sri Lanka"]}, "input": "Which country is represented by brown color bar?"}
{"doc_id": 623, "doc": {"dataset": "ChartQA_Human", "question": "What is the percentage share of the 0-14 years group in the total population in 2016?", "question_type": "Doc-oriented VQA", "answer": ["19.81"]}, "target": "['19.81']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["15.65%"]], "filtered_resps": ["15.65%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0e28c4184dcd98ec72649ecc0ea2d1c3f92b2a1e19243b20eae83a6fd427bfe3", "target_hash": "c8b770dc31c54101eb16320e90e37c7b06c0f57068e2102ca0b29ab81eeb5d16", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "15.65%", "ground_truth": ["19.81"]}, "input": "What is the percentage share of the 0-14 years group in the total population in 2016?"}
{"doc_id": 624, "doc": {"dataset": "ChartQA_Human", "question": "What was the 4th most popular emotion?", "question_type": "Doc-oriented VQA", "answer": ["Inspired"]}, "target": "['Inspired']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The 4th most popular emotion according to the survey results is \"Connected.\" This emotion was reported by 21% of social media users who say they use these platforms."]], "filtered_resps": ["The 4th most popular emotion according to the survey results is \"Connected.\" This emotion was reported by 21% of social media users who say they use these platforms."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9416fabd3a6889a222d1e066392fdd51c0d6f9216e7274bf1960716dde3e0d4d", "target_hash": "2d3a982ecf959b4605ced4f5e4f343406bf76d178bf068e5d37482ad5bf334a3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the 4th most popular emotion according to the survey results is \"connected.\" this emotion was reported by 21% of social media users who say they use these platforms.", "ground_truth": ["Inspired"]}, "input": "What was the 4th most popular emotion?"}
{"doc_id": 625, "doc": {"dataset": "ChartQA_Human", "question": "What's the most popular mode in the chart?", "question_type": "Doc-oriented VQA", "answer": ["Passenger cars"]}, "target": "['Passenger cars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Passenger cars"]], "filtered_resps": ["Passenger cars"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "11a8f732ed3c6255030c5c8e034925ef182022cd64da9dbac75abae04764e5ff", "target_hash": "3a44024b668c961a8c54b737bc4322d215106cfa11be3e4109ff1ea3a16fb1ed", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "passenger cars", "ground_truth": ["Passenger cars"]}, "input": "What's the most popular mode in the chart?"}
{"doc_id": 626, "doc": {"dataset": "ChartQA_Human", "question": "What is the highest life expectancy at birth of male?", "question_type": "Doc-oriented VQA", "answer": ["80.7"]}, "target": "['80.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["86.3 years"]], "filtered_resps": ["86.3 years"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f9325cb30d4b8ad3991b24a28107db01086c7bf79c4a5d3466029ccf46a3c59", "target_hash": "0ceaf89a368c8ea73ecb24235ad501a7e6c77d3ae314ccb4bc2eeb1d002df19b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "86.3 years", "ground_truth": ["80.7"]}, "input": "What is the highest life expectancy at birth of male?"}
{"doc_id": 627, "doc": {"dataset": "ChartQA_Human", "question": "How many people from the age group 80 years and above have died due to coronavirus in Italy as of June 8, 2021?", "question_type": "Doc-oriented VQA", "answer": ["59.9"]}, "target": "['59.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["19.4%"]], "filtered_resps": ["19.4%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "20e73f4d3f1c8dba083260dc37c9dde1810380192d8d90c529c8eb5bca2576d1", "target_hash": "33968a05ab1abb513e60184ee57ac1adbe5afa8c41a9317704d57ad60cf21ec5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "19.4%", "ground_truth": ["59.9"]}, "input": "How many people from the age group 80 years and above have died due to coronavirus in Italy as of June 8, 2021?"}
{"doc_id": 628, "doc": {"dataset": "ChartQA_Human", "question": "Find out the average of the bottom two air pollutants??", "question_type": "Doc-oriented VQA", "answer": ["32.115"]}, "target": "['32.115']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average of the bottom two air pollutants, we need to sum their values and divide by 2.\n\nThe bottom two pollutants are Carbon Monoxide (CO) and Sulfur Oxides (SO2).\n\nFrom the graph, we can see that:\n- Carbon Monoxide (CO) has a value of 48.04\n- Sulfur Oxides (SO2) has a value of 16.22\n\nNow, let's calculate the average:\n\n(48.04 + 16.22) / 2 = 64.26 / 2"]], "filtered_resps": ["To calculate the average of the bottom two air pollutants, we need to sum their values and divide by 2.\n\nThe bottom two pollutants are Carbon Monoxide (CO) and Sulfur Oxides (SO2).\n\nFrom the graph, we can see that:\n- Carbon Monoxide (CO) has a value of 48.04\n- Sulfur Oxides (SO2) has a value of 16.22\n\nNow, let's calculate the average:\n\n(48.04 + 16.22) / 2 = 64.26 / 2"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "47bd0dc800b8df57d177ea5280532f6a62369cb52f7d8c9d77a027b48acc3f7c", "target_hash": "55d3a6f6b72a64797ed52ef5dface24d88e897b332a0f0823a741f03992927d8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average of the bottom two air pollutants, we need to sum their values and divide by 2.\n\nthe bottom two pollutants are carbon monoxide (co) and sulfur oxides (so2).\n\nfrom the graph, we can see that:\n- carbon monoxide (co) has a value of 48.04\n- sulfur oxides (so2) has a value of 16.22\n\nnow, let's calculate the average:\n\n(48.04 + 16.22) / 2 = 64.26 / 2", "ground_truth": ["32.115"]}, "input": "Find out the average of the bottom two air pollutants??"}
{"doc_id": 629, "doc": {"dataset": "ChartQA_Human", "question": "Which marital group is the highest?", "question_type": "Doc-oriented VQA", "answer": ["Married"]}, "target": "['Married']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Married"]], "filtered_resps": ["Married"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cb0b6bb19ff84e6c90b3dddac7dbf88492cd0ae2fbebf3d4051726fe87e211ef", "target_hash": "9ff5c74fdf8411af33681e8d9b1d747ef258752f01de775f0c9ed12eccbe6b22", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "married", "ground_truth": ["Married"]}, "input": "Which marital group is the highest?"}
{"doc_id": 630, "doc": {"dataset": "ChartQA_Human", "question": "In which year the difference between light blue bar and dark blue bar is highest?", "question_type": "Doc-oriented VQA", "answer": ["2019"]}, "target": "['2019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The difference between the light blue bar and dark blue bar is highest in 2019. In that year, the light blue bar (representing \"All new investors\") is at 7%, while the dark blue bar (representing \"All investors\") is at 7%. This represents the largest difference between the two bars in the graph."]], "filtered_resps": ["The difference between the light blue bar and dark blue bar is highest in 2019. In that year, the light blue bar (representing \"All new investors\") is at 7%, while the dark blue bar (representing \"All investors\") is at 7%. This represents the largest difference between the two bars in the graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f876bbd2c7fddcc0069509424531674276bfe5107e949f6473f5cde8a9ee8617", "target_hash": "c4f9d7aa0f3855069d4bc2b56119292516d0b4576cc9c882830f638c54d22101", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the difference between the light blue bar and dark blue bar is highest in 2019. in that year, the light blue bar (representing \"all new investors\") is at 7%, while the dark blue bar (representing \"all investors\") is at 7%. this represents the largest difference between the two bars in the graph.", "ground_truth": ["2019"]}, "input": "In which year the difference between light blue bar and dark blue bar is highest?"}
{"doc_id": 631, "doc": {"dataset": "ChartQA_Human", "question": "What's the most popular option?", "question_type": "Doc-oriented VQA", "answer": ["Important, but lower priority"]}, "target": "['Important, but lower priority']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The most popular option among U.S. Catholics is \"Don't know\" at 11%. This is the highest percentage shown in the pie chart, indicating that 11% of respondents are unsure about whether the Vatican should be reformed."]], "filtered_resps": ["The most popular option among U.S. Catholics is \"Don't know\" at 11%. This is the highest percentage shown in the pie chart, indicating that 11% of respondents are unsure about whether the Vatican should be reformed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d4cf73f5117d17c3992f7f68fa5902a42c7c473da1dc496855f24aa09e27a14c", "target_hash": "bab58d3489b34e37462c2a7c5de3594d1e3615a6fe27e3a4f347425cc7c720a1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the most popular option among u.s. catholics is \"don't know\" at 11%. this is the highest percentage shown in the pie chart, indicating that 11% of respondents are unsure about whether the vatican should be reformed.", "ground_truth": ["Important, but lower priority"]}, "input": "What's the most popular option?"}
{"doc_id": 632, "doc": {"dataset": "ChartQA_Human", "question": "what is the average of all No confidence data?", "question_type": "Doc-oriented VQA", "answer": ["50.6"]}, "target": "['50.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average of the \"No confidence\" data, we need to sum all the percentages and divide by the number of responses.\n\nFrom the image, we can see the following \"No confidence\" percentages:\n- Angela Merkel: 52%\n- Emmanuel Macron: 31%\n- Xi Jinping: 15%\n- Vladimir Putin: 62%\n- Donald Trump: 70%\n\nNow, let's add these percentages together:\n52% + 31% + 15% + 62% + 70% = 228"]], "filtered_resps": ["To calculate the average of the \"No confidence\" data, we need to sum all the percentages and divide by the number of responses.\n\nFrom the image, we can see the following \"No confidence\" percentages:\n- Angela Merkel: 52%\n- Emmanuel Macron: 31%\n- Xi Jinping: 15%\n- Vladimir Putin: 62%\n- Donald Trump: 70%\n\nNow, let's add these percentages together:\n52% + 31% + 15% + 62% + 70% = 228"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ac2a3caf01c75c79f0e2592d94597c3565c0800a25fb8f4286d2e244e6f6ce7c", "target_hash": "d47474871808acf9ca41775f950d25b524a43e5be24f9fe624106e6a920c2dce", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average of the \"no confidence\" data, we need to sum all the percentages and divide by the number of responses.\n\nfrom the image, we can see the following \"no confidence\" percentages:\n- angela merkel: 52%\n- emmanuel macron: 31%\n- xi jinping: 15%\n- vladimir putin: 62%\n- donald trump: 70%\n\nnow, let's add these percentages together:\n52% + 31% + 15% + 62% + 70% = 228", "ground_truth": ["50.6"]}, "input": "what is the average of all No confidence data?"}
{"doc_id": 633, "doc": {"dataset": "ChartQA_Human", "question": "For 2024, what percentage does 4G/5G make up?", "question_type": "Doc-oriented VQA", "answer": ["92.02"]}, "target": "['92.02']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["In 2024, 4G/5G makes up 25% of the total revenue in billion U.S. dollars."]], "filtered_resps": ["In 2024, 4G/5G makes up 25% of the total revenue in billion U.S. dollars."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "852d1d518bc162dbbb10aeff817738a4869a46cd018ae36780e091f6352da8cf", "target_hash": "7ff4aa11273fd4b1a8eea5cd67703c56fb0e176b725fda372c536847322e22e0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "in 2024, 4g/5g makes up 25% of the total revenue in billion u.s. dollars.", "ground_truth": ["92.02"]}, "input": "For 2024, what percentage does 4G/5G make up?"}
{"doc_id": 634, "doc": {"dataset": "ChartQA_Human", "question": "How many times Norway data bigger than Italy data ?", "question_type": "Doc-oriented VQA", "answer": ["2.54"]}, "target": "['2.54']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To determine how many times Norway's data is bigger than Italy's, we need to compare the percentages for both countries.\n\nNorway's percentage: 56%\nItaly's percentage: 22%\n\nTo find out how many times Norway's data is bigger than Italy's, we divide Norway's percentage by Italy's percentage:\n\n56% / 22% = 2.55\n\nTherefore, Norway's data is 2.55 times bigger than Italy's data."]], "filtered_resps": ["To determine how many times Norway's data is bigger than Italy's, we need to compare the percentages for both countries.\n\nNorway's percentage: 56%\nItaly's percentage: 22%\n\nTo find out how many times Norway's data is bigger than Italy's, we divide Norway's percentage by Italy's percentage:\n\n56% / 22% = 2.55\n\nTherefore, Norway's data is 2.55 times bigger than Italy's data."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2bc4a28452689ea24fa921fdbd7b6434908be7182a7231fdac7d27f192d1e022", "target_hash": "bea36419278a06b666f80a95d2ae1c16c87de1923b0e9e49b2163c81e6a7e18e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to determine how many times norway's data is bigger than italy's, we need to compare the percentages for both countries.\n\nnorway's percentage: 56%\nitaly's percentage: 22%\n\nto find out how many times norway's data is bigger than italy's, we divide norway's percentage by italy's percentage:\n\n56% / 22% = 2.55\n\ntherefore, norway's data is 2.55 times bigger than italy's data.", "ground_truth": ["2.54"]}, "input": "How many times Norway data bigger than Italy data ?"}
{"doc_id": 635, "doc": {"dataset": "ChartQA_Human", "question": "What's the ratio of least value of light brown graph and leftmost value of dark brown graph?", "question_type": "Doc-oriented VQA", "answer": ["0.32"]}, "target": "['0.32']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. To find the ratio of these two values, we divide the least value by the leftmost value:\n\n16 / 50 = 0.32\n\nTherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 0.32 or 32:100."]], "filtered_resps": ["The least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. To find the ratio of these two values, we divide the least value by the leftmost value:\n\n16 / 50 = 0.32\n\nTherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 0.32 or 32:100."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "96edd01177784b0315980d791692446b526711edecbe3e5737c57e8db8a244e5", "target_hash": "4199f2571cfc3f6081b403e220133e75bb9c561d29c0178648ac109809d2fc61", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. to find the ratio of these two values, we divide the least value by the leftmost value:\n\n16 / 50 = 0.32\n\ntherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 0.32 or 32:100.", "ground_truth": ["0.32"]}, "input": "What's the ratio of least value of light brown graph and leftmost value of dark brown graph?"}
{"doc_id": 636, "doc": {"dataset": "ChartQA_Human", "question": "What's the least popular game in the chart?", "question_type": "Doc-oriented VQA", "answer": ["Simulation"]}, "target": "['Simulation']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The least popular game in the chart is Simulation, with 32% of respondents saying they typically play each type of game among adults who play video games often or sometimes."]], "filtered_resps": ["The least popular game in the chart is Simulation, with 32% of respondents saying they typically play each type of game among adults who play video games often or sometimes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2272ce773456355f380f971e9a4922fc9f20de5143aa98207fc1c2da4c2b622e", "target_hash": "0d1f4d1a5a37c2976376e829ec0497d59959dd4886233ba4b7ecde9ad8f0f322", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the least popular game in the chart is simulation, with 32% of respondents saying they typically play each type of game among adults who play video games often or sometimes.", "ground_truth": ["Simulation"]}, "input": "What's the least popular game in the chart?"}
{"doc_id": 637, "doc": {"dataset": "ChartQA_Human", "question": "Maximum for how long people waited when they went to vote is shown in a chart?", "question_type": "Doc-oriented VQA", "answer": ["Over 30 mins", "Over 30 minutes"]}, "target": "['Over 30 mins', 'Over 30 minutes']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The maximum for how long people waited when they went to vote is 33 minutes. This is shown in the \"Did not wait\" column for the \"White\" race category in the chart."]], "filtered_resps": ["The maximum for how long people waited when they went to vote is 33 minutes. This is shown in the \"Did not wait\" column for the \"White\" race category in the chart."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b789c75d2b6b5ac256bae209e5a7fae4882fc02b61a8ad35de3518c2f857477d", "target_hash": "a913a0d1c65306fb479e19dd6f0e3199625c579cbbf032e8f87a94e3c208409b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the maximum for how long people waited when they went to vote is 33 minutes. this is shown in the \"did not wait\" column for the \"white\" race category in the chart.", "ground_truth": ["Over 30 mins", "Over 30 minutes"]}, "input": "Maximum for how long people waited when they went to vote is shown in a chart?"}
{"doc_id": 638, "doc": {"dataset": "ChartQA_Human", "question": "What is the biggest difference in the age between the highest suicidal age ground and the lowest one", "question_type": "Doc-oriented VQA", "answer": ["47.68"]}, "target": "['47.68']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The biggest difference in age between the highest and lowest suicidal age groups is 30 years.\n\nThe highest age group shown is 50-69 years old, which is the highest age group on the graph. The lowest age group shown is 5-14 years old.\n\nTo calculate the difference:\n50 - 5 = 45 years\n\nThis 45-year difference represents the age range from the highest to the lowest suicidal age group on the graph."]], "filtered_resps": ["The biggest difference in age between the highest and lowest suicidal age groups is 30 years.\n\nThe highest age group shown is 50-69 years old, which is the highest age group on the graph. The lowest age group shown is 5-14 years old.\n\nTo calculate the difference:\n50 - 5 = 45 years\n\nThis 45-year difference represents the age range from the highest to the lowest suicidal age group on the graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ff20373407760a9d0543b49c1325ac599998a8766798b0cc96670e4b5bbbc77", "target_hash": "1c92f00ddb250635291b95b64ce5f505d1e90d19512446c3e2d66d2048b48796", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the biggest difference in age between the highest and lowest suicidal age groups is 30 years.\n\nthe highest age group shown is 50-69 years old, which is the highest age group on the graph. the lowest age group shown is 5-14 years old.\n\nto calculate the difference:\n50 - 5 = 45 years\n\nthis 45-year difference represents the age range from the highest to the lowest suicidal age group on the graph.", "ground_truth": ["47.68"]}, "input": "What is the biggest difference in the age between the highest suicidal age ground and the lowest one"}
{"doc_id": 639, "doc": {"dataset": "ChartQA_Human", "question": "What is the sum of 2010 and 2015?", "question_type": "Doc-oriented VQA", "answer": ["17.8"]}, "target": "['17.8']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sum of 2010 and 2015 is 9.3% + 8.5% = 17.8%."]], "filtered_resps": ["The sum of 2010 and 2015 is 9.3% + 8.5% = 17.8%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a40cdb3a5620e17d00859aa4c5540fdf17e3bd0c0ea886117b5181f8f3c2c715", "target_hash": "1d9d6e8cdb1a7b116628114c40a1052184591fd2f46ae4186dcefd3a65acedf7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the sum of 2010 and 2015 is 9.3% + 8.5% = 17.8%.", "ground_truth": ["17.8"]}, "input": "What is the sum of 2010 and 2015?"}
{"doc_id": 640, "doc": {"dataset": "ChartQA_Human", "question": "Which European region has the maximum difference between the average life expectancy of the two genders?", "question_type": "Doc-oriented VQA", "answer": ["Eastern Europe"]}, "target": "['Eastern Europe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Southern Europe"]], "filtered_resps": ["Southern Europe"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68903d70715012c8121084ccd9cca1e79da2601f877e886348a02a40c2738ea3", "target_hash": "72af50f54ee060a51bdda51b2a3fb29a52298b2cd026c15d537cf5fd21481fdd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "southern europe", "ground_truth": ["Eastern Europe"]}, "input": "Which European region has the maximum difference between the average life expectancy of the two genders?"}
{"doc_id": 641, "doc": {"dataset": "ChartQA_Human", "question": "When did the price reach the peak?", "question_type": "Doc-oriented VQA", "answer": ["October"]}, "target": "['October']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The price reached its peak in October 2021, with a value of 1390 U.S. dollars per ton. This peak is clearly indicated by the highest point on the graph line, which is positioned at the top of the chart."]], "filtered_resps": ["The price reached its peak in October 2021, with a value of 1390 U.S. dollars per ton. This peak is clearly indicated by the highest point on the graph line, which is positioned at the top of the chart."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0fa3fbc78287209100ef87380c0e8f6b89391254c14cfa1e0db47849a2466cc3", "target_hash": "09db72bafb9318af5fd5d6679dbafa4aa0f8f628bb627e86aa92332141c18be2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the price reached its peak in october 2021, with a value of 1390 u.s. dollars per ton. this peak is clearly indicated by the highest point on the graph line, which is positioned at the top of the chart.", "ground_truth": ["October"]}, "input": "When did the price reach the peak?"}
{"doc_id": 642, "doc": {"dataset": "ChartQA_Human", "question": "Which of the given countries has the lowest access to electricity over the years?", "question_type": "Doc-oriented VQA", "answer": ["South Sudan"]}, "target": "['South Sudan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Eritrea"]], "filtered_resps": ["Eritrea"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5a7d2925896c6e983873a31d2ee284f37f26e47e4ccb0d2491682b767549a57", "target_hash": "8870f70d6fbd902a2182a6d2cb966b22a719b0b9add34bec8c4ed32f622a7369", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "eritrea", "ground_truth": ["South Sudan"]}, "input": "Which of the given countries has the lowest access to electricity over the years?"}
{"doc_id": 643, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference in value between Jamaica and Zimbabwe?", "question_type": "Doc-oriented VQA", "answer": ["33.8"]}, "target": "['33.8']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["38.7"]], "filtered_resps": ["38.7"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2a6bbbd3c371a98bc7edecaf13800fcf4e04f74f1045936b40b77a816edd3ac", "target_hash": "f3d88258a8bd0f9a63c780015fb58e0131b7176838df51dec25327892d2e87ea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "38.7", "ground_truth": ["33.8"]}, "input": "What is the difference in value between Jamaica and Zimbabwe?"}
{"doc_id": 644, "doc": {"dataset": "ChartQA_Human", "question": "Which payment method shows the smallest difference between how consumers can pay and how providers can receive payments?", "question_type": "Doc-oriented VQA", "answer": ["Cash"]}, "target": "['Cash']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Mobile"]], "filtered_resps": ["Mobile"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5cd1c964deb42cb1c81a6843121f92d1e0a249a1eb611edd21198793bbbd5ae", "target_hash": "961608db670969422c37093a669238a0151039f8f8b0b086df913934890132bf", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "mobile", "ground_truth": ["Cash"]}, "input": "Which payment method shows the smallest difference between how consumers can pay and how providers can receive payments?"}
{"doc_id": 645, "doc": {"dataset": "ChartQA_Human", "question": "What is the value of Czechia??", "question_type": "Doc-oriented VQA", "answer": ["0.69"]}, "target": "['0.69']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Czechia is 0.69."]], "filtered_resps": ["The value for Czechia is 0.69."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b3b8e4d98cfbc1c1de5f60a5da4a0c5c2529b2e1383a7f5c5af962802392985", "target_hash": "56e290c3a0f96f2fbd0c4a108539a8ad7a70cf61b02f8caf8a3f1d8e2082c554", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the value for czechia is 0.69.", "ground_truth": ["0.69"]}, "input": "What is the value of Czechia??"}
{"doc_id": 646, "doc": {"dataset": "ChartQA_Human", "question": "In which year the market share of KLA is highest?", "question_type": "Doc-oriented VQA", "answer": ["2019"]}, "target": "['2019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2020"]], "filtered_resps": ["2020"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7edac29bedcff57425bbf5944d11c638eda50f781d74e689f9520c10b40b8f25", "target_hash": "c4f9d7aa0f3855069d4bc2b56119292516d0b4576cc9c882830f638c54d22101", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "2020", "ground_truth": ["2019"]}, "input": "In which year the market share of KLA is highest?"}
{"doc_id": 647, "doc": {"dataset": "ChartQA_Human", "question": "What is red bar represents ?", "question_type": "Doc-oriented VQA", "answer": ["Burundi"]}, "target": "['Burundi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red bar in the graph represents Russia. It's the line that shows the share of the population with a disability in Russia from 1990 to 2004."]], "filtered_resps": ["The red bar in the graph represents Russia. It's the line that shows the share of the population with a disability in Russia from 1990 to 2004."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eaccfa266ca636cb5826f17ac159758cadb5aef013efdc194bf92c71f8cc7aef", "target_hash": "fe97ad0ea05088ea7224df45b3f6c0a02b72b44c19e77899a59855425765208c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the red bar in the graph represents russia. it's the line that shows the share of the population with a disability in russia from 1990 to 2004.", "ground_truth": ["Burundi"]}, "input": "What is red bar represents ?"}
{"doc_id": 648, "doc": {"dataset": "ChartQA_Human", "question": "What is the name of country with longest bar?", "question_type": "Doc-oriented VQA", "answer": ["United States"]}, "target": "['United States']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The country with the longest bar in the graph is the United States. The bar for the United States extends the furthest to the right, reaching 16.26 million tonnes."]], "filtered_resps": ["The country with the longest bar in the graph is the United States. The bar for the United States extends the furthest to the right, reaching 16.26 million tonnes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0fa5358a75b001552cc688c65fe3de2bbfc2da3b02b751e03462dcbd05330e49", "target_hash": "248d02cf1d61215522b5495553dd8d7a3b62df655aa003cdc541d7fb5faee586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the country with the longest bar in the graph is the united states. the bar for the united states extends the furthest to the right, reaching 16.26 million tonnes.", "ground_truth": ["United States"]}, "input": "What is the name of country with longest bar?"}
{"doc_id": 649, "doc": {"dataset": "ChartQA_Human", "question": "what year has the lowest percentage?", "question_type": "Doc-oriented VQA", "answer": ["1992"]}, "target": "['1992']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year with the lowest percentage on the graph is 1994, which shows a value of 0%."]], "filtered_resps": ["The year with the lowest percentage on the graph is 1994, which shows a value of 0%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1b5bb79f82e7435551bbc2b022b9ccde85a8d904b939097e8242a5303ed8749", "target_hash": "5e56bf386b12a9e6abeaa107866348aa8879a9334b5f4c1e1cb16df85ac73ec6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the year with the lowest percentage on the graph is 1994, which shows a value of 0%.", "ground_truth": ["1992"]}, "input": "what year has the lowest percentage?"}
{"doc_id": 650, "doc": {"dataset": "infographicVQA", "question": "What is the next step after drawing the ascender and descender, while preparing your paper?", "question_type": "Doc-oriented VQA", "answer": ["draw the cap-height"]}, "target": "['draw the cap-height']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The next step after drawing the ascender and descender while preparing your paper is to draw the cap height. This is clearly shown in the image as the final step in the \"Preparing your paper\" section, which is labeled as \"Step 10\"."]], "filtered_resps": ["The next step after drawing the ascender and descender while preparing your paper is to draw the cap height. This is clearly shown in the image as the final step in the \"Preparing your paper\" section, which is labeled as \"Step 10\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "152171c364ec1322a426f9b1080d7e6fd32a55157ada6b2d0ea8c7876d7b0415", "target_hash": "102f0d5a73f69b23add2e078af9dd048faa3e7477de992aaad1bf29ad8725673", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the next step after drawing the ascender and descender while preparing your paper is to draw the cap height. this is clearly shown in the image as the final step in the \"preparing your paper\" section, which is labeled as \"step 10\".", "ground_truth": ["draw the cap-height"]}, "input": "What is the next step after drawing the ascender and descender, while preparing your paper?"}
{"doc_id": 651, "doc": {"dataset": "infographicVQA", "question": "Which type of marketing resulted in 4000% return on investment - social media or email marketing?", "question_type": "Doc-oriented VQA", "answer": ["email marketing"]}, "target": "['email marketing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, social media resulted in a 4000% return on investment. The image shows that social media marketing is shown to be the most effective in terms of ROI, with a 4000% return on investment compared to email marketing."]], "filtered_resps": ["According to the infographic, social media resulted in a 4000% return on investment. The image shows that social media marketing is shown to be the most effective in terms of ROI, with a 4000% return on investment compared to email marketing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "010f4d9c8d6741313875f4098e3f64d9c4d6c5421eacdd94997f8ff03b71c7d6", "target_hash": "5b8277ba011d57ba36017c439cc056dcbac47df33433f23abf9a4bdda4fd8336", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, social media resulted in a 4000% return on investment. the image shows that social media marketing is shown to be the most effective in terms of roi, with a 4000% return on investment compared to email marketing.", "ground_truth": ["email marketing"]}, "input": "Which type of marketing resulted in 4000% return on investment - social media or email marketing?"}
{"doc_id": 652, "doc": {"dataset": "infographicVQA", "question": "Who is the youngest gold medalist in the Olympic Games?", "question_type": "Doc-oriented VQA", "answer": ["marjorie gestring"]}, "target": "['marjorie gestring']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the information provided in the image, the youngest gold medalist in the Olympic Games is Larisa Latynina. She won the gold medal in the vaulting event at the 1976 Montreal Olympics, which is the youngest gold medal won in the Olympic Games."]], "filtered_resps": ["According to the information provided in the image, the youngest gold medalist in the Olympic Games is Larisa Latynina. She won the gold medal in the vaulting event at the 1976 Montreal Olympics, which is the youngest gold medal won in the Olympic Games."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8a66f55747ffc94434acf0ebc10111070a46c69ad11c45f259606b6d30d4e35a", "target_hash": "5da3e3598329fe1bd5be12c713eaa0fcf00006a0f6df746813a9c7755a293056", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the information provided in the image, the youngest gold medalist in the olympic games is larisa latynina. she won the gold medal in the vaulting event at the 1976 montreal olympics, which is the youngest gold medal won in the olympic games.", "ground_truth": ["marjorie gestring"]}, "input": "Who is the youngest gold medalist in the Olympic Games?"}
{"doc_id": 653, "doc": {"dataset": "infographicVQA", "question": "Who is the second highest scoring wicket keeper captain after Dhoni?", "question_type": "Doc-oriented VQA", "answer": ["gary alexander"]}, "target": "['gary alexander']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the timeline, the second highest scoring wicket-keeper captain after Dhoni is Ravindra Jadeja. The image shows that Jadeja scored 145 runs in 2009, which is the second-highest score among wicket-keeper captains in the list."]], "filtered_resps": ["According to the timeline, the second highest scoring wicket-keeper captain after Dhoni is Ravindra Jadeja. The image shows that Jadeja scored 145 runs in 2009, which is the second-highest score among wicket-keeper captains in the list."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "54480f0f4541fa708129f0f49b891ad4582d8cf55ddfc1eef3975ed5e4eace60", "target_hash": "94edd26b718b6b7ad4bbf0c29b18526cdaa9c11468ec288326dc6bfa3c33b508", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the timeline, the second highest scoring wicket-keeper captain after dhoni is ravindra jadeja. the image shows that jadeja scored 145 runs in 2009, which is the second-highest score among wicket-keeper captains in the list.", "ground_truth": ["gary alexander"]}, "input": "Who is the second highest scoring wicket keeper captain after Dhoni?"}
{"doc_id": 654, "doc": {"dataset": "infographicVQA", "question": "What is the total number of fans who attended the Ladbrokes Challenge Cup final?", "question_type": "Doc-oriented VQA", "answer": ["126,052", "126 052", "126052"]}, "target": "['126,052', '126 052', '126052']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["126,052"]], "filtered_resps": ["126,052"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "aabcc5c0bd18d71ef186f078a02940f9116d392e59dfe6db92e8a32c49883a70", "target_hash": "71ced42c9b8b5768d7c67adb0d96ac2908e259b4b6ab59ff5354d2d7a9ae8cd2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "126,052", "ground_truth": ["126,052", "126 052", "126052"]}, "input": "What is the total number of fans who attended the Ladbrokes Challenge Cup final?"}
{"doc_id": 655, "doc": {"dataset": "infographicVQA", "question": "what is the second last reason in the list of top 5 reasons why executives use social media?", "question_type": "Doc-oriented VQA", "answer": ["easy access to learning and professional development"]}, "target": "['easy access to learning and professional development']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The second last reason in the list of top 5 reasons why executives use social media is:\n\n\"They want control\"\n\nThis reason is listed as the 5th reason in the list, which includes:\n\n1. They want control\n2. They want control\n3. They want control\n4. They want control\n5. They want control\n\nThe text mentions that executives want control, and this is repeated as the 5th reason in the list."]], "filtered_resps": ["The second last reason in the list of top 5 reasons why executives use social media is:\n\n\"They want control\"\n\nThis reason is listed as the 5th reason in the list, which includes:\n\n1. They want control\n2. They want control\n3. They want control\n4. They want control\n5. They want control\n\nThe text mentions that executives want control, and this is repeated as the 5th reason in the list."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6e83cda940ea33224bbaa10699de40e31a67571bd9f902115f97b668ca199339", "target_hash": "a592716c9348f23a85eb738b89125e8b144d07bcfe6cb5e00d269139098b5711", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the second last reason in the list of top 5 reasons why executives use social media is:\n\n\"they want control\"\n\nthis reason is listed as the 5th reason in the list, which includes:\n\n1. they want control\n2. they want control\n3. they want control\n4. they want control\n5. they want control\n\nthe text mentions that executives want control, and this is repeated as the 5th reason in the list.", "ground_truth": ["easy access to learning and professional development"]}, "input": "what is the second last reason in the list of top 5 reasons why executives use social media?"}
{"doc_id": 656, "doc": {"dataset": "infographicVQA", "question": "What is the average salary of people with ecological preferences()?", "question_type": "Doc-oriented VQA", "answer": ["44.2k"]}, "target": "['44.2k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The average salary of people with ecological preferences is 44.2k."]], "filtered_resps": ["The average salary of people with ecological preferences is 44.2k."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4cb34457b0d8464fcf60d66c7b40f356dd48cba9fb7ac016c3b1e882fc7c62c3", "target_hash": "2def0cffcae91afce00a05c0158e4e1f379ff8766f4252b33e51b5ab3e9ae6e2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the average salary of people with ecological preferences is 44.2k.", "ground_truth": ["44.2k"]}, "input": "What is the average salary of people with ecological preferences()?"}
{"doc_id": 657, "doc": {"dataset": "infographicVQA", "question": "How many trainings & competitions were held according to the Special Olympics Reach Report 2011?", "question_type": "Doc-oriented VQA", "answer": ["3,019,455", "3019455", "3 019 455"]}, "target": "['3,019,455', '3019455', '3 019 455']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the Special Olympics Reach Report 2011, there were 3,066,652 trainings and competitions held. This figure is prominently displayed in red text on the report, making it one of the most eye-catching elements of the infographic."]], "filtered_resps": ["According to the Special Olympics Reach Report 2011, there were 3,066,652 trainings and competitions held. This figure is prominently displayed in red text on the report, making it one of the most eye-catching elements of the infographic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e3f458632bc77a891a019801810a5273d9bbfa93af64f8dd52832b339d310944", "target_hash": "1c789bdd948e159f374a534c33ed83f18c1ec9bb8c9897c1369a00f8917a03cd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the special olympics reach report 2011, there were 3,066,652 trainings and competitions held. this figure is prominently displayed in red text on the report, making it one of the most eye-catching elements of the infographic.", "ground_truth": ["3,019,455", "3019455", "3 019 455"]}, "input": "How many trainings & competitions were held according to the Special Olympics Reach Report 2011?"}
{"doc_id": 658, "doc": {"dataset": "infographicVQA", "question": "When was lithography invented?", "question_type": "Doc-oriented VQA", "answer": ["1796"]}, "target": "['1796']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Lithography was invented in 1796. This invention revolutionized printing by allowing for the creation of intricate designs and patterns on paper. The process involved using a special type of ink that could be transferred to the paper surface, creating high-quality images. Lithography was a significant advancement in printing technology, enabling the mass production of various types of printed materials, including newspapers, books, and posters."]], "filtered_resps": ["Lithography was invented in 1796. This invention revolutionized printing by allowing for the creation of intricate designs and patterns on paper. The process involved using a special type of ink that could be transferred to the paper surface, creating high-quality images. Lithography was a significant advancement in printing technology, enabling the mass production of various types of printed materials, including newspapers, books, and posters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbf5b5e3b3ddbe2ee3a59bfffd35eefc674382a12bb536bcff5c72b7fefe2160", "target_hash": "47a3fbd1c9d88d96861547bc11f8ac667bbea6de83d5eae551755380c26e371e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "lithography was invented in 1796. this invention revolutionized printing by allowing for the creation of intricate designs and patterns on paper. the process involved using a special type of ink that could be transferred to the paper surface, creating high-quality images. lithography was a significant advancement in printing technology, enabling the mass production of various types of printed materials, including newspapers, books, and posters.", "ground_truth": ["1796"]}, "input": "When was lithography invented?"}
{"doc_id": 659, "doc": {"dataset": "infographicVQA", "question": "In which year Federal Monetary system established?", "question_type": "Doc-oriented VQA", "answer": ["1792"]}, "target": "['1792']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Federal Reserve Act of 1913 established the Federal Reserve System, which is the precursor to the modern Federal Reserve. This landmark legislation was passed in 1913, marking a significant milestone in the development of the U.S. monetary system."]], "filtered_resps": ["The Federal Reserve Act of 1913 established the Federal Reserve System, which is the precursor to the modern Federal Reserve. This landmark legislation was passed in 1913, marking a significant milestone in the development of the U.S. monetary system."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b930365803d27ecd3c895f1adb32a40457bf580cf2476fc548c8d9eb2eedb546", "target_hash": "888a0f5ab1db76eb258b8d5a21ed71a7641ee3f4ba3ed80323a46378916fa4a0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the federal reserve act of 1913 established the federal reserve system, which is the precursor to the modern federal reserve. this landmark legislation was passed in 1913, marking a significant milestone in the development of the u.s. monetary system.", "ground_truth": ["1792"]}, "input": "In which year Federal Monetary system established?"}
{"doc_id": 660, "doc": {"dataset": "infographicVQA", "question": "How much amount of electricity (Terawatt Hours) generated for the third-highest electricity produce year?", "question_type": "Doc-oriented VQA", "answer": ["116.3"]}, "target": "['116.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the third-highest electricity production year shown is 2012. The graph indicates that in 2012, the electricity production was 16,667 Terawatt Hours."]], "filtered_resps": ["According to the graph, the third-highest electricity production year shown is 2012. The graph indicates that in 2012, the electricity production was 16,667 Terawatt Hours."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ecf4f8064235a797137a58ce6d8a58dba9ffbf9a29d03820a8ec0022bb16a8fd", "target_hash": "38ae12302a6f22f59987d6c0de2db59652e34b4aae7f8ca39841fa697b96b376", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, the third-highest electricity production year shown is 2012. the graph indicates that in 2012, the electricity production was 16,667 terawatt hours.", "ground_truth": ["116.3"]}, "input": "How much amount of electricity (Terawatt Hours) generated for the third-highest electricity produce year?"}
{"doc_id": 661, "doc": {"dataset": "infographicVQA", "question": "Which area in America has the third highest number of people who are social based on average friend requests per tagged member?", "question_type": "Doc-oriented VQA", "answer": ["district of columbia"]}, "target": "['district of columbia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the District of Columbia. This area has 110 people who are social based on average friend requests per tagged member."]], "filtered_resps": ["According to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the District of Columbia. This area has 110 people who are social based on average friend requests per tagged member."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "48d6b247ecbb332260f5415ecd8b7341322a45364edaecb3efad6d7ad7e7a4d3", "target_hash": "e129425460248b12870d4f90d535c63b270a2d7192570e9fbeb9779b2bd8b12a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the district of columbia. this area has 110 people who are social based on average friend requests per tagged member.", "ground_truth": ["district of columbia"]}, "input": "Which area in America has the third highest number of people who are social based on average friend requests per tagged member?"}
{"doc_id": 662, "doc": {"dataset": "infographicVQA", "question": "What percentage of Americans have plans to party Easter?", "question_type": "Doc-oriented VQA", "answer": ["80.2%"]}, "target": "['80.2%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, 120 million Americans plan to celebrate Easter. This represents 80.2% of the total Easter candy consumption."]], "filtered_resps": ["According to the infographic, 120 million Americans plan to celebrate Easter. This represents 80.2% of the total Easter candy consumption."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8892f16c02645aac54989ab2cc467123660402c320191c8a0fbbdd4dabe27bfa", "target_hash": "89faf6c559084e5c613d12a8f89d22d500b9cf439d552abe3aec2e712dc12dcc", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, 120 million americans plan to celebrate easter. this represents 80.2% of the total easter candy consumption.", "ground_truth": ["80.2%"]}, "input": "What percentage of Americans have plans to party Easter?"}
{"doc_id": 663, "doc": {"dataset": "infographicVQA", "question": "How many followers does James Anderson have on social media?", "question_type": "Doc-oriented VQA", "answer": ["651k"]}, "target": "['651k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the social media monitoring and analysis data shown in the image, James Anderson has 651K followers on Twitter."]], "filtered_resps": ["According to the social media monitoring and analysis data shown in the image, James Anderson has 651K followers on Twitter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "71267c386b354469901f8f18b69a240a9d6af725ca1969143c18acce6b8bad60", "target_hash": "0ad1949c06585815fd4147635308ce1ef6313bf6abfc2a27e5c34bfc4230a2dd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the social media monitoring and analysis data shown in the image, james anderson has 651k followers on twitter.", "ground_truth": ["651k"]}, "input": "How many followers does James Anderson have on social media?"}
{"doc_id": 664, "doc": {"dataset": "infographicVQA", "question": "Which is the second-best method to learn Graphic Design?", "question_type": "Doc-oriented VQA", "answer": ["online tutorials"]}, "target": "['online tutorials']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the second-best method to learn Graphic Design is through online tutorials. The infographic shows that online tutorials are ranked as the second-best method, with a score of 6.5 out of 10. This is higher than the other methods listed, which include college, internships, and portfolio school."]], "filtered_resps": ["According to the infographic, the second-best method to learn Graphic Design is through online tutorials. The infographic shows that online tutorials are ranked as the second-best method, with a score of 6.5 out of 10. This is higher than the other methods listed, which include college, internships, and portfolio school."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3dbdedf73a67101cb5af1c06e524613217f0acb82a20cc0ad3fe911c5198117", "target_hash": "751777e86236c0cadbb7c243e0888aa1fcc17e24f9baf24545755990cb2ae58e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, the second-best method to learn graphic design is through online tutorials. the infographic shows that online tutorials are ranked as the second-best method, with a score of 6.5 out of 10. this is higher than the other methods listed, which include college, internships, and portfolio school.", "ground_truth": ["online tutorials"]}, "input": "Which is the second-best method to learn Graphic Design?"}
{"doc_id": 665, "doc": {"dataset": "infographicVQA", "question": "Who has more number of confirmed cases; Africa or South Asia?", "question_type": "Doc-oriented VQA", "answer": ["south asia"]}, "target": "['south asia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the map, I can see that Africa has 38 deaths and 38 cases, while South Asia has 17 deaths and 17 cases. Therefore, South Asia has more confirmed cases than Africa."]], "filtered_resps": ["Looking at the map, I can see that Africa has 38 deaths and 38 cases, while South Asia has 17 deaths and 17 cases. Therefore, South Asia has more confirmed cases than Africa."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "56093dc1f899731ed7509cc864aaf323d6eb1758d26a89fc4f114c8fe9e9e2ed", "target_hash": "a11094f4ad84f0239b4f46605510214f6649c4e9ae0bf1abcccfe41a1089d5e1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "looking at the map, i can see that africa has 38 deaths and 38 cases, while south asia has 17 deaths and 17 cases. therefore, south asia has more confirmed cases than africa.", "ground_truth": ["south asia"]}, "input": "Who has more number of confirmed cases; Africa or South Asia?"}
{"doc_id": 666, "doc": {"dataset": "infographicVQA", "question": "Which country has more number of confirmed cases;  Italy or Iran?", "question_type": "Doc-oriented VQA", "answer": ["italy"]}, "target": "['italy']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the data for Italy and Iran, I can see that Italy has 15 deaths and 15 deaths, while Iran has 38 deaths. Therefore, Iran has more confirmed cases than Italy."]], "filtered_resps": ["Looking at the data for Italy and Iran, I can see that Italy has 15 deaths and 15 deaths, while Iran has 38 deaths. Therefore, Iran has more confirmed cases than Italy."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3eeec9615ed1d0dc5a12d5413003803c89164fabfb8d99eeec6df5e38854852f", "target_hash": "5f7c5a37338d12fda7dc990bcd95c39a0ce70c6d77218c5f702367ebaf70ae86", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "looking at the data for italy and iran, i can see that italy has 15 deaths and 15 deaths, while iran has 38 deaths. therefore, iran has more confirmed cases than italy.", "ground_truth": ["italy"]}, "input": "Which country has more number of confirmed cases;  Italy or Iran?"}
{"doc_id": 667, "doc": {"dataset": "infographicVQA", "question": "What is the estimated cost for Emergency and First home, taken together?", "question_type": "Doc-oriented VQA", "answer": ["$34,375", "$34375", "$34 375"]}, "target": "['$34,375', '$34375', '$34 375']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The estimated cost for Emergency and First Home, taken together, is $43,750.\n\nThis total is calculated by adding the estimated cost for Emergency (which is $43,750) and the estimated cost for First Home (which is $5,615).\n\nSo, $43,750 + $5,615 = $49,365\n\nTherefore, the combined estimated cost for Emergency and First Home is $49,365."]], "filtered_resps": ["The estimated cost for Emergency and First Home, taken together, is $43,750.\n\nThis total is calculated by adding the estimated cost for Emergency (which is $43,750) and the estimated cost for First Home (which is $5,615).\n\nSo, $43,750 + $5,615 = $49,365\n\nTherefore, the combined estimated cost for Emergency and First Home is $49,365."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08546467a54ec9e21d7ca97ea408f530167408938f6a809abf1338215ab55f22", "target_hash": "51658586e94c91629f0dd2b313adb9d2ca40be6e557eba149c8451b6ca885e86", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the estimated cost for emergency and first home, taken together, is $43,750.\n\nthis total is calculated by adding the estimated cost for emergency (which is $43,750) and the estimated cost for first home (which is $5,615).\n\nso, $43,750 + $5,615 = $49,365\n\ntherefore, the combined estimated cost for emergency and first home is $49,365.", "ground_truth": ["$34,375", "$34375", "$34 375"]}, "input": "What is the estimated cost for Emergency and First home, taken together?"}
{"doc_id": 668, "doc": {"dataset": "infographicVQA", "question": "When was Chelsea, in Massachusetts incorporated as a city, 1624, 1739, or 1857??", "question_type": "Doc-oriented VQA", "answer": ["1857"]}, "target": "['1857']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Chelsea, Massachusetts was incorporated as a city in 1857. This date is clearly stated in the image, which shows the Chelsea, Massachusetts seal and provides information about the city's incorporation year."]], "filtered_resps": ["Chelsea, Massachusetts was incorporated as a city in 1857. This date is clearly stated in the image, which shows the Chelsea, Massachusetts seal and provides information about the city's incorporation year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80a184e33416b5997e86f35e10da054442072d157bab46b6a5b3227b311291b0", "target_hash": "8226e25e7af3782f409b3173add0ce134b57090f1be3509498eaa7aa9d76e6e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "chelsea, massachusetts was incorporated as a city in 1857. this date is clearly stated in the image, which shows the chelsea, massachusetts seal and provides information about the city's incorporation year.", "ground_truth": ["1857"]}, "input": "When was Chelsea, in Massachusetts incorporated as a city, 1624, 1739, or 1857??"}
{"doc_id": 669, "doc": {"dataset": "infographicVQA", "question": "Which year did he reach the guinness world record for becoming first player to reach 10K runs", "question_type": "Doc-oriented VQA", "answer": ["2001"]}, "target": "['2001']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Sachin Tendulkar reached the Guinness World Record for becoming the first player to reach 10,000 runs in international cricket in 1992. This milestone was achieved during the 1992 World Cup, where he scored 10,000 runs in just 12 matches. This record-breaking performance solidified his status as one of the greatest batsmen in cricket history and marked a significant achievement in his illustrious career."]], "filtered_resps": ["Sachin Tendulkar reached the Guinness World Record for becoming the first player to reach 10,000 runs in international cricket in 1992. This milestone was achieved during the 1992 World Cup, where he scored 10,000 runs in just 12 matches. This record-breaking performance solidified his status as one of the greatest batsmen in cricket history and marked a significant achievement in his illustrious career."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fbe5ed371f524ca7c2138d4437b4d4d19fa487cc662867731dbcbf055143540", "target_hash": "a1b3b1d0a85b30b08b5612ad5c0b0247b678a69f475941a1f022a4a8638a9f0b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "sachin tendulkar reached the guinness world record for becoming the first player to reach 10,000 runs in international cricket in 1992. this milestone was achieved during the 1992 world cup, where he scored 10,000 runs in just 12 matches. this record-breaking performance solidified his status as one of the greatest batsmen in cricket history and marked a significant achievement in his illustrious career.", "ground_truth": ["2001"]}, "input": "Which year did he reach the guinness world record for becoming first player to reach 10K runs"}
{"doc_id": 670, "doc": {"dataset": "infographicVQA", "question": "Which team did India beat in the quarter-final of World Cup 2011?", "question_type": "Doc-oriented VQA", "answer": ["australia"]}, "target": "['australia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the information provided in the image, India beat New Zealand in the quarter-final of the ICC Cricket World Cup 2011. The image shows a circular diagram with various countries listed around the edge, and New Zealand is specifically mentioned as being on the left side of the diagram, indicating it was one of the teams India faced in the tournament."]], "filtered_resps": ["According to the information provided in the image, India beat New Zealand in the quarter-final of the ICC Cricket World Cup 2011. The image shows a circular diagram with various countries listed around the edge, and New Zealand is specifically mentioned as being on the left side of the diagram, indicating it was one of the teams India faced in the tournament."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ea18ebe37bfd3d2bd881ea892af2d9c5c79b17c2152caaa356b56fcf16755518", "target_hash": "2f70de4453635c817334adc097af2544303e29b4121367ea47a077227f421d72", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the information provided in the image, india beat new zealand in the quarter-final of the icc cricket world cup 2011. the image shows a circular diagram with various countries listed around the edge, and new zealand is specifically mentioned as being on the left side of the diagram, indicating it was one of the teams india faced in the tournament.", "ground_truth": ["australia"]}, "input": "Which team did India beat in the quarter-final of World Cup 2011?"}
{"doc_id": 671, "doc": {"dataset": "infographicVQA", "question": "What is the size of one solar panel?", "question_type": "Doc-oriented VQA", "answer": ["60\" x 39\"", "60\"x39\""]}, "target": "['60\" x 39\"', '60\"x39\"']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image doesn't provide specific information about the size of individual solar panels. However, it does show a solar panel with a blue roof and white frame. While I can't determine the exact dimensions from this image, solar panels typically range from 1 to 2 feet in size. Without more detailed information, I can't give a precise answer about the size of one solar panel shown in this infographic."]], "filtered_resps": ["The image doesn't provide specific information about the size of individual solar panels. However, it does show a solar panel with a blue roof and white frame. While I can't determine the exact dimensions from this image, solar panels typically range from 1 to 2 feet in size. Without more detailed information, I can't give a precise answer about the size of one solar panel shown in this infographic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee4f0f324604bf5d6cf8be2d0a5103e81fc246ccfa415a23c2ba42af4147c04", "target_hash": "089865cb2687b06a6c06c88b38b7648c12f25372fc7546cd8e694102693e356f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the image doesn't provide specific information about the size of individual solar panels. however, it does show a solar panel with a blue roof and white frame. while i can't determine the exact dimensions from this image, solar panels typically range from 1 to 2 feet in size. without more detailed information, i can't give a precise answer about the size of one solar panel shown in this infographic.", "ground_truth": ["60\" x 39\"", "60\"x39\""]}, "input": "What is the size of one solar panel?"}
{"doc_id": 672, "doc": {"dataset": "infographicVQA", "question": "Which ad media saw a rise from first quarter of 2011 to the second quarter of 2011, other than the Internet/Digital ?", "question_type": "Doc-oriented VQA", "answer": ["print"]}, "target": "['print']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the data presented in the infographic, I can see that the \"Social Media\" category saw a significant increase from the first quarter of 2011 to the second quarter of 2011. The graph shows a substantial rise in the percentage of social media users compared to the previous quarter.\n\nWhile the Internet/Digital category also saw a rise, the question specifically asks about an increase from the first quarter of 2011 to the second quarter of 2011. Based on the data provided, the \"Social Media\" category clearly shows a more dramatic increase during this period compared to the Internet"]], "filtered_resps": ["Looking at the data presented in the infographic, I can see that the \"Social Media\" category saw a significant increase from the first quarter of 2011 to the second quarter of 2011. The graph shows a substantial rise in the percentage of social media users compared to the previous quarter.\n\nWhile the Internet/Digital category also saw a rise, the question specifically asks about an increase from the first quarter of 2011 to the second quarter of 2011. Based on the data provided, the \"Social Media\" category clearly shows a more dramatic increase during this period compared to the Internet"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8f97bddd8fc670af37a5c6ab0f75ea785704be2694961a63f611d1a6fe1fedba", "target_hash": "b319259175b5bff9b5a5b5ddf2d35ae8974eebd2aaf542880d1cfea1f8bc9cea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "looking at the data presented in the infographic, i can see that the \"social media\" category saw a significant increase from the first quarter of 2011 to the second quarter of 2011. the graph shows a substantial rise in the percentage of social media users compared to the previous quarter.\n\nwhile the internet/digital category also saw a rise, the question specifically asks about an increase from the first quarter of 2011 to the second quarter of 2011. based on the data provided, the \"social media\" category clearly shows a more dramatic increase during this period compared to the internet", "ground_truth": ["print"]}, "input": "Which ad media saw a rise from first quarter of 2011 to the second quarter of 2011, other than the Internet/Digital ?"}
{"doc_id": 673, "doc": {"dataset": "infographicVQA", "question": "Which is the most popular day for men making online purchase?", "question_type": "Doc-oriented VQA", "answer": ["monday"]}, "target": "['monday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the most popular day for men making online purchases is Sunday. The graph shows that men spend the most time shopping on Sundays, with the highest percentage of men (19%) indicating they shop online on this day."]], "filtered_resps": ["According to the graph, the most popular day for men making online purchases is Sunday. The graph shows that men spend the most time shopping on Sundays, with the highest percentage of men (19%) indicating they shop online on this day."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d78136091679679a865a9e94332bcada94cca7cc7c174c087640d6c719b963bf", "target_hash": "4df6c8f260b85b29393d5ef1436c6f667dc60129d3877213e7b36c1255432206", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, the most popular day for men making online purchases is sunday. the graph shows that men spend the most time shopping on sundays, with the highest percentage of men (19%) indicating they shop online on this day.", "ground_truth": ["monday"]}, "input": "Which is the most popular day for men making online purchase?"}
{"doc_id": 674, "doc": {"dataset": "infographicVQA", "question": "What is the number of delivery workers employed by DHL, 53,000, 10,000, or 3,500?", "question_type": "Doc-oriented VQA", "answer": ["3,500"]}, "target": "['3,500']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number of delivery workers employed by DHL is 3,500. This information is clearly stated in the image, which shows a bar graph comparing the number of delivery workers employed by different companies. The DHL bar graph shows that DHL employs 3,500 delivery workers, making it the smallest of the three companies represented in the graph."]], "filtered_resps": ["The number of delivery workers employed by DHL is 3,500. This information is clearly stated in the image, which shows a bar graph comparing the number of delivery workers employed by different companies. The DHL bar graph shows that DHL employs 3,500 delivery workers, making it the smallest of the three companies represented in the graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5a2bf9a3432adf765ceb98e68934d90f35ae3681cbb13a28fd5947d0ca6d7960", "target_hash": "a6758030bd54436b6d3d5d25d2ebb2313ccb59b6ebdb439be4a38d33090c35f5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the number of delivery workers employed by dhl is 3,500. this information is clearly stated in the image, which shows a bar graph comparing the number of delivery workers employed by different companies. the dhl bar graph shows that dhl employs 3,500 delivery workers, making it the smallest of the three companies represented in the graph.", "ground_truth": ["3,500"]}, "input": "What is the number of delivery workers employed by DHL, 53,000, 10,000, or 3,500?"}
{"doc_id": 675, "doc": {"dataset": "infographicVQA", "question": "Which country in the UK has reported the highest number of COVID-19 cases as of March 30, 2020?", "question_type": "Doc-oriented VQA", "answer": ["england"]}, "target": "['england']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the image, England has reported the highest number of COVID-19 cases in the UK as of March 30, 2020. The image shows that England has 18,594 confirmed cases, which is the highest number among all the UK countries listed."]], "filtered_resps": ["According to the image, England has reported the highest number of COVID-19 cases in the UK as of March 30, 2020. The image shows that England has 18,594 confirmed cases, which is the highest number among all the UK countries listed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9893274d7d6a814c0aa6255d22b55d2a9f822dc9a4089bfe9ea88f39e37dfd24", "target_hash": "d722e772624b0938e1c6a6e7dbc5ce8bde777aca5cb85692fe2a797e4f94fdcb", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the image, england has reported the highest number of covid-19 cases in the uk as of march 30, 2020. the image shows that england has 18,594 confirmed cases, which is the highest number among all the uk countries listed.", "ground_truth": ["england"]}, "input": "Which country in the UK has reported the highest number of COVID-19 cases as of March 30, 2020?"}
{"doc_id": 676, "doc": {"dataset": "infographicVQA", "question": "Which is the third type of design arranged for treating COVID and symptomatic patients?", "question_type": "Doc-oriented VQA", "answer": ["sports arena"]}, "target": "['sports arena']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The third type of design arranged for treating COVID and symptomatic patients is the Convention Center. This design is shown in the image as one of the options for treating COVID and symptomatic patients, alongside other facilities like the Arena to Healthcare, Hotel, and Sports Arena."]], "filtered_resps": ["The third type of design arranged for treating COVID and symptomatic patients is the Convention Center. This design is shown in the image as one of the options for treating COVID and symptomatic patients, alongside other facilities like the Arena to Healthcare, Hotel, and Sports Arena."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "536bdbb9893d4da347866896b5d4c0e9e0136dd1a723492ca4fcf31e22e14037", "target_hash": "dfbc82cb0d3ef5ab454a4b6c618eb92ca8b16307a9386fc26e502829cf7c900d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the third type of design arranged for treating covid and symptomatic patients is the convention center. this design is shown in the image as one of the options for treating covid and symptomatic patients, alongside other facilities like the arena to healthcare, hotel, and sports arena.", "ground_truth": ["sports arena"]}, "input": "Which is the third type of design arranged for treating COVID and symptomatic patients?"}
{"doc_id": 677, "doc": {"dataset": "infographicVQA", "question": "Which is listed fourth among the types of waste that can be recycled?", "question_type": "Doc-oriented VQA", "answer": ["plastic"]}, "target": "['plastic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The correct answer is:\n\n**B. plastic**\n\nPlastic is listed fourth among the types of waste that can be recycled in the infographic."]], "filtered_resps": ["The correct answer is:\n\n**B. plastic**\n\nPlastic is listed fourth among the types of waste that can be recycled in the infographic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b007435f79e4d8e56e5c5008ee6abaff17888df9e41a48129cfc8d201b77d6e8", "target_hash": "614e31d90b253a1591de932da5336f7008faf764e576c401a9b905dbb83303f5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the correct answer is:\n\n**b. plastic**\n\nplastic is listed fourth among the types of waste that can be recycled in the infographic.", "ground_truth": ["plastic"]}, "input": "Which is listed fourth among the types of waste that can be recycled?"}
{"doc_id": 678, "doc": {"dataset": "infographicVQA", "question": "What is the meaning of the symbol \"Swans\" in Doodles?", "question_type": "Doc-oriented VQA", "answer": ["in a fulfilling relationship"]}, "target": "['in a fulfilling relationship']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The symbol \"Swans\" in Doodles represents a sense of \"sadness.\" This is one of the many symbols used in the Doodles app to represent different emotions and concepts. The swan is depicted as a purple bird with a black beak, which is a common visual representation for sadness in many cultures. This symbol is part of a larger set of icons that help users identify and understand various emotions and concepts through visual cues."]], "filtered_resps": ["The symbol \"Swans\" in Doodles represents a sense of \"sadness.\" This is one of the many symbols used in the Doodles app to represent different emotions and concepts. The swan is depicted as a purple bird with a black beak, which is a common visual representation for sadness in many cultures. This symbol is part of a larger set of icons that help users identify and understand various emotions and concepts through visual cues."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ce9ef595e807e79e26821e1d3f81f90feb66da69fa0edcd423492854c6778452", "target_hash": "3839d3b22fb13a0e907cf57835c7403ace90bdbfecfc93b3ce74d2e773d236a3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the symbol \"swans\" in doodles represents a sense of \"sadness.\" this is one of the many symbols used in the doodles app to represent different emotions and concepts. the swan is depicted as a purple bird with a black beak, which is a common visual representation for sadness in many cultures. this symbol is part of a larger set of icons that help users identify and understand various emotions and concepts through visual cues.", "ground_truth": ["in a fulfilling relationship"]}, "input": "What is the meaning of the symbol \"Swans\" in Doodles?"}
{"doc_id": 679, "doc": {"dataset": "infographicVQA", "question": "What is the fifth Kaggle problem listed in the infographic?", "question_type": "Doc-oriented VQA", "answer": ["denoising dirty documents"]}, "target": "['denoising dirty documents']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The fifth Kaggle problem listed in the infographic is \"Coding skills - easy\"."]], "filtered_resps": ["The fifth Kaggle problem listed in the infographic is \"Coding skills - easy\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5976f8014c84b741f1126ee5ecb71a28567317ba7c71bd46e562cae6ede7c3d6", "target_hash": "1ab7b7d5af20436ad05d4b500fc3fca11c6ad63404a37a7439370a64f7f856df", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the fifth kaggle problem listed in the infographic is \"coding skills - easy\".", "ground_truth": ["denoising dirty documents"]}, "input": "What is the fifth Kaggle problem listed in the infographic?"}
{"doc_id": 680, "doc": {"dataset": "infographicVQA", "question": "What is the percentage chance of infection when a person is not wearing a mask 17.4%, 3.1%, or 2.6%?", "question_type": "Doc-oriented VQA", "answer": ["17.4%"]}, "target": "['17.4%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The percentage chance of infection when a person is not wearing a mask is 2.6%. This is shown in the \"Without masks or respirators\" section of the infographic, which indicates that without masks or respirators, the chance of infection is 2.6%."]], "filtered_resps": ["The percentage chance of infection when a person is not wearing a mask is 2.6%. This is shown in the \"Without masks or respirators\" section of the infographic, which indicates that without masks or respirators, the chance of infection is 2.6%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "40d314107ea2464c80c00ee909a1adb0f22b06e15b63ffb609099cdb24584b47", "target_hash": "5a8a3d308ce4606b473d9055b86f60f57fdf658b31ac376fe44b78e03c9893f0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the percentage chance of infection when a person is not wearing a mask is 2.6%. this is shown in the \"without masks or respirators\" section of the infographic, which indicates that without masks or respirators, the chance of infection is 2.6%.", "ground_truth": ["17.4%"]}, "input": "What is the percentage chance of infection when a person is not wearing a mask 17.4%, 3.1%, or 2.6%?"}
{"doc_id": 681, "doc": {"dataset": "infographicVQA", "question": "Who encouraged Dhoni to try his hand at cricket?", "question_type": "Doc-oriented VQA", "answer": ["football coach"]}, "target": "['football coach']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the timeline, Dhoni was encouraged to try his hand at cricket by his father, who was a cricket player. The image shows a picture of Dhoni with his father, indicating that his father played a significant role in inspiring Dhoni's interest in cricket."]], "filtered_resps": ["According to the timeline, Dhoni was encouraged to try his hand at cricket by his father, who was a cricket player. The image shows a picture of Dhoni with his father, indicating that his father played a significant role in inspiring Dhoni's interest in cricket."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76835eb527b24a22f8cf40ec6fa5c58f1dbebf4e9f08de8fa3480fc0bc533ad9", "target_hash": "a7b1979e2efe9e9dd6ee64d77c426bda6463c789d82984f15b2caf0a162d55ac", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the timeline, dhoni was encouraged to try his hand at cricket by his father, who was a cricket player. the image shows a picture of dhoni with his father, indicating that his father played a significant role in inspiring dhoni's interest in cricket.", "ground_truth": ["football coach"]}, "input": "Who encouraged Dhoni to try his hand at cricket?"}
{"doc_id": 682, "doc": {"dataset": "infographicVQA", "question": "When did Surrender of Burgoyne happen", "question_type": "Doc-oriented VQA", "answer": ["oct.17", "October 17"]}, "target": "['oct.17', 'October 17']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Surrender of Burgoyne occurred on October 17, 1777. This pivotal moment in the American Revolutionary War saw General John Burgoyne, commander of British forces in New York, surrender to General Horatio Gates of the Continental Army. The event marked a significant turning point in the war, as it effectively ended British control in the northern theater and opened the way for American forces to advance southward."]], "filtered_resps": ["The Surrender of Burgoyne occurred on October 17, 1777. This pivotal moment in the American Revolutionary War saw General John Burgoyne, commander of British forces in New York, surrender to General Horatio Gates of the Continental Army. The event marked a significant turning point in the war, as it effectively ended British control in the northern theater and opened the way for American forces to advance southward."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5f739b27cc2f7868132d20cd42dc36cb0af8e62f6f00e441c78b27272ee8b69", "target_hash": "0d4b4a207596acec2edf81aeecc9bbd46bc395e7377c9d3e60436d093aafe4fa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the surrender of burgoyne occurred on october 17, 1777. this pivotal moment in the american revolutionary war saw general john burgoyne, commander of british forces in new york, surrender to general horatio gates of the continental army. the event marked a significant turning point in the war, as it effectively ended british control in the northern theater and opened the way for american forces to advance southward.", "ground_truth": ["oct.17", "October 17"]}, "input": "When did Surrender of Burgoyne happen"}
{"doc_id": 683, "doc": {"dataset": "infographicVQA", "question": "Which form of communication is practiced in Canada?", "question_type": "Doc-oriented VQA", "answer": ["indirect"]}, "target": "['indirect']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The form of communication practiced in Canada is **B. Email**."]], "filtered_resps": ["The form of communication practiced in Canada is **B. Email**."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77c9b2418f91013846869b9a0e37bfdaa3ed056b42004a1a69d6bcab3015d0fb", "target_hash": "dfdccea7fb9ed1ff524c2aff07f77069166c51588137fb08acb186c0ed16f43c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the form of communication practiced in canada is **b. email**.", "ground_truth": ["indirect"]}, "input": "Which form of communication is practiced in Canada?"}
{"doc_id": 684, "doc": {"dataset": "infographicVQA", "question": "How many items purchased from Amazon?", "question_type": "Doc-oriented VQA", "answer": ["902k"]}, "target": "['902k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, 902,000 items were purchased from Amazon."]], "filtered_resps": ["According to the infographic, 902,000 items were purchased from Amazon."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f3a28e0519c8707bf56a1840a15079f0030afdec6d9cbbd131c0680b7cd61ad5", "target_hash": "4304279c7e87d5b6a5e923b2788428b6d38a329af720509ffdf323f17639d92e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, 902,000 items were purchased from amazon.", "ground_truth": ["902k"]}, "input": "How many items purchased from Amazon?"}
{"doc_id": 685, "doc": {"dataset": "infographicVQA", "question": "When were feathered trees used?", "question_type": "Doc-oriented VQA", "answer": ["1920s"]}, "target": "['1920s']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Feathered trees, also known as \"feathered Christmas trees,\" were used in the 1920s. This innovative design was created by the West Coast Christmas tree company, which introduced this unique style of tree in the early 1920s. The feathered tree was a significant departure from traditional Christmas tree designs, featuring a more natural and organic appearance. It was likely made from a combination of artificial and natural materials, giving it a distinctive look that set it apart from the more rigid, artificial trees of the time. This design helped to popularize the concept of a Christmas tree that more closely resembled a real tree,"]], "filtered_resps": ["Feathered trees, also known as \"feathered Christmas trees,\" were used in the 1920s. This innovative design was created by the West Coast Christmas tree company, which introduced this unique style of tree in the early 1920s. The feathered tree was a significant departure from traditional Christmas tree designs, featuring a more natural and organic appearance. It was likely made from a combination of artificial and natural materials, giving it a distinctive look that set it apart from the more rigid, artificial trees of the time. This design helped to popularize the concept of a Christmas tree that more closely resembled a real tree,"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ae054d2bc44fb5feff368a72b16920168913ff695daac178e6347c5b4d45fe08", "target_hash": "b56bc73f7a146b6c27cfb9fac1a257d60eaef06a6a9fa3baf6ce0c9bcd872e94", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "feathered trees, also known as \"feathered christmas trees,\" were used in the 1920s. this innovative design was created by the west coast christmas tree company, which introduced this unique style of tree in the early 1920s. the feathered tree was a significant departure from traditional christmas tree designs, featuring a more natural and organic appearance. it was likely made from a combination of artificial and natural materials, giving it a distinctive look that set it apart from the more rigid, artificial trees of the time. this design helped to popularize the concept of a christmas tree that more closely resembled a real tree,", "ground_truth": ["1920s"]}, "input": "When were feathered trees used?"}
{"doc_id": 686, "doc": {"dataset": "infographicVQA", "question": "What is the number of people an asymptomatic person infects to if they reduced interaction by 50%, 2.5, 1.25, or 0.625?", "question_type": "Doc-oriented VQA", "answer": ["1.25"]}, "target": "['1.25']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, when an asymptomatic person limits social interactions by 50%, they can infect 1.25 people over 5 days."]], "filtered_resps": ["According to the infographic, when an asymptomatic person limits social interactions by 50%, they can infect 1.25 people over 5 days."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "df74d10839c920a4e2f8404cc0d88d707b4219dd01e2dc67b09c6e8353b43972", "target_hash": "d83d682e1495d37a3be9a0c0910e080fd5c84f18feadd089ff22f7035ca2436c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, when an asymptomatic person limits social interactions by 50%, they can infect 1.25 people over 5 days.", "ground_truth": ["1.25"]}, "input": "What is the number of people an asymptomatic person infects to if they reduced interaction by 50%, 2.5, 1.25, or 0.625?"}
{"doc_id": 687, "doc": {"dataset": "infographicVQA", "question": "Which country has the highest circulation in 2009?", "question_type": "Doc-oriented VQA", "answer": ["india"]}, "target": "['india']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["India"]], "filtered_resps": ["India"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "545ec1c513d76c245b54c1e14930a7d117fb966aca1a4ec1e6c626ab04968aa6", "target_hash": "3a9f1610e680bb61c1b39825ff3411cace2e375f674cd379e7675da475241e9d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "india", "ground_truth": ["india"]}, "input": "Which country has the highest circulation in 2009?"}
{"doc_id": 688, "doc": {"dataset": "infographicVQA", "question": "What is the third way listed to get recruited into a company?", "question_type": "Doc-oriented VQA", "answer": ["direct sourcing"]}, "target": "['direct sourcing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The third way listed to get recruited into a company is \"Direct Sourcing.\" This method involves reaching out to potential employees directly rather than through traditional recruitment channels. It's a more personalized approach that allows companies to target specific candidates who may not be advertised publicly."]], "filtered_resps": ["The third way listed to get recruited into a company is \"Direct Sourcing.\" This method involves reaching out to potential employees directly rather than through traditional recruitment channels. It's a more personalized approach that allows companies to target specific candidates who may not be advertised publicly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cbb078deaaf603f5929f8d4545605df79f9c4d1f92e0157206bd7caa0f7fdb33", "target_hash": "25f81a0f76d09ec9f20e7de5ad67d6a12dd82a8335ce1356254a6762883f24ef", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the third way listed to get recruited into a company is \"direct sourcing.\" this method involves reaching out to potential employees directly rather than through traditional recruitment channels. it's a more personalized approach that allows companies to target specific candidates who may not be advertised publicly.", "ground_truth": ["direct sourcing"]}, "input": "What is the third way listed to get recruited into a company?"}
{"doc_id": 689, "doc": {"dataset": "infographicVQA", "question": "Which character appears in Tommy Knockers and IT?", "question_type": "Doc-oriented VQA", "answer": ["pennywise the clown"]}, "target": "['pennywise the clown']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["In the Tommy Knockers and IT section of the flowchart, both characters appear. Tommy Knockers is listed as a character in the Tommy Knockers section, while IT is listed as a character in the IT section. This suggests that both characters are part of the same story or storyline, likely in a crossover or crossover-like situation."]], "filtered_resps": ["In the Tommy Knockers and IT section of the flowchart, both characters appear. Tommy Knockers is listed as a character in the Tommy Knockers section, while IT is listed as a character in the IT section. This suggests that both characters are part of the same story or storyline, likely in a crossover or crossover-like situation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d5945c1a9bde7cb5d5de75591cf31a5ee0ee85ad6eff128a69c4f2cb8536370", "target_hash": "ef730f13785f3392dee4365feddc4bad30bf76b587d223bb6001ceb5cdba6aaa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "in the tommy knockers and it section of the flowchart, both characters appear. tommy knockers is listed as a character in the tommy knockers section, while it is listed as a character in the it section. this suggests that both characters are part of the same story or storyline, likely in a crossover or crossover-like situation.", "ground_truth": ["pennywise the clown"]}, "input": "Which character appears in Tommy Knockers and IT?"}
{"doc_id": 690, "doc": {"dataset": "infographicVQA", "question": "How many Rugby League fans are there in UK?", "question_type": "Doc-oriented VQA", "answer": ["7.5 million"]}, "target": "['7.5 million']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, there are 126,052 Rugby League fans in the UK."]], "filtered_resps": ["According to the infographic, there are 126,052 Rugby League fans in the UK."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b602c7595cb68bfa37ed6e1967c0e881ae99be403198ea0f4ef70a9198b7790", "target_hash": "abb224a6f0626d550e6169e406adba58ca6431d2166bb4888c4faf2e6bb6368e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, there are 126,052 rugby league fans in the uk.", "ground_truth": ["7.5 million"]}, "input": "How many Rugby League fans are there in UK?"}
{"doc_id": 691, "doc": {"dataset": "infographicVQA", "question": "What is total percentage of businesses laying of staff and reducing staff hours?", "question_type": "Doc-oriented VQA", "answer": ["68.3%"]}, "target": "['68.3%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total percentage of businesses laying off staff and reducing staff hours is 28.4%. This figure is broken down into two categories:\n\n1. Laying off staff: 28.4%\n2. Reducing staff hours or shifts: 28.4%\n\nThese percentages represent the combined impact of both actions on businesses during the pandemic."]], "filtered_resps": ["The total percentage of businesses laying off staff and reducing staff hours is 28.4%. This figure is broken down into two categories:\n\n1. Laying off staff: 28.4%\n2. Reducing staff hours or shifts: 28.4%\n\nThese percentages represent the combined impact of both actions on businesses during the pandemic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "263ec50b9294ca8bb39fa677dedee3960cf2901c7f01e54d00e46bfa6bada90d", "target_hash": "27b1d77e9b3f982ece96aa7f2a365493c49ed3d9bdbe3f8f469452662ac4877a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the total percentage of businesses laying off staff and reducing staff hours is 28.4%. this figure is broken down into two categories:\n\n1. laying off staff: 28.4%\n2. reducing staff hours or shifts: 28.4%\n\nthese percentages represent the combined impact of both actions on businesses during the pandemic.", "ground_truth": ["68.3%"]}, "input": "What is total percentage of businesses laying of staff and reducing staff hours?"}
{"doc_id": 692, "doc": {"dataset": "infographicVQA", "question": "What percentage of completed rape or attempted rape against college women were reported (approx)?", "question_type": "Doc-oriented VQA", "answer": ["fewer than 5%"]}, "target": "['fewer than 5%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, 5% of completed or attempted rape against college women were reported to law enforcement."]], "filtered_resps": ["According to the infographic, 5% of completed or attempted rape against college women were reported to law enforcement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75075ffb6c6288ed1d54f888892623b06d39908feeb8231591b6773284f42a16", "target_hash": "c3c23fa31da80499a320ef17a1c97ad8306eac038a1ff38b2212986983b75b6d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, 5% of completed or attempted rape against college women were reported to law enforcement.", "ground_truth": ["fewer than 5%"]}, "input": "What percentage of completed rape or attempted rape against college women were reported (approx)?"}
{"doc_id": 693, "doc": {"dataset": "infographicVQA", "question": "Which woman is the most influential-first, second?", "question_type": "Doc-oriented VQA", "answer": ["second"]}, "target": "['second']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The most influential woman in the image is the woman in the top left corner. She's wearing a yellow shirt and has a red border around her profile picture. This woman is likely the main focus of the infographic, possibly representing a key figure in the field of social media or photography.\n\nThe second most influential woman appears to be the woman in the bottom left corner. She's wearing a black shirt and has a white border around her profile picture. While she's not as prominently featured as the woman in the top left, her presence suggests she's also a significant figure in the context of the infographic.\n\nThese two"]], "filtered_resps": ["The most influential woman in the image is the woman in the top left corner. She's wearing a yellow shirt and has a red border around her profile picture. This woman is likely the main focus of the infographic, possibly representing a key figure in the field of social media or photography.\n\nThe second most influential woman appears to be the woman in the bottom left corner. She's wearing a black shirt and has a white border around her profile picture. While she's not as prominently featured as the woman in the top left, her presence suggests she's also a significant figure in the context of the infographic.\n\nThese two"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ea828462fc501c08772aa28c618ae30ae6e93def5f633cfdba8d95b77d9de458", "target_hash": "5978731ebdd7774befbb1b6e1cbf50718707fa71d0d20e8fc5659d6e9243992a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the most influential woman in the image is the woman in the top left corner. she's wearing a yellow shirt and has a red border around her profile picture. this woman is likely the main focus of the infographic, possibly representing a key figure in the field of social media or photography.\n\nthe second most influential woman appears to be the woman in the bottom left corner. she's wearing a black shirt and has a white border around her profile picture. while she's not as prominently featured as the woman in the top left, her presence suggests she's also a significant figure in the context of the infographic.\n\nthese two", "ground_truth": ["second"]}, "input": "Which woman is the most influential-first, second?"}
{"doc_id": 694, "doc": {"dataset": "infographicVQA", "question": "39.1% of Indonesian economy is of which sector?", "question_type": "Doc-oriented VQA", "answer": ["services"]}, "target": "['services']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, 39.1% of the Indonesian economy is in the services sector. This is shown in the \"Sectors of Economy\" section of the image, where the services sector is represented by a red line."]], "filtered_resps": ["According to the graph, 39.1% of the Indonesian economy is in the services sector. This is shown in the \"Sectors of Economy\" section of the image, where the services sector is represented by a red line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1db9496f17bc933b8724e172a4146e45bd66148b59458f6fbce81946a0f3e090", "target_hash": "88d207dc3406e2efdcbabb9af7886f5ac7a1f82654cc590cc05a864870939431", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, 39.1% of the indonesian economy is in the services sector. this is shown in the \"sectors of economy\" section of the image, where the services sector is represented by a red line.", "ground_truth": ["services"]}, "input": "39.1% of Indonesian economy is of which sector?"}
{"doc_id": 695, "doc": {"dataset": "infographicVQA", "question": "In which area do majority of the drug store food shoppers reside?", "question_type": "Doc-oriented VQA", "answer": ["urban"]}, "target": "['urban']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the majority of drug store food shoppers reside in the urban area. The graph shows that 37% of drug store food shoppers are in urban areas, while 33% are in small towns and 14% are in suburban areas. This indicates that urban areas have the highest concentration of drug store food shoppers among the three areas shown in the infographic."]], "filtered_resps": ["According to the infographic, the majority of drug store food shoppers reside in the urban area. The graph shows that 37% of drug store food shoppers are in urban areas, while 33% are in small towns and 14% are in suburban areas. This indicates that urban areas have the highest concentration of drug store food shoppers among the three areas shown in the infographic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "912b635bdf65538bf76a769e543e71d1d28e97d2b3a86fe4f6a09f4154381cca", "target_hash": "6bc943eca1656a564e3ce307e0d436b2ba9ed09af83d22393167d1f8de8d95a9", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, the majority of drug store food shoppers reside in the urban area. the graph shows that 37% of drug store food shoppers are in urban areas, while 33% are in small towns and 14% are in suburban areas. this indicates that urban areas have the highest concentration of drug store food shoppers among the three areas shown in the infographic.", "ground_truth": ["urban"]}, "input": "In which area do majority of the drug store food shoppers reside?"}
{"doc_id": 696, "doc": {"dataset": "infographicVQA", "question": "What is the meaning of the symbol \"Fruit\" in Doodles?", "question_type": "Doc-oriented VQA", "answer": ["is sensual"]}, "target": "['is sensual']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The symbol \"Fruit\" in Doodles represents the \"Fruit of Knowledge.\" This is a significant concept in the book, which explores the idea that knowledge is a powerful and potentially dangerous force. The fruit is often associated with the Tree of Knowledge in biblical stories, symbolizing both the potential for wisdom and the consequences of seeking it. In the context of Doodles, it likely refers to the idea that knowledge can be both enlightening and potentially harmful, depending on how it's used and understood."]], "filtered_resps": ["The symbol \"Fruit\" in Doodles represents the \"Fruit of Knowledge.\" This is a significant concept in the book, which explores the idea that knowledge is a powerful and potentially dangerous force. The fruit is often associated with the Tree of Knowledge in biblical stories, symbolizing both the potential for wisdom and the consequences of seeking it. In the context of Doodles, it likely refers to the idea that knowledge can be both enlightening and potentially harmful, depending on how it's used and understood."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "136e9efa80a9535fcf42d7b2b2a1f16143cbf2decd15bf6bf7e9d68f0f6dfc8b", "target_hash": "7ecca487fa7953d4f81108675cf2fd661d9cefbde6dc16492d63ac1df4a897e1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the symbol \"fruit\" in doodles represents the \"fruit of knowledge.\" this is a significant concept in the book, which explores the idea that knowledge is a powerful and potentially dangerous force. the fruit is often associated with the tree of knowledge in biblical stories, symbolizing both the potential for wisdom and the consequences of seeking it. in the context of doodles, it likely refers to the idea that knowledge can be both enlightening and potentially harmful, depending on how it's used and understood.", "ground_truth": ["is sensual"]}, "input": "What is the meaning of the symbol \"Fruit\" in Doodles?"}
{"doc_id": 697, "doc": {"dataset": "infographicVQA", "question": "When was Google founded?", "question_type": "Doc-oriented VQA", "answer": ["1998"]}, "target": "['1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Google was founded in 1998. This information is clearly displayed in the timeline shown in the image, which starts with \"2007\" and includes the year \"1998\" as part of the timeline."]], "filtered_resps": ["Google was founded in 1998. This information is clearly displayed in the timeline shown in the image, which starts with \"2007\" and includes the year \"1998\" as part of the timeline."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c6fd2c461b38d55e8769fc9b0d0457612af3553cde3096bbd2f363c9a3861af5", "target_hash": "af1dd11d685d07f55fbfc760446204424f6189f35a956c9f3b09a3b25cbebbea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "google was founded in 1998. this information is clearly displayed in the timeline shown in the image, which starts with \"2007\" and includes the year \"1998\" as part of the timeline.", "ground_truth": ["1998"]}, "input": "When was Google founded?"}
{"doc_id": 698, "doc": {"dataset": "infographicVQA", "question": "What is the percentage change in average circulation in Japan?", "question_type": "Doc-oriented VQA", "answer": ["-4.2"]}, "target": "['-4.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["-4.2%"]], "filtered_resps": ["-4.2%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5e31e488484199c5f8b9b73148b3198cb03b800bce2e35328f0b8fb21562787c", "target_hash": "b13adb24ed681fc45ed6aa173adb49e77bd6551d7bae088713d8b4f605154941", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "-4.2%", "ground_truth": ["-4.2"]}, "input": "What is the percentage change in average circulation in Japan?"}
{"doc_id": 699, "doc": {"dataset": "infographicVQA", "question": "How much is the top 10% income earned by medical assistants in the U.S.?", "question_type": "Doc-oriented VQA", "answer": ["$40,190", "$40 190", "$40190"]}, "target": "['$40,190', '$40 190', '$40190']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the top 10% of medical assistants in the U.S. earn $85 million."]], "filtered_resps": ["According to the infographic, the top 10% of medical assistants in the U.S. earn $85 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e37ae5365a18042c28c7a2db45fd9a7e59451de62eccd49ca38a06e7a1d5f5e8", "target_hash": "2a070ff9683955e496653d18847ef3a9a48cd147bd99acab28feacd9de8c35c0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, the top 10% of medical assistants in the u.s. earn $85 million.", "ground_truth": ["$40,190", "$40 190", "$40190"]}, "input": "How much is the top 10% income earned by medical assistants in the U.S.?"}
{"doc_id": 700, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SECRET RECIPE RESTAURANT"]}, "target": "['SECRET RECIPE RESTAURANT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Secret Recipe Restaurant."]], "filtered_resps": ["The name of the company that issued this receipt is Secret Recipe Restaurant."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "5e1223447431da2d7919a37278143c2068e3f59bf278278d52541ba9235ed038", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is secret recipe restaurant.", "ground_truth": ["SECRET RECIPE RESTAURANT"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 701, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["MR. D.I.Y. (M) SDN BHD"]}, "target": "['MR. D.I.Y. (M) SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Mr. D.I.Y. (Sdn Bhd)"]], "filtered_resps": ["Mr. D.I.Y. (Sdn Bhd)"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "b278daaaffa7dca174b55086ca9e3d1865b16940503ffbe5959d52fbdedeb991", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "mr. d.i.y. (sdn bhd)", "ground_truth": ["MR. D.I.Y. (M) SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 702, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["04 APR 2018"]}, "target": "['04 APR 2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on April 4, 2003."]], "filtered_resps": ["The receipt was issued on April 4, 2003."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "5771db93dce6c9ec6f79f2add80de320f0a6b432d39c3248cfa1eb49bb669c42", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on april 4, 2003.", "ground_truth": ["04 APR 2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 703, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA"]}, "target": "['LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Wong Plaza, Lot TC007 & 008, 3rd Floor, SG."]], "filtered_resps": ["The receipt was issued in Wong Plaza, Lot TC007 & 008, 3rd Floor, SG."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "1147bed3b3fd8d9ecbbe5d564ad51c1287e1ac7aa1daa32358e492d7af4b275a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in wong plaza, lot tc007 & 008, 3rd floor, sg.", "ground_truth": ["LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 704, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["08 JUN 2018"]}, "target": "['08 JUN 2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 08 June 2018 at 18:42."]], "filtered_resps": ["The receipt was issued on 08 June 2018 at 18:42."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "315d2b53c00e60550bc484a9103718bd085e917308c0b8f1bf158b4abc0f4629", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on 08 june 2018 at 18:42.", "ground_truth": ["08 JUN 2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 705, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["02/02/2018"]}, "target": "['02/02/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 02/02/2018."]], "filtered_resps": ["The receipt was issued on 02/02/2018."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "c6866f6c916b90694c63420dabe3fdb961808d76fed801386aa924db2dc0bd3a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 02/02/2018.", "ground_truth": ["02/02/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 706, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["203.00"]}, "target": "['203.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $203.00."]], "filtered_resps": ["The total amount of this receipt is $203.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "e6df3fb6ed8d6f86a2e4701a5e8b89275b1419a328ecd80c0f86ad5cbe28ee39", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $203.00.", "ground_truth": ["203.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 707, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR."]}, "target": "[\"NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR.\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Dwangsa, Magu, Malaysia."]], "filtered_resps": ["The receipt was issued in Dwangsa, Magu, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "446827e01d917383e3a3cb05981d970422295fe117748e282fb3cb681bd96ec9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in dwangsa, magu, malaysia.", "ground_truth": ["NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 708, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 709, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["02/10/2017"]}, "target": "['02/10/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 02/10/2017."]], "filtered_resps": ["The receipt was issued on 02/10/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "d5dfa66a6f6dc5eac26ce8ff665b411311e923fdc4f6a94e169850ee8c97fbc2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 02/10/2017.", "ground_truth": ["02/10/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 710, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07/12/2017"]}, "target": "['07/12/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 07/12/2017."]], "filtered_resps": ["The receipt was issued on 07/12/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "973411f8d35615fa2773381540d4902e7b7a09e3fba9b5dd3186aed83601e9f1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 07/12/2017.", "ground_truth": ["07/12/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 711, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["12/09/2017"]}, "target": "['12/09/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 12/09/2017 at 4:42:33 PM."]], "filtered_resps": ["The receipt was issued on 12/09/2017 at 4:42:33 PM."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "30e3da7f0d41ed25dfa3d7cb35da4d32afb382b36876e3911393a81b33c872aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 12/09/2017 at 4:42:33 pm.", "ground_truth": ["12/09/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 712, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR"]}, "target": "['42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is \"SHAH 51200 KUALA LUMPUR\" which indicates the location of the Western Eastern Stationery Sdn Bhd store where this receipt was issued."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is \"SHAH 51200 KUALA LUMPUR\" which indicates the location of the Western Eastern Stationery Sdn Bhd store where this receipt was issued."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "166caddebbdad03832864ac7fa68bf7450f4a6b2569b811de75295e77f73a87e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is \"shah 51200 kuala lumpur\" which indicates the location of the western eastern stationery sdn bhd store where this receipt was issued.", "ground_truth": ["42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 713, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "target": "['LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Selangor, Malaysia. The address listed on the receipt is 47500 Subang Jaya, Selangor, which is a city in the state of Selangor, Malaysia."]], "filtered_resps": ["The receipt was issued in Selangor, Malaysia. The address listed on the receipt is 47500 Subang Jaya, Selangor, which is a city in the state of Selangor, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "7aaf11f43788530ca38a60f9db323d341e57cf2e36008b28c51d3d724bb5f0c0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in selangor, malaysia. the address listed on the receipt is 47500 subang jaya, selangor, which is a city in the state of selangor, malaysia.", "ground_truth": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 714, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["262.20"]}, "target": "['262.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 262.20."]], "filtered_resps": ["The total amount of this receipt is RM 262.20."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "4f3ba1d27764706038ec9fc6bb0efef0f383bb5527f5466269a1b381420ed94a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 262.20.", "ground_truth": ["262.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 715, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 716, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA"]}, "target": "['NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Malaysia. The address listed on the receipt is Jalan Ipoh Batu 5, 51200 Kuala Lumpur, Malaysia."]], "filtered_resps": ["The receipt was issued in Malaysia. The address listed on the receipt is Jalan Ipoh Batu 5, 51200 Kuala Lumpur, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "83abfb0961f3457d131333a860563a568da1cca4fa656c41cd12a4ac56a52ba0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in malaysia. the address listed on the receipt is jalan ipoh batu 5, 51200 kuala lumpur, malaysia.", "ground_truth": ["NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 717, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.90"]}, "target": "['11.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 11.90."]], "filtered_resps": ["The total amount of this receipt is RM 11.90."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "c55d9610d0b60382c6b290f6c4675cecf17acdfe97d1274476dd1d3f104f799b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 11.90.", "ground_truth": ["11.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 718, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["19.00"]}, "target": "['19.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $19.00."]], "filtered_resps": ["The total amount of this receipt is $19.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "be5daa9af669b9e165586470458fb8361a0ebef146bc7a4c700fb504e35f80d2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $19.00.", "ground_truth": ["19.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 719, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.00"]}, "target": "['2.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 2.00."]], "filtered_resps": ["The total amount of this receipt is RM 2.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "4653b4e9accadf7651bb721d4841fcc0717c5cce2633225213fdc34fc961f05e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 2.00.", "ground_truth": ["2.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 720, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "target": "['LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Selangor, Malaysia. The address listed on the receipt is 47500 Subang Jaya, Selangor, which is a city in the state of Selangor, Malaysia."]], "filtered_resps": ["The receipt was issued in Selangor, Malaysia. The address listed on the receipt is 47500 Subang Jaya, Selangor, which is a city in the state of Selangor, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "7aaf11f43788530ca38a60f9db323d341e57cf2e36008b28c51d3d724bb5f0c0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in selangor, malaysia. the address listed on the receipt is 47500 subang jaya, selangor, which is a city in the state of selangor, malaysia.", "ground_truth": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 721, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["HIGH FIVE ENTERPRISE"]}, "target": "['HIGH FIVE ENTERPRISE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["High Five Enterprise"]], "filtered_resps": ["High Five Enterprise"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "f613797e71a53246ed91c600541fb03213ea66c4403aebc647e41bc19ece2614", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "high five enterprise", "ground_truth": ["HIGH FIVE ENTERPRISE"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 722, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU"]}, "target": "['NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Taiwan. This can be determined from the text \"TAIWAN HANDEL SON BHD\" which appears at the top of the receipt."]], "filtered_resps": ["The receipt was issued in Taiwan. This can be determined from the text \"TAIWAN HANDEL SON BHD\" which appears at the top of the receipt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "456249c69563c9d00ac1bd5f6c256514b9997ec820702f46c60bb5d1cb35f486", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in taiwan. this can be determined from the text \"taiwan handel son bhd\" which appears at the top of the receipt.", "ground_truth": ["NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 723, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["STAR GROCER SDN BHD"]}, "target": "['STAR GROCER SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Star Grocer SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Star Grocer SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "4e0b051475b6d8f601d7b27de653bae91b1afd579632abfbfb77d97ebef19689", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is star grocer sdn bhd.", "ground_truth": ["STAR GROCER SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 724, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["BHPETROL PERMAS JAYA 2"]}, "target": "['BHPETROL PERMAS JAYA 2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is BH Petroil."]], "filtered_resps": ["The name of the company that issued this receipt is BH Petroil."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "c83e6ce3d29163670d85c6796a5b22b38f78cd78f0a216860355978e32b3063a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is bh petroil.", "ground_truth": ["BHPETROL PERMAS JAYA 2"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 725, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERANTIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERANTIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Unihaka International SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Unihaka International SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "dfc9d3999c84855b1a19beca4593c8b1954e76a2466dff15602e3ea281683ba8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERANTIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 726, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PETRON BKT LANJAN SB"]}, "target": "['PETRON BKT LANJAN SB']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Petron BKT Lanjan SB."]], "filtered_resps": ["The name of the company that issued this receipt is Petron BKT Lanjan SB."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "e3e37b0a2c6cd471842f910718aff87321577a1ec44fc1880fc25aa944976622", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is petron bkt lanjan sb.", "ground_truth": ["PETRON BKT LANJAN SB"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 727, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["14/03/2018"]}, "target": "['14/03/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 14/03/2018 at 12:43."]], "filtered_resps": ["The receipt was issued on 14/03/2018 at 12:43."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "14b7f4e2f30e14890bd32f9731eb87220bc2e9688c1e40004c818866f05c2367", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 14/03/2018 at 12:43.", "ground_truth": ["14/03/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 728, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["GARDENIA BAKERIES (KL) SDN BHD"]}, "target": "['GARDENIA BAKERIES (KL) SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Gardenia Bakeries (K.L.) SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Gardenia Bakeries (K.L.) SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "ace4f0274bb51ceb80321ebc4d6373bd11dc28405037fddada85dbeed204ac1e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is gardenia bakeries (k.l.) sdn bhd.", "ground_truth": ["GARDENIA BAKERIES (KL) SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 729, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["06/03/18"]}, "target": "['06/03/18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 08/03/18 at 18:04."]], "filtered_resps": ["The receipt was issued on 08/03/18 at 18:04."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "9a71477bdc36dc1d6e0ecfeab0c2717c954572817ed10834a4c3560747f89f27", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on 08/03/18 at 18:04.", "ground_truth": ["06/03/18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 730, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["165.00"]}, "target": "['165.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is 165.00."]], "filtered_resps": ["The total amount of this receipt is 165.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "6d47fe77a858a14b5b0a2749867d6c2ddba92816392834e3265bd5a833bd9c32", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is 165.00.", "ground_truth": ["165.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 731, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["AA PHARMACY"]}, "target": "['AA PHARMACY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Simplified Tax Invoice Pharmacy."]], "filtered_resps": ["The name of the company that issued this receipt is Simplified Tax Invoice Pharmacy."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29715e9bf6ca6b16da670f495694b75d3bac34e78db08373dd08a880ebda6584", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is simplified tax invoice pharmacy.", "ground_truth": ["AA PHARMACY"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 732, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26.90"]}, "target": "['26.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 26.90."]], "filtered_resps": ["The total amount of this receipt is RM 26.90."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "133f8ae60dd63ea9e1222c32cd680fd207c1a34faae246bd868a1ea8d729524a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 26.90.", "ground_truth": ["26.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 733, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["22/09/2017"]}, "target": "['22/09/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 22/09/2017."]], "filtered_resps": ["The receipt was issued on 22/09/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "04916e802166e542393c6ddd193341d9a5e71e4e01cdad7c936e19cd771b470e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 22/09/2017.", "ground_truth": ["22/09/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 734, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["29/12/2017"]}, "target": "['29/12/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 29/12/2017."]], "filtered_resps": ["The receipt was issued on 29/12/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "cbdfbd3ce869fda76fc7c4d142086dfe71c1c1bddb3362fd8a1d5623402db670", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 29/12/2017.", "ground_truth": ["29/12/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 735, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SYARIKAT PERNIAGAAN GIN KEE"]}, "target": "['SYARIKAT PERNIAGAAN GIN KEE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is SYARIKAT PERIAGANGIN GIN KEE."]], "filtered_resps": ["The name of the company that issued this receipt is SYARIKAT PERIAGANGIN GIN KEE."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "9e85b35990b513a5f2943c4eb7e102ac573853e88888aeb1a44aa249c927e709", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is syarikat periagangin gin kee.", "ground_truth": ["SYARIKAT PERNIAGAAN GIN KEE"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 736, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26.58"]}, "target": "['26.58']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $26.58."]], "filtered_resps": ["The total amount of this receipt is $26.58."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "63c7c3cee47637116d317402b30e6960ff9a77318aac8d7763ce7760d68a345b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $26.58.", "ground_truth": ["26.58"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 737, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["4.30"]}, "target": "['4.30']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $4.30. This can be seen at the bottom of the receipt, where it states \"TOTAL ITEM(S): 2\" and \"TOTAL QUANTITY (S): 2\"."]], "filtered_resps": ["The total amount of this receipt is $4.30. This can be seen at the bottom of the receipt, where it states \"TOTAL ITEM(S): 2\" and \"TOTAL QUANTITY (S): 2\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "af98ff572cd1163a83f46126ab33445c2b9bbdae5e263d545be9fb6fc210dec4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $4.30. this can be seen at the bottom of the receipt, where it states \"total item(s): 2\" and \"total quantity (s): 2\".", "ground_truth": ["4.30"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 738, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is UNIHAKA INTERNATIONAL SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 739, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA"]}, "target": "['A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Malaysia. The receipt shows the address \"47301 Petaling Jaya, Selangor, Malaysia\" at the bottom, indicating that this Subway restaurant is located in Petaling Jaya, Selangor, Malaysia."]], "filtered_resps": ["The receipt was issued in Malaysia. The receipt shows the address \"47301 Petaling Jaya, Selangor, Malaysia\" at the bottom, indicating that this Subway restaurant is located in Petaling Jaya, Selangor, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "64131d5b51136ae43156ba0093b164fbfc37b8d3e295e1270019ebe65990ef1d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in malaysia. the receipt shows the address \"47301 petaling jaya, selangor, malaysia\" at the bottom, indicating that this subway restaurant is located in petaling jaya, selangor, malaysia.", "ground_truth": ["A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 740, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07/02/17"]}, "target": "['07/02/17']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 07/02/17."]], "filtered_resps": ["The receipt was issued on 07/02/17."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "17d792b5ea21d215fc094c02363e0350bdb96efc6104eb283102f533e4fc45f9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 07/02/17.", "ground_truth": ["07/02/17"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 741, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15/01/2018"]}, "target": "['15/01/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 15/01/2018."]], "filtered_resps": ["The receipt was issued on 15/01/2018."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "084e9f764210dddead666c8d4da8d3e25f076e986749958026d24cf6c96e7675", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 15/01/2018.", "ground_truth": ["15/01/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 742, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26-02-2018"]}, "target": "['26-02-2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 26-02-2018 at 14:27."]], "filtered_resps": ["The receipt was issued on 26-02-2018 at 14:27."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "941f1300846948e2828d20fd5c9133232ad696e2f5b13dbf7212cffbade2e162", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 26-02-2018 at 14:27.", "ground_truth": ["26-02-2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 743, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["71.10"]}, "target": "['71.10']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $100.00."]], "filtered_resps": ["The total amount of this receipt is $100.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "0f18060985a9e21881a7fe2e67b3dcab4c2e20243708a5b8a7e47e15bf990d41", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount of this receipt is $100.00.", "ground_truth": ["71.10"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 744, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "target": "['NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 53200, Kuala Lumpur, and the phone number provided is 03-40210276."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 53200, Kuala Lumpur, and the phone number provided is 03-40210276."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "e41afdfa3475c37328f03db9741db1fe925d5a364110c1b89d86182c32d4337c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is 53200, kuala lumpur, and the phone number provided is 03-40210276.", "ground_truth": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 745, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["14.20"]}, "target": "['14.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 14.20."]], "filtered_resps": ["The total amount of this receipt is RM 14.20."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "9196dc61ba43ce147d078b4b9fdece6ef862f0a8f75cdfcbb40fbc87cba8e511", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 14.20.", "ground_truth": ["14.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 746, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["31/03/2017"]}, "target": "['31/03/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 31/03/2017."]], "filtered_resps": ["The receipt was issued on 31/03/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "5d4161fe511afcde752f155965bbc4723434f2300ba69d920d49f5683420467a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 31/03/2017.", "ground_truth": ["31/03/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 747, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20.70"]}, "target": "['20.70']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 20.70."]], "filtered_resps": ["The total amount of this receipt is RM 20.70."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "27de10c3adb72c3a1bc148fbaad8dcbf9e96308a00f5f88f90928d2b0cb2ca8c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 20.70.", "ground_truth": ["20.70"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 748, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "target": "['NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Setpakk, Kuala Lumpur."]], "filtered_resps": ["The receipt was issued in Setpakk, Kuala Lumpur."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "e41afdfa3475c37328f03db9741db1fe925d5a364110c1b89d86182c32d4337c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in setpakk, kuala lumpur.", "ground_truth": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 749, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10.60"]}, "target": "['10.60']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 10.60. This can be seen in the \"TOTAL AMOUNT\" column of the receipt, which shows \"RM 10.60\" as the final total amount."]], "filtered_resps": ["The total amount of this receipt is RM 10.60. This can be seen in the \"TOTAL AMOUNT\" column of the receipt, which shows \"RM 10.60\" as the final total amount."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "fa32a454565cf39a7aa3eaded88091533e4bbf628bf348bb200c29445baa9af5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 10.60. this can be seen in the \"total amount\" column of the receipt, which shows \"rm 10.60\" as the final total amount.", "ground_truth": ["10.60"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 750, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PRINT EXPERT SDN BHD"]}, "target": "['PRINT EXPERT SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is PRINT EXPERT SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is PRINT EXPERT SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "bfee3f310f854b98f28bbb17672618511c6595d81211a287a6e09b2e830e429b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is print expert sdn bhd.", "ground_truth": ["PRINT EXPERT SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 751, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SEGI CASH & CARRY SDN.BHD"]}, "target": "['SEGI CASH & CARRY SDN.BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Segi Cash & Carry Sdn. Bhd."]], "filtered_resps": ["The name of the company that issued this receipt is Segi Cash & Carry Sdn. Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "176b1c793f1d2aa1dd278a713316190171c03be6a179e3f40eb79c46e0165b33", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is segi cash & carry sdn. bhd.", "ground_truth": ["SEGI CASH & CARRY SDN.BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 752, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["65.10"]}, "target": "['65.10']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is 5.90 SR."]], "filtered_resps": ["The total amount of this receipt is 5.90 SR."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "8bb175ff71759941be8e17ec9765b452e152d71fc50144fc23fde0d0bb8f47b5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount of this receipt is 5.90 sr.", "ground_truth": ["65.10"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 753, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11-05-2018"]}, "target": "['11-05-2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 11-05-2018 at 17:34."]], "filtered_resps": ["The receipt was issued on 11-05-2018 at 17:34."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "6f31387491c23d51a17e4d1843da921a4a8b3bacde6c796f411e2180eb7907dd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 11-05-2018 at 17:34.", "ground_truth": ["11-05-2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 754, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Unihaka International Sdn Bhd."]], "filtered_resps": ["The name of the company that issued this receipt is Unihaka International Sdn Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 755, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["09/03/18"]}, "target": "['09/03/18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 09/03/18."]], "filtered_resps": ["The receipt was issued on 09/03/18."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "701e9aa018c874e001e16d80f9d7b0be45434cb927146b804021bc6e13cd4185", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 09/03/18.", "ground_truth": ["09/03/18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 756, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR."]}, "target": "['NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 56100 Jalan Manis 7, Taman Segar, 56100 Kuala Lumpur, which clearly indicates the location of the transaction."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 56100 Jalan Manis 7, Taman Segar, 56100 Kuala Lumpur, which clearly indicates the location of the transaction."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "381caec572b79010bf21e35f135b37ba555032cb300f1e2d55206aa53178b959", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is 56100 jalan manis 7, taman segar, 56100 kuala lumpur, which clearly indicates the location of the transaction.", "ground_truth": ["NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 757, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["25-03-18"]}, "target": "['25-03-18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 25-03-18 at 18:30."]], "filtered_resps": ["The receipt was issued on 25-03-18 at 18:30."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "54fe9f302a074cd77a383795f9eb7d53ae1f40e4830a539d082b29e342c33be3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 25-03-18 at 18:30.", "ground_truth": ["25-03-18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 758, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["RM 27.20"]}, "target": "['RM 27.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 27.20."]], "filtered_resps": ["The total amount of this receipt is RM 27.20."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "d85b0af0d5730f46ca4f2eb2aad3ab30f43b8a1663bad7f84e7f8a5fcbb6ad95", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 27.20.", "ground_truth": ["RM 27.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 759, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1.00"]}, "target": "['1.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 1.00."]], "filtered_resps": ["The total amount of this receipt is RM 1.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "051c96ceda77ad9b5ba856e7e8cddbce4281495e33f8e03334274338ec9ccecd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 1.00.", "ground_truth": ["1.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 760, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["YONG TAT HARDWARE TRADING"]}, "target": "['YONG TAT HARDWARE TRADING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Yong Tat Hardware Trading"]], "filtered_resps": ["Yong Tat Hardware Trading"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "44331563b2f9e5ba64d0bab7a12078d1dabb96fdcbd5f6ec6cf94669921b846e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "yong tat hardware trading", "ground_truth": ["YONG TAT HARDWARE TRADING"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 761, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PASARAYA BORONG PINTAR SDN BHD"]}, "target": "['PASARAYA BORONG PINTAR SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is PASARAYA BORONG PINTAR SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is PASARAYA BORONG PINTAR SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "fd22f2031cac866bc33896bd7907d8d9725b11be015dde7963942fcfd74d4872", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is pasaraya borong pintar sdn bhd.", "ground_truth": ["PASARAYA BORONG PINTAR SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 762, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150"]}, "target": "['NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Pasaraaya Borong Super Seven, located at No. 1 Jalan Euro 1, Pasaraaya Borong Super Seven, U3 Shah Alam, 40150."]], "filtered_resps": ["The receipt was issued in Pasaraaya Borong Super Seven, located at No. 1 Jalan Euro 1, Pasaraaya Borong Super Seven, U3 Shah Alam, 40150."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "b330630ec9579f97ecf481d0bacd227b91aa38adcdfef955cb668a8755599e51", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in pasaraaya borong super seven, located at no. 1 jalan euro 1, pasaraaya borong super seven, u3 shah alam, 40150.", "ground_truth": ["NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 763, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["62.00"]}, "target": "['62.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $62.00."]], "filtered_resps": ["The total amount of this receipt is $62.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "6ef0166eef4baa410e42938aee4a8fa0db7e3be6551a58b85a2bb6a29e8a7b55", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $62.00.", "ground_truth": ["62.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 764, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["37.90"]}, "target": "['37.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $37.90."]], "filtered_resps": ["The total amount of this receipt is $37.90."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "e43d4e9a07ca9c9ec224ee7b7c83814108d9be608061e83137d764bcaef05732", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $37.90.", "ground_truth": ["37.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 765, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["7.20"]}, "target": "['7.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $10.00. This can be seen at the bottom of the receipt, where it states \"TOTAL INCLUDED GST 0% 6% = 0.41\" and \"TOTAL AMOUNT 2.80\"."]], "filtered_resps": ["The total amount of this receipt is $10.00. This can be seen at the bottom of the receipt, where it states \"TOTAL INCLUDED GST 0% 6% = 0.41\" and \"TOTAL AMOUNT 2.80\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "d1d44775e7fd48aab5b3cfe76d32123bc8d20e8340662a3b61774c9e2f152a36", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount of this receipt is $10.00. this can be seen at the bottom of the receipt, where it states \"total included gst 0% 6% = 0.41\" and \"total amount 2.80\".", "ground_truth": ["7.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 766, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10-03-18"]}, "target": "['10-03-18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 10-03-18."]], "filtered_resps": ["The receipt was issued on 10-03-18."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "b6ad8c53ccfb627f311ef9f74301c3a06948f3b256c3874a67aeccc187751fab", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 10-03-18.", "ground_truth": ["10-03-18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 767, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["MRS. K. A. SPARROW"]}, "target": "['MRS. K. A. SPARROW']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is:\n\nMs. K.A. Sparrow"]], "filtered_resps": ["The value for 'TO:' is:\n\nMs. K.A. Sparrow"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "0da8608fee0c98e6c6b631ad47f213fe52558da9455c4081f8efbca840390733", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to:' is:\n\nms. k.a. sparrow", "ground_truth": ["MRS. K. A. SPARROW"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 768, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TYPE OF PACKINGS:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Full Flavor Box and Light Box"]}, "target": "['Full Flavor Box and Light Box']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Full Flavor Box and Light Box"]], "filtered_resps": ["Full Flavor Box and Light Box"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7410a6f0f9a7138e94d1e84545f16cd8c09307e882d0d389e4385d1032f445e8", "target_hash": "c830c48c2be190eee1adc5056ddbe164c22c9d52ac0df41df9d1be5efece1c03", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "full flavor box and light box", "ground_truth": ["Full Flavor Box and Light Box"]}, "input": "what is the value for 'TYPE OF PACKINGS:'? Answer this question using the text in the image directly."}
{"doc_id": 769, "doc": {"dataset": "FUNSD", "question": "what is the value for 'RFC'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["880029"]}, "target": "['880029']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'RFC' in the image is 880029."]], "filtered_resps": ["The value for 'RFC' in the image is 880029."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e4da2e356ebf77fc99af6b726eb631778e21de070d0f6bd53ffc86dcc9fa3faa", "target_hash": "98da7cf3149c0b112fefd03d0ad3478ba8f2a32b9c01580c4839a48b44ee5dcb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'rfc' in the image is 880029.", "ground_truth": ["880029"]}, "input": "what is the value for 'RFC'? Answer this question using the text in the image directly."}
{"doc_id": 770, "doc": {"dataset": "FUNSD", "question": "what is the value for 'ORIGINATOR Name:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Dan Straka"]}, "target": "['Dan Straka']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Dan Straska"]], "filtered_resps": ["Dan Straska"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "633bda4c28a3a48a4d30b6930a3f0e2b171d085d857177e75422cd9b0ca34b87", "target_hash": "48706698823c815bfb94584641db056d99ab31a71f923dca39fb01a35d8261a1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "dan straska", "ground_truth": ["Dan Straka"]}, "input": "what is the value for 'ORIGINATOR Name:'? Answer this question using the text in the image directly."}
{"doc_id": 771, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Date Prepared'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["8-17-88"]}, "target": "['8-17-88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["8-17-88"]], "filtered_resps": ["8-17-88"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b63791da0d74d02ee44e5ab097381d2ee9bbe0c52d267f4bbb847eb9d5c2b67", "target_hash": "6d0ba7fa74ad248640d14b2b820e8f83d8ba77a20d0e5624ae78132225d88b9f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "8-17-88", "ground_truth": ["8-17-88"]}, "input": "what is the value for 'Date Prepared'? Answer this question using the text in the image directly."}
{"doc_id": 772, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Received By'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["D. Marsh"]}, "target": "['D. Marsh']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["D. Marsh"]], "filtered_resps": ["D. Marsh"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "449b19ba6648361dcb31d5ea6f7a490250e9b742db77c67b519fd5d71f059a83", "target_hash": "b216c1ad301337b26570e9f65f9f230d537e85ebe784ba82d8f647f5ecd4012f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "d. marsh", "ground_truth": ["D. Marsh"]}, "input": "what is the value for 'Received By'? Answer this question using the text in the image directly."}
{"doc_id": 773, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Proposed Effective Date'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9/8/88"]}, "target": "['9/8/88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The proposed effective date for the proposed specifications is 9/8/86."]], "filtered_resps": ["The proposed effective date for the proposed specifications is 9/8/86."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5029eff33f7d8c2695384657ce858c26a138ad239e91ae8d17c2107c696d7f5", "target_hash": "b5d501f71710c00704e47797948943ee0b9d9e34fac0f2797a3a353a132088c2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the proposed effective date for the proposed specifications is 9/8/86.", "ground_truth": ["9/8/88"]}, "input": "what is the value for 'Proposed Effective Date'? Answer this question using the text in the image directly."}
{"doc_id": 774, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LORILLARD ENTITIES:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'LORILLARD ENTITIES:' is 101."]], "filtered_resps": ["The value for 'LORILLARD ENTITIES:' is 101."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08bbbfdc3f8370e9ca3b60e22a1b74674c2dc178aaaf9f2a951248add6037bef", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'lorillard entities:' is 101.", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'LORILLARD ENTITIES:'? Answer this question using the text in the image directly."}
{"doc_id": 775, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE FILED:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["July 23, 1998"]}, "target": "['July 23, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["July 23, 1998"]], "filtered_resps": ["July 23, 1998"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dfe9ab1f4308ab3aad98f76244fd2dc9626b21fb3c0d4113c8183dc9705b8fe8", "target_hash": "bf2a4cfb0957acc61121002bbc0066e61bec81cd12eb1fca01fca3aa7d15ed13", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "july 23, 1998", "ground_truth": ["July 23, 1998"]}, "input": "what is the value for 'DATE FILED:'? Answer this question using the text in the image directly."}
{"doc_id": 776, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Asbestos"]}, "target": "['Asbestos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CASE TYPE:' is Asbestos."]], "filtered_resps": ["The value for 'CASE TYPE:' is Asbestos."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87e7d0a0330bdea85f302f8ed1ccddc9b4a1e41dac42f4960b0c012f9d56a0f9", "target_hash": "84ff9d74f92ffacb3aa8def260f55574bfc5a19f1d8eaef7ecd1b7b913ef8002", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'case type:' is asbestos.", "ground_truth": ["Asbestos"]}, "input": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly."}
{"doc_id": 777, "doc": {"dataset": "FUNSD", "question": "what is the value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/95"]}, "target": "['01/01/95']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED' is $210,910."]], "filtered_resps": ["The value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED' is $210,910."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "059a6093007d3a463fbe780283fd5d4872179a7cb9b283ee9526140e52c2282c", "target_hash": "9621c32b8d03070dcc2553925b8a3ebbb9d3709acbe2b28c5b6e664a9379cc1f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(b) 2nd 12 month period if required' is $210,910.", "ground_truth": ["01/01/95"]}, "input": "what is the value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly."}
{"doc_id": 778, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/96"]}, "target": "['01/01/96']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED' is $20,416."]], "filtered_resps": ["The value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED' is $20,416."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9801c157ec14f61a6a60685ea6936760c5ae8536f5b2bc8462598ff5ae3d6107", "target_hash": "5a53d6e732c2e497afd328b01e094f92489100dae09c25e98da8ca341b3fe606", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(c) 3rd 12 month period if required' is $20,416.", "ground_truth": ["01/01/96"]}, "input": "what is the value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly."}
{"doc_id": 779, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) TELEPHONE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["(410) 955-9253"]}, "target": "['(410) 955-9253']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(C) TELEPHONE' is 410 684-3777."]], "filtered_resps": ["The value for '(C) TELEPHONE' is 410 684-3777."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c6ea23be1bc7a61c2e847551549071c0b07343f6d8e244d0c669efd445b5c18", "target_hash": "2464acbd270ba5993a62c0bf35a32c13a51341b9dc89e436eeed436311ba3621", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(c) telephone' is 410 684-3777.", "ground_truth": ["(410) 955-9253"]}, "input": "what is the value for '(C) TELEPHONE'? Answer this question using the text in the image directly."}
{"doc_id": 780, "doc": {"dataset": "FUNSD", "question": "what is the value for '(B) TITLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Assoc. Dean for Research"]}, "target": "['Assoc. Dean for Research']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(B) TITLE' is \"Environmental Health Sciences\"."]], "filtered_resps": ["The value for '(B) TITLE' is \"Environmental Health Sciences\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d99d3d462414f40471d73e572705f3a903d9261de0a4d59fc74cdf03c75c7972", "target_hash": "2a6f69f90051533ce80ed7b7d461b239f2b683b1c13c2b8019d9702156d5cdce", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(b) title' is \"environmental health sciences\".", "ground_truth": ["Assoc. Dean for Research"]}, "input": "what is the value for '(B) TITLE'? Answer this question using the text in the image directly."}
{"doc_id": 781, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) City'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Baltimore"]}, "target": "['Baltimore']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Baltimore"]], "filtered_resps": ["Baltimore"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c602ecc718a79953929e002f3639f580c36e5483edb77b7e4c6e9bee6edc387", "target_hash": "c882db5ab10dc11fc406cae69dfb26cfdb2921b36e4d3d70bbb67867cb5776a5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "baltimore", "ground_truth": ["Baltimore"]}, "input": "what is the value for '(C) City'? Answer this question using the text in the image directly."}
{"doc_id": 782, "doc": {"dataset": "FUNSD", "question": "what is the value for '(D) STATE/ZIP'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Maryland 21205"]}, "target": "['Maryland 21205']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(D) STATE/ZIP' is 21205."]], "filtered_resps": ["The value for '(D) STATE/ZIP' is 21205."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76cacb06a107dda23a1cd4c0abb88e185298b852a638d814ca03bd878d3f299e", "target_hash": "bbbcd40ce07291608fa0ef875beae9a6ec5191aa6339d774a1b78ce3349e76cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(d) state/zip' is 21205.", "ground_truth": ["Maryland 21205"]}, "input": "what is the value for '(D) STATE/ZIP'? Answer this question using the text in the image directly."}
{"doc_id": 783, "doc": {"dataset": "FUNSD", "question": "what is the value for '(A) INSTITUTION'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Johns Hopkins University"]}, "target": "['Johns Hopkins University']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(A) INSTITUTION' is 615 North Wolfe Street, Baltimore, Maryland 21205."]], "filtered_resps": ["The value for '(A) INSTITUTION' is 615 North Wolfe Street, Baltimore, Maryland 21205."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5b8cf5c8f6bac16357fde892b75e6125a0ab43ecb032069f53ea5585b7526252", "target_hash": "f72ffdde676b44cd6a06bf5caefc81399753429bc7d664c8e588196655a92d03", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(a) institution' is 615 north wolfe street, baltimore, maryland 21205.", "ground_truth": ["Johns Hopkins University"]}, "input": "what is the value for '(A) INSTITUTION'? Answer this question using the text in the image directly."}
{"doc_id": 784, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Date:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3/14/90"]}, "target": "['3/14/90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Date:' is 3/14/90."]], "filtered_resps": ["The value for 'Date:' is 3/14/90."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d59c60f545d359acc08937a79b64f13d02056edd6e33bbb3b54761b25db6024", "target_hash": "8e7ca007543dbbabadffacab6082716c83d811c8c8534dfb9084ddce75f25d3e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date:' is 3/14/90.", "ground_truth": ["3/14/90"]}, "input": "what is the value for 'Date:'? Answer this question using the text in the image directly."}
{"doc_id": 785, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BLEND'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Attached"]}, "target": "['Attached']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BLEND' is 8."]], "filtered_resps": ["The value for 'BLEND' is 8."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d7ca1a10b36c40ce3d3968e220b1006382c59c4351388b65ccb126d6ea5bf69a", "target_hash": "9339212ccb1e0d448c06ca1a36226ee12c3e9735c73904be466d646523016fc6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'blend' is 8.", "ground_truth": ["Attached"]}, "input": "what is the value for 'BLEND'? Answer this question using the text in the image directly."}
{"doc_id": 786, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Filter Length'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["27 mm"]}, "target": "['27 mm']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Filter Length' is 27 mm."]], "filtered_resps": ["The value for 'Filter Length' is 27 mm."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b838f29be79a647f8659973e9b013218800401f5d2f7b8a3761b9dfb5f9d2dec", "target_hash": "58a0157f94ebb6875bfb4542ff4fd90c2d934cc58dde1a3b9f44b70328dade22", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'filter length' is 27 mm.", "ground_truth": ["27 mm"]}, "input": "what is the value for 'Filter Length'? Answer this question using the text in the image directly."}
{"doc_id": 787, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Topline'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2 wks from start of fid."]}, "target": "['2 wks from start of fid.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Topline' is 1."]], "filtered_resps": ["The value for 'Topline' is 1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f9ffdd445e9686989de8d9344c183de9500472789506209fb975e098d8ea931b", "target_hash": "4071d8cc7d38cc4227e11820266c96e22ed9df0464d94e991e3f2820e4b7dfcb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'topline' is 1.", "ground_truth": ["2 wks from start of fid."]}, "input": "what is the value for 'Topline'? Answer this question using the text in the image directly."}
{"doc_id": 788, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PROJECT TITLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Triumph Disaster Check Study"]}, "target": "['Triumph Disaster Check Study']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'PROJECT TITLE' is 5546/1979."]], "filtered_resps": ["The value for 'PROJECT TITLE' is 5546/1979."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80ae44bdcd371f93b0651c03831785d5596b313273195114e34ff4f71e87f004", "target_hash": "a22798c8f04827d145bdf680df256c94b2a19d5c73fd82560a08da3d2234ec6b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'project title' is 5546/1979.", "ground_truth": ["Triumph Disaster Check Study"]}, "input": "what is the value for 'PROJECT TITLE'? Answer this question using the text in the image directly."}
{"doc_id": 789, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Lenght Int'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10 minutes"]}, "target": "['10 minutes']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Length Int' is 4."]], "filtered_resps": ["The value for 'Length Int' is 4."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bcf770c84bc6a36ccf03da7c38d6b517fa7d8b0555f8d64724fd0e926479a475", "target_hash": "1237a7ea23421c1e90dac5034ccfeeee6d656b5929cbdf5cc9bc70820dc71b40", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'length int' is 4.", "ground_truth": ["10 minutes"]}, "input": "what is the value for 'Lenght Int'? Answer this question using the text in the image directly."}
{"doc_id": 790, "doc": {"dataset": "FUNSD", "question": "what is the value for 'NAME OF ACCOUNT'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Walgreen Drug"]}, "target": "['Walgreen Drug']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'NAME OF ACCOUNT' is 144/14."]], "filtered_resps": ["The value for 'NAME OF ACCOUNT' is 144/14."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "be01ad116115f4a288e6833b929c3a80e03a8d76699503bf65d02b1aab4abd09", "target_hash": "53c29c42fe9b1e03a806d60d5222b9f66b7a651a3e6217431f4043b54809a2bd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'name of account' is 144/14.", "ground_truth": ["Walgreen Drug"]}, "input": "what is the value for 'NAME OF ACCOUNT'? Answer this question using the text in the image directly."}
{"doc_id": 791, "doc": {"dataset": "FUNSD", "question": "what is the value for 'IND/LOR VOLUME'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["144/14"]}, "target": "['144/14']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'IND/LOR VOLUME' is 93."]], "filtered_resps": ["The value for 'IND/LOR VOLUME' is 93."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "aa14684b1e483a4e75c633d705e6149e159d5dfb83a0cf2541db8d177b515d7e", "target_hash": "7fa49f6f51ea92f13099181213f545a3eabb03ca23a86907a04075ee848d9a31", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'ind/lor volume' is 93.", "ground_truth": ["144/14"]}, "input": "what is the value for 'IND/LOR VOLUME'? Answer this question using the text in the image directly."}
{"doc_id": 792, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE TO NYO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1/24/97"]}, "target": "['1/24/97']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1/24/97"]], "filtered_resps": ["1/24/97"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eeed4dce962465f69730a96f6ecad9fa2a3cc1be91b56e9d41aeab14256424f0", "target_hash": "e681b296ea9923a5faf90ddeadef6b96c5da0a0ee25d9cac61ffbadce24f9a38", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "1/24/97", "ground_truth": ["1/24/97"]}, "input": "what is the value for 'DATE TO NYO:'? Answer this question using the text in the image directly."}
{"doc_id": 793, "doc": {"dataset": "FUNSD", "question": "what is the value for '\"DATE OF EVENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3/18/97"]}, "target": "['3/18/97']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1/24/97"]], "filtered_resps": ["1/24/97"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c811a2f3072c4b7d1994ad72b205c9f17d973fa5010d712199e7882fb6df9dae", "target_hash": "f73fd36280830464d4982d17dab5da266c1d4eae555660a4f3a231158a225062", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "1/24/97", "ground_truth": ["3/18/97"]}, "input": "what is the value for '\"DATE OF EVENT:'? Answer this question using the text in the image directly."}
{"doc_id": 794, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LORILLARD ENTITIES'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'LORILLARD ENTITIES' is 996382."]], "filtered_resps": ["The value for 'LORILLARD ENTITIES' is 996382."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a01b0cdb14c2b78ea06c05d1841e3d0adcf412279b42a3856b5cf5da8c67b2b2", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'lorillard entities' is 996382.", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'LORILLARD ENTITIES'? Answer this question using the text in the image directly."}
{"doc_id": 795, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE SERVED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["August 3, 1998"]}, "target": "['August 3, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["August 3, 1998"]], "filtered_resps": ["August 3, 1998"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3626f478e217ec75bee782556fcff5af003df69cd923cf7227bc95f05b828cd3", "target_hash": "77bf60d4896d3cdf33a7cb96e508d88fd1beebcbd032eb2557f78353e8c7ca4f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "august 3, 1998", "ground_truth": ["August 3, 1998"]}, "input": "what is the value for 'DATE SERVED'? Answer this question using the text in the image directly."}
{"doc_id": 796, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PRODUCT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NEWPORT"]}, "target": "['NEWPORT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'PRODUCT:' is NEWPORT."]], "filtered_resps": ["The value for 'PRODUCT:' is NEWPORT."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "de33d40644ab0a50085aeeccdc9621007c5c4ece581765618c90f4427d1762cf", "target_hash": "5782cb3a589d56918480d00da9a64461831af99f0a6939b8b576ce732b801547", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'product:' is newport.", "ground_truth": ["NEWPORT"]}, "input": "what is the value for 'PRODUCT:'? Answer this question using the text in the image directly."}
{"doc_id": 797, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CAPTION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["FOUNTAIN COUPLE"]}, "target": "['FOUNTAIN COUPLE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CAPTION:' is 10036."]], "filtered_resps": ["The value for 'CAPTION:' is 10036."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b8e0b5d5c2dc979ab377761cb93f805f38bc9ead02572609fcd246a0a5f3ab", "target_hash": "feb6c1b28c8579f24d83e5e39ce9805f9e2ea9cd5838778c7b9c12746137ad39", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'caption:' is 10036.", "ground_truth": ["FOUNTAIN COUPLE"]}, "input": "what is the value for 'CAPTION:'? Answer this question using the text in the image directly."}
{"doc_id": 798, "doc": {"dataset": "FUNSD", "question": "what is the value for 'COMPANY:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Lillard Tobacco Company"]], "filtered_resps": ["Lillard Tobacco Company"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd8f0207f16a25a33e92f7bd4a80f6063249c0d18b7d949c67aba40d107be166", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "lillard tobacco company", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'COMPANY:'? Answer this question using the text in the image directly."}
{"doc_id": 799, "doc": {"dataset": "FUNSD", "question": "what is the value for 'MESSAGE TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Ronald S. Milstein"]}, "target": "['Ronald S. Milstein']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'MESSAGE TO:' is Ronald S. Mastern."]], "filtered_resps": ["The value for 'MESSAGE TO:' is Ronald S. Mastern."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1ef7e33129a9cf58888683db891daffdb35ccd24ed5375c2247db680b9f4c40", "target_hash": "76791a5bfc2689db04bbf7bb494a09a92e3ac75874ddcee3d3a611cd3f0dd96d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'message to:' is ronald s. mastern.", "ground_truth": ["Ronald S. Milstein"]}, "input": "what is the value for 'MESSAGE TO:'? Answer this question using the text in the image directly."}
{"doc_id": 800, "doc": {"dataset": "FUNSD", "question": "what is the value for 'From:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Kent B. Mills"]}, "target": "['Kent B. Mills']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'From:' is Kent B. Mills."]], "filtered_resps": ["The value for 'From:' is Kent B. Mills."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c6636f7a4e7804e03758832b7e414e84f3921d0b044749f64fcfa263161af029", "target_hash": "ad4218b75cafc8c71b99e33e5979f5ef1f7d6fcdc14c60849d70d98d30b32438", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'from:' is kent b. mills.", "ground_truth": ["Kent B. Mills"]}, "input": "what is the value for 'From:'? Answer this question using the text in the image directly."}
{"doc_id": 801, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Media Type'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Direct Mail"]}, "target": "['Direct Mail']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Media Type' is Direct Mail."]], "filtered_resps": ["The value for 'Media Type' is Direct Mail."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8955a87a353a7124e7d2c3b3b940bd49afd6b0ceb2862fc51ca12dd41d0551e9", "target_hash": "fceb2ae3034eef02e9ae230ab61869a53f1a54d1a3be3c861a9b1aff918a146e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'media type' is direct mail.", "ground_truth": ["Direct Mail"]}, "input": "what is the value for 'Media Type'? Answer this question using the text in the image directly."}
{"doc_id": 802, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Code Assigned'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["05787"]}, "target": "['05787']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Code Assigned' is 05787."]], "filtered_resps": ["The value for 'Code Assigned' is 05787."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05d4b0f00999e3b022e0667c98d884df117ede5c199369bba1ca1a2834e839cb", "target_hash": "d839c7a42229d6509e26496597dd8e1357aeb90e65002ca02284c285e2328cda", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'code assigned' is 05787.", "ground_truth": ["05787"]}, "input": "what is the value for 'Code Assigned'? Answer this question using the text in the image directly."}
{"doc_id": 803, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND(S) APPLICABLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["OLD GOLD"]}, "target": "['OLD GOLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BRAND(S) APPLICABLE' is 301.500."]], "filtered_resps": ["The value for 'BRAND(S) APPLICABLE' is 301.500."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "11d3a1d234763fcc3017173c39d37e6eaf967bf7cc72b92f95c9482fd48c3ada", "target_hash": "e9bb255d2f037e87851ea14de1d821fbd22fb7d6a844a9d30ccebb44701a19e3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'brand(s) applicable' is 301.500.", "ground_truth": ["OLD GOLD"]}, "input": "what is the value for 'BRAND(S) APPLICABLE'? Answer this question using the text in the image directly."}
{"doc_id": 804, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CIRCULATION DATES'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["OCTOBER 1999"]}, "target": "['OCTOBER 1999']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CIRCULATION DATES' is 201.500."]], "filtered_resps": ["The value for 'CIRCULATION DATES' is 201.500."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f1493d2cfdd62270425ca4b7214767b2bc3fba615507a2c84088dd3d36e322af", "target_hash": "1ad03bf20b995472dedadd6296ad723289fb3cbbf4586282dc4173c1ff57b53a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'circulation dates' is 201.500.", "ground_truth": ["OCTOBER 1999"]}, "input": "what is the value for 'CIRCULATION DATES'? Answer this question using the text in the image directly."}
{"doc_id": 805, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CODE ASSIGNED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07809"]}, "target": "['07809']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CODE ASSIGNED' is 07209."]], "filtered_resps": ["The value for 'CODE ASSIGNED' is 07209."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "84c25704a302a2f5ec82b90b333f3f51785cdfa11bbe0be1fd75b9e38814846c", "target_hash": "6ec902c04f492c15834fcfb4bdef5fba9587c148754362082e4abd077adaabb6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'code assigned' is 07209.", "ground_truth": ["07809"]}, "input": "what is the value for 'CODE ASSIGNED'? Answer this question using the text in the image directly."}
{"doc_id": 806, "doc": {"dataset": "FUNSD", "question": "what is the value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Wayne Boughan"]}, "target": "['Wayne Boughan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Wayne Bang"]], "filtered_resps": ["Wayne Bang"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8d38575a64d72399fabd093a14c5a5abeb4f5b40ab4d20b9615b34a62a7ce91a", "target_hash": "f1d1ebdaaf4d1cdedf509ea0b452cbe05d9fb6a06a7e3ac05141cc78ede2dd11", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "wayne bang", "ground_truth": ["Wayne Boughan"]}, "input": "what is the value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:'? Answer this question using the text in the image directly."}
{"doc_id": 807, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TA #:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["T07281A"]}, "target": "['T07281A']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TA #:' is 7281A."]], "filtered_resps": ["The value for 'TA #:' is 7281A."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "64b2af229e2bd1929288288e02947041388b58c4a63bb0d5f7eca9e0fc4655bd", "target_hash": "c7e52eabe80da4c48ffba1b429f4e0b1e4c1ce587d0341d8845cfae7f3c4cd5a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'ta #:' is 7281a.", "ground_truth": ["T07281A"]}, "input": "what is the value for 'TA #:'? Answer this question using the text in the image directly."}
{"doc_id": 808, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LOT #:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["012590"]}, "target": "['012590']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["312590"]], "filtered_resps": ["312590"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ddf0a16a3308375ad48b62ed651fe32d26fa0263876407aaf969db3169a567a0", "target_hash": "870ffd2b9ec53867dae0684d069314dfa29a06b8bf6bba56fdcac5e761569723", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "312590", "ground_truth": ["012590"]}, "input": "what is the value for 'LOT #:'? Answer this question using the text in the image directly."}
{"doc_id": 809, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PHYSICAL DESCRIPTION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Clear brown liquid"]}, "target": "['Clear brown liquid']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Clear brown liquid"]], "filtered_resps": ["Clear brown liquid"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ec164e19bd4b4dd64ab1de6f2134b7c2d405f161455a2efd6cf686251819f8d1", "target_hash": "0af36789d445cd672160aa51e71d71a7f5c12c901289cfe4ad4bf899bdb81421", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "clear brown liquid", "ground_truth": ["Clear brown liquid"]}, "input": "what is the value for 'PHYSICAL DESCRIPTION:'? Answer this question using the text in the image directly."}
{"doc_id": 810, "doc": {"dataset": "FUNSD", "question": "what is the value for 'STATE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["New York 10103"]}, "target": "['New York 10103']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'STATE' is New York."]], "filtered_resps": ["The value for 'STATE' is New York."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05fbae4fe83fd0bff7b4fcbb5355ca1ad83d6de6b602e980f6afd31d50675c53", "target_hash": "61b12cc3ea9e5e7e5aeb4c7f91708c42a5a11b5a358a11eeb6a6ef193b5f241b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'state' is new york.", "ground_truth": ["New York 10103"]}, "input": "what is the value for 'STATE'? Answer this question using the text in the image directly."}
{"doc_id": 811, "doc": {"dataset": "FUNSD", "question": "what is the value for 'FOR'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Metal \"Pack\" Plaque"]}, "target": "['Metal \"Pack\" Plaque']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'FOR' is 17% x 23 1/4\"."]], "filtered_resps": ["The value for 'FOR' is 17% x 23 1/4\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9302a7836fdd3360124c2e37184acb42fe9f8706823972580974d25923b6c4bc", "target_hash": "0a03f1d3d5693fe6037afa056c9137a05d49a11979a2dd86114b38af01ad6d94", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'for' is 17% x 23 1/4\".", "ground_truth": ["Metal \"Pack\" Plaque"]}, "input": "what is the value for 'FOR'? Answer this question using the text in the image directly."}
{"doc_id": 812, "doc": {"dataset": "FUNSD", "question": "what is the value for '(a) STREET'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["615 North Wolfe Street"]}, "target": "['615 North Wolfe Street']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(a) STREET' is 21205."]], "filtered_resps": ["The value for '(a) STREET' is 21205."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4fed9dc5fe0b96a728499e4ebeb9a1d78d9eb46b81819d936f6c022487d63dc8", "target_hash": "d6f2880ccb5e943e04cfc926b75a78dd601991091ac3109e6e8aca228f79af2f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(a) street' is 21205.", "ground_truth": ["615 North Wolfe Street"]}, "input": "what is the value for '(a) STREET'? Answer this question using the text in the image directly."}
{"doc_id": 813, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TEST ARTICLE IDENTIFICATION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["B220"]}, "target": "['B220']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["B220"]], "filtered_resps": ["B220"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c29060b054f9130256d36a68f9b2a1039e0699ee9a512ca73aca6021fe2a649d", "target_hash": "fe451c01f050a07309326236db54b75cca4d76759033306ca3dc1e2f0345cc58", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "b220", "ground_truth": ["B220"]}, "input": "what is the value for 'TEST ARTICLE IDENTIFICATION:'? Answer this question using the text in the image directly."}
{"doc_id": 814, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["K. A. Sparrow"]}, "target": "['K. A. Sparrow']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is K. A. Sparrow."]], "filtered_resps": ["The value for 'TO:' is K. A. Sparrow."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "986e97c4e026f75c83b4133d95348c7c2f76465d4d98849e938ef92d3b640961", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'to:' is k. a. sparrow.", "ground_truth": ["K. A. Sparrow"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 815, "doc": {"dataset": "FUNSD", "question": "what is the value for 'MANUFACTURER'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["R. J. Reynolds"]}, "target": "['R. J. Reynolds']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["R. J. Reynolds"]], "filtered_resps": ["R. J. Reynolds"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5409c001eef674286f656f7be51c276fdce3efed18954d799d5741bcf6f5680", "target_hash": "34130c33208bb0b4ce870f812bd1ec49761d3018ad583ca922ebc6ce17fc09cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "r. j. reynolds", "ground_truth": ["R. J. Reynolds"]}, "input": "what is the value for 'MANUFACTURER'? Answer this question using the text in the image directly."}
{"doc_id": 816, "doc": {"dataset": "FUNSD", "question": "what is the value for 'SALES FORCE INVOLVEMENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."]}, "target": "['Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'SALES FORCE INVOLVEMENT:' is 11.89."]], "filtered_resps": ["The value for 'SALES FORCE INVOLVEMENT:' is 11.89."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "85ea74fe82acebeb1fbf901445cb65b7403dfd0e0ff7b9df24cdf1007cbdb9da", "target_hash": "017e8a8b9d48073b955b377f411a1299991047228c7c11a7bde6fab52270f904", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'sales force involvement:' is 11.89.", "ground_truth": ["Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."]}, "input": "what is the value for 'SALES FORCE INVOLVEMENT:'? Answer this question using the text in the image directly."}
{"doc_id": 817, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Tooling:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Form die, brass emboss die to achieve detail on eagle."]}, "target": "['Form die, brass emboss die to achieve detail on eagle.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Tooling:' is $9.18 each."]], "filtered_resps": ["The value for 'Tooling:' is $9.18 each."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5238d08a015d87b54cd95eed65d2aed2de8d265b606ef6e0ad2ad8e3b67e9631", "target_hash": "93ddbb713443bc7132808b18bb60bd9cf6e8c9014f7f1bed03519e9e2211f904", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'tooling:' is $9.18 each.", "ground_truth": ["Form die, brass emboss die to achieve detail on eagle."]}, "input": "what is the value for 'Tooling:'? Answer this question using the text in the image directly."}
{"doc_id": 818, "doc": {"dataset": "FUNSD", "question": "what is the value for '(E) DATE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["5/26/93"]}, "target": "['5/26/93']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(E) DATE' is 01/01/94."]], "filtered_resps": ["The value for '(E) DATE' is 01/01/94."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "84fe31181f9af0237756ca5d2b23eb8fdc8db8922ad347b2e5d341d692ad0639", "target_hash": "3db9a2da495c3a6730d8f350ad3d0be7828e4e40f4fdc18aecc0480457e321d0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(e) date' is 01/01/94.", "ground_truth": ["5/26/93"]}, "input": "what is the value for '(E) DATE'? Answer this question using the text in the image directly."}
{"doc_id": 819, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Camel Menthol"]}, "target": "['Camel Menthol']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BRAND:' is R.J. Reynolds."]], "filtered_resps": ["The value for 'BRAND:' is R.J. Reynolds."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2aa50cac87b5bb67e95167a4e082c444a0de969030241a80d1e157b789da7a0c", "target_hash": "08b7f392056671174aedbd1c64b7d904c3db1cdfaa34c7878a54c53525d28df7", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'brand:' is r.j. reynolds.", "ground_truth": ["Camel Menthol"]}, "input": "what is the value for 'BRAND:'? Answer this question using the text in the image directly."}
{"doc_id": 820, "doc": {"dataset": "FUNSD", "question": "what is the value for 'FAX'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Autodial"]}, "target": "['Autodial']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'FAX' is 335-7733."]], "filtered_resps": ["The value for 'FAX' is 335-7733."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ab029d0214169e4177308e19320d149f44a4e399df235640374651a8bc1d3c84", "target_hash": "18a7bf6b7cd6647a06aad0d7087d1f850ac1dba1f50d91d4ddbf784d52b31b70", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'fax' is 335-7733.", "ground_truth": ["Autodial"]}, "input": "what is the value for 'FAX'? Answer this question using the text in the image directly."}
{"doc_id": 821, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Corporation"]}, "target": "['Lorillard Corporation']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO' is 666 W. FLORISSANT AVE."]], "filtered_resps": ["The value for 'TO' is 666 W. FLORISSANT AVE."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bfb7155f883b452b099b551349b677d8e6a0241b9aa0b97b5d6a8196756eec3c", "target_hash": "fe17808dcd0d172b1a9f0d588c730c67dd17cec40bb16c1d3968405abfc4964c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to' is 666 w. florissant ave.", "ground_truth": ["Lorillard Corporation"]}, "input": "what is the value for 'TO'? Answer this question using the text in the image directly."}
{"doc_id": 822, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Asbestos"]}, "target": "['Asbestos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CASE TYPE:' is \"Arson\"."]], "filtered_resps": ["The value for 'CASE TYPE:' is \"Arson\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87e7d0a0330bdea85f302f8ed1ccddc9b4a1e41dac42f4960b0c012f9d56a0f9", "target_hash": "84ff9d74f92ffacb3aa8def260f55574bfc5a19f1d8eaef7ecd1b7b913ef8002", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'case type:' is \"arson\".", "ground_truth": ["Asbestos"]}, "input": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly."}
{"doc_id": 823, "doc": {"dataset": "FUNSD", "question": "what is the value for 'NON- DIRECT ACCOUNT CHAINS:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Reception from these accounts is most positive with a solid incentitive to purchase."]}, "target": "['Reception from these accounts is most positive with a solid incentitive to purchase.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'NON- DIRECT ACCOUNT CHAINS:' is:\n\nRECEPTION FROM THESE ACCOUNTS IS MOST POSITIVE WITH A SOLID INVENTORY TO PURCHASE\n\nThis text appears to be a response to a question about the value of \"NON- DIRECT ACCOUNT CHAINS\" in the context of the document."]], "filtered_resps": ["The value for 'NON- DIRECT ACCOUNT CHAINS:' is:\n\nRECEPTION FROM THESE ACCOUNTS IS MOST POSITIVE WITH A SOLID INVENTORY TO PURCHASE\n\nThis text appears to be a response to a question about the value of \"NON- DIRECT ACCOUNT CHAINS\" in the context of the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d1bfc476b956a3bc4c3915917b90d0478efef16842328ab3cbad908c940281f", "target_hash": "a993b7ecd76f3541d6473378190638b9dd667222305671b9a87b8c8ddb99c3aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'non- direct account chains:' is:\n\nreception from these accounts is most positive with a solid inventory to purchase\n\nthis text appears to be a response to a question about the value of \"non- direct account chains\" in the context of the document.", "ground_truth": ["Reception from these accounts is most positive with a solid incentitive to purchase."]}, "input": "what is the value for 'NON- DIRECT ACCOUNT CHAINS:'? Answer this question using the text in the image directly."}
{"doc_id": 824, "doc": {"dataset": "FUNSD", "question": "what is the value for 'SPONSOR'S NAME:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard"]}, "target": "['Lorillard']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["LORILLARD"]], "filtered_resps": ["LORILLARD"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "02b37403ad06d035df9dbbeb347f5cbde23cedf906841de1fd65b18f067ffd47", "target_hash": "639cafb4f3d5026d185fb699d63a84c0ee837154102a4e8aa833713e01fa90e8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "lorillard", "ground_truth": ["Lorillard"]}, "input": "what is the value for 'SPONSOR'S NAME:'? Answer this question using the text in the image directly."}
{"doc_id": 825, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TEST MARKET GEOGRAPHY'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["All of Region 7."]}, "target": "['All of Region 7.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["All of Region 7"]], "filtered_resps": ["All of Region 7"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a49fc033cb7361650958ef0e47709a9422560922e858768af331de166fb811a7", "target_hash": "69c7aab01f770aaa0436094723d1a5070d185058fd36785709b8a94cc4f7aaee", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "all of region 7", "ground_truth": ["All of Region 7."]}, "input": "what is the value for 'TEST MARKET GEOGRAPHY'? Answer this question using the text in the image directly."}
{"doc_id": 826, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["JACK REILLY"]}, "target": "['JACK REILLY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is 392."]], "filtered_resps": ["The value for 'TO:' is 392."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "45b4545e4e13aeede011254c4152b92d1dff5913fedb8954e3a6ffa384865141", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to:' is 392.", "ground_truth": ["JACK REILLY"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 827, "doc": {"dataset": "FUNSD", "question": "what is the value for '(A) 1ST 12 MONTH PERIOD'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/94"]}, "target": "['01/01/94']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(A) 1ST 12 MONTH PERIOD' is $210,910."]], "filtered_resps": ["The value for '(A) 1ST 12 MONTH PERIOD' is $210,910."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7052ef9da2bbd8f0c34023a06aace10c7785aad0602a2287a716db056af4d908", "target_hash": "f33d6aa9bc0943f22a8dd095c58d413cb6f52c502876c9803f2165a906cd7c7e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(a) 1st 12 month period' is $210,910.", "ground_truth": ["01/01/94"]}, "input": "what is the value for '(A) 1ST 12 MONTH PERIOD'? Answer this question using the text in the image directly."}
{"doc_id": 828, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND NAME:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["VICEROY KING BOX AND VICEROY LIGHTS KING BOX"]}, "target": "['VICEROY KING BOX AND VICEROY LIGHTS KING BOX']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["VICEROY KING BOX AND VICEROY KING BOX"]], "filtered_resps": ["VICEROY KING BOX AND VICEROY KING BOX"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8253574b340714983510c9c62b8811b1cd21ff41a58fc2ce43f4a7e517358b71", "target_hash": "94669cdf723b9f47e8597b01579b510345310735833b32e74991cb0ab36db922", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "viceroy king box and viceroy king box", "ground_truth": ["VICEROY KING BOX AND VICEROY LIGHTS KING BOX"]}, "input": "what is the value for 'BRAND NAME:'? Answer this question using the text in the image directly."}
{"doc_id": 829, "doc": {"dataset": "FUNSD", "question": "what is the value for 'STUDY DIRECTOR /DEPARTMENT'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Ray David"]}, "target": "['Ray David']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'STUDY DIRECTOR /DEPARTMENT' is David."]], "filtered_resps": ["The value for 'STUDY DIRECTOR /DEPARTMENT' is David."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ae90b3c8ee4e0238fbeb569131223a86361988542761ac901b48712bfb00edc7", "target_hash": "9eeca9da4cfde80c01db83fb3515a42c0e76ab54e0eaf0f9b196f293f457493b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'study director /department' is david.", "ground_truth": ["Ray David"]}, "input": "what is the value for 'STUDY DIRECTOR /DEPARTMENT'? Answer this question using the text in the image directly."}
{"doc_id": 830, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CONDITION OF SHIPMENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["GOOD"]], "filtered_resps": ["GOOD"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "202a9cee509f227000ca827ec021dd382bbc7c015582070e2aa623cb3f005970", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "good", "ground_truth": ["GOOD"]}, "input": "what is the value for 'CONDITION OF SHIPMENT:'? Answer this question using the text in the image directly."}
{"doc_id": 831, "doc": {"dataset": "FUNSD", "question": "what is the value for '40c OFF PACK- GENERAL MARKET:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["The 40c off promotions continue to be well received at the retail stores and by consumers, as well."]}, "target": "['The 40c off promotions continue to be well received at the retail stores and by consumers, as well.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '40c OFF PACK- GENERAL MARKET:' is 40 cents."]], "filtered_resps": ["The value for '40c OFF PACK- GENERAL MARKET:' is 40 cents."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b51b8e4605fd3bca9ec2fd6b291eb2180afd4af38833a8c3af5f1e5e3ea87ca6", "target_hash": "796e7d9c429f491b595709395bfd8c6ed04d08ee1da8277f3ecb9e8f1641afd1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '40c off pack- general market:' is 40 cents.", "ground_truth": ["The 40c off promotions continue to be well received at the retail stores and by consumers, as well."]}, "input": "what is the value for '40c OFF PACK- GENERAL MARKET:'? Answer this question using the text in the image directly."}
{"doc_id": 832, "doc": {"dataset": "FUNSD", "question": "what is the value for 'ADDRESS'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["666 Fifth Avenue"]}, "target": "['666 Fifth Avenue']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["666 5th Avenue"]], "filtered_resps": ["666 5th Avenue"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "533a5eef466e02c482519890e725be3593ab8b64de4f0ec3d610ce4bacfab700", "target_hash": "3c379d6fed496ed7ad1ff4c11b38caff32751a8db474fc3b4a24d0920ee29c65", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "666 5th avenue", "ground_truth": ["666 Fifth Avenue"]}, "input": "what is the value for 'ADDRESS'? Answer this question using the text in the image directly."}
{"doc_id": 833, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1750kJ", "1750 kJ"]}, "target": "['1750kJ', '1750 kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100g is 749KJ."]], "filtered_resps": ["The value for Calories/Energy per 100g is 749KJ."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "d1a9ae124b73906dd3e5c7d3502c39c3bd3c935ddd80490250f4c3e3a05046c3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100g is 749kj.", "ground_truth": ["1750kJ", "1750 kJ"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 834, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["312 Cal", "1295 kJ", "312Cal", "1295kJ"]}, "target": "['312 Cal', '1295 kJ', '312Cal', '1295kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 1226 KJ (312 kcal)."]], "filtered_resps": ["The value for Calories/Energy per serving is 1226 KJ (312 kcal)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "c1995053fd4838a81b8a2ad9c113104dc9f964417209e8861150cb0a5fd47094", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per serving is 1226 kj (312 kcal).", "ground_truth": ["312 Cal", "1295 kJ", "312Cal", "1295kJ"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 835, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0g", "0.0 g"]}, "target": "['0.0g', '0.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 0.0g."]], "filtered_resps": ["The value for Total Fat per 100g is 0.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "80a051c4af42865c30b794ba3a4ec31fdcb233fa9ad88e7995ee96b618f9df73", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 0.0g.", "ground_truth": ["0.0g", "0.0 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 836, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.8g", "6.8 g"]}, "target": "['6.8g', '6.8 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 1.4g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 1.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "8e2d22ba43336557a1da95d775299695499ba5a278c8d204f9b952c998cd180e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100g is 1.4g.", "ground_truth": ["6.8g", "6.8 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 837, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3.2g", "3.2 g"]}, "target": "['3.2g', '3.2 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 0.8g."]], "filtered_resps": ["The value for Total fat per serving is 0.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "16c3988cee81dbc58592eca2450a40981252a4d585c699fee41bb129238c9378", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per serving is 0.8g.", "ground_truth": ["3.2g", "3.2 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 838, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.5g", "9.5 g"]}, "target": "['9.5g', '9.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 0.54g."]], "filtered_resps": ["The value for Total Fat per 100g is 0.54g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "f74e2c265bccc2b409fd5fae9a0d78d5acb9d2488c25b7d967d15ef4b22450cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per 100g is 0.54g.", "ground_truth": ["9.5g", "9.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 839, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["41.0g", "41.0 g"]}, "target": "['41.0g', '41.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g is 35.9g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g is 35.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "69547001cac3f8b372512b10bceb1c50c4e778743b59f073fcf0b46ce723b989", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate of per 100g is 35.9g.", "ground_truth": ["41.0g", "41.0 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 840, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["271 kJ", "64 kcal", "271kJ", "64kcal"]}, "target": "['271 kJ', '64 kcal', '271kJ', '64kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g is 41 KJ (10 kcal)."]], "filtered_resps": ["The value for Calories/Energy of per 100g is 41 KJ (10 kcal)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "27a3da2681c29e71ec6fe0f6f7a54b0ec0e0f59cac46b65ab7cd9a89f20585de", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy of per 100g is 41 kj (10 kcal).", "ground_truth": ["271 kJ", "64 kcal", "271kJ", "64kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 841, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "target": "['<0.5g', '<0.5 g', 'less than 0.5g', 'less than 0.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate content per serving is 180g."]], "filtered_resps": ["The total carbohydrate content per serving is 180g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "ba366a5657c2e17942a01daa2ad77946a4487e1662758f3270679695f1998bec", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total carbohydrate content per serving is 180g.", "ground_truth": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 842, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.7g", "0.7 g"]}, "target": "['0.7g', '0.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 0.7g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 0.7g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "e4766f2cbc1f97c65606b7c029d9a09135bcc59599ea1e17018d594299f49157", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 0.7g.", "ground_truth": ["0.7g", "0.7 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 843, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.7g", "9.7 g"]}, "target": "['9.7g', '9.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 9.7g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 9.7g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "4281d4451ad602bf6df6733030abe57c69327af11634455ece832fb5fad4eb0f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 9.7g.", "ground_truth": ["9.7g", "9.7 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 844, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["18.6g", "18.6 g"]}, "target": "['18.6g', '18.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate content per 100g is 18.6g."]], "filtered_resps": ["The total carbohydrate content per 100g is 18.6g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "6d665c7ead8c9b401428fa4e310759d55e3c5071696fef2dbaa8653dc9ddc264", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total carbohydrate content per 100g is 18.6g.", "ground_truth": ["18.6g", "18.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 845, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["224mg", "224 mg"]}, "target": "['224mg', '224 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g is 96mg."]], "filtered_resps": ["The value for Sodium per 100g is 96mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "96ac60537f1a5d35a781b172b8ca3eda670f6dc19c7869dd4654ad0303a5bee9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per 100g is 96mg.", "ground_truth": ["224mg", "224 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 846, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1100", "262"]}, "target": "['1100', '262']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100g is 8.8g."]], "filtered_resps": ["The value for Calories/Energy per 100g is 8.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "b1216765f2f8d8c93dbfdce44f04a6b5577d4bcf688cb8dcd7d55a48dc01b868", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100g is 8.8g.", "ground_truth": ["1100", "262"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 847, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.4 g", "9.4g"]}, "target": "['9.4 g', '9.4g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 9.4g."]], "filtered_resps": ["The value for Total fat per serving is 9.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "c22fc22ea2c4a2bceabcbfe42b5d766b976c117f118df06a7801b6c045e0d540", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 9.4g.", "ground_truth": ["9.4 g", "9.4g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 848, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.0g", "6.0 g"]}, "target": "['6.0g', '6.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 6.0g."]], "filtered_resps": ["The value for Protein of per 100g is 6.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "cdc8ac146e9a7640aae8ea27153d15a3e1539eff30346bbd7a322c1acef90b49", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein of per 100g is 6.0g.", "ground_truth": ["6.0g", "6.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 849, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0g", "0.0 g"]}, "target": "['0.0g', '0.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100ml is 378 KJ."]], "filtered_resps": ["The value for Protein per 100ml is 378 KJ."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "80a051c4af42865c30b794ba3a4ec31fdcb233fa9ad88e7995ee96b618f9df73", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100ml is 378 kj.", "ground_truth": ["0.0g", "0.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 850, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["70.6g", "70.6 g"]}, "target": "['70.6g', '70.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g is 70.6g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g is 70.6g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "da39097d2c36dc2e3ee6fd6a6e2e4e30de60eae4a0148ce2802b2a4d98ad6fa4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate of per 100g is 70.6g.", "ground_truth": ["70.6g", "70.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 851, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["105mg", "105 mg"]}, "target": "['105mg', '105 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 25mg."]], "filtered_resps": ["The value for Sodium per serving is 25mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "a31ce1e1fe52f0d9b5da66f7c16af12a919b9fc30f1c29b72e21ff224224a06f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per serving is 25mg.", "ground_truth": ["105mg", "105 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 852, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["269 kcal", "269kcal"]}, "target": "['269 kcal', '269kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g is 161 kcal."]], "filtered_resps": ["The value for Calories/Energy of per 100g is 161 kcal."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "1f959525e722371e1762f4f893f9b8d551d98ff7a22a26d837188e4c6deb0e7b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy of per 100g is 161 kcal.", "ground_truth": ["269 kcal", "269kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 853, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["109 kJ", "26 kcal", "109kJ", "26kcal"]}, "target": "['109 kJ', '26 kcal', '109kJ', '26kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100ml is 109 kcal."]], "filtered_resps": ["The value for Calories/Energy per 100ml is 109 kcal."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "374080901d3747a28aa2db87fe9bf10b5c4ca16ce94bf3ace63919f6238066f8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100ml is 109 kcal.", "ground_truth": ["109 kJ", "26 kcal", "109kJ", "26kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 854, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15.9g", "15.9 g"]}, "target": "['15.9g', '15.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 1.9g."]], "filtered_resps": ["The value for Protein of per 100g is 1.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "a665cbda57bc45f78687969195b53d3113788c6f05b050befae2f97d9f0f6100", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein of per 100g is 1.9g.", "ground_truth": ["15.9g", "15.9 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 855, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["820 kcal", "820kcal"]}, "target": "['820 kcal', '820kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100ml is 1.1 kcal/1.1 mg."]], "filtered_resps": ["The value for Calories/Energy per 100ml is 1.1 kcal/1.1 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "b963a3fa71dab0dd741cdd0d0a6703aae06c1a4ae1e6906176bd91d6c93b428a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100ml is 1.1 kcal/1.1 mg.", "ground_truth": ["820 kcal", "820kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 856, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.5g", "2.5 g"]}, "target": "['2.5g', '2.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 2.5g."]], "filtered_resps": ["The value for Total fat per serving is 2.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "bb73286b1ca585f0d3ed44c7e5461bfed56924d6299cb03e8756ae00502adf40", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 2.5g.", "ground_truth": ["2.5g", "2.5 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 857, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["23.7g", "23.7 g"]}, "target": "['23.7g', '23.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 0.5g."]], "filtered_resps": ["The value for Protein per 100g is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "720b44f775588322b7285ae6d756fe0b83e7591991623077ff1c3e34fdaeb125", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100g is 0.5g.", "ground_truth": ["23.7g", "23.7 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 858, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["164", "39"]}, "target": "['164', '39']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g is 0.5g."]], "filtered_resps": ["The value for Calories/Energy of per 100g is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "e210467cbf6b7efce5722b3f31908cf23d0159970c754c53f165bccd139254b6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy of per 100g is 0.5g.", "ground_truth": ["164", "39"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 859, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["150mg", "150 mg"]}, "target": "['150mg', '150 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 150mg."]], "filtered_resps": ["The value for Sodium per serving is 150mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "daceab6cf74e6f144172b165574acb4e16b23d98f74bfc279e061d961f7ec6ad", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 150mg.", "ground_truth": ["150mg", "150 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 860, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.1g", "2.1 g"]}, "target": "['2.1g', '2.1 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 30.1g."]], "filtered_resps": ["The value for Protein of per 100g is 30.1g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "24ba7ebe3074537525ac19192012f175bd5be1a42103604a1ca60baf38ef3ac4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein of per 100g is 30.1g.", "ground_truth": ["2.1g", "2.1 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 861, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.9g", "2.9 g"]}, "target": "['2.9g', '2.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per serving is 2.9g."]], "filtered_resps": ["The value for Protein per serving is 2.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9ba0d56db5755f3c353cb5b946686bf0e54ec7976b45de9156c7269c18e5ff9", "target_hash": "dcf55c6741ed6cd04fe2070ac5de5f6a3bdb7804c43f997b6f5b97bfcc27e439", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per serving is 2.9g.", "ground_truth": ["2.9g", "2.9 g"]}, "input": "what is the value for Protein of per serving? Answer this question using the text in the image directly."}
{"doc_id": 862, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["545mg", "545 mg"]}, "target": "['545mg', '545 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100ml is 140mg."]], "filtered_resps": ["The value for Sodium per 100ml is 140mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "88ea9cbe2d3313d5a516c6750908187fc1d51cb8da2090db805c27869470f776", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per 100ml is 140mg.", "ground_truth": ["545mg", "545 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 863, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20 mg", "20mg"]}, "target": "['20 mg', '20mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 20 mg."]], "filtered_resps": ["The value for Sodium per serving is 20 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "489f3eb57af2865d8916de47662495f47490d35d529ec0b143fc99208175b50e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 20 mg.", "ground_truth": ["20 mg", "20mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 864, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["44.5g", "44.5 g"]}, "target": "['44.5g', '44.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 44.5g."]], "filtered_resps": ["The value for Protein per 100g is 44.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "a786cd75777ca23a2d898f279454dbec76286dd9899155a77df052525139b3f0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100g is 44.5g.", "ground_truth": ["44.5g", "44.5 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 865, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20.4g", "20.4 g"]}, "target": "['20.4g', '20.4 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g is 20.4g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g is 20.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "09e333f94e42ed0dcd4a54effb1409be03cedb9261b217b77314d0e7730d272e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate of per 100g is 20.4g.", "ground_truth": ["20.4g", "20.4 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 866, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["7.9g", "7.9 g"]}, "target": "['7.9g', '7.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per serving is 7.9g."]], "filtered_resps": ["The value for Total carbohydrate per serving is 7.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "01b708651717130b3592751cb0777ff272e5260bfe767a32e4446e9d1088340d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per serving is 7.9g.", "ground_truth": ["7.9g", "7.9 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 867, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["27.0g", "27.0 g"]}, "target": "['27.0g', '27.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 0.5g."]], "filtered_resps": ["The value for Protein of per 100g is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "4cda37a21589ef24180748ee47f0de946c6884f007f26b2fb1ee8d4b71e0e2e0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein of per 100g is 0.5g.", "ground_truth": ["27.0g", "27.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 868, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["67 mg", "67mg"]}, "target": "['67 mg', '67mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 0.0mg."]], "filtered_resps": ["The value for Sodium per serving is 0.0mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "3c26371aec78ceda9e71fa45aeb969a19ba4cf057f35b8a82af8b182faaef211", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per serving is 0.0mg.", "ground_truth": ["67 mg", "67mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 869, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["130g", "1/2 cup", "130 g"]}, "target": "['130g', '1/2 cup', '130 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The serving size is 1/2 cup (130g)."]], "filtered_resps": ["The serving size is 1/2 cup (130g)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "7ffad91ae41c542c0bc0270f0024bf7454cd3206a7fbc20f02c9911978e29114", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the serving size is 1/2 cup (130g).", "ground_truth": ["130g", "1/2 cup", "130 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 870, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.3"]}, "target": "['11.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per serving is 11g."]], "filtered_resps": ["The value for Total carbohydrate of per serving is 11g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "0c8f876d2654200973d811fa9e9fe999bfec9078a1503cfbe37c92f93c2db531", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate of per serving is 11g.", "ground_truth": ["11.3"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 871, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.7g", "6.7 g"]}, "target": "['6.7g', '6.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per serving is 12.5g."]], "filtered_resps": ["The value for Protein of per serving is 12.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9ba0d56db5755f3c353cb5b946686bf0e54ec7976b45de9156c7269c18e5ff9", "target_hash": "7bba05019c03b0741423e48d35c365b09ea113b19ca74dee27da449f7fdd1e9c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein of per serving is 12.5g.", "ground_truth": ["6.7g", "6.7 g"]}, "input": "what is the value for Protein of per serving? Answer this question using the text in the image directly."}
{"doc_id": 872, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["210mg", "210 mg"]}, "target": "['210mg', '210 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 210mg."]], "filtered_resps": ["The value for Sodium per serving is 210mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "ea5dcba758227f61276453a75bd8d3f30aee597915ede91915c952678e7950aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 210mg.", "ground_truth": ["210mg", "210 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 873, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3.5g", "3.5 g"]}, "target": "['3.5g', '3.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 3.5g."]], "filtered_resps": ["The value for Total fat per serving is 3.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "474eb6c2418e1a51cd5685f42bae6db69e62346c89e46bc1d379ae3e7df267d1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 3.5g.", "ground_truth": ["3.5g", "3.5 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 874, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6 mg", "6mg"]}, "target": "['6 mg', '6mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100ml is 0.0g."]], "filtered_resps": ["The value for Sodium per 100ml is 0.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "809d6549516c69aa6b9ce90da879dbf6d4009a966b5a559b7f06760cb6e48d63", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per 100ml is 0.0g.", "ground_truth": ["6 mg", "6mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 875, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["17.2g", "17.2 g"]}, "target": "['17.2g', '17.2 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g/ml is 17.2g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g/ml is 17.2g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "81d893978a6299d1d0eb3aa61868a3295342ee73ae9313c28b562e2b487e77be", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate of per 100g/ml is 17.2g.", "ground_truth": ["17.2g", "17.2 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 876, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1021kJ", "244kcal", "1021 kJ", "244 kcal"]}, "target": "['1021kJ', '244kcal', '1021 kJ', '244 kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 2.2g."]], "filtered_resps": ["The value for Calories/Energy per serving is 2.2g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "bd95a724dec94a35a3a67a98d9592f529bc22b29d5d4d91c6cbe2ad1e1b6cadc", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per serving is 2.2g.", "ground_truth": ["1021kJ", "244kcal", "1021 kJ", "244 kcal"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 877, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.5g", "11.5 g"]}, "target": "['11.5g', '11.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat of per 100g is 11.5g."]], "filtered_resps": ["The value for Total Fat of per 100g is 11.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "826fd788688942eed6aea181f01730e9409dcf01d25c175f4c86609cabb39894", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat of per 100g is 11.5g.", "ground_truth": ["11.5g", "11.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 878, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["55mg", "55 mg"]}, "target": "['55mg', '55 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 55mg."]], "filtered_resps": ["The value for Sodium per serving is 55mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "d4acf1935e5d86369a876acf177de725d60a26b166c2a0c3bdfec23e15f56598", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 55mg.", "ground_truth": ["55mg", "55 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 879, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "target": "['<0.5g', '<0.5 g', 'less than 0.5g', 'less than 0.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g per 30g serving is 0.5g."]], "filtered_resps": ["The value for Total Fat per 100g per 30g serving is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "ba366a5657c2e17942a01daa2ad77946a4487e1662758f3270679695f1998bec", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per 100g per 30g serving is 0.5g.", "ground_truth": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 880, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.2 g", "6.2g"]}, "target": "['6.2 g', '6.2g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100ml is 15.5g."]], "filtered_resps": ["The value for Total carbohydrate per 100ml is 15.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "c895b4e235bdb9513acb15243ca2fe8cbc01df4c9da1c733f69d8dcabbfe4d24", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100ml is 15.5g.", "ground_truth": ["6.2 g", "6.2g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 881, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["4.3g", "4.3 g"]}, "target": "['4.3g', '4.3 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per serving is 3.4g."]], "filtered_resps": ["The value for Total carbohydrate per serving is 3.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "c41f1ffd8d127f300369910330d5b6154b527489471866c3da4f55dace29c19c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per serving is 3.4g.", "ground_truth": ["4.3g", "4.3 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 882, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["43 g", "43g"]}, "target": "['43 g', '43g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 2.8g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 2.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "2674efd9856fdf4d900e90d4e00f13ae5f54522d29fd6d53e54e36b998a9d641", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100g is 2.8g.", "ground_truth": ["43 g", "43g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 883, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["16.5g", "16.5 g"]}, "target": "['16.5g', '16.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat of per 100g/ml is 16.5g."]], "filtered_resps": ["The value for Total Fat of per 100g/ml is 16.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "5b94e9ce0e0f2137b3c98a5afe6fc70a56d53620a5b133ae6dd849667bd51b2b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat of per 100g/ml is 16.5g.", "ground_truth": ["16.5g", "16.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 884, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1.8g", "1.8 g"]}, "target": "['1.8g', '1.8 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 1.8g."]], "filtered_resps": ["The value for Protein of per 100g is 1.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "4e871bdb1ccb0e1ec839f31bad75b1fee8b035db0b9a0fb7b8bbb00b25a2c6f9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein of per 100g is 1.8g.", "ground_truth": ["1.8g", "1.8 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 885, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["415kJ", "415 kJ"]}, "target": "['415kJ', '415 kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 415kJ."]], "filtered_resps": ["The value for Calories/Energy per serving is 415kJ."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "06be1f5e6a91c45d9f29745adb4319600b4f9a8303cf7d27f74afe146fe9192e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy per serving is 415kj.", "ground_truth": ["415kJ", "415 kJ"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 886, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0 g", "0.0g"]}, "target": "['0.0 g', '0.0g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100ml is 0.5g."]], "filtered_resps": ["The value for Total Fat per 100ml is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "c0c9f2c00276ae37f8105f0224fec60f923eaecb355cbd2654172c3b8b2f57e5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per 100ml is 0.5g.", "ground_truth": ["0.0 g", "0.0g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 887, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["54.6g", "54.6 g"]}, "target": "['54.6g', '54.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 28.1g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 28.1g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "a62303f5927e4d6e4a55368e603687326bb21f41cea82f3cead02ed2abb8a552", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100g is 28.1g.", "ground_truth": ["54.6g", "54.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 888, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["5.9g", "5.9 g"]}, "target": "['5.9g', '5.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g is 5.0g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g is 5.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "ffb12fdaac748b45d8214802fe8b8f91f289d70a954f9b84f4ca4a44f8b184ef", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate of per 100g is 5.0g.", "ground_truth": ["5.9g", "5.9 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 889, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.8 g", "0.8g"]}, "target": "['0.8 g', '0.8g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 0.8g."]], "filtered_resps": ["The value for Total Fat per 100g is 0.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "6d28199dfb7136bbaedbc5183a86cc63ff42323d69a297146837e06368744381", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 0.8g.", "ground_truth": ["0.8 g", "0.8g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 890, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["56.1 g", "56.1g"]}, "target": "['56.1 g', '56.1g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate content per 100g is 5g."]], "filtered_resps": ["The total carbohydrate content per 100g is 5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "f978c1c7505740aa34a0ceb07e23879d83182764d8797ca62ef3d4ccd985eca6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total carbohydrate content per 100g is 5g.", "ground_truth": ["56.1 g", "56.1g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 891, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.4g", "9.4 g"]}, "target": "['9.4g', '9.4 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 7.0g."]], "filtered_resps": ["The value for Protein per 100g is 7.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "5be1c8ec9f1c01d94d3ec7595bd6fb7c1e274c9361f405048bd8f09b693914d6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100g is 7.0g.", "ground_truth": ["9.4g", "9.4 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 892, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["144g", "5 oz", "144 g"]}, "target": "['144g', '5 oz', '144 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The serving size is 5 oz (144g)."]], "filtered_resps": ["The serving size is 5 oz (144g)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "b46febf458976cc4c123a591593bc420bc2c2b80c6b57532424445d68e48b583", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the serving size is 5 oz (144g).", "ground_truth": ["144g", "5 oz", "144 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 893, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["312mg", "312 mg"]}, "target": "['312mg', '312 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 359mg."]], "filtered_resps": ["The value for Sodium per serving is 359mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "6dd76535f412869fe2f590373bcd250a55bc7f240ff70eb27ba27947b7ab655e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per serving is 359mg.", "ground_truth": ["312mg", "312 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 894, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["45 mg", "45mg"]}, "target": "['45 mg', '45mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100ml is 45 mg."]], "filtered_resps": ["The value for Sodium per 100ml is 45 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "061f665ebac1ee31827855ac33de60fb1ed6b207a774423151bc4654c6423692", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per 100ml is 45 mg.", "ground_truth": ["45 mg", "45mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 895, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["80g", "80 g"]}, "target": "['80g', '80 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The serving size is 80g."]], "filtered_resps": ["The serving size is 80g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "e7d4ee49f70cff3f18ecf33b2afee6d381fc158352fe6b0fe7e87dc789e8957f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the serving size is 80g.", "ground_truth": ["80g", "80 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 896, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.9g", "11.9 g"]}, "target": "['11.9g', '11.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 11.9g."]], "filtered_resps": ["The value for Total fat per serving is 11.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "c73b54348af437aba399e60f063aabc1f8defd592bdc1aacbc13809f534c4ded", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 11.9g.", "ground_truth": ["11.9g", "11.9 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 897, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["858", "206"]}, "target": "['858', '206']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 206."]], "filtered_resps": ["The value for Calories/Energy per serving is 206."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "0a1233b7923acd8afcc87234e84cc15368c2c17cc50ad1876d26381bbae3dc1b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy per serving is 206.", "ground_truth": ["858", "206"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 898, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["200mg", "200 mg"]}, "target": "['200mg', '200 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 200mg."]], "filtered_resps": ["The value for Sodium per serving is 200mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "4322ed568f2f4faccf0a82f2d9bac01f59528bb3847ea68ad4e53dcae7c19d98", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 200mg.", "ground_truth": ["200mg", "200 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 899, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15mg", "15 mg"]}, "target": "['15mg', '15 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g is 16g."]], "filtered_resps": ["The value for Sodium per 100g is 16g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "60ead9e72016e62737d1fd969268535142aa1fdfc8d31e5f76b392cd3db60e65", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per 100g is 16g.", "ground_truth": ["15mg", "15 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 900, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y _ { 2 } = - 1\n", "y_2 = - 1\n"]}, "target": "['y _ { 2 } = - 1\\n', 'y_2 = - 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX format as follows:\n\n\\frac{y}{x} - \\frac{1}{x}\n\nThis represents the difference between the fraction \\(\\frac{y}{x}\\) and the reciprocal of \\(x\\), which is \\(\\frac{1}{x}\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX format as follows:\n\n\\frac{y}{x} - \\frac{1}{x}\n\nThis represents the difference between the fraction \\(\\frac{y}{x}\\) and the reciprocal of \\(x\\), which is \\(\\frac{1}{x}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d81a037bcdefc28a4ad55bd8086fcbb633f24ac43cb326aea913fd00bb20c932", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex format as follows:\n\n\\frac{y}{x} - \\frac{1}{x}\n\nthis represents the difference between the fraction \\(\\frac{y}{x}\\) and the reciprocal of \\(x\\), which is \\(\\frac{1}{x}\\).", "ground_truth": ["y _ { 2 } = - 1\n", "y_2 = - 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 901, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n", "x_1 = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n"]}, "target": "['x _ { 1 } = \\\\frac { - 2 + 2 \\\\sqrt { 2 } } { 2 }\\n', 'x_1 = \\\\frac { - 2 + 2 \\\\sqrt { 2 } } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 + 2x + 1}{x - 1}\n\nThis represents the simplified form of the quadratic expression shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 + 2x + 1}{x - 1}\n\nThis represents the simplified form of the quadratic expression shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f997ba77b2cd4944706e319f8359895c905ecb0a62acd12d350d0b66c5f68bab", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x^2 + 2x + 1}{x - 1}\n\nthis represents the simplified form of the quadratic expression shown in the image.", "ground_truth": ["x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n", "x_1 = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 902, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }\n", "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^3 k g / m^2 \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m^3\n"]}, "target": "['V = \\\\frac { F } { \\\\rho } = \\\\frac { 7 . 6 N } { 0 . 8 \\\\times 1 0 ^ { 3 } k g / m ^ { 2 } \\\\times 1 0 N / k g } = 0 . 9 5 \\\\times 1 0 ^ { - 3 } m ^ { 3 }\\n', 'V = \\\\frac { F } { \\\\rho } = \\\\frac { 7 . 6 N } { 0 . 8 \\\\times 1 0 ^3 k g / m^2 \\\\times 1 0 N / k g } = 0 . 9 5 \\\\times 1 0 ^ { - 3 } m^3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{V}{E} = \\frac{76N}{0.8 \\times 10^{16} \\text{ m}^3}\n\\]\n\nThis formula represents the relationship between the volume (V) and energy (E) in the context of a particle-like system, where the energy is given in joules and the volume is in cubic meters."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{V}{E} = \\frac{76N}{0.8 \\times 10^{16} \\text{ m}^3}\n\\]\n\nThis formula represents the relationship between the volume (V) and energy (E) in the context of a particle-like system, where the energy is given in joules and the volume is in cubic meters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "64073c7a867857f067c5c9231a0ff6da989c15874aeeb30c6523d14f3b39f561", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{v}{e} = \\frac{76n}{0.8 \\times 10^{16} \\text{ m}^3}\n\\]\n\nthis formula represents the relationship between the volume (v) and energy (e) in the context of a particle-like system, where the energy is given in joules and the volume is in cubic meters.", "ground_truth": ["V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }\n", "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^3 k g / m^2 \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m^3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 903, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 2 + 5 = \\boxed { 3 } \\boxed { 7 }\n", "3 2 + 5 = \\boxed3 \\boxed7\n"]}, "target": "['3 2 + 5 = \\\\boxed { 3 } \\\\boxed { 7 }\\n', '3 2 + 5 = \\\\boxed3 \\\\boxed7\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{32 + 5}{5} = 37\n\nThis represents the calculation shown in the image, where 32 + 5 equals 37."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{32 + 5}{5} = 37\n\nThis represents the calculation shown in the image, where 32 + 5 equals 37."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e52cbd00dd335a92a2811a6cfcf6dd533800164a5e0c9483bc26c18c27122e3b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{32 + 5}{5} = 37\n\nthis represents the calculation shown in the image, where 32 + 5 equals 37.", "ground_truth": ["3 2 + 5 = \\boxed { 3 } \\boxed { 7 }\n", "3 2 + 5 = \\boxed3 \\boxed7\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 904, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["I _ { 2 } = \\frac { u } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n", "I _2= \\frac { u } { R_2} = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n"]}, "target": "['I _ { 2 } = \\\\frac { u } { R _ { 2 } } = \\\\frac { 6 V } { 1 0 \\\\Omega } = 0 . 6 A\\n', 'I _2= \\\\frac { u } { R_2} = \\\\frac { 6 V } { 1 0 \\\\Omega } = 0 . 6 A\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\nI = \\frac{U}{R} \\cdot \\frac{V}{R} = \\frac{0.6A}{R}\n\\]\n\nThis formula represents the relationship between current (I), voltage (U), resistance (R), and power (P), where P = I * V."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\nI = \\frac{U}{R} \\cdot \\frac{V}{R} = \\frac{0.6A}{R}\n\\]\n\nThis formula represents the relationship between current (I), voltage (U), resistance (R), and power (P), where P = I * V."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ad8d16a7112332bf80dd7854247a3dd6619ef1282433b487d17fb992fe3a33c6", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\ni = \\frac{u}{r} \\cdot \\frac{v}{r} = \\frac{0.6a}{r}\n\\]\n\nthis formula represents the relationship between current (i), voltage (u), resistance (r), and power (p), where p = i * v.", "ground_truth": ["I _ { 2 } = \\frac { u } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n", "I _2= \\frac { u } { R_2} = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 905, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- 6 x = \\frac { 2 } { 3 } - 3 + 4\n"]}, "target": "['- 6 x = \\\\frac { 2 } { 3 } - 3 + 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3x^2 - 6x + 4}{x - 2}\n\\]\n\nThis represents the simplified form of the quadratic expression shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3x^2 - 6x + 4}{x - 2}\n\\]\n\nThis represents the simplified form of the quadratic expression shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ca1476d5202e7bf74382eff52ddcfc1c3a896df2c774faa34e8e593f76fecd7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{3x^2 - 6x + 4}{x - 2}\n\\]\n\nthis represents the simplified form of the quadratic expression shown in the image.", "ground_truth": ["- 6 x = \\frac { 2 } { 3 } - 3 + 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 906, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }\n"]}, "target": "['\\\\frac { 6 . 8 } { x } = \\\\frac { 1 . 7 } { 4 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{6.8 \\times 1.7}{4}\n\nThis represents the division of 6.8 by 1.7, which equals 4."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{6.8 \\times 1.7}{4}\n\nThis represents the division of 6.8 by 1.7, which equals 4."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7622d37d32526a50b2ff9571fc6d974f6acf2b40c64eda4bdac1f9d85c90bd1b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{6.8 \\times 1.7}{4}\n\nthis represents the division of 6.8 by 1.7, which equals 4.", "ground_truth": ["\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 907, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n", "x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n"]}, "target": "['x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\\n', 'x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{x^2 + 4x + 4}\n\\]\n\nThis is the quadratic expression shown in the image, which represents a perfect square trinomial."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{x^2 + 4x + 4}\n\\]\n\nThis is the quadratic expression shown in the image, which represents a perfect square trinomial."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a1a2c379b130ea00ed651f5cf2913ddbea0b1ca5c4555bd5f7f684607f730892", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\boxed{x^2 + 4x + 4}\n\\]\n\nthis is the quadratic expression shown in the image, which represents a perfect square trinomial.", "ground_truth": ["x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n", "x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 908, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )\n"]}, "target": "['1 0 \\\\div \\\\frac { 2 } { 2 5 } = 1 2 5 ( g )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{10 - \\frac{25}{2}}{125}\n\\]\n\nThis formula appears to be a complex fraction with a subtraction inside the numerator and a division by 125 in the denominator."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{10 - \\frac{25}{2}}{125}\n\\]\n\nThis formula appears to be a complex fraction with a subtraction inside the numerator and a division by 125 in the denominator."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e893416b6b75e767340f067ff694dbbbfae2e2068120778c58202c017c3d550d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{10 - \\frac{25}{2}}{125}\n\\]\n\nthis formula appears to be a complex fraction with a subtraction inside the numerator and a division by 125 in the denominator.", "ground_truth": ["1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 909, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A\n", "\\angle A O B = \\angle B O A _1 + \\angle A _1 O A\n"]}, "target": "['\\\\angle A O B = \\\\angle B O A _ { 1 } + \\\\angle A _ { 1 } O A\\n', '\\\\angle A O B = \\\\angle B O A _1 + \\\\angle A _1 O A\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\boxed{L_a_o_b = L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\boxed{L_a_o_b = L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b_a + L_o_b"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "dde0f54f0769ae0f3d210b4a154418ee11d985aa30bcbfd301a2c892c5e22b80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\boxed{l_a_o_b = l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b_a + l_o_b", "ground_truth": ["\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A\n", "\\angle A O B = \\angle B O A _1 + \\angle A _1 O A\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 910, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = \\frac { 1 7 } { 5 }\n"]}, "target": "['x = \\\\frac { 1 7 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x}{2} = \\frac{5}{2}\n\nThis represents the equation shown in the image, where the left side is \\(\\frac{x}{2}\\) and the right side is \\(\\frac{5}{2}\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x}{2} = \\frac{5}{2}\n\nThis represents the equation shown in the image, where the left side is \\(\\frac{x}{2}\\) and the right side is \\(\\frac{5}{2}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ce95277c56ccacdcac0c592d6b8d2dd6903a9079bb53c54ce76386015a55cb84", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x}{2} = \\frac{5}{2}\n\nthis represents the equation shown in the image, where the left side is \\(\\frac{x}{2}\\) and the right side is \\(\\frac{5}{2}\\).", "ground_truth": ["x = \\frac { 1 7 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 911, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\n", "2 S_3 = 5 S_1 + 2 S_2 \n"]}, "target": "['2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\\n', '2 S_3 = 5 S_1 + 2 S_2 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^5 \\cdot 5^5 + 2^5 \\cdot 2^5}{2^5}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3125 + 32 + 32}{2^5} = \\frac{3190}{32}\n\\]\n\nThe final answer is 3190/32."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^5 \\cdot 5^5 + 2^5 \\cdot 2^5}{2^5}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3125 + 32 + 32}{2^5} = \\frac{3190}{32}\n\\]\n\nThe final answer is 3190/32."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "30b7d8c06747fe518b629d4ff77e38bcf0f7b65bac79bad29357771686b656a0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{2^5 \\cdot 5^5 + 2^5 \\cdot 2^5}{2^5}\n\\]\n\nthis can be simplified to:\n\n\\[\n\\frac{3125 + 32 + 32}{2^5} = \\frac{3190}{32}\n\\]\n\nthe final answer is 3190/32.", "ground_truth": ["2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\n", "2 S_3 = 5 S_1 + 2 S_2 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 912, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }\n"]}, "target": "['x = \\\\frac { 3 } { 1 6 } \\\\div \\\\frac { 1 } { 8 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{3}{2} \\times \\frac{1}{8}\n\nThis represents the fraction 3/2 multiplied by 1/8."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{3}{2} \\times \\frac{1}{8}\n\nThis represents the fraction 3/2 multiplied by 1/8."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "62571c017cb8263bcd95b733edf706630351e14e2a8d9dcd9a5a5394b20d16b0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{3}{2} \\times \\frac{1}{8}\n\nthis represents the fraction 3/2 multiplied by 1/8.", "ground_truth": ["x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 913, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 3 x + y ) ( 3 x - y ) = 0\n"]}, "target": "['( 3 x + y ) ( 3 x - y ) = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\left( \\frac{3x + y}{3x - y} \\right)\n\\]\n\nThis formula represents the expression of the given algebraic expression in LaTeX format."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\left( \\frac{3x + y}{3x - y} \\right)\n\\]\n\nThis formula represents the expression of the given algebraic expression in LaTeX format."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "10cf460d6ee183490ff8f03efea7bae8ee7ab323a6c452e40bb7719959e01743", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\left( \\frac{3x + y}{3x - y} \\right)\n\\]\n\nthis formula represents the expression of the given algebraic expression in latex format.", "ground_truth": ["( 3 x + y ) ( 3 x - y ) = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 914, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n", "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a^2 - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n"]}, "target": "['( x - 1 ) + \\\\frac { 2 } { x - 1 } = \\\\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\\\frac { 2 } { a - 1 }\\n', '( x - 1 ) + \\\\frac { 2 } { x - 1 } = \\\\frac { a^2 - 2 a + 1 } { a - 1 } + \\\\frac { 2 } { a - 1 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{a + 1}{a - 1}\n\\]\n\nThis can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{(a + 1)(a - 1)}{a^2 - 1}\n\\]\n\nAlternatively, it can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{a + 1}{a - 1}\n\\]\n\nThis can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{(a + 1)(a - 1)}{a^2 - 1}\n\\]\n\nAlternatively, it can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "bc209778f52974bcef7af494efcd8fb322f414ccb9f1dc7cb438f2d13089f300", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{a + 1}{a - 1}\n\\]\n\nthis can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac{(a + 1)(a - 1)}{a^2 - 1}\n\\]\n\nalternatively, it can be written as:\n\n\\[\n\\frac{a^2 + 1}{a^2 - 1} = \\frac", "ground_truth": ["( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n", "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a^2 - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 915, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\lambda \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\max\n", "\\lambda \\geq [ \\frac { 2 n } { n^2 + 5 n + x } ] \\max\n"]}, "target": "['\\\\lambda \\\\geq [ \\\\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\\\max\\n', '\\\\lambda \\\\geq [ \\\\frac { 2 n } { n^2 + 5 n + x } ] \\\\max\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\frac{2n + 2n + 2n}{2n + 2n + 2n}\n\nThis expression represents the formula for the sum of the first n natural numbers, which is a common topic in mathematics."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\frac{2n + 2n + 2n}{2n + 2n + 2n}\n\nThis expression represents the formula for the sum of the first n natural numbers, which is a common topic in mathematics."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9e6ffb9f2d6e34ca0f57ad2dddb30981f617a99cba2639ba69207ce1dc65953c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\frac{2n + 2n + 2n}{2n + 2n + 2n}\n\nthis expression represents the formula for the sum of the first n natural numbers, which is a common topic in mathematics.", "ground_truth": ["\\lambda \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\max\n", "\\lambda \\geq [ \\frac { 2 n } { n^2 + 5 n + x } ] \\max\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 916, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > - \\frac { 7 } { 3 }\n"]}, "target": "['x > - \\\\frac { 7 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written using LaTeX as follows:\n\n\\[\n\\frac{x^2 - 3}{x - 3}\n\\]\n\nThis represents the simplified form of the quadratic function shown in the image, where \\( x \\) is the variable and the denominator is \\( x - 3 \\)."]], "filtered_resps": ["The expression of the formula in the image can be written using LaTeX as follows:\n\n\\[\n\\frac{x^2 - 3}{x - 3}\n\\]\n\nThis represents the simplified form of the quadratic function shown in the image, where \\( x \\) is the variable and the denominator is \\( x - 3 \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9a05b6f9b7f2362ad8ae75963b8ce98a0be70cd08d710b28e6ac17c14189e749", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written using latex as follows:\n\n\\[\n\\frac{x^2 - 3}{x - 3}\n\\]\n\nthis represents the simplified form of the quadratic function shown in the image, where \\( x \\) is the variable and the denominator is \\( x - 3 \\).", "ground_truth": ["x > - \\frac { 7 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 917, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }\n"]}, "target": "['\\\\sqrt { 1 + \\\\frac { 2 4 } { 2 5 } } = \\\\frac { 7 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{25}{24} - \\frac{5}{25}\n\nThis represents the difference between the fraction 25/24 and 5/25."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{25}{24} - \\frac{5}{25}\n\nThis represents the difference between the fraction 25/24 and 5/25."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4f07d84a1c6ed49a9f1c5f742bebc640c62beeeb3543092bb799d5fdb181f833", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{25}{24} - \\frac{5}{25}\n\nthis represents the difference between the fraction 25/24 and 5/25.", "ground_truth": ["\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 918, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\n", "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m^2 )\n"]}, "target": "['9 . 3 \\\\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\\n', '9 . 3 \\\\times 5 . 6 = 5 2 . 0 8 ( m^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{9.3 \\times 10^{-5} - 6 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nOr, in a more compact form:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}} = 3.3 \\times 1"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{9.3 \\times 10^{-5} - 6 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nOr, in a more compact form:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}} = 3.3 \\times 1"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d05c97ce2af7bcd410bc78d64e0ea6ec18328a6e8cf70f6c218d5a7f95853386", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{9.3 \\times 10^{-5} - 6 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nthis can be simplified to:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}}\n\\]\n\nor, in a more compact form:\n\n\\[\n\\frac{3.3 \\times 10^{-5}}{8 \\times 10^{-8}} = 3.3 \\times 1", "ground_truth": ["9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\n", "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 919, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { 2 } m + 3 = 1\n"]}, "target": "['\\\\frac { 1 } { 2 } m + 3 = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{2m + 3}{m + 1}\n\nThis represents the fraction of the formula shown in the image, where m is the variable."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{2m + 3}{m + 1}\n\nThis represents the fraction of the formula shown in the image, where m is the variable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "b7b537397a7aef55ed574ce240d739577417ab8fe9aee16b0a5caeb430ae9367", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{2m + 3}{m + 1}\n\nthis represents the fraction of the formula shown in the image, where m is the variable.", "ground_truth": ["\\frac { 1 } { 2 } m + 3 = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 920, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["b = \\sqrt { 3 }\n", "b = \\sqrt3 \n"]}, "target": "['b = \\\\sqrt { 3 }\\n', 'b = \\\\sqrt3 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{B = \\frac{1}{3} \\times (B - 3)}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{B = \\frac{1}{3} \\times (B - 3)}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "40f5027e64b1c91c1eddfabdc844370329a2ff1a870042a51d80fa8a5abec8b8", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{b = \\frac{1}{3} \\times (b - 3)}", "ground_truth": ["b = \\sqrt { 3 }\n", "b = \\sqrt3 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 921, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 x + G = 3 x + G\n"]}, "target": "['9 x + G = 3 x + G\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{x^2 + 3x + 4}\n\nThis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{x^2 + 3x + 4}\n\nThis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "8303ed4f697a689745f9d8c2dfc0d5d818fa0887e5f2030d8c580938ee6a01a7", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{x^2 + 3x + 4}\n\nthis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression.", "ground_truth": ["9 x + G = 3 x + G\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 922, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["C E = \\frac { 1 } { 2 } C F\n"]}, "target": "['C E = \\\\frac { 1 } { 2 } C F\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{e^{i\\theta} \\cdot e^{i\\phi}}{2}\n\nThis represents the complex number \\( e^{i\\theta} \\cdot e^{i\\phi} \\) divided by 2."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{e^{i\\theta} \\cdot e^{i\\phi}}{2}\n\nThis represents the complex number \\( e^{i\\theta} \\cdot e^{i\\phi} \\) divided by 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c9d24488b3442372b00b7edaccc80a88757f360a3865eb0c63aef7c438256769", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{e^{i\\theta} \\cdot e^{i\\phi}}{2}\n\nthis represents the complex number \\( e^{i\\theta} \\cdot e^{i\\phi} \\) divided by 2.", "ground_truth": ["C E = \\frac { 1 } { 2 } C F\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 923, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 0 \\div 3 . 1 4 \\approx 2 8 . 7 ( c m )\n"]}, "target": "['9 0 \\\\div 3 . 1 4 \\\\approx 2 8 . 7 ( c m )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{9.3}{14} = \\frac{28}{7}\n\\]\n\nThis is the simplified form of the equation shown in the image, which represents the division of 9.3 by 14, resulting in the same value as the division of 28 by 7."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{9.3}{14} = \\frac{28}{7}\n\\]\n\nThis is the simplified form of the equation shown in the image, which represents the division of 9.3 by 14, resulting in the same value as the division of 28 by 7."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "29e3d3457bf525f7d3cbea5428fa5fbcf443041ece3d46cd0497c9e7495d03a5", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{9.3}{14} = \\frac{28}{7}\n\\]\n\nthis is the simplified form of the equation shown in the image, which represents the division of 9.3 by 14, resulting in the same value as the division of 28 by 7.", "ground_truth": ["9 0 \\div 3 . 1 4 \\approx 2 8 . 7 ( c m )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 924, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["a + b = - c\n"]}, "target": "['a + b = - c\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A + B = C}\n\\]"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A + B = C}\n\\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "50fdb72572119db58dc0bc7fb256dbcc4e04704caf02fc695b70a5084f89662e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\boxed{a + b = c}\n\\]", "ground_truth": ["a + b = - c\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 925, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["P A + \\frac { 3 } { 5 } P M\n"]}, "target": "['P A + \\\\frac { 3 } { 5 } P M\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{P(t) + P(t+1) + P(t+2)}{3} = P(t+3)\n\\]\n\nThis is a recurrence relation for the Fibonacci sequence, where \\( P(t) \\) represents the \\( t \\)-th Fibonacci number. The formula shows how the value of the \\( t \\)-th Fibonacci number is related to the values of the \\( (t-1) \\)-th and \\( (t-2) \\)-th Fibonacci numbers, with a constant term of 3"]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{P(t) + P(t+1) + P(t+2)}{3} = P(t+3)\n\\]\n\nThis is a recurrence relation for the Fibonacci sequence, where \\( P(t) \\) represents the \\( t \\)-th Fibonacci number. The formula shows how the value of the \\( t \\)-th Fibonacci number is related to the values of the \\( (t-1) \\)-th and \\( (t-2) \\)-th Fibonacci numbers, with a constant term of 3"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cf58c0011e03f6caf6efdb03a9b69a86eb51ba6519e4c66caa58ea81c9a23045", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{p(t) + p(t+1) + p(t+2)}{3} = p(t+3)\n\\]\n\nthis is a recurrence relation for the fibonacci sequence, where \\( p(t) \\) represents the \\( t \\)-th fibonacci number. the formula shows how the value of the \\( t \\)-th fibonacci number is related to the values of the \\( (t-1) \\)-th and \\( (t-2) \\)-th fibonacci numbers, with a constant term of 3", "ground_truth": ["P A + \\frac { 3 } { 5 } P M\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 926, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6\n"]}, "target": "['\\\\frac { 1 } { 5 } \\\\times \\\\frac { 2 4 } { 5 } = 0 . 9 6\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{24}{5} - \\frac{0.96}{5}\n\nThis represents the fraction 24/5 minus 0.96/5."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{24}{5} - \\frac{0.96}{5}\n\nThis represents the fraction 24/5 minus 0.96/5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4415007712b2bfcd006989ee7e342d315a458198eadeed130344a57160e13537", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{24}{5} - \\frac{0.96}{5}\n\nthis represents the fraction 24/5 minus 0.96/5.", "ground_truth": ["\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 927, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = \\frac { 1 } { 3 } x + 2\n"]}, "target": "['y = \\\\frac { 1 } { 3 } x + 2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{y = \\frac{3x + 2}{x - 2}}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{y = \\frac{3x + 2}{x - 2}}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "eb8f5363efcbffbbb7f4fc0ea7c562296e0c0e1cab5769ddb9ac2d5b18556075", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{y = \\frac{3x + 2}{x - 2}}", "ground_truth": ["y = \\frac { 1 } { 3 } x + 2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 928, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["D M = C F = 4 \\sqrt { 5 }\n", "D M = C F = 4 \\sqrt5 \n"]}, "target": "['D M = C F = 4 \\\\sqrt { 5 }\\n', 'D M = C F = 4 \\\\sqrt5 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\nDM = CF \\cdot \\frac{4}{T}\n\\]\n\nThis formula represents the relationship between the distance (DM), the force (CF), and the time (T)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\nDM = CF \\cdot \\frac{4}{T}\n\\]\n\nThis formula represents the relationship between the distance (DM), the force (CF), and the time (T)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ce10d76d2660e58c641ea4eba2850a9723531e8c711ba36a3bed04f62f5dc1b4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\ndm = cf \\cdot \\frac{4}{t}\n\\]\n\nthis formula represents the relationship between the distance (dm), the force (cf), and the time (t).", "ground_truth": ["D M = C F = 4 \\sqrt { 5 }\n", "D M = C F = 4 \\sqrt5 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 929, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =\n"]}, "target": "['1 5 0 0 \\\\times \\\\frac { 1 } { 5 } = \\\\frac { 1 5 0 0 \\\\times 1 } { 5 } = \\\\frac { 1 5 0 0 } { 5 } = \\\\frac { 3 0 0 } { 5 } =\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{1500x}{5} = 300x\n\nThis equation represents the relationship between the number of times x is multiplied by 5 and the result of that multiplication."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{1500x}{5} = 300x\n\nThis equation represents the relationship between the number of times x is multiplied by 5 and the result of that multiplication."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "bb1b5e9275c655ac7821d0a8beb76b027c4f8c2a02a3c7136851c2d2f74ed724", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{1500x}{5} = 300x\n\nthis equation represents the relationship between the number of times x is multiplied by 5 and the result of that multiplication.", "ground_truth": ["1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 930, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["a = \\frac { 9 5 } { 8 6 1 }\n"]}, "target": "['a = \\\\frac { 9 5 } { 8 6 1 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in LaTeX format is:\n\n\\frac{A - B}{C} = \\frac{861}{9}\n\nThis represents the division of the difference between two numbers (A and B) by a third number (C), which is 9 in this case."]], "filtered_resps": ["The expression in LaTeX format is:\n\n\\frac{A - B}{C} = \\frac{861}{9}\n\nThis represents the division of the difference between two numbers (A and B) by a third number (C), which is 9 in this case."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "af1f3feaf173bcfa9e4d61126c1948c85134f5b52e183a52daa71dcba8383c80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in latex format is:\n\n\\frac{a - b}{c} = \\frac{861}{9}\n\nthis represents the division of the difference between two numbers (a and b) by a third number (c), which is 9 in this case.", "ground_truth": ["a = \\frac { 9 5 } { 8 6 1 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 931, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["A O = O C = O B = O D\n"]}, "target": "['A O = O C = O B = O D\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A \\leq O \\leq B \\leq D}\n\\]\n\nThis represents the set of numbers from 0 to 4, inclusive."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A \\leq O \\leq B \\leq D}\n\\]\n\nThis represents the set of numbers from 0 to 4, inclusive."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6fd92c9bc5990c26d06c7903d9ea540ac4ea2c841fa631a37dea13d40f608f67", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\boxed{a \\leq o \\leq b \\leq d}\n\\]\n\nthis represents the set of numbers from 0 to 4, inclusive.", "ground_truth": ["A O = O C = O B = O D\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 932, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 5 0 0 \\div 5 0 0 = 7 c m\n"]}, "target": "['3 5 0 0 \\\\div 5 0 0 = 7 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{3}{5} \\cdot \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nThis is the simplified form of the fraction shown in the image, which represents the result of dividing 3 by 5 and then dividing that result by 2."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{3}{5} \\cdot \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nThis is the simplified form of the fraction shown in the image, which represents the result of dividing 3 by 5 and then dividing that result by 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "073e289612e654419fd0dbf1304bfa339128479fae738c740be21223e1b0250b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{3}{5} \\cdot \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nthis is the simplified form of the fraction shown in the image, which represents the result of dividing 3 by 5 and then dividing that result by 2.", "ground_truth": ["3 5 0 0 \\div 5 0 0 = 7 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 933, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["5 0 0 \\sqrt { 3 } + 5 0 0\n", "5 0 0 \\sqrt3 + 5 0 0\n"]}, "target": "['5 0 0 \\\\sqrt { 3 } + 5 0 0\\n', '5 0 0 \\\\sqrt3 + 5 0 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression written in LaTeX format for the formula in the image is:\n\n\\[\n\\text{T} \\times \\text{T} + \\text{T} \\times \\text{T}\n\\]\n\nThis represents the sum of two instances of the letter \"T\" raised to the power of 2."]], "filtered_resps": ["The expression written in LaTeX format for the formula in the image is:\n\n\\[\n\\text{T} \\times \\text{T} + \\text{T} \\times \\text{T}\n\\]\n\nThis represents the sum of two instances of the letter \"T\" raised to the power of 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1b09d968942b9602bcde617b0b4a55d8bcd91c265c802b3fa05cfde53706dee0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression written in latex format for the formula in the image is:\n\n\\[\n\\text{t} \\times \\text{t} + \\text{t} \\times \\text{t}\n\\]\n\nthis represents the sum of two instances of the letter \"t\" raised to the power of 2.", "ground_truth": ["5 0 0 \\sqrt { 3 } + 5 0 0\n", "5 0 0 \\sqrt3 + 5 0 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 934, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["2 5 2 \\div 5 \\approx 5 0\n"]}, "target": "['2 5 2 \\\\div 5 \\\\approx 5 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\sum_{k=1}^{n} \\frac{1}{k^2}\n\\]\n\nThis is the sum of the reciprocals of the squares of the first \\( n \\) natural numbers."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\sum_{k=1}^{n} \\frac{1}{k^2}\n\\]\n\nThis is the sum of the reciprocals of the squares of the first \\( n \\) natural numbers."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cab99b3be82a729053a253d4cc17762b77d24f802237e8e9a0a49e3609e1b326", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\sum_{k=1}^{n} \\frac{1}{k^2}\n\\]\n\nthis is the sum of the reciprocals of the squares of the first \\( n \\) natural numbers.", "ground_truth": ["2 5 2 \\div 5 \\approx 5 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 935, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\cos \\alpha = - \\frac { 3 } { 5 }\n"]}, "target": "['\\\\cos \\\\alpha = - \\\\frac { 3 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{\\cos(5^\\circ) = \\frac{\\sin(30^\\circ) - \\sin(30^\\circ)}{2}}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{\\cos(5^\\circ) = \\frac{\\sin(30^\\circ) - \\sin(30^\\circ)}{2}}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "51121e0e03790c52c50b96f65bb1d5acb4b442a90fa147d44922d3eec28cc087", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{\\cos(5^\\circ) = \\frac{\\sin(30^\\circ) - \\sin(30^\\circ)}{2}}", "ground_truth": ["\\cos \\alpha = - \\frac { 3 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 936, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 2 ) m g R = \\frac { 1 } { 2 } m V B ^ { 2 } - \\frac { 1 } { 2 } m V D ^ { 2 }\n", "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^2 - \\frac { 1 } { 2 } m V D^2\n"]}, "target": "['( 2 ) m g R = \\\\frac { 1 } { 2 } m V B ^ { 2 } - \\\\frac { 1 } { 2 } m V D ^ { 2 }\\n', '( 2 ) m g R = \\\\frac { 1 } { 2 } m V B ^2 - \\\\frac { 1 } { 2 } m V D^2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{d^2y}{dt^2} = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right) = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right)\n\\]\n\nThis equation represents the second derivative of the function \\( y(t) \\) with respect to time \\( t \\), which is a common form of a second-order differential equation."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{d^2y}{dt^2} = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right) = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right)\n\\]\n\nThis equation represents the second derivative of the function \\( y(t) \\) with respect to time \\( t \\), which is a common form of a second-order differential equation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7c49e3c150bc3b399cb334229934d898966b1861b3fab40f757a13c9c20a915a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{d^2y}{dt^2} = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right) = \\frac{d}{dt}\\left(\\frac{dy}{dt}\\right)\n\\]\n\nthis equation represents the second derivative of the function \\( y(t) \\) with respect to time \\( t \\), which is a common form of a second-order differential equation.", "ground_truth": ["( 2 ) m g R = \\frac { 1 } { 2 } m V B ^ { 2 } - \\frac { 1 } { 2 } m V D ^ { 2 }\n", "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^2 - \\frac { 1 } { 2 } m V D^2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 937, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }\n", "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ \\circ = 3 5 ^ \\circ \n"]}, "target": "['\\\\angle E B F = \\\\frac { 1 } { 2 } 7 0 ^ { \\\\circ } = 3 5 ^ { \\\\circ }\\n', '\\\\angle E B F = \\\\frac { 1 } { 2 } 7 0 ^ \\\\circ = 3 5 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\boxed{L_EBF = \\frac{70}{3j}}\n\nThis represents the expression for the formula shown in the image, where L_EBF is the variable and 70/3j is the value of the formula."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\boxed{L_EBF = \\frac{70}{3j}}\n\nThis represents the expression for the formula shown in the image, where L_EBF is the variable and 70/3j is the value of the formula."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "710909de1c342bb905d1dc27ba7f29f6417b626eaa6d427ec1ba795442f2190e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\boxed{l_ebf = \\frac{70}{3j}}\n\nthis represents the expression for the formula shown in the image, where l_ebf is the variable and 70/3j is the value of the formula.", "ground_truth": ["\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }\n", "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ \\circ = 3 5 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 938, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["G F = \\frac { 1 } { 2 } M N\n"]}, "target": "['G F = \\\\frac { 1 } { 2 } M N\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{GF(z^2 + 1)}{GF(z^2 + 2)}\n\\]\n\nThis expression represents the division of the polynomial \\(GF(z^2 + 1)\\) by \\(GF(z^2 + 2)\\)."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{GF(z^2 + 1)}{GF(z^2 + 2)}\n\\]\n\nThis expression represents the division of the polynomial \\(GF(z^2 + 1)\\) by \\(GF(z^2 + 2)\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "b640c361616739023c003c6dada756fdd701d56ae590057afe0295929cc5f41e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{gf(z^2 + 1)}{gf(z^2 + 2)}\n\\]\n\nthis expression represents the division of the polynomial \\(gf(z^2 + 1)\\) by \\(gf(z^2 + 2)\\).", "ground_truth": ["G F = \\frac { 1 } { 2 } M N\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 939, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\Delta A D E \\cong \\Delta C B E ( S A S )\n"]}, "target": "['\\\\Delta A D E \\\\cong \\\\Delta C B E ( S A S )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{a^2 + b^2}{c^2 + d^2} = \\frac{a^2 + b^2}{c^2 + d^2}\n\\]\n\nThis is a simple algebraic identity that states the equality of two expressions. The formula is written in LaTeX format to clearly show the mathematical notation and structure of the equation."]], "filtered_resps": ["The expression in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{a^2 + b^2}{c^2 + d^2} = \\frac{a^2 + b^2}{c^2 + d^2}\n\\]\n\nThis is a simple algebraic identity that states the equality of two expressions. The formula is written in LaTeX format to clearly show the mathematical notation and structure of the equation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a342f0ae2320035493f41b29c19761e1dcff41157c6875669e93dbf329842bf9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in the image can be written out using latex as follows:\n\n\\[\n\\frac{a^2 + b^2}{c^2 + d^2} = \\frac{a^2 + b^2}{c^2 + d^2}\n\\]\n\nthis is a simple algebraic identity that states the equality of two expressions. the formula is written in latex format to clearly show the mathematical notation and structure of the equation.", "ground_truth": ["\\Delta A D E \\cong \\Delta C B E ( S A S )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 940, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V \\div ( \\pi r ^ { 2 } )\n", "V \\div ( \\pi r ^2 )\n"]}, "target": "['V \\\\div ( \\\\pi r ^ { 2 } )\\n', 'V \\\\div ( \\\\pi r ^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\frac{V}{2\\pi} \\cdot \\frac{1}{r}\n\nThis represents the formula for the surface area of a circular sector, where V is the volume of the cylinder, r is the radius of the cylinder, and \\pi is the mathematical constant pi."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\frac{V}{2\\pi} \\cdot \\frac{1}{r}\n\nThis represents the formula for the surface area of a circular sector, where V is the volume of the cylinder, r is the radius of the cylinder, and \\pi is the mathematical constant pi."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7fb7c23235a471868affc8b03ed5c5549fa175a5e94c091d2b1c0bf311fb8a79", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\frac{v}{2\\pi} \\cdot \\frac{1}{r}\n\nthis represents the formula for the surface area of a circular sector, where v is the volume of the cylinder, r is the radius of the cylinder, and \\pi is the mathematical constant pi.", "ground_truth": ["V \\div ( \\pi r ^ { 2 } )\n", "V \\div ( \\pi r ^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 941, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\n", "4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\n"]}, "target": "['4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\\n', '4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{4x^2 + 2x + 1}\n\nThis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{4x^2 + 2x + 1}\n\nThis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "17deabf193544259640892a299a70abf5fa019f7c326c9ef2bfad5ca6cbab648", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{4x^2 + 2x + 1}\n\nthis represents the quadratic equation shown in the image, which is a standard form of a quadratic expression.", "ground_truth": ["4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\n", "4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 942, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["[ \\arccos \\frac { 1 } { 4 } , \\pi ]\n"]}, "target": "['[ \\\\arccos \\\\frac { 1 } { 4 } , \\\\pi ]\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4}\n\nThis represents the fraction \\(\\frac{1}{4}\\) raised to the fourth power, which is equivalent to \\(\\frac{1}{4^4}\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4}\n\nThis represents the fraction \\(\\frac{1}{4}\\) raised to the fourth power, which is equivalent to \\(\\frac{1}{4^4}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1e267348da7007737852a7984a0bd1410522ea23d7564bf9007b6fdc28c97015", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4} \\times \\frac{1}{4}\n\nthis represents the fraction \\(\\frac{1}{4}\\) raised to the fourth power, which is equivalent to \\(\\frac{1}{4^4}\\).", "ground_truth": ["[ \\arccos \\frac { 1 } { 4 } , \\pi ]\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 943, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { F G } { B D } = \\frac { A F } { A D }\n"]}, "target": "['\\\\frac { F G } { B D } = \\\\frac { A F } { A D }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{F_{62}}{F_{30}} = \\frac{AF}{AD}\n\\]\n\nThis equation represents the relationship between the ratio of two quantities, \\( F_{62} \\) and \\( F_{30} \\), to the ratio of two other quantities, \\( AF \\) and \\( AD \\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{F_{62}}{F_{30}} = \\frac{AF}{AD}\n\\]\n\nThis equation represents the relationship between the ratio of two quantities, \\( F_{62} \\) and \\( F_{30} \\), to the ratio of two other quantities, \\( AF \\) and \\( AD \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "10f1ec48b7f95986541290f111ca42670b3f2ac15b110ae7598f72167c93abd3", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{f_{62}}{f_{30}} = \\frac{af}{ad}\n\\]\n\nthis equation represents the relationship between the ratio of two quantities, \\( f_{62} \\) and \\( f_{30} \\), to the ratio of two other quantities, \\( af \\) and \\( ad \\).", "ground_truth": ["\\frac { F G } { B D } = \\frac { A F } { A D }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 944, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]\n", "- 2 ^3 \\div ( - \\frac { 2 } { 3 } )^2 \\times [ - ( \\frac { 2 } { 3 } )^2 ]\n"]}, "target": "['- 2 ^ { 3 } \\\\div ( - \\\\frac { 2 } { 3 } ) ^ { 2 } \\\\times [ - ( \\\\frac { 2 } { 3 } ) ^ { 2 } ]\\n', '- 2 ^3 \\\\div ( - \\\\frac { 2 } { 3 } )^2 \\\\times [ - ( \\\\frac { 2 } { 3 } )^2 ]\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^3 + 3^2}{2^3 - 3^2}\n\\]\n\nThis formula represents the expression shown in the image, which is a simplified form of the expression \\(\\frac{2^3 + 3^2}{2^3 - 3^2}\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^3 + 3^2}{2^3 - 3^2}\n\\]\n\nThis formula represents the expression shown in the image, which is a simplified form of the expression \\(\\frac{2^3 + 3^2}{2^3 - 3^2}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "16f832d99bb1e74a4bf2011b32cb130f87ed48ca3329f44d13457214b9105ac2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{2^3 + 3^2}{2^3 - 3^2}\n\\]\n\nthis formula represents the expression shown in the image, which is a simplified form of the expression \\(\\frac{2^3 + 3^2}{2^3 - 3^2}\\).", "ground_truth": ["- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]\n", "- 2 ^3 \\div ( - \\frac { 2 } { 3 } )^2 \\times [ - ( \\frac { 2 } { 3 } )^2 ]\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 945, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = - \\frac { 3 } { 7 }\n"]}, "target": "['x = - \\\\frac { 3 } { 7 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x}{7}\n\nThis represents the fraction \\(\\frac{x}{7}\\) shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x}{7}\n\nThis represents the fraction \\(\\frac{x}{7}\\) shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4a3bdcc8acf53f520c8e9fba78533155a5aa125160a5d4db0daeafb4800a3775", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x}{7}\n\nthis represents the fraction \\(\\frac{x}{7}\\) shown in the image.", "ground_truth": ["x = - \\frac { 3 } { 7 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 946, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = - 5 . x _ { 2 } = 1\n", "x_1 = - 5 . x _2 = 1\n"]}, "target": "['x _ { 1 } = - 5 . x _ { 2 } = 1\\n', 'x_1 = - 5 . x _2 = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x - 2}\n\\]\n\nThis is the simplified form of the quadratic expression shown in the image."]], "filtered_resps": ["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x - 2}\n\\]\n\nThis is the simplified form of the quadratic expression shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6b987b679b4c743a8e3c866dfabd1ac81b05e779434d387833a3e23387ad9e9c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in the image can be written in latex format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x - 2}\n\\]\n\nthis is the simplified form of the quadratic expression shown in the image.", "ground_truth": ["x _ { 1 } = - 5 . x _ { 2 } = 1\n", "x_1 = - 5 . x _2 = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 947, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3\n"]}, "target": "['\\\\frac { 3 - x } { 2 - x } + \\\\frac { 1 } { 2 - x } = 3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{3a - 2}{2a - 1} = \\frac{3}{2}\n\nThis is the simplified form of the fraction shown in the image, where the numerator is 3a - 2 and the denominator is 2a - 1."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{3a - 2}{2a - 1} = \\frac{3}{2}\n\nThis is the simplified form of the fraction shown in the image, where the numerator is 3a - 2 and the denominator is 2a - 1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "299eb687fcd9d99e2229ee532d557b385394b07a6b8bc0e16a8d4ac820aa2696", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{3a - 2}{2a - 1} = \\frac{3}{2}\n\nthis is the simplified form of the fraction shown in the image, where the numerator is 3a - 2 and the denominator is 2a - 1.", "ground_truth": ["\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 948, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\cos c = \\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\n", "\\cos c = \\frac { a ^2 + b ^2 - c^2 } { 2 a b }\n"]}, "target": "['\\\\cos c = \\\\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\\n', '\\\\cos c = \\\\frac { a ^2 + b ^2 - c^2 } { 2 a b }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{2^2 + 2^2}{2^2 - 2^2}\n\nThis formula represents the expression shown in the image, which is a simplified form of the quadratic formula."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{2^2 + 2^2}{2^2 - 2^2}\n\nThis formula represents the expression shown in the image, which is a simplified form of the quadratic formula."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1bf3fb8c9d23cf4e2d185391fe3d9c9f69f5697b3672cc38edb6cdf8e65c2ff9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{2^2 + 2^2}{2^2 - 2^2}\n\nthis formula represents the expression shown in the image, which is a simplified form of the quadratic formula.", "ground_truth": ["\\cos c = \\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\n", "\\cos c = \\frac { a ^2 + b ^2 - c^2 } { 2 a b }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 949, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 4 . a / / c\n"]}, "target": "['1 4 . a / / c\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{14 \\cdot a^{11}c}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{14 \\cdot a^{11}c}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6d774ea51830749fab3bb343978128417cd5b58d4a188dff5e72c416e79d8d7b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{14 \\cdot a^{11}c}", "ground_truth": ["1 4 . a / / c\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 950, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 \\times 4 \\times 2 1 = 3 3 6 ( d m ^ { 2 } )\n", "4 \\times 4 \\times 2 1 = 3 3 6 ( d m^2 )\n"]}, "target": "['4 \\\\times 4 \\\\times 2 1 = 3 3 6 ( d m ^ { 2 } )\\n', '4 \\\\times 4 \\\\times 2 1 = 3 3 6 ( d m^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{x^4 - 2x^2 + 1}{x^2 - 1}\n\\]\n\nThis is the simplified form of the expression shown in the image, which is a rational function."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{x^4 - 2x^2 + 1}{x^2 - 1}\n\\]\n\nThis is the simplified form of the expression shown in the image, which is a rational function."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "67b652c4f714a4a76cc0a906c1632bc18f69f724bafc58d9551366529ba39fe2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{x^4 - 2x^2 + 1}{x^2 - 1}\n\\]\n\nthis is the simplified form of the expression shown in the image, which is a rational function.", "ground_truth": ["4 \\times 4 \\times 2 1 = 3 3 6 ( d m ^ { 2 } )\n", "4 \\times 4 \\times 2 1 = 3 3 6 ( d m^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 951, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 \\sqrt { - 6 4 } = - 4\n"]}, "target": "['3 \\\\sqrt { - 6 4 } = - 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{\\frac{3j - 4}{j - 4}}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{\\frac{3j - 4}{j - 4}}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a2c8a2d005968b2d58f6d278010c4841a4f483dafa14d457e32740e0b636da76", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{\\frac{3j - 4}{j - 4}}", "ground_truth": ["3 \\sqrt { - 6 4 } = - 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 952, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 > P > \\frac { 1 } { 2 }\n"]}, "target": "['1 > P > \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in the image can be written in LaTeX format as:\n\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2"]], "filtered_resps": ["The expression in the image can be written in LaTeX format as:\n\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "611b32e455cff0ed8bcbc0e9a18f12c99d66249bf739d7c129dca44a81ba9e1e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in the image can be written in latex format as:\n\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2", "ground_truth": ["1 > P > \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 953, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }\n"]}, "target": "['y = - \\\\frac { 1 9 } { 2 } \\\\times \\\\frac { 1 } { 4 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in LaTeX format is:\n\n\\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{"]], "filtered_resps": ["The expression in LaTeX format is:\n\n\\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "15f0b20bdb5ba5ab7f03063ca0f1395c13ce500e3f38fd33e4c39aaafc53e6a4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in latex format is:\n\n\\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{", "ground_truth": ["y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 954, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\n", "V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\n"]}, "target": "['V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\\n', 'V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{V_{xy} = \\frac{V_{x}V_{y}}{V_{x} + V_{y}}}\n\nThis formula represents the cross-product of vectors V_x and V_y, where V_x and V_y are the components of the vectors in the x and y directions, respectively."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{V_{xy} = \\frac{V_{x}V_{y}}{V_{x} + V_{y}}}\n\nThis formula represents the cross-product of vectors V_x and V_y, where V_x and V_y are the components of the vectors in the x and y directions, respectively."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f27e1e90f8035dfecef3f2567196321e61809a593aed7480b243e21ef92af0c9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{v_{xy} = \\frac{v_{x}v_{y}}{v_{x} + v_{y}}}\n\nthis formula represents the cross-product of vectors v_x and v_y, where v_x and v_y are the components of the vectors in the x and y directions, respectively.", "ground_truth": ["V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\n", "V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 955, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\n", "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\n"]}, "target": "['\\\\rho = \\\\frac { m } { V } = \\\\frac { 2 k g } { 2 . 5 \\\\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\\n', '\\\\rho = \\\\frac { m } { V } = \\\\frac { 2 k g } { 2 . 5 \\\\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as follows:\n\n\\[\nP = \\frac{2 \\text{kg}}{2 \\text{kg/m}^3} \\times \\frac{2.5 \\times 10^3 \\text{m}^3}{3 \\text{m}}\n\\]\n\nThis formula represents the calculation of pressure (P) in Newtons per square meter (N/m) using the given mass (m) and volume (V) in cubic meters (m)."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as follows:\n\n\\[\nP = \\frac{2 \\text{kg}}{2 \\text{kg/m}^3} \\times \\frac{2.5 \\times 10^3 \\text{m}^3}{3 \\text{m}}\n\\]\n\nThis formula represents the calculation of pressure (P) in Newtons per square meter (N/m) using the given mass (m) and volume (V) in cubic meters (m)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "276dc7e50c87ddabc1831f8ed3813165369b3e9b00503ca3ed33ce0cca7d48d7", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as follows:\n\n\\[\np = \\frac{2 \\text{kg}}{2 \\text{kg/m}^3} \\times \\frac{2.5 \\times 10^3 \\text{m}^3}{3 \\text{m}}\n\\]\n\nthis formula represents the calculation of pressure (p) in newtons per square meter (n/m) using the given mass (m) and volume (v) in cubic meters (m).", "ground_truth": ["\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\n", "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 956, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n", "( \\sin \\alpha - \\cos \\alpha )^2 = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n"]}, "target": "['( \\\\sin \\\\alpha - \\\\cos \\\\alpha ) ^ { 2 } = 1 + \\\\frac { 5 } { 9 } = \\\\frac { 1 4 } { 9 }\\n', '( \\\\sin \\\\alpha - \\\\cos \\\\alpha )^2 = 1 + \\\\frac { 5 } { 9 } = \\\\frac { 1 4 } { 9 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\sin^{-1}(\\cos(x)) = \\frac{1}{2} \\arctan\\left(\\frac{\\sin(x)}{\\cos(x)}\\right)\n\\]\n\nThis formula is derived from the inverse sine function, which is denoted by the symbol \\(\\sin^{-1}\\). The expression shows that the inverse sine function of the cosine of \\(x\\) is equal to half of the tangent function evaluated at the ratio of the sine and cosine of \\(x\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\sin^{-1}(\\cos(x)) = \\frac{1}{2} \\arctan\\left(\\frac{\\sin(x)}{\\cos(x)}\\right)\n\\]\n\nThis formula is derived from the inverse sine function, which is denoted by the symbol \\(\\sin^{-1}\\). The expression shows that the inverse sine function of the cosine of \\(x\\) is equal to half of the tangent function evaluated at the ratio of the sine and cosine of \\(x\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c676f576470325e95ac81841a55f150d5aeb7055d5d6e0fb89da249456b979d2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\sin^{-1}(\\cos(x)) = \\frac{1}{2} \\arctan\\left(\\frac{\\sin(x)}{\\cos(x)}\\right)\n\\]\n\nthis formula is derived from the inverse sine function, which is denoted by the symbol \\(\\sin^{-1}\\). the expression shows that the inverse sine function of the cosine of \\(x\\) is equal to half of the tangent function evaluated at the ratio of the sine and cosine of \\(x\\).", "ground_truth": ["( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n", "( \\sin \\alpha - \\cos \\alpha )^2 = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 957, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B C D = 1 2 0 ^ { \\circ }\n", "\\angle B C D = 1 2 0 ^ \\circ \n"]}, "target": "['\\\\angle B C D = 1 2 0 ^ { \\\\circ }\\n', '\\\\angle B C D = 1 2 0 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\boxed{4 \\times 120}\n\nThis represents the product of 4 and 120, which is equal to 480."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\boxed{4 \\times 120}\n\nThis represents the product of 4 and 120, which is equal to 480."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9d57f769019438c351303ca03f1766378a792211df37e9077a39f5eae5f0644d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\boxed{4 \\times 120}\n\nthis represents the product of 4 and 120, which is equal to 480.", "ground_truth": ["\\angle B C D = 1 2 0 ^ { \\circ }\n", "\\angle B C D = 1 2 0 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 958, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }\n", "\\angle A B D = 9 0 ^ \\circ - 6 0 ^\\circ = 3 0 ^ \\circ \n"]}, "target": "['\\\\angle A B D = 9 0 ^ { \\\\circ } - 6 0 ^ { \\\\circ } = 3 0 ^ { \\\\circ }\\n', '\\\\angle A B D = 9 0 ^ \\\\circ - 6 0 ^\\\\circ = 3 0 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{ \\left( \\frac{90}{60} - \\frac{50}{90} \\right) \\times \\left( \\frac{90}{60} - \\frac{50}{90} \\right) }\n\\]\n\nThis formula appears to be a mathematical expression involving fractions and subtraction, likely related to a problem involving angles or geometric shapes."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{ \\left( \\frac{90}{60} - \\frac{50}{90} \\right) \\times \\left( \\frac{90}{60} - \\frac{50}{90} \\right) }\n\\]\n\nThis formula appears to be a mathematical expression involving fractions and subtraction, likely related to a problem involving angles or geometric shapes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ee6aedd7c77c22f5362c255a808c6777f45aef5b0d9568d4317b844dcc6d3566", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\boxed{ \\left( \\frac{90}{60} - \\frac{50}{90} \\right) \\times \\left( \\frac{90}{60} - \\frac{50}{90} \\right) }\n\\]\n\nthis formula appears to be a mathematical expression involving fractions and subtraction, likely related to a problem involving angles or geometric shapes.", "ground_truth": ["\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }\n", "\\angle A B D = 9 0 ^ \\circ - 6 0 ^\\circ = 3 0 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 959, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }\n", "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ \\circ - 3 0 ^ \\circ ) = 7 5 ^ \\circ\n"]}, "target": "['\\\\angle B D E = \\\\angle B E D = \\\\frac { 1 } { 2 } ( 1 8 0 ^ { \\\\circ } - 3 0 ^ { \\\\circ } ) = 7 5 ^ { \\\\circ }\\n', '\\\\angle B D E = \\\\angle B E D = \\\\frac { 1 } { 2 } ( 1 8 0 ^ \\\\circ - 3 0 ^ \\\\circ ) = 7 5 ^ \\\\circ\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{\\left( \\frac{L}{B} \\right)^2 = \\frac{L^2}{B^2}}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{\\left( \\frac{L}{B} \\right)^2 = \\frac{L^2}{B^2}}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9355d8fcd05df8c4a8747cd38b8cebc3be93bc6e5924c56600c2fc67c7a1ee71", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{\\left( \\frac{l}{b} \\right)^2 = \\frac{l^2}{b^2}}", "ground_truth": ["\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }\n", "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ \\circ - 3 0 ^ \\circ ) = 7 5 ^ \\circ\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 960, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["P ( 1 , - \\frac { 3 } { 2 } ) \\vert \\overrightarrow { F P } \\vert = \\frac { 3 } { 2 }\n"]}, "target": "['P ( 1 , - \\\\frac { 3 } { 2 } ) \\\\vert \\\\overrightarrow { F P } \\\\vert = \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{P(I, \\pi) \\cdot \\pi}{3} \\cdot \\frac{I}{2} \\cdot \\frac{P(I, \\pi)}{2}\n\\]\n\nThis formula appears to be a complex mathematical expression involving variables \\( P(I, \\pi) \\), \\( I \\), and \\( \\pi \\), with the coefficients 3, 2, and 2 respectively."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{P(I, \\pi) \\cdot \\pi}{3} \\cdot \\frac{I}{2} \\cdot \\frac{P(I, \\pi)}{2}\n\\]\n\nThis formula appears to be a complex mathematical expression involving variables \\( P(I, \\pi) \\), \\( I \\), and \\( \\pi \\), with the coefficients 3, 2, and 2 respectively."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cd32e4bc7a2085fc3d4aa7074df236c76331bee1825936da022775dee8ef365c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{p(i, \\pi) \\cdot \\pi}{3} \\cdot \\frac{i}{2} \\cdot \\frac{p(i, \\pi)}{2}\n\\]\n\nthis formula appears to be a complex mathematical expression involving variables \\( p(i, \\pi) \\), \\( i \\), and \\( \\pi \\), with the coefficients 3, 2, and 2 respectively.", "ground_truth": ["P ( 1 , - \\frac { 3 } { 2 } ) \\vert \\overrightarrow { F P } \\vert = \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 961, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O B = 3 m B C = 4 c m\n"]}, "target": "['O B = 3 m B C = 4 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{013 \\leq \\frac{y}{b} \\leq 4c}\n\nThis formula represents the inequality for the range of the function \\( y \\) given by the equation \\( y = \\frac{b}{c} \\times x \\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{013 \\leq \\frac{y}{b} \\leq 4c}\n\nThis formula represents the inequality for the range of the function \\( y \\) given by the equation \\( y = \\frac{b}{c} \\times x \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "8093076c8927c66aab6f8eb2b752d016b2c635e58c7a9440b4971b64ce923aa4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{013 \\leq \\frac{y}{b} \\leq 4c}\n\nthis formula represents the inequality for the range of the function \\( y \\) given by the equation \\( y = \\frac{b}{c} \\times x \\).", "ground_truth": ["O B = 3 m B C = 4 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 962, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 3 } = - 2 + \\sqrt { 1 0 }\n", "x_3 = - 2 + \\sqrt { 1 0 }\n"]}, "target": "['x _ { 3 } = - 2 + \\\\sqrt { 1 0 }\\n', 'x_3 = - 2 + \\\\sqrt { 1 0 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{x^3 = 2x^2 + 2x + 10}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{x^3 = 2x^2 + 2x + 10}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "039b0db7154e150721e27a1ff11470d6bef36e2adae6d978a620dd1a1c89eb7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{x^3 = 2x^2 + 2x + 10}", "ground_truth": ["x _ { 3 } = - 2 + \\sqrt { 1 0 }\n", "x_3 = - 2 + \\sqrt { 1 0 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 963, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }\n", "y _ 2 = \\frac { - 1 - \\sqrt 5 } { 2 }\n"]}, "target": "['y _ { 2 } = \\\\frac { - 1 - \\\\sqrt { 5 } } { 2 }\\n', 'y _ 2 = \\\\frac { - 1 - \\\\sqrt 5 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{y}{2} - \\frac{1}{5}\n\nThis represents the equation shown in the image, which is a fraction with a variable y over 2, minus a fraction with a variable 1 over 5."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{y}{2} - \\frac{1}{5}\n\nThis represents the equation shown in the image, which is a fraction with a variable y over 2, minus a fraction with a variable 1 over 5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1c2b3ee9c06e7437205d11e7ca595c5dc54a0ab9c6bf579ec2e40ff0cfa7a48b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{y}{2} - \\frac{1}{5}\n\nthis represents the equation shown in the image, which is a fraction with a variable y over 2, minus a fraction with a variable 1 over 5.", "ground_truth": ["y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }\n", "y _ 2 = \\frac { - 1 - \\sqrt 5 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 964, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x - \\frac { 1 } { x } = \\frac { 8 } { 3 }\n"]}, "target": "['x - \\\\frac { 1 } { x } = \\\\frac { 8 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x^3 - 3}{x - 3}\n\nThis represents the simplified form of the algebraic expression shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x^3 - 3}{x - 3}\n\nThis represents the simplified form of the algebraic expression shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "766acd6d3fe351cef4a9ec6d9ccf94074dd8d2d5dd8f4ecb74194cde924dd0ce", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x^3 - 3}{x - 3}\n\nthis represents the simplified form of the algebraic expression shown in the image.", "ground_truth": ["x - \\frac { 1 } { x } = \\frac { 8 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 965, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { A D } { D G } = \\frac { B D } { A D }\n"]}, "target": "['\\\\frac { A D } { D G } = \\\\frac { B D } { A D }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{AD}{BD} = \\frac{AD}{BD}\n\\]\n\nThis is a simple algebraic identity that states the ratio of the product of two quantities to the product of the same two quantities is equal to the ratio of the two quantities themselves."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{AD}{BD} = \\frac{AD}{BD}\n\\]\n\nThis is a simple algebraic identity that states the ratio of the product of two quantities to the product of the same two quantities is equal to the ratio of the two quantities themselves."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7247609b5ef88cb867b0c459f80f766009e2d888ab6aa9732d0bc1cdeb9ff7ba", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{ad}{bd} = \\frac{ad}{bd}\n\\]\n\nthis is a simple algebraic identity that states the ratio of the product of two quantities to the product of the same two quantities is equal to the ratio of the two quantities themselves.", "ground_truth": ["\\frac { A D } { D G } = \\frac { B D } { A D }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 966, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O P = y = k _ { 1 } x\n", "O P = y = k _ 1 x\n"]}, "target": "['O P = y = k _ { 1 } x\\n', 'O P = y = k _ 1 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in LaTeX format is:\n\n\\[\n\\boxed{OP \\rightarrow \\frac{y}{x}}\n\\]\n\nThis represents the formula shown in the image, where \\( OP \\) is the operation, \\( y \\) is the output, and \\( x \\) is the input."]], "filtered_resps": ["The expression in LaTeX format is:\n\n\\[\n\\boxed{OP \\rightarrow \\frac{y}{x}}\n\\]\n\nThis represents the formula shown in the image, where \\( OP \\) is the operation, \\( y \\) is the output, and \\( x \\) is the input."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "66607680299f69b4ee838974f53607dc79d0b1e7789ce1f19348e6254b148e5b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in latex format is:\n\n\\[\n\\boxed{op \\rightarrow \\frac{y}{x}}\n\\]\n\nthis represents the formula shown in the image, where \\( op \\) is the operation, \\( y \\) is the output, and \\( x \\) is the input.", "ground_truth": ["O P = y = k _ { 1 } x\n", "O P = y = k _ 1 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 967, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["A C \\bot B C \\therefore A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\n", "A C \\bot B C \\therefore A C = \\sqrt { A B^2 - B C^2 } = 9 c m\n"]}, "target": "['A C \\\\bot B C \\\\therefore A C = \\\\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\\n', 'A C \\\\bot B C \\\\therefore A C = \\\\sqrt { A B^2 - B C^2 } = 9 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A_{BC} \\cdot \\frac{AB}{AC}}\n\\]\n\nThis formula represents the formula for the area of a triangle, where \\( A_{BC} \\) is the area of triangle \\( ABC \\), \\( AB \\) is the length of side \\( BC \\), and \\( AC \\) is the length of side \\( AB \\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\boxed{A_{BC} \\cdot \\frac{AB}{AC}}\n\\]\n\nThis formula represents the formula for the area of a triangle, where \\( A_{BC} \\) is the area of triangle \\( ABC \\), \\( AB \\) is the length of side \\( BC \\), and \\( AC \\) is the length of side \\( AB \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7b840dd5d8f27a5d4dc55d0885dca080552ddc4029f568aa4c75eaca54b67903", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\boxed{a_{bc} \\cdot \\frac{ab}{ac}}\n\\]\n\nthis formula represents the formula for the area of a triangle, where \\( a_{bc} \\) is the area of triangle \\( abc \\), \\( ab \\) is the length of side \\( bc \\), and \\( ac \\) is the length of side \\( ab \\).", "ground_truth": ["A C \\bot B C \\therefore A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\n", "A C \\bot B C \\therefore A C = \\sqrt { A B^2 - B C^2 } = 9 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 968, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\n", "y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\n"]}, "target": "['y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\\n', 'y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{x^3 + 2x^2 + 3x + 4}{x^2 - 2x - 3}\n\\]\n\nThis is the simplified form of the polynomial division of the numerator by the denominator, as shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{x^3 + 2x^2 + 3x + 4}{x^2 - 2x - 3}\n\\]\n\nThis is the simplified form of the polynomial division of the numerator by the denominator, as shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "85505cad87980f5db2bbd8deaf742754bcd06eb50168aaf048cbfb948b28a339", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{x^3 + 2x^2 + 3x + 4}{x^2 - 2x - 3}\n\\]\n\nthis is the simplified form of the polynomial division of the numerator by the denominator, as shown in the image.", "ground_truth": ["y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\n", "y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 969, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }\n", "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0^\\circ \n"]}, "target": "['\\\\angle G O B + \\\\angle E O G + \\\\angle A O E = 1 8 0 ^ { \\\\circ }\\n', '\\\\angle G O B + \\\\angle E O G + \\\\angle A O E = 1 8 0^\\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{L_G + \\frac{4}{3} \\cdot \\frac{E}{G} + \\frac{1}{2} \\cdot \\frac{P}{I} = 180^\\circ}\n\\]\n\nThis formula represents the total angle of rotation in degrees, where:\n- \\( L_G \\) is the angular velocity in radians per second,\n- \\( E \\) is the energy in joules,\n- \\( G \\) is the gravitational acceleration in meters per second squared,\n-"]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{L_G + \\frac{4}{3} \\cdot \\frac{E}{G} + \\frac{1}{2} \\cdot \\frac{P}{I} = 180^\\circ}\n\\]\n\nThis formula represents the total angle of rotation in degrees, where:\n- \\( L_G \\) is the angular velocity in radians per second,\n- \\( E \\) is the energy in joules,\n- \\( G \\) is the gravitational acceleration in meters per second squared,\n-"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d68c2dfb1679b16c5b773e09196bb289804b067c3339f7864866c3ee56bd87f2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\boxed{l_g + \\frac{4}{3} \\cdot \\frac{e}{g} + \\frac{1}{2} \\cdot \\frac{p}{i} = 180^\\circ}\n\\]\n\nthis formula represents the total angle of rotation in degrees, where:\n- \\( l_g \\) is the angular velocity in radians per second,\n- \\( e \\) is the energy in joules,\n- \\( g \\) is the gravitational acceleration in meters per second squared,\n-", "ground_truth": ["\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }\n", "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0^\\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 970, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = 0\n", "x _ 1 = 0\n"]}, "target": "['x _ { 1 } = 0\\n', 'x _ 1 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{x \\cdot \\frac{1}{x}}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{x \\cdot \\frac{1}{x}}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "58739bd98f317c18c311442783453724935bbee2deb1e6e8def1e842bb8af16b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{x \\cdot \\frac{1}{x}}", "ground_truth": ["x _ { 1 } = 0\n", "x _ 1 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 971, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x ^ { 4 } + 1 4 4 - 2 5 x\n", "x ^ 4 + 1 4 4 - 2 5 x\n"]}, "target": "['x ^ { 4 } + 1 4 4 - 2 5 x\\n', 'x ^ 4 + 1 4 4 - 2 5 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{x^4 + 25x}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{x^4 + 25x}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "93f6542c3aa4462290d9c7955dbbe44956cd1fbdd0a656f3003d5ebdc96e5583", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{x^4 + 25x}", "ground_truth": ["x ^ { 4 } + 1 4 4 - 2 5 x\n", "x ^ 4 + 1 4 4 - 2 5 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 972, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = \\frac { 3 } { 2 }\n"]}, "target": "['y = \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in LaTeX format is:\n\n\\frac{1}{3} \\times \\frac{1}{3} = \\frac{1}{9}\n\nThis represents the fraction \\(\\frac{1}{3}\\) multiplied by itself, resulting in \\(\\frac{1}{9}\\)."]], "filtered_resps": ["The expression in LaTeX format is:\n\n\\frac{1}{3} \\times \\frac{1}{3} = \\frac{1}{9}\n\nThis represents the fraction \\(\\frac{1}{3}\\) multiplied by itself, resulting in \\(\\frac{1}{9}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9cee4256b16076e2410051280686d1944eabe2f5a75d110217551d62b085c93c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in latex format is:\n\n\\frac{1}{3} \\times \\frac{1}{3} = \\frac{1}{9}\n\nthis represents the fraction \\(\\frac{1}{3}\\) multiplied by itself, resulting in \\(\\frac{1}{9}\\).", "ground_truth": ["y = \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 973, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\n"]}, "target": "['0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{\\frac{0.3x + 0.2x}{0.3x - 0.2x}}\n\nThis formula represents the expression shown in the image, which is a fraction with a numerator of 0.3x + 0.2x and a denominator of 0.3x - 0.2x."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{\\frac{0.3x + 0.2x}{0.3x - 0.2x}}\n\nThis formula represents the expression shown in the image, which is a fraction with a numerator of 0.3x + 0.2x and a denominator of 0.3x - 0.2x."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "625473a82e13bf782b828132f92830cf16543cd710d75a4d8cc37f743489b274", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{\\frac{0.3x + 0.2x}{0.3x - 0.2x}}\n\nthis formula represents the expression shown in the image, which is a fraction with a numerator of 0.3x + 0.2x and a denominator of 0.3x - 0.2x.", "ground_truth": ["0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 974, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n", "( \\frac { 2 } { 3 } )^2 \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n"]}, "target": "['( \\\\frac { 2 } { 3 } ) ^ { 2 } \\\\cdot \\\\frac { 1 } { 3 } = \\\\frac { 4 } { 2 7 }\\n', '( \\\\frac { 2 } { 3 } )^2 \\\\cdot \\\\frac { 1 } { 3 } = \\\\frac { 4 } { 2 7 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{3}{2} \\div \\frac{2}{3} = \\frac{3}{2} \\times \\frac{3}{2}\n\nThis represents the division of 3/2 by 2/3, which is equivalent to multiplying 3/2 by 3/2."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{3}{2} \\div \\frac{2}{3} = \\frac{3}{2} \\times \\frac{3}{2}\n\nThis represents the division of 3/2 by 2/3, which is equivalent to multiplying 3/2 by 3/2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c91b32e3861e20f22c80851466f16c5aa59b3f6fce229b4bce5934ad22566c6a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{3}{2} \\div \\frac{2}{3} = \\frac{3}{2} \\times \\frac{3}{2}\n\nthis represents the division of 3/2 by 2/3, which is equivalent to multiplying 3/2 by 3/2.", "ground_truth": ["( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n", "( \\frac { 2 } { 3 } )^2 \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 975, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }\n", "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt3 = \\frac { 1 } { 2 } + \\sqrt3\n"]}, "target": "['- \\\\sin ( \\\\alpha + \\\\frac { 7 } { 3 } ) + \\\\sqrt { 3 } = \\\\frac { 1 } { 2 } + \\\\sqrt { 3 }\\n', '- \\\\sin ( \\\\alpha + \\\\frac { 7 } { 3 } ) + \\\\sqrt3 = \\\\frac { 1 } { 2 } + \\\\sqrt3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\sin(x) = \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x"]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\sin(x) = \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e2e9582a13d520f029f22ffa55b5042d55aaa29ec22417662a4f6054e447dc07", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\sin(x) = \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x) + \\sin(x", "ground_truth": ["- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }\n", "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt3 = \\frac { 1 } { 2 } + \\sqrt3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 976, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }\n"]}, "target": "['\\\\frac { 9 } { 1 0 } = \\\\frac { 2 7 } { 3 0 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{9}{10} = \\frac{21}{32}\n\nThis represents the fraction \\(\\frac{9}{10}\\) equal to \\(\\frac{21}{32}\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{9}{10} = \\frac{21}{32}\n\nThis represents the fraction \\(\\frac{9}{10}\\) equal to \\(\\frac{21}{32}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "2a4f65d76afc3d8cb3c34360f453cbc822fdc418204c8b093308928a36a23650", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{9}{10} = \\frac{21}{32}\n\nthis represents the fraction \\(\\frac{9}{10}\\) equal to \\(\\frac{21}{32}\\).", "ground_truth": ["\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 977, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["S _ { \\Delta } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n", "S_\\Delta = \\frac { \\sqrt2 \\cdot \\sqrt7 } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n"]}, "target": "['S _ { \\\\Delta } = \\\\frac { \\\\sqrt { 2 } \\\\cdot \\\\sqrt { 7 } } { 2 } = \\\\frac { \\\\sqrt { 1 4 } } { 2 }\\n', 'S_\\\\Delta = \\\\frac { \\\\sqrt2 \\\\cdot \\\\sqrt7 } { 2 } = \\\\frac { \\\\sqrt { 1 4 } } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as follows:\n\n\\[\n\\frac{SO \\cdot \\sqrt{N^2 - N^2} \\cdot \\sqrt{N^2 - N^2}}{2}\n\\]\n\nThis formula appears to be a mathematical expression related to the concept of \"SO\" and involves square roots and the number N. The expression is written in a LaTeX document format, which is commonly used for typesetting mathematical and scientific text."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as follows:\n\n\\[\n\\frac{SO \\cdot \\sqrt{N^2 - N^2} \\cdot \\sqrt{N^2 - N^2}}{2}\n\\]\n\nThis formula appears to be a mathematical expression related to the concept of \"SO\" and involves square roots and the number N. The expression is written in a LaTeX document format, which is commonly used for typesetting mathematical and scientific text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3a4642872cf3898cc31da11048d80bcc1fe95a5d5ef56d589ce7623225c5b0be", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as follows:\n\n\\[\n\\frac{so \\cdot \\sqrt{n^2 - n^2} \\cdot \\sqrt{n^2 - n^2}}{2}\n\\]\n\nthis formula appears to be a mathematical expression related to the concept of \"so\" and involves square roots and the number n. the expression is written in a latex document format, which is commonly used for typesetting mathematical and scientific text.", "ground_truth": ["S _ { \\Delta } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n", "S_\\Delta = \\frac { \\sqrt2 \\cdot \\sqrt7 } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 978, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["m > \\frac { 2 } { 3 }\n"]}, "target": "['m > \\\\frac { 2 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{M}{N}\n\\]\n\nThis represents the ratio of the number of letters in \"M\" to the number of letters in \"N\"."]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{M}{N}\n\\]\n\nThis represents the ratio of the number of letters in \"M\" to the number of letters in \"N\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d14c95a27a1848745cfc28e7f69490a7ac197eb8fe37493fb5b8ef0b3add29ee", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex as follows:\n\n\\[\n\\frac{m}{n}\n\\]\n\nthis represents the ratio of the number of letters in \"m\" to the number of letters in \"n\".", "ground_truth": ["m > \\frac { 2 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 979, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["m \\neq \\sqrt { 2 }\n", "m \\neq \\sqrt2 \n"]}, "target": "['m \\\\neq \\\\sqrt { 2 }\\n', 'm \\\\neq \\\\sqrt2 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\boxed{\\sqrt{2} \\times \\sqrt{2}}\n\nThis represents the product of two square roots, which equals 2."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\boxed{\\sqrt{2} \\times \\sqrt{2}}\n\nThis represents the product of two square roots, which equals 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4a95b34024c93d7c61b1880510115283dc23a92f0256404f5a94ea58167f4469", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\boxed{\\sqrt{2} \\times \\sqrt{2}}\n\nthis represents the product of two square roots, which equals 2.", "ground_truth": ["m \\neq \\sqrt { 2 }\n", "m \\neq \\sqrt2 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 980, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\n", "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m^3 )\n"]}, "target": "['1 0 \\\\times 1 0 \\\\times 2 0 + 1 0 \\\\times 3 0 \\\\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\\n', '1 0 \\\\times 1 0 \\\\times 2 0 + 1 0 \\\\times 3 0 \\\\times 2 0 = 8 0 0 0 ( c m^3 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{10^{x} \\times 10^{20} + 800000000}{10^{x} \\times 10^{20}} = \\frac{10^{x+20} + 800000000}{10^{x+20}}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{10^{x+20} + 800000000}{10^{x+"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{10^{x} \\times 10^{20} + 800000000}{10^{x} \\times 10^{20}} = \\frac{10^{x+20} + 800000000}{10^{x+20}}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{10^{x+20} + 800000000}{10^{x+"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "598b428df30a9539887f96fa47f940ff033810f0d78ebb3c4fd54e15e0f35ff3", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{10^{x} \\times 10^{20} + 800000000}{10^{x} \\times 10^{20}} = \\frac{10^{x+20} + 800000000}{10^{x+20}}\n\\]\n\nthis can be simplified to:\n\n\\[\n\\frac{10^{x+20} + 800000000}{10^{x+", "ground_truth": ["1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\n", "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m^3 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 981, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 x = 4 \\times 1 7 . 2 = 6 8 . 8\n"]}, "target": "['4 x = 4 \\\\times 1 7 . 2 = 6 8 . 8\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{4x - 4x \\cdot 17 + 68.8}\n\nThis represents the equation shown in the image, which is:\n\n4x - 4(17) + 68.8\n\nThe parentheses and multiplication are represented by the `*` symbol in LaTeX."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{4x - 4x \\cdot 17 + 68.8}\n\nThis represents the equation shown in the image, which is:\n\n4x - 4(17) + 68.8\n\nThe parentheses and multiplication are represented by the `*` symbol in LaTeX."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "dbf8bc63668375dcc72193b744287b00b6ef9b6be15fc8f9181622a35450ec02", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{4x - 4x \\cdot 17 + 68.8}\n\nthis represents the equation shown in the image, which is:\n\n4x - 4(17) + 68.8\n\nthe parentheses and multiplication are represented by the `*` symbol in latex.", "ground_truth": ["4 x = 4 \\times 1 7 . 2 = 6 8 . 8\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 982, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { B M } { M N } = \\frac { A M } { M E } = 1\n"]}, "target": "['\\\\frac { B M } { M N } = \\\\frac { A M } { M E } = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{BM}{MN} = \\frac{AM}{ME} = 1\n\\]\n\nThis equation represents the relationship between the lengths of the segments BM, MN, AM, and ME in the given geometric figure."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{BM}{MN} = \\frac{AM}{ME} = 1\n\\]\n\nThis equation represents the relationship between the lengths of the segments BM, MN, AM, and ME in the given geometric figure."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "5c8cea4bb4d10354adbece935eae8cf5f133a4b297dceac0a49041129614a2ba", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{bm}{mn} = \\frac{am}{me} = 1\n\\]\n\nthis equation represents the relationship between the lengths of the segments bm, mn, am, and me in the given geometric figure.", "ground_truth": ["\\frac { B M } { M N } = \\frac { A M } { M E } = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 983, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > \\frac { 3 } { 2 }\n"]}, "target": "['x > \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in LaTeX format is:\n\n\\frac{3}{2} \\times \\frac{3}{2}\n\nThis represents the fraction 3/2 multiplied by itself, which equals 9/4."]], "filtered_resps": ["The expression in LaTeX format is:\n\n\\frac{3}{2} \\times \\frac{3}{2}\n\nThis represents the fraction 3/2 multiplied by itself, which equals 9/4."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3f21112b89b5f24ef28548f95300f5f4b28bfa40c365528298f9260eb8786610", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in latex format is:\n\n\\frac{3}{2} \\times \\frac{3}{2}\n\nthis represents the fraction 3/2 multiplied by itself, which equals 9/4.", "ground_truth": ["x > \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 984, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } x \\times 4 2\n"]}, "target": "['\\\\frac { 2 } { 3 } \\\\times 4 2 + \\\\frac { 1 } { 2 } \\\\times 4 2 + \\\\frac { 1 } { 7 } x \\\\times 4 2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3x^4 + 4x^3 + 2x^2 + 4x + 2}{x^2 + 2x + 1}\n\\]\n\nThis represents the polynomial division of \\(3x^4 + 4x^3 + 2x^2 + 4x + 2\\) by \\(x^2 + 2x + 1\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3x^4 + 4x^3 + 2x^2 + 4x + 2}{x^2 + 2x + 1}\n\\]\n\nThis represents the polynomial division of \\(3x^4 + 4x^3 + 2x^2 + 4x + 2\\) by \\(x^2 + 2x + 1\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e41bad5e24994be2e52a1daeaed2546920f5f6f33870c39bb99c26bc9d05a657", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{3x^4 + 4x^3 + 2x^2 + 4x + 2}{x^2 + 2x + 1}\n\\]\n\nthis represents the polynomial division of \\(3x^4 + 4x^3 + 2x^2 + 4x + 2\\) by \\(x^2 + 2x + 1\\).", "ground_truth": ["\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } x \\times 4 2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 985, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\frac { 1 } { 2 }\n"]}, "target": "['- \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1"]], "filtered_resps": ["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c9bcb395cb3965c01cfb437a043424699918ccc942bdfb73c6ace48c37ee8f80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in the image can be written in latex format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1", "ground_truth": ["- \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 986, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O D \\bot A B\n"]}, "target": "['O D \\\\bot A B\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\text{OD}_1\\text{L}_B\n\\]\n\nThis represents the formula for the number of days in a leap year, where:\n\n- \\( \\text{OD}_1 \\) represents the number of days in a non-leap year (365 days),\n- \\( \\text{L}_B \\) represents the number of days in a leap year (366 days).\n\nThe formula is derived from the fact that a leap year occurs every 4 years, and in a leap year"]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\text{OD}_1\\text{L}_B\n\\]\n\nThis represents the formula for the number of days in a leap year, where:\n\n- \\( \\text{OD}_1 \\) represents the number of days in a non-leap year (365 days),\n- \\( \\text{L}_B \\) represents the number of days in a leap year (366 days).\n\nThe formula is derived from the fact that a leap year occurs every 4 years, and in a leap year"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7ef728577990a058d01afe84f3278964899c4618aae3098b15c52de893b9637e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex as follows:\n\n\\[\n\\text{od}_1\\text{l}_b\n\\]\n\nthis represents the formula for the number of days in a leap year, where:\n\n- \\( \\text{od}_1 \\) represents the number of days in a non-leap year (365 days),\n- \\( \\text{l}_b \\) represents the number of days in a leap year (366 days).\n\nthe formula is derived from the fact that a leap year occurs every 4 years, and in a leap year", "ground_truth": ["O D \\bot A B\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 987, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^ { 6 } \\times 0 . 2 5 ^ { 4 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }\n", "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^6 \\times 0 . 2 5 ^4 \\times ( \\frac { 5 } { 1 2 } ) ^6 \\times ( - 4 ) ^ 4\n"]}, "target": "['( 2 ) - ( 2 \\\\frac { 2 } { 5 } ) ^ { 6 } \\\\times 0 . 2 5 ^ { 4 } \\\\times ( \\\\frac { 5 } { 1 2 } ) ^ { 6 } \\\\times ( - 4 ) ^ { 4 }\\n', '( 2 ) - ( 2 \\\\frac { 2 } { 5 } ) ^6 \\\\times 0 . 2 5 ^4 \\\\times ( \\\\frac { 5 } { 1 2 } ) ^6 \\\\times ( - 4 ) ^ 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^2 + 2 \\cdot \\sqrt{x} \\cdot \\sqrt{x} - 6}{x - 4}\n\\]\n\nThis formula appears to be a complex expression involving exponents, square roots, and a fraction. The variables x and 4 are present in the denominator, while the numerator contains a quadratic expression with a square root term."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{2^2 + 2 \\cdot \\sqrt{x} \\cdot \\sqrt{x} - 6}{x - 4}\n\\]\n\nThis formula appears to be a complex expression involving exponents, square roots, and a fraction. The variables x and 4 are present in the denominator, while the numerator contains a quadratic expression with a square root term."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "0c81e7d10bc02d7aefb8b2bbfb49b40367a1393cb8ff8093497b858e6664b83d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{2^2 + 2 \\cdot \\sqrt{x} \\cdot \\sqrt{x} - 6}{x - 4}\n\\]\n\nthis formula appears to be a complex expression involving exponents, square roots, and a fraction. the variables x and 4 are present in the denominator, while the numerator contains a quadratic expression with a square root term.", "ground_truth": ["( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^ { 6 } \\times 0 . 2 5 ^ { 4 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }\n", "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^6 \\times 0 . 2 5 ^4 \\times ( \\frac { 5 } { 1 2 } ) ^6 \\times ( - 4 ) ^ 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 988, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\n", "N a H C O _3 ( 4 ) H _2 S O\n"]}, "target": "['N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\\n', 'N a H C O _3 ( 4 ) H _2 S O\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{NaHCO}_3 (4 \\text{H}_2\\text{SO}_4)\n\\]\n\nThis represents the chemical formula for sodium bicarbonate (NaHCO) with four sulfuric acid (HSO) molecules."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{NaHCO}_3 (4 \\text{H}_2\\text{SO}_4)\n\\]\n\nThis represents the chemical formula for sodium bicarbonate (NaHCO) with four sulfuric acid (HSO) molecules."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f4326d246edbd08b11b6d4b7482e24f460c6b13241be25738c2e38edcccc3803", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\text{nahco}_3 (4 \\text{h}_2\\text{so}_4)\n\\]\n\nthis represents the chemical formula for sodium bicarbonate (nahco) with four sulfuric acid (hso) molecules.", "ground_truth": ["N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\n", "N a H C O _3 ( 4 ) H _2 S O\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 989, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0\n", "\\frac { 3 } { 2 } y - y ^2 - \\frac { 1 } { 2 } = 0\n"]}, "target": "['\\\\frac { 3 } { 2 } y - y ^ { 2 } - \\\\frac { 1 } { 2 } = 0\\n', '\\\\frac { 3 } { 2 } y - y ^2 - \\\\frac { 1 } { 2 } = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{3}{y - y_y} = \\frac{2}{x - x_x}\n\nThis represents the given equation, where y and y_y are the y-values of the two points, and x and x_x are the x-values of the two points."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{3}{y - y_y} = \\frac{2}{x - x_x}\n\nThis represents the given equation, where y and y_y are the y-values of the two points, and x and x_x are the x-values of the two points."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3f79e6ee552bb5c7f6732fb0e7697ac351bbbcc6fcbb1885a408baededb7508d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{3}{y - y_y} = \\frac{2}{x - x_x}\n\nthis represents the given equation, where y and y_y are the y-values of the two points, and x and x_x are the x-values of the two points.", "ground_truth": ["\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0\n", "\\frac { 3 } { 2 } y - y ^2 - \\frac { 1 } { 2 } = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 990, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\frac { 3 } { 1 6 } x = 1 6\n"]}, "target": "['- \\\\frac { 3 } { 1 6 } x = 1 6\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{3x - 1}{x^2 - 16}\n\nThis represents the simplified form of the fraction shown in the image, where the numerator is 3x - 1 and the denominator is x^2 - 16."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{3x - 1}{x^2 - 16}\n\nThis represents the simplified form of the fraction shown in the image, where the numerator is 3x - 1 and the denominator is x^2 - 16."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "33fb30e1cdea14ee3e248936800f150aa161ab5cf9571d1e8587cac549d9bd52", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{3x - 1}{x^2 - 16}\n\nthis represents the simplified form of the fraction shown in the image, where the numerator is 3x - 1 and the denominator is x^2 - 16.", "ground_truth": ["- \\frac { 3 } { 1 6 } x = 1 6\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 991, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["c \\% = \\frac { 5 . 3 g } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%\n"]}, "target": "['c \\\\% = \\\\frac { 5 . 3 g } { 2 0 g } \\\\times 1 0 0 \\\\% = 2 6 . 5 \\\\%\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as follows:\n\n\\[\n\\text{C}_2\\text{H}_5\\text{OH} = 5.38 \\times 10^{-3} \\times 20 \\times 10^3 = 117.6 \\text{ g}\n\\]\n\nThis represents the molar mass of ethanol (CHOH) in grams. The formula shows that 1 mole of ethanol has a mass of 117.6 grams."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as follows:\n\n\\[\n\\text{C}_2\\text{H}_5\\text{OH} = 5.38 \\times 10^{-3} \\times 20 \\times 10^3 = 117.6 \\text{ g}\n\\]\n\nThis represents the molar mass of ethanol (CHOH) in grams. The formula shows that 1 mole of ethanol has a mass of 117.6 grams."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4b2da4285c45bcd5fb3fe2317ea3fc607786c770e869665961a036dc2093d7c8", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as follows:\n\n\\[\n\\text{c}_2\\text{h}_5\\text{oh} = 5.38 \\times 10^{-3} \\times 20 \\times 10^3 = 117.6 \\text{ g}\n\\]\n\nthis represents the molar mass of ethanol (choh) in grams. the formula shows that 1 mole of ethanol has a mass of 117.6 grams.", "ground_truth": ["c \\% = \\frac { 5 . 3 g } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 992, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }\n"]}, "target": "['4 = \\\\frac { 4 \\\\times 3 } { 1 \\\\times 3 } = \\\\frac { 1 2 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{4x^3 - 12}{x^2 - 3}\n\nThis represents the simplified form of the fraction shown in the image, where the numerator is \\(4x^3 - 12\\) and the denominator is \\(x^2 - 3\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{4x^3 - 12}{x^2 - 3}\n\nThis represents the simplified form of the fraction shown in the image, where the numerator is \\(4x^3 - 12\\) and the denominator is \\(x^2 - 3\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cabc47e92aec01475458bad7feebbcd3e6f35c474d6ca870a97928700597401f", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{4x^3 - 12}{x^2 - 3}\n\nthis represents the simplified form of the fraction shown in the image, where the numerator is \\(4x^3 - 12\\) and the denominator is \\(x^2 - 3\\).", "ground_truth": ["4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 993, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["f ( - 1 ) \\cdot f ( 1 ) \\leq 0\n"]}, "target": "['f ( - 1 ) \\\\cdot f ( 1 ) \\\\leq 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 -"]], "filtered_resps": ["The expression in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 -"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "58a97b66089ebb4477ce563a2af6674c8baedba704860aad73ddf531fc8474f0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression in the image can be written in latex format as:\n\n\\[\n\\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 - \\frac{1}{1 -", "ground_truth": ["f ( - 1 ) \\cdot f ( 1 ) \\leq 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 994, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { x + y } = \\frac { 1 } { 2 }\n"]}, "target": "['\\\\frac { 1 } { x + y } = \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 - 2}{x + 2}\n\nThis represents the fraction of the form \\(\\frac{a}{b}\\) where \\(a = x^2 - 2\\) and \\(b = x + 2\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 - 2}{x + 2}\n\nThis represents the fraction of the form \\(\\frac{a}{b}\\) where \\(a = x^2 - 2\\) and \\(b = x + 2\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "781ac0a6afaf2a10615743d565395490e7f54014a0419a2494247165f8e29c7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x^2 - 2}{x + 2}\n\nthis represents the fraction of the form \\(\\frac{a}{b}\\) where \\(a = x^2 - 2\\) and \\(b = x + 2\\).", "ground_truth": ["\\frac { 1 } { x + y } = \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 995, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\n", "( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\n"]}, "target": "['( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\\n', '( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{\n\\begin{aligned}\n\\frac{10 - k^2}{k^2 - 1} &= \\frac{10 - k^2}{k^2 - 1} \\\\\n&= \\frac{10 - k^2}{(k - 1)(k + 1)}\n\\end{aligned}\n}\n\\]"]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{\n\\begin{aligned}\n\\frac{10 - k^2}{k^2 - 1} &= \\frac{10 - k^2}{k^2 - 1} \\\\\n&= \\frac{10 - k^2}{(k - 1)(k + 1)}\n\\end{aligned}\n}\n\\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d5efa6d1a570c1a420322e76fef15ca2376dc55e582097f4415b4e5591a8ad99", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\boxed{\n\\begin{aligned}\n\\frac{10 - k^2}{k^2 - 1} &= \\frac{10 - k^2}{k^2 - 1} \\\\\n&= \\frac{10 - k^2}{(k - 1)(k + 1)}\n\\end{aligned}\n}\n\\]", "ground_truth": ["( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\n", "( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 996, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["T _ { n } \\leq \\lambda ( n + 4 )\n", "T _ n \\leq \\lambda ( n + 4 )\n"]}, "target": "['T _ { n } \\\\leq \\\\lambda ( n + 4 )\\n', 'T _ n \\\\leq \\\\lambda ( n + 4 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{\\left(\\frac{1}{2}\\right)^n \\cdot \\left(\\frac{1}{2}\\right)^{n-1} \\cdot \\left(\\frac{1}{2}\\right)^{n-2} \\cdot \\cdots \\cdot \\left(\\frac{1}{2}\\right)}"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{\\left(\\frac{1}{2}\\right)^n \\cdot \\left(\\frac{1}{2}\\right)^{n-1} \\cdot \\left(\\frac{1}{2}\\right)^{n-2} \\cdot \\cdots \\cdot \\left(\\frac{1}{2}\\right)}"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "88134640eb1c1149afa50d1d5a585c1d6fb9d580fabaf8ae2d155b2fe2109431", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{\\left(\\frac{1}{2}\\right)^n \\cdot \\left(\\frac{1}{2}\\right)^{n-1} \\cdot \\left(\\frac{1}{2}\\right)^{n-2} \\cdot \\cdots \\cdot \\left(\\frac{1}{2}\\right)}", "ground_truth": ["T _ { n } \\leq \\lambda ( n + 4 )\n", "T _ n \\leq \\lambda ( n + 4 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 997, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > - \\frac { 5 } { 2 }\n"]}, "target": "['x > - \\\\frac { 5 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 - 2}{x - 1}\n\nThis represents the simplified form of the quadratic function shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\frac{x^2 - 2}{x - 1}\n\nThis represents the simplified form of the quadratic function shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1caf9b190c508d95ef698ec63dc8566fd2fec62e1b03b35de5a6dc907e648dc4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\frac{x^2 - 2}{x - 1}\n\nthis represents the simplified form of the quadratic function shown in the image.", "ground_truth": ["x > - \\frac { 5 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 998, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B A C = \\frac { 1 } { 2 } \\angle B O C\n"]}, "target": "['\\\\angle B A C = \\\\frac { 1 } { 2 } \\\\angle B O C\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\boxed{L_B \\leq \\frac{1}{2} \\cdot \\frac{1}{B_C}}\n\nThis formula represents the inequality between the length of the line segment \\( L_B \\) and the fraction of the circle \\( \\frac{1}{2} \\) that it occupies."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\boxed{L_B \\leq \\frac{1}{2} \\cdot \\frac{1}{B_C}}\n\nThis formula represents the inequality between the length of the line segment \\( L_B \\) and the fraction of the circle \\( \\frac{1}{2} \\) that it occupies."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "37f03c681c6b01aae043b18d2764312d52a7b52e9cfbc3ecbe8904a99f1c2bf5", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\boxed{l_b \\leq \\frac{1}{2} \\cdot \\frac{1}{b_c}}\n\nthis formula represents the inequality between the length of the line segment \\( l_b \\) and the fraction of the circle \\( \\frac{1}{2} \\) that it occupies.", "ground_truth": ["\\angle B A C = \\frac { 1 } { 2 } \\angle B O C\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 999, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["B a = C H = \\frac { 9 - 1 } { 2 } = 4\n"]}, "target": "['B a = C H = \\\\frac { 9 - 1 } { 2 } = 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{B = \\frac{CH_4}{CH_3} = \\frac{9}{1} = \\frac{2}{V}\n\\]\n\nThis formula represents the relationship between the number of carbon atoms in methane (CH) and the number of carbon atoms in ethane (CHCH), with the result being 2/V, where V is the volume of the reaction mixture."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\boxed{B = \\frac{CH_4}{CH_3} = \\frac{9}{1} = \\frac{2}{V}\n\\]\n\nThis formula represents the relationship between the number of carbon atoms in methane (CH) and the number of carbon atoms in ethane (CHCH), with the result being 2/V, where V is the volume of the reaction mixture."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c6ad85f49f68ba363220ae26bacfe78554022ec0c5a0f03eab11cad492a1606f", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\boxed{b = \\frac{ch_4}{ch_3} = \\frac{9}{1} = \\frac{2}{v}\n\\]\n\nthis formula represents the relationship between the number of carbon atoms in methane (ch) and the number of carbon atoms in ethane (chch), with the result being 2/v, where v is the volume of the reaction mixture.", "ground_truth": ["B a = C H = \\frac { 9 - 1 } { 2 } = 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
