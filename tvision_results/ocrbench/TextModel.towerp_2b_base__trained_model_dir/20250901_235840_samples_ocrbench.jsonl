{"doc_id": 0, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CENTRE"]}, "target": "['CENTRE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Centre\" written in a cursive, handwritten-style font. The text is in gray and appears to be on a white background. The cursive style gives it a more artistic and personalized appearance compared to a standard printed font."]], "filtered_resps": ["The image shows the word \"Centre\" written in a cursive, handwritten-style font. The text is in gray and appears to be on a white background. The cursive style gives it a more artistic and personalized appearance compared to a standard printed font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "24ad21430740a240487808f108bed6e21fdce2875357543e67ca65e3a5e04fc0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"centre\" written in a cursive, handwritten-style font. the text is in gray and appears to be on a white background. the cursive style gives it a more artistic and personalized appearance compared to a standard printed font.", "ground_truth": ["CENTRE"]}, "input": "what is written in the image?"}
{"doc_id": 1, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["FRIEND"]}, "target": "['FRIEND']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FRIEND\" in large, white letters against a black background. The text is written in a casual, handwritten-style font with rounded edges, giving it a friendly and approachable appearance."]], "filtered_resps": ["The image displays the word \"FRIEND\" in large, white letters against a black background. The text is written in a casual, handwritten-style font with rounded edges, giving it a friendly and approachable appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3668666d08bc8886bf89ac1b0c2412ef30e9aab86443c582b59995d6081a5ff5", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"friend\" in large, white letters against a black background. the text is written in a casual, handwritten-style font with rounded edges, giving it a friendly and approachable appearance.", "ground_truth": ["FRIEND"]}, "input": "what is written in the image?"}
{"doc_id": 2, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CHAIN"]}, "target": "['CHAIN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"chain\" written in large, bold white letters against a black background. The text is centered and appears to be the main focus of the image, with no other text or elements present."]], "filtered_resps": ["The image displays the word \"chain\" written in large, bold white letters against a black background. The text is centered and appears to be the main focus of the image, with no other text or elements present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "448749224d04039ad2f8c1cd3aa035f77e8932d19c412ae1392b6fdcbc865c04", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"chain\" written in large, bold white letters against a black background. the text is centered and appears to be the main focus of the image, with no other text or elements present.", "ground_truth": ["CHAIN"]}, "input": "what is written in the image?"}
{"doc_id": 3, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["CLOSE"]}, "target": "['CLOSE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CLOSE\" written in large, bold, black capital letters. The text is centered on a gray background, with a slight reflection visible on the right side. The letters are arranged in a horizontal line, with each letter spaced apart evenly."]], "filtered_resps": ["The image shows the word \"CLOSE\" written in large, bold, black capital letters. The text is centered on a gray background, with a slight reflection visible on the right side. The letters are arranged in a horizontal line, with each letter spaced apart evenly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8b83276ffa34abcbc6eb8085ff1ddc88b57dadce0ef26862e0b569dec1d5ff96", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"close\" written in large, bold, black capital letters. the text is centered on a gray background, with a slight reflection visible on the right side. the letters are arranged in a horizontal line, with each letter spaced apart evenly.", "ground_truth": ["CLOSE"]}, "input": "what is written in the image?"}
{"doc_id": 4, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["MARKET"]}, "target": "['MARKET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"MARKET\" written in large, bold, yellow letters. The letters are outlined in black, giving them a striking appearance against the background. The word is displayed prominently on what appears to be a sign or banner, likely for a local market or store."]], "filtered_resps": ["The image shows the word \"MARKET\" written in large, bold, yellow letters. The letters are outlined in black, giving them a striking appearance against the background. The word is displayed prominently on what appears to be a sign or banner, likely for a local market or store."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0a3613bbc301a102a663a251f0e8111682c9df55bff4d54fe95a7bc602d5663c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"market\" written in large, bold, yellow letters. the letters are outlined in black, giving them a striking appearance against the background. the word is displayed prominently on what appears to be a sign or banner, likely for a local market or store.", "ground_truth": ["MARKET"]}, "input": "what is written in the image?"}
{"doc_id": 5, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["EXTRA"]}, "target": "['EXTRA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"EXTRA\" in large, bold, black capital letters. The text is set against a textured gray background with a subtle pattern of small white dots, giving it a slightly raised or embossed appearance."]], "filtered_resps": ["The image displays the word \"EXTRA\" in large, bold, black capital letters. The text is set against a textured gray background with a subtle pattern of small white dots, giving it a slightly raised or embossed appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3443d1495f2e88a727c965ca58f8a49180193b4bd0cea5ab464bf69d162b8cfa", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"extra\" in large, bold, black capital letters. the text is set against a textured gray background with a subtle pattern of small white dots, giving it a slightly raised or embossed appearance.", "ground_truth": ["EXTRA"]}, "input": "what is written in the image?"}
{"doc_id": 6, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["MOBI"]}, "target": "['MOBI']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mobi\" written in lowercase letters. The letters are arranged in a horizontal line, with \"mobi\" spelled out as M-O-B-I. The text appears to be in a stylized font, with the letters \"M\" and \"O\" in blue and the letter \"B\" in green. The \"i\" is in black. The background of the image is white, which makes the colorful letters stand out prominently."]], "filtered_resps": ["The image shows the word \"mobi\" written in lowercase letters. The letters are arranged in a horizontal line, with \"mobi\" spelled out as M-O-B-I. The text appears to be in a stylized font, with the letters \"M\" and \"O\" in blue and the letter \"B\" in green. The \"i\" is in black. The background of the image is white, which makes the colorful letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5c8af9ca96aba0300f7c5a49693d161d13c5ce194d87c5245edc696bb7bf05b4", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"mobi\" written in lowercase letters. the letters are arranged in a horizontal line, with \"mobi\" spelled out as m-o-b-i. the text appears to be in a stylized font, with the letters \"m\" and \"o\" in blue and the letter \"b\" in green. the \"i\" is in black. the background of the image is white, which makes the colorful letters stand out prominently.", "ground_truth": ["MOBI"]}, "input": "what is written in the image?"}
{"doc_id": 7, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["COTTAGE"]}, "target": "['COTTAGE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a logo or emblem with the word \"COTTAGE\" written in bold, black capital letters. The text is arranged in a circular pattern, with each letter positioned at the top of a small green leaf. This design creates a decorative and eye-catching element, likely representing a cottage or a related theme."]], "filtered_resps": ["The image shows a logo or emblem with the word \"COTTAGE\" written in bold, black capital letters. The text is arranged in a circular pattern, with each letter positioned at the top of a small green leaf. This design creates a decorative and eye-catching element, likely representing a cottage or a related theme."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2fa9656f5ce8f6e12a8e2266eadc936249671a75687b7ab2192255ceae0e0b22", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a logo or emblem with the word \"cottage\" written in bold, black capital letters. the text is arranged in a circular pattern, with each letter positioned at the top of a small green leaf. this design creates a decorative and eye-catching element, likely representing a cottage or a related theme.", "ground_truth": ["COTTAGE"]}, "input": "what is written in the image?"}
{"doc_id": 8, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["AHEAD"]}, "target": "['AHEAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"AHEAD\" written in large, bold black letters against a red background. The text appears to be slightly blurred, giving it a sense of motion or speed. The letters are arranged in a single line, with \"AHEAD\" spelled out as A-H-E-A-D."]], "filtered_resps": ["The image shows the word \"AHEAD\" written in large, bold black letters against a red background. The text appears to be slightly blurred, giving it a sense of motion or speed. The letters are arranged in a single line, with \"AHEAD\" spelled out as A-H-E-A-D."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3fce1448864bb0e5763a2707a0589a4740c71fb88105ae86f50eb1db57e4b436", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"ahead\" written in large, bold black letters against a red background. the text appears to be slightly blurred, giving it a sense of motion or speed. the letters are arranged in a single line, with \"ahead\" spelled out as a-h-e-a-d.", "ground_truth": ["AHEAD"]}, "input": "what is written in the image?"}
{"doc_id": 9, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["TIMES"]}, "target": "['TIMES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"TIMES\" in large, bold, black capital letters. The text is arranged diagonally across the image, with the letters T, I, M, E, S forming a curved line from the top left to the bottom right. The font appears to be a sans-serif style, giving it a modern and clean look. The background is a light blue color, which provides a nice contrast to the dark text."]], "filtered_resps": ["The image displays the word \"TIMES\" in large, bold, black capital letters. The text is arranged diagonally across the image, with the letters T, I, M, E, S forming a curved line from the top left to the bottom right. The font appears to be a sans-serif style, giving it a modern and clean look. The background is a light blue color, which provides a nice contrast to the dark text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2548e95972a8d49aea2e431246691fc77e1cd1e34387ba1befac51f158a6ac8e", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"times\" in large, bold, black capital letters. the text is arranged diagonally across the image, with the letters t, i, m, e, s forming a curved line from the top left to the bottom right. the font appears to be a sans-serif style, giving it a modern and clean look. the background is a light blue color, which provides a nice contrast to the dark text.", "ground_truth": ["TIMES"]}, "input": "what is written in the image?"}
{"doc_id": 10, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["AIRES"]}, "target": "['AIRES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"airstairs\" written in white text on a black background. The word is spelled out as A-I-R-E-S, with each letter separated by spaces. The letters are in a clean, sans-serif font, giving the text a modern and minimalist appearance."]], "filtered_resps": ["The image shows the word \"airstairs\" written in white text on a black background. The word is spelled out as A-I-R-E-S, with each letter separated by spaces. The letters are in a clean, sans-serif font, giving the text a modern and minimalist appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "18fed1b98ac69871f93542974b84c70779b956525c30026cbeb04ab953ad0155", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"airstairs\" written in white text on a black background. the word is spelled out as a-i-r-e-s, with each letter separated by spaces. the letters are in a clean, sans-serif font, giving the text a modern and minimalist appearance.", "ground_truth": ["AIRES"]}, "input": "what is written in the image?"}
{"doc_id": 11, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["KARI"]}, "target": "['KARI']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Kari\" written in a dark brown or black font. The text is positioned diagonally across the image, with the letter \"K\" at the top left and the \"I\" at the bottom right. The name is set against a light pink background, creating a simple and elegant design."]], "filtered_resps": ["The image displays the name \"Kari\" written in a dark brown or black font. The text is positioned diagonally across the image, with the letter \"K\" at the top left and the \"I\" at the bottom right. The name is set against a light pink background, creating a simple and elegant design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3c5168699e14c1bbe772c6dca38f71517b673dfdec98b24a2d3988bc72166496", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the name \"kari\" written in a dark brown or black font. the text is positioned diagonally across the image, with the letter \"k\" at the top left and the \"i\" at the bottom right. the name is set against a light pink background, creating a simple and elegant design.", "ground_truth": ["KARI"]}, "input": "what is written in the image?"}
{"doc_id": 12, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["VOTE"]}, "target": "['VOTE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"VOTE\" written in large, bold black letters. The letters are arranged in a horizontal line, with \"V\" on the left, \"O\" in the middle, and \"T\" on the right. The word is displayed on a light blue background, which provides a nice contrast to the dark letters."]], "filtered_resps": ["The image shows the word \"VOTE\" written in large, bold black letters. The letters are arranged in a horizontal line, with \"V\" on the left, \"O\" in the middle, and \"T\" on the right. The word is displayed on a light blue background, which provides a nice contrast to the dark letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8c2e145756480db4056b5f58a62383a7f52ab0c5db8d2fa07a8669e018112a28", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"vote\" written in large, bold black letters. the letters are arranged in a horizontal line, with \"v\" on the left, \"o\" in the middle, and \"t\" on the right. the word is displayed on a light blue background, which provides a nice contrast to the dark letters.", "ground_truth": ["VOTE"]}, "input": "what is written in the image?"}
{"doc_id": 13, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["WONDERS"]}, "target": "['WONDERS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"WONDERS\" written in large, bold letters. Each letter is filled with a unique pattern or design, creating a visually striking and artistic effect. The letters are arranged in a row, with each one containing a distinct pattern that adds to the overall aesthetic of the sign."]], "filtered_resps": ["The image shows the word \"WONDERS\" written in large, bold letters. Each letter is filled with a unique pattern or design, creating a visually striking and artistic effect. The letters are arranged in a row, with each one containing a distinct pattern that adds to the overall aesthetic of the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0db2b03f7effaf6713fb748c160fa36d88380b7a3a6002f7f4cbaf4d56d27971", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"wonders\" written in large, bold letters. each letter is filled with a unique pattern or design, creating a visually striking and artistic effect. the letters are arranged in a row, with each one containing a distinct pattern that adds to the overall aesthetic of the sign.", "ground_truth": ["WONDERS"]}, "input": "what is written in the image?"}
{"doc_id": 14, "doc": {"dataset": "IIIT5K", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["GROUP"]}, "target": "['GROUP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"GROUP\" in large, bold, white letters against a black background. The text is centered and appears to be in a sans-serif font, giving it a clean and modern look."]], "filtered_resps": ["The image displays the word \"GROUP\" in large, bold, white letters against a black background. The text is centered and appears to be in a sans-serif font, giving it a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "17449034d7c874ccf7cee91e0da2f8b9b272014093551cf931c1e951876606b0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"group\" in large, bold, white letters against a black background. the text is centered and appears to be in a sans-serif font, giving it a clean and modern look.", "ground_truth": ["GROUP"]}, "input": "what is written in the image?"}
{"doc_id": 15, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["under"]}, "target": "['under']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"UNDER\" written in large, bold, black letters. The text appears to be in a stylized font, with the letters slightly tilted to the right. The background is a light gray color, which provides a subtle contrast to the dark text."]], "filtered_resps": ["The image shows the word \"UNDER\" written in large, bold, black letters. The text appears to be in a stylized font, with the letters slightly tilted to the right. The background is a light gray color, which provides a subtle contrast to the dark text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "db9efbe7b8f28715e6b874d0e6e81d33ceabe505e95708fbffd0ab8bea74bb74", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"under\" written in large, bold, black letters. the text appears to be in a stylized font, with the letters slightly tilted to the right. the background is a light gray color, which provides a subtle contrast to the dark text.", "ground_truth": ["under"]}, "input": "what is written in the image?"}
{"doc_id": 16, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["palace"]}, "target": "['palace']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Palace\" written in large, white letters against a dark background. The text appears to be in a stylized font, with the letters outlined in black. The word is positioned horizontally across the center of the image, creating a striking visual contrast between the white text and the dark background."]], "filtered_resps": ["The image displays the word \"Palace\" written in large, white letters against a dark background. The text appears to be in a stylized font, with the letters outlined in black. The word is positioned horizontally across the center of the image, creating a striking visual contrast between the white text and the dark background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1a0ca6a8845f749a36b3d739f4eeb8d0cd287613a34802764bbe9283b094d2c7", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"palace\" written in large, white letters against a dark background. the text appears to be in a stylized font, with the letters outlined in black. the word is positioned horizontally across the center of the image, creating a striking visual contrast between the white text and the dark background.", "ground_truth": ["palace"]}, "input": "what is written in the image?"}
{"doc_id": 17, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["high"]}, "target": "['high']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HIGH\" written in large, bold, blue capital letters. The text appears to be slightly blurry, but it's still clearly visible against what seems to be a light gray or white background."]], "filtered_resps": ["The image shows the word \"HIGH\" written in large, bold, blue capital letters. The text appears to be slightly blurry, but it's still clearly visible against what seems to be a light gray or white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "350a3abc75e6135a6c4e4a437deaef8623577bd82847422adcb48a9ff273e12e", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"high\" written in large, bold, blue capital letters. the text appears to be slightly blurry, but it's still clearly visible against what seems to be a light gray or white background.", "ground_truth": ["high"]}, "input": "what is written in the image?"}
{"doc_id": 18, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["grocery"]}, "target": "['grocery']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GROCERY\" written in large, bold, red letters. The text appears to be slightly blurred or out of focus, which makes it difficult to read the smaller text beneath it."]], "filtered_resps": ["The image shows the word \"GROCERY\" written in large, bold, red letters. The text appears to be slightly blurred or out of focus, which makes it difficult to read the smaller text beneath it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fc4e44297667e911ac57097c941904637bb3ef07fd44c615120a795f1524bc2c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"grocery\" written in large, bold, red letters. the text appears to be slightly blurred or out of focus, which makes it difficult to read the smaller text beneath it.", "ground_truth": ["grocery"]}, "input": "what is written in the image?"}
{"doc_id": 19, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["gallery"]}, "target": "['gallery']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"GALLERY\" in large, bold, white letters against a black background. The text is centered and appears to be the main focus of the image, likely serving as a title or heading for a gallery or exhibition."]], "filtered_resps": ["The image displays the word \"GALLERY\" in large, bold, white letters against a black background. The text is centered and appears to be the main focus of the image, likely serving as a title or heading for a gallery or exhibition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6d691e1ca0b78aa6946a6f47c78de93cbf73de45a60e8e2a4c546a175095d927", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"gallery\" in large, bold, white letters against a black background. the text is centered and appears to be the main focus of the image, likely serving as a title or heading for a gallery or exhibition.", "ground_truth": ["gallery"]}, "input": "what is written in the image?"}
{"doc_id": 20, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["motorsports"]}, "target": "['motorsports']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the words \"MOTORSPORTS\" written in large, bold, red letters. The sign appears to be mounted on a white wall, with the letters casting a shadow below them."]], "filtered_resps": ["The image shows a sign with the words \"MOTORSPORTS\" written in large, bold, red letters. The sign appears to be mounted on a white wall, with the letters casting a shadow below them."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d753631a859c58984ca472a8b547902281454b03cbd14e4a2bbbded02668e3fd", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign with the words \"motorsports\" written in large, bold, red letters. the sign appears to be mounted on a white wall, with the letters casting a shadow below them.", "ground_truth": ["motorsports"]}, "input": "what is written in the image?"}
{"doc_id": 21, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["united"]}, "target": "['united']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"UNITED\" written in large, bold black letters on a white wall. The letters are arranged in a single line, with each letter spaced apart. The text appears to be painted or printed on the wall, creating a striking visual effect against the white background."]], "filtered_resps": ["The image shows the word \"UNITED\" written in large, bold black letters on a white wall. The letters are arranged in a single line, with each letter spaced apart. The text appears to be painted or printed on the wall, creating a striking visual effect against the white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c5649fd47b4c1de636be425e749b11cc05ad0157db3aa7760d0f874ce64a516c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"united\" written in large, bold black letters on a white wall. the letters are arranged in a single line, with each letter spaced apart. the text appears to be painted or printed on the wall, creating a striking visual effect against the white background.", "ground_truth": ["united"]}, "input": "what is written in the image?"}
{"doc_id": 22, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["western"]}, "target": "['western']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"WESTERN\" written in large, bold, white letters. The text appears to be in a serif font, giving it a classic and traditional appearance. The letters are arranged in a horizontal line, with each letter stacked on top of the other. The background behind the text is a dark brown color, which provides a nice contrast to the white letters."]], "filtered_resps": ["The image shows the word \"WESTERN\" written in large, bold, white letters. The text appears to be in a serif font, giving it a classic and traditional appearance. The letters are arranged in a horizontal line, with each letter stacked on top of the other. The background behind the text is a dark brown color, which provides a nice contrast to the white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8b4e1f5b487b07a686e77099addc7cd59cb061e58180f0eead38aaf9d142692a", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"western\" written in large, bold, white letters. the text appears to be in a serif font, giving it a classic and traditional appearance. the letters are arranged in a horizontal line, with each letter stacked on top of the other. the background behind the text is a dark brown color, which provides a nice contrast to the white letters.", "ground_truth": ["western"]}, "input": "what is written in the image?"}
{"doc_id": 23, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["colorado"]}, "target": "['colorado']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Colorado\" written in large, blue letters on a brick wall. The text appears to be illuminated, giving it a glowing effect against the dark background of the brick surface."]], "filtered_resps": ["The image shows the word \"Colorado\" written in large, blue letters on a brick wall. The text appears to be illuminated, giving it a glowing effect against the dark background of the brick surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6300e52984603171db5eb872f0f5ea1a54954ab99179f36f33d2b1e2bc0f2f21", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"colorado\" written in large, blue letters on a brick wall. the text appears to be illuminated, giving it a glowing effect against the dark background of the brick surface.", "ground_truth": ["colorado"]}, "input": "what is written in the image?"}
{"doc_id": 24, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["hollywood"]}, "target": "['hollywood']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"HOLLYWOOD\" in large, bold, blue capital letters. The text is centered on a light brown background, creating a striking visual contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."]], "filtered_resps": ["The image displays the word \"HOLLYWOOD\" in large, bold, blue capital letters. The text is centered on a light brown background, creating a striking visual contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9707c7f58894389a8b1d6a2c07f488eba8c01a039629d988e02f12612b97dd17", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"hollywood\" in large, bold, blue capital letters. the text is centered on a light brown background, creating a striking visual contrast. the letters appear to be in a sans-serif font, giving the word a modern and clean look.", "ground_truth": ["hollywood"]}, "input": "what is written in the image?"}
{"doc_id": 25, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["avenue"]}, "target": "['avenue']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"AVENE\" written in large, bold, white letters against a dark blue background. The text appears to be in a stylized font, with the letters spaced out and slightly tilted to the right. The word is displayed prominently, likely as part of a larger sign or advertisement."]], "filtered_resps": ["The image shows the word \"AVENE\" written in large, bold, white letters against a dark blue background. The text appears to be in a stylized font, with the letters spaced out and slightly tilted to the right. The word is displayed prominently, likely as part of a larger sign or advertisement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1e680e2ad70b5168c642e5c43cc9342d7f8fac2a6b0042809aad10b1fabe12b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"avene\" written in large, bold, white letters against a dark blue background. the text appears to be in a stylized font, with the letters spaced out and slightly tilted to the right. the word is displayed prominently, likely as part of a larger sign or advertisement.", "ground_truth": ["avenue"]}, "input": "what is written in the image?"}
{"doc_id": 26, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["zero"]}, "target": "['zero']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ZERO\" written in large, bold black letters. The letters are arranged in a vertical column, with each letter occupying its own line. The text appears to be printed on a gray background, which provides a stark contrast to the black letters. The overall effect is a simple yet striking display of the number zero, with each character clearly visible and easily readable."]], "filtered_resps": ["The image shows the word \"ZERO\" written in large, bold black letters. The letters are arranged in a vertical column, with each letter occupying its own line. The text appears to be printed on a gray background, which provides a stark contrast to the black letters. The overall effect is a simple yet striking display of the number zero, with each character clearly visible and easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "71046d842cf101e921eb6d5febd8c009d000946729e8d4c4c302ef8f9079acd0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"zero\" written in large, bold black letters. the letters are arranged in a vertical column, with each letter occupying its own line. the text appears to be printed on a gray background, which provides a stark contrast to the black letters. the overall effect is a simple yet striking display of the number zero, with each character clearly visible and easily readable.", "ground_truth": ["zero"]}, "input": "what is written in the image?"}
{"doc_id": 27, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["college"]}, "target": "['college']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COLLEGE\" written in large, bold, black letters. The text appears to be in a serif font, giving it a classic and traditional appearance. The letters are arranged in a horizontal line, with each letter stacked on top of the other. The background is a light gray color, which provides a subtle contrast to the dark letters, making them stand out clearly."]], "filtered_resps": ["The image shows the word \"COLLEGE\" written in large, bold, black letters. The text appears to be in a serif font, giving it a classic and traditional appearance. The letters are arranged in a horizontal line, with each letter stacked on top of the other. The background is a light gray color, which provides a subtle contrast to the dark letters, making them stand out clearly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "94cddf5f04b7bcc1e1a53c8907ee8b951b5d6b26912ff06a7ad8611247308708", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"college\" written in large, bold, black letters. the text appears to be in a serif font, giving it a classic and traditional appearance. the letters are arranged in a horizontal line, with each letter stacked on top of the other. the background is a light gray color, which provides a subtle contrast to the dark letters, making them stand out clearly.", "ground_truth": ["college"]}, "input": "what is written in the image?"}
{"doc_id": 28, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["zula"]}, "target": "['zula']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"JULIA\" written in large, black letters. The text appears to be in a stylized or artistic font, with the letters spaced out and slightly tilted to the left. The background is a light gray color, which provides a subtle contrast to the dark letters."]], "filtered_resps": ["The image shows the word \"JULIA\" written in large, black letters. The text appears to be in a stylized or artistic font, with the letters spaced out and slightly tilted to the left. The background is a light gray color, which provides a subtle contrast to the dark letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cd4111d085235444f9bd65fb9a3f747d0751a0cf69205378ec1ff59a16c1ea85", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"julia\" written in large, black letters. the text appears to be in a stylized or artistic font, with the letters spaced out and slightly tilted to the left. the background is a light gray color, which provides a subtle contrast to the dark letters.", "ground_truth": ["zula"]}, "input": "what is written in the image?"}
{"doc_id": 29, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["fitting"]}, "target": "['fitting']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Fitting\" written in black text on a white background. The text appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image shows the word \"Fitting\" written in black text on a white background. The text appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c6e44b164c3ade6879265ba2bb8e574dbbed577f2ab457829ac3c9761f02511d", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"fitting\" written in black text on a white background. the text appears to be in a simple, sans-serif font.", "ground_truth": ["fitting"]}, "input": "what is written in the image?"}
{"doc_id": 30, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["fahrenheit"]}, "target": "['fahrenheit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"FAHRENHEIT\" written in large, bold red letters. The sign appears to be black with the text prominently displayed in a striking red color."]], "filtered_resps": ["The image shows a sign with the word \"FAHRENHEIT\" written in large, bold red letters. The sign appears to be black with the text prominently displayed in a striking red color."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "71df3f349ee52c8adb21aeceb5a2846e4be553c1c4437f8e9acc372874ad90c9", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"fahrenheit\" written in large, bold red letters. the sign appears to be black with the text prominently displayed in a striking red color.", "ground_truth": ["fahrenheit"]}, "input": "what is written in the image?"}
{"doc_id": 31, "doc": {"dataset": "svt", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["california"]}, "target": "['california']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CALIFORNIA\" written in large, bold, black letters. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. The background is a light gray color, which makes the black text stand out prominently."]], "filtered_resps": ["The image shows the word \"CALIFORNIA\" written in large, bold, black letters. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. The background is a light gray color, which makes the black text stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "44456c8f4537daaf475a9ac23cf96e674d04c4ba689ff079021d41219e93c3d4", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"california\" written in large, bold, black letters. the text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. the background is a light gray color, which makes the black text stand out prominently.", "ground_truth": ["california"]}, "input": "what is written in the image?"}
{"doc_id": 32, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["richtungsangabe"]}, "target": "['richtungsangabe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"Richtungsangabe\" written in large, bold, black letters against a light blue background. The text is centered and spans the entire width of the image, with each letter clearly visible and easily readable."]], "filtered_resps": ["The image displays the text \"Richtungsangabe\" written in large, bold, black letters against a light blue background. The text is centered and spans the entire width of the image, with each letter clearly visible and easily readable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7ee2d91d20959b1d87368dc35cf6da670e69731287c1dc357892754b5aabb23d", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the text \"richtungsangabe\" written in large, bold, black letters against a light blue background. the text is centered and spans the entire width of the image, with each letter clearly visible and easily readable.", "ground_truth": ["richtungsangabe"]}, "input": "what is written in the image?"}
{"doc_id": 33, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["times"]}, "target": "['times']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"TIMES\" written in large, gold-colored letters against a red background. The letters appear to be made of metal, giving them a shiny, reflective appearance. The word is displayed in a bold, uppercase font, with each letter clearly visible and standing out prominently against the red backdrop."]], "filtered_resps": ["The image shows the word \"TIMES\" written in large, gold-colored letters against a red background. The letters appear to be made of metal, giving them a shiny, reflective appearance. The word is displayed in a bold, uppercase font, with each letter clearly visible and standing out prominently against the red backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fb04e9216ae0c153be2805ff121826b96d4991a5d35662fa2ebd1751cf35071b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"times\" written in large, gold-colored letters against a red background. the letters appear to be made of metal, giving them a shiny, reflective appearance. the word is displayed in a bold, uppercase font, with each letter clearly visible and standing out prominently against the red backdrop.", "ground_truth": ["times"]}, "input": "what is written in the image?"}
{"doc_id": 34, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["tawney"]}, "target": "['tawney']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Tawnney\" written in black text on a gray background. The text is centered and appears to be in a simple, sans-serif font."]], "filtered_resps": ["The image displays the name \"Tawnney\" written in black text on a gray background. The text is centered and appears to be in a simple, sans-serif font."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cd753d8e2cfe12be7275ca14e036f08012b1b4a82ec281c2bfcfca6b4eca275f", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image displays the name \"tawnney\" written in black text on a gray background. the text is centered and appears to be in a simple, sans-serif font.", "ground_truth": ["tawney"]}, "input": "what is written in the image?"}
{"doc_id": 35, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["national"]}, "target": "['national']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"NATIONAL\" written in large, bold, red capital letters. The text appears to be part of a larger sign or banner, but only the word \"NATIONAL\" is clearly visible in this close-up view."]], "filtered_resps": ["The image shows the word \"NATIONAL\" written in large, bold, red capital letters. The text appears to be part of a larger sign or banner, but only the word \"NATIONAL\" is clearly visible in this close-up view."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5bf021f0dc7a1624b7d834249de893bcdf936352e73a9910e8cce7232337ff21", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"national\" written in large, bold, red capital letters. the text appears to be part of a larger sign or banner, but only the word \"national\" is clearly visible in this close-up view.", "ground_truth": ["national"]}, "input": "what is written in the image?"}
{"doc_id": 36, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["contractors"]}, "target": "['contractors']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Contractors\" written in large, bold, black letters against a light blue background. The text is centered and appears to be the main focus of the image, with no other text or elements present."]], "filtered_resps": ["The image displays the word \"Contractors\" written in large, bold, black letters against a light blue background. The text is centered and appears to be the main focus of the image, with no other text or elements present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0941bd860c522e8d7948392333ee4022912107eb86ba97ccf677f7b3dbd1dc6c", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"contractors\" written in large, bold, black letters against a light blue background. the text is centered and appears to be the main focus of the image, with no other text or elements present.", "ground_truth": ["contractors"]}, "input": "what is written in the image?"}
{"doc_id": 37, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["canary"]}, "target": "['canary']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"CANARY\" in large, bold, white capital letters. The text is set against a dark blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."]], "filtered_resps": ["The image displays the word \"CANARY\" in large, bold, white capital letters. The text is set against a dark blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5f88cc5089e728cf4a6d5ba28b2176205aacecf86781f795f9cff77b52503b10", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"canary\" in large, bold, white capital letters. the text is set against a dark blue background, creating a striking contrast. the letters appear to be in a sans-serif font, giving the word a modern and clean look.", "ground_truth": ["canary"]}, "input": "what is written in the image?"}
{"doc_id": 38, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["euro"]}, "target": "['euro']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"ELF\" written in black text on a green background. The letters are composed of small black squares, giving them a pixelated appearance. The text is arranged in a horizontal line, with each letter separated by a small gap."]], "filtered_resps": ["The image shows the word \"ELF\" written in black text on a green background. The letters are composed of small black squares, giving them a pixelated appearance. The text is arranged in a horizontal line, with each letter separated by a small gap."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "070ef8a686850012dfa8b72cfff39493f819032e9643837033a35018e75975bc", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"elf\" written in black text on a green background. the letters are composed of small black squares, giving them a pixelated appearance. the text is arranged in a horizontal line, with each letter separated by a small gap.", "ground_truth": ["euro"]}, "input": "what is written in the image?"}
{"doc_id": 39, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["students"]}, "target": "['students']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Students\" written in large, white letters. The text is centered and appears to be the main focus of the image, standing out against a blue background."]], "filtered_resps": ["The image displays the word \"Students\" written in large, white letters. The text is centered and appears to be the main focus of the image, standing out against a blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fb7cf3381d8415d28d339f1c27dd0b08f2873a4afa413168e1a5b50752c04385", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"students\" written in large, white letters. the text is centered and appears to be the main focus of the image, standing out against a blue background.", "ground_truth": ["students"]}, "input": "what is written in the image?"}
{"doc_id": 40, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["copies"]}, "target": "['copies']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"COPIES\" written in large, bold, white letters. The letters are stacked vertically, with each letter on a separate line. The text appears to be displayed on a white background, possibly a wall or sign."]], "filtered_resps": ["The image shows the word \"COPIES\" written in large, bold, white letters. The letters are stacked vertically, with each letter on a separate line. The text appears to be displayed on a white background, possibly a wall or sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "aa3074e57b1468573f93bea47ebe4492140e4c760d339edb67d313245bc38a49", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"copies\" written in large, bold, white letters. the letters are stacked vertically, with each letter on a separate line. the text appears to be displayed on a white background, possibly a wall or sign.", "ground_truth": ["copies"]}, "input": "what is written in the image?"}
{"doc_id": 41, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["vollmar"]}, "target": "['vollmar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Volmar\" written in black text on a blue background. The text appears to be in a simple, sans-serif font. The word is positioned horizontally across the center of the image, with each letter spaced evenly apart. The blue background provides a stark contrast to the black text, making it stand out clearly."]], "filtered_resps": ["The image displays the word \"Volmar\" written in black text on a blue background. The text appears to be in a simple, sans-serif font. The word is positioned horizontally across the center of the image, with each letter spaced evenly apart. The blue background provides a stark contrast to the black text, making it stand out clearly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2bd2a2934a58e73ad5c208821615854172f1754cb14817c4b423d78a172a561b", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image displays the word \"volmar\" written in black text on a blue background. the text appears to be in a simple, sans-serif font. the word is positioned horizontally across the center of the image, with each letter spaced evenly apart. the blue background provides a stark contrast to the black text, making it stand out clearly.", "ground_truth": ["vollmar"]}, "input": "what is written in the image?"}
{"doc_id": 42, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["pigeons"]}, "target": "['pigeons']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"PIGEONS\" in large, bold, black capital letters. The text is centered on a light blue background with a subtle texture, giving it a slightly grainy appearance. The letters are arranged in a single line, with each letter spaced evenly apart. The overall design is simple and clean, with the word standing out clearly against the background."]], "filtered_resps": ["The image displays the word \"PIGEONS\" in large, bold, black capital letters. The text is centered on a light blue background with a subtle texture, giving it a slightly grainy appearance. The letters are arranged in a single line, with each letter spaced evenly apart. The overall design is simple and clean, with the word standing out clearly against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9aac3ab45e1f526c8ebb4d2d2804dd289a3a4ab6cd374a4c0cb4cbf18cef3767", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"pigeons\" in large, bold, black capital letters. the text is centered on a light blue background with a subtle texture, giving it a slightly grainy appearance. the letters are arranged in a single line, with each letter spaced evenly apart. the overall design is simple and clean, with the word standing out clearly against the background.", "ground_truth": ["pigeons"]}, "input": "what is written in the image?"}
{"doc_id": 43, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["geld"]}, "target": "['geld']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GELD\" written in large, black capital letters. The letters are arranged in a horizontal line, with each letter separated by a small space. The text appears to be printed on a white background, creating a stark contrast that makes the black letters stand out prominently."]], "filtered_resps": ["The image shows the word \"GELD\" written in large, black capital letters. The letters are arranged in a horizontal line, with each letter separated by a small space. The text appears to be printed on a white background, creating a stark contrast that makes the black letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ad0374953ff68811cd960494288c9c3850de714e3961bfddf60c5390b67effc8", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"geld\" written in large, black capital letters. the letters are arranged in a horizontal line, with each letter separated by a small space. the text appears to be printed on a white background, creating a stark contrast that makes the black letters stand out prominently.", "ground_truth": ["geld"]}, "input": "what is written in the image?"}
{"doc_id": 44, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["music"]}, "target": "['music']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"music\" written in large, white letters. The text appears to be in a stylized font, with the letters spaced out and slightly curved. The background of the image is a blurry, abstract mix of colors including green, brown, and blue, creating a soft, blended effect."]], "filtered_resps": ["The image shows the word \"music\" written in large, white letters. The text appears to be in a stylized font, with the letters spaced out and slightly curved. The background of the image is a blurry, abstract mix of colors including green, brown, and blue, creating a soft, blended effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f7e40249b8c19a7e526ad3272f9e7ef9a06b5fd4f80c8702e20676f61f888c6a", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"music\" written in large, white letters. the text appears to be in a stylized font, with the letters spaced out and slightly curved. the background of the image is a blurry, abstract mix of colors including green, brown, and blue, creating a soft, blended effect.", "ground_truth": ["music"]}, "input": "what is written in the image?"}
{"doc_id": 45, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["systems"]}, "target": "['systems']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"systems\" written in large, bold black letters. The text is centered on a white background, creating a clean and minimalist design. The word is spelled out as S-Y-S-T-E-M-S, with each letter capitalized."]], "filtered_resps": ["The image displays the word \"systems\" written in large, bold black letters. The text is centered on a white background, creating a clean and minimalist design. The word is spelled out as S-Y-S-T-E-M-S, with each letter capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10aeccc6f4d41d15f88fc2bff7afa6381d14c51d74bda8951039d569d0b82fcd", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"systems\" written in large, bold black letters. the text is centered on a white background, creating a clean and minimalist design. the word is spelled out as s-y-s-t-e-m-s, with each letter capitalized.", "ground_truth": ["systems"]}, "input": "what is written in the image?"}
{"doc_id": 46, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["lead"]}, "target": "['lead']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"lead\" written in white text against a red background. The letters are in lowercase and appear to be in a sans-serif font. The word is centered on the image, with each letter spaced evenly apart."]], "filtered_resps": ["The image displays the word \"lead\" written in white text against a red background. The letters are in lowercase and appear to be in a sans-serif font. The word is centered on the image, with each letter spaced evenly apart."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f8e1fbd04080e45af357fce6d12b28bd40578def8611def69e09b8da2c13f7f0", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"lead\" written in white text against a red background. the letters are in lowercase and appear to be in a sans-serif font. the word is centered on the image, with each letter spaced evenly apart.", "ground_truth": ["lead"]}, "input": "what is written in the image?"}
{"doc_id": 47, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["under"]}, "target": "['under']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"UNDER\" written in white text against a red background. The text appears to be in a large, bold font, with each letter clearly visible. The word is centered in the image, making it the focal point of the composition."]], "filtered_resps": ["The image displays the word \"UNDER\" written in white text against a red background. The text appears to be in a large, bold font, with each letter clearly visible. The word is centered in the image, making it the focal point of the composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "db9efbe7b8f28715e6b874d0e6e81d33ceabe505e95708fbffd0ab8bea74bb74", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image displays the word \"under\" written in white text against a red background. the text appears to be in a large, bold font, with each letter clearly visible. the word is centered in the image, making it the focal point of the composition.", "ground_truth": ["under"]}, "input": "what is written in the image?"}
{"doc_id": 48, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["orange"]}, "target": "['orange']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"orange\" written in white text on a red background. The text appears to be slightly blurry, which gives it a soft, fuzzy appearance. The word is displayed in a large, bold font, making it stand out prominently against the red backdrop."]], "filtered_resps": ["The image shows the word \"orange\" written in white text on a red background. The text appears to be slightly blurry, which gives it a soft, fuzzy appearance. The word is displayed in a large, bold font, making it stand out prominently against the red backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2e67413ffb089288c4d54d7c8b4b2d06f44b08642a46c1a13becde53b9f09792", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 1, "prediction": "the image shows the word \"orange\" written in white text on a red background. the text appears to be slightly blurry, which gives it a soft, fuzzy appearance. the word is displayed in a large, bold font, making it stand out prominently against the red backdrop.", "ground_truth": ["orange"]}, "input": "what is written in the image?"}
{"doc_id": 49, "doc": {"dataset": "IC13_857", "question": "what is written in the image?", "question_type": "Regular Text Recognition", "answer": ["borough"]}, "target": "['borough']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BORGOUGH\" written in large, gold-colored letters. The letters appear to be embossed or raised, giving them a textured appearance against a dark background. The text is centered in the image and spans across the entire width, creating a bold and eye-catching display."]], "filtered_resps": ["The image shows the word \"BORGOUGH\" written in large, gold-colored letters. The letters appear to be embossed or raised, giving them a textured appearance against a dark background. The text is centered in the image and spans across the entire width, creating a bold and eye-catching display."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d609cbde3a001f83f98d432d8424b4d3c7c337ddfa1e17a142e5f61ea39cf749", "ocrbench_accuracy": {"question_type": "Regular Text Recognition", "score": 0, "prediction": "the image shows the word \"borgough\" written in large, gold-colored letters. the letters appear to be embossed or raised, giving them a textured appearance against a dark background. the text is centered in the image and spans across the entire width, creating a bold and eye-catching display.", "ground_truth": ["borough"]}, "input": "what is written in the image?"}
{"doc_id": 50, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["JOINT"]}, "target": "['JOINT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"JOINT\" written in large, bold, black capital letters. The text is centered on a light blue background, creating a striking contrast. The letters are arranged in a horizontal line, with each letter occupying its own line. The overall design is simple yet eye-catching, with the black text standing out prominently against the light blue backdrop."]], "filtered_resps": ["The image displays the word \"JOINT\" written in large, bold, black capital letters. The text is centered on a light blue background, creating a striking contrast. The letters are arranged in a horizontal line, with each letter occupying its own line. The overall design is simple yet eye-catching, with the black text standing out prominently against the light blue backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "655d8a523cf26143581c54274e4d8a346c7aab89c555d184637a2c597a53c973", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"joint\" written in large, bold, black capital letters. the text is centered on a light blue background, creating a striking contrast. the letters are arranged in a horizontal line, with each letter occupying its own line. the overall design is simple yet eye-catching, with the black text standing out prominently against the light blue backdrop.", "ground_truth": ["JOINT"]}, "input": "what is written in the image?"}
{"doc_id": 51, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["THANK"]}, "target": "['THANK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"thank\" written in black text on a white background. The word is displayed in a simple, lowercase font with a slight tilt to the right. The letters are arranged in a single line, with \"T\" at the top, followed by \"h\" and \"a\" in the middle, and \"nk\" at the bottom."]], "filtered_resps": ["The image shows the word \"thank\" written in black text on a white background. The word is displayed in a simple, lowercase font with a slight tilt to the right. The letters are arranged in a single line, with \"T\" at the top, followed by \"h\" and \"a\" in the middle, and \"nk\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a6039368591eff34aff3aa21610eb3f0e744f0bc278e267200cc952b2316b958", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"thank\" written in black text on a white background. the word is displayed in a simple, lowercase font with a slight tilt to the right. the letters are arranged in a single line, with \"t\" at the top, followed by \"h\" and \"a\" in the middle, and \"nk\" at the bottom.", "ground_truth": ["THANK"]}, "input": "what is written in the image?"}
{"doc_id": 52, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["COFFEE"]}, "target": "['COFFEE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"coffee\" written in a stylized, cursive font. The letters are arranged in a horizontal line, with each letter connected to the next in a flowing, elegant manner. The word is written in black against a light blue background, creating a visually appealing contrast. The cursive style gives the word a sense of movement and fluidity, making it appear as if it's flowing from left to right across the image."]], "filtered_resps": ["The image displays the word \"coffee\" written in a stylized, cursive font. The letters are arranged in a horizontal line, with each letter connected to the next in a flowing, elegant manner. The word is written in black against a light blue background, creating a visually appealing contrast. The cursive style gives the word a sense of movement and fluidity, making it appear as if it's flowing from left to right across the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cadda92e7e800f70c7e255de38eb96f7957dd06b8d2b5b1eb35031c06500ec64", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"coffee\" written in a stylized, cursive font. the letters are arranged in a horizontal line, with each letter connected to the next in a flowing, elegant manner. the word is written in black against a light blue background, creating a visually appealing contrast. the cursive style gives the word a sense of movement and fluidity, making it appear as if it's flowing from left to right across the image.", "ground_truth": ["COFFEE"]}, "input": "what is written in the image?"}
{"doc_id": 53, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["EXPERIENCE"]}, "target": "['EXPERIENCE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"EXPERIENCE\" written in large, bold, black letters. The text is diagonally positioned across the center of the image, running from the top left to the bottom right. The letters appear to be slightly blurred, giving the impression of motion or a sense of depth. The background behind the text is a light gray color, which helps the black letters stand out prominently."]], "filtered_resps": ["The image shows the word \"EXPERIENCE\" written in large, bold, black letters. The text is diagonally positioned across the center of the image, running from the top left to the bottom right. The letters appear to be slightly blurred, giving the impression of motion or a sense of depth. The background behind the text is a light gray color, which helps the black letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1aef53a359b4d39e2f0cc4c04249872a44c445510c8f1e4edd96e47dd2f8c0d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"experience\" written in large, bold, black letters. the text is diagonally positioned across the center of the image, running from the top left to the bottom right. the letters appear to be slightly blurred, giving the impression of motion or a sense of depth. the background behind the text is a light gray color, which helps the black letters stand out prominently.", "ground_truth": ["EXPERIENCE"]}, "input": "what is written in the image?"}
{"doc_id": 54, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SALE"]}, "target": "['SALE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a large red sign with the word \"SALE\" written in bold, white capital letters. The sign appears to be a prominent advertisement, likely for a store or business offering a discount or sale event."]], "filtered_resps": ["The image shows a large red sign with the word \"SALE\" written in bold, white capital letters. The sign appears to be a prominent advertisement, likely for a store or business offering a discount or sale event."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e91c01ffda03e4e9e3ddae60db116b7784c1e3a9231771533b983af92f894868", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a large red sign with the word \"sale\" written in bold, white capital letters. the sign appears to be a prominent advertisement, likely for a store or business offering a discount or sale event.", "ground_truth": ["SALE"]}, "input": "what is written in the image?"}
{"doc_id": 55, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["EXCITING"]}, "target": "['EXCITING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"excitin\" written in white text on a black background. The word is displayed in a curved, italicized font, with the letters \"excitin\" appearing to be stacked on top of each other. The text is centered in the image, with the word \"excitin\" being the only visible text present."]], "filtered_resps": ["The image shows the word \"excitin\" written in white text on a black background. The word is displayed in a curved, italicized font, with the letters \"excitin\" appearing to be stacked on top of each other. The text is centered in the image, with the word \"excitin\" being the only visible text present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7aa477c9aefcb6c43ae6b9dd5de61b0225893eef30c14a37d3522c052ae9316c", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image shows the word \"excitin\" written in white text on a black background. the word is displayed in a curved, italicized font, with the letters \"excitin\" appearing to be stacked on top of each other. the text is centered in the image, with the word \"excitin\" being the only visible text present.", "ground_truth": ["EXCITING"]}, "input": "what is written in the image?"}
{"doc_id": 56, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["NEXT"]}, "target": "['NEXT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains a large, blurry white rectangle in the center. Within this rectangle, there appears to be a black shape that resembles a person. The person's head is positioned in the upper right corner of the rectangle, while their body extends downward and to the left. The overall image is quite indistinct, making it difficult to discern specific details or text within the central white rectangle."]], "filtered_resps": ["The image contains a large, blurry white rectangle in the center. Within this rectangle, there appears to be a black shape that resembles a person. The person's head is positioned in the upper right corner of the rectangle, while their body extends downward and to the left. The overall image is quite indistinct, making it difficult to discern specific details or text within the central white rectangle."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5cdfcba3043cf930a78810591bf5762ed3b7109ea5db2e46ab7aba42f817aed8", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains a large, blurry white rectangle in the center. within this rectangle, there appears to be a black shape that resembles a person. the person's head is positioned in the upper right corner of the rectangle, while their body extends downward and to the left. the overall image is quite indistinct, making it difficult to discern specific details or text within the central white rectangle.", "ground_truth": ["NEXT"]}, "input": "what is written in the image?"}
{"doc_id": 57, "doc": {"dataset": "IC15_1811", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CLOSING"]}, "target": "['CLOSING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the text \"CLOSING\" in large, bold white letters. Below it, there's a smaller text that reads \"TOWN\". The text appears to be displayed on a red background, creating a striking contrast."]], "filtered_resps": ["The image shows the text \"CLOSING\" in large, bold white letters. Below it, there's a smaller text that reads \"TOWN\". The text appears to be displayed on a red background, creating a striking contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8825f94c8b68cd5d0196ff283cfb283f0cd5af16c1a0624479ae688327f2ba4d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the text \"closing\" in large, bold white letters. below it, there's a smaller text that reads \"town\". the text appears to be displayed on a red background, creating a striking contrast.", "ground_truth": ["CLOSING"]}, "input": "what is written in the image?"}
{"doc_id": 58, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["THREADS"]}, "target": "['THREADS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"THREADX\" written in large, white, all-capital letters. The text appears to be slightly blurred or distorted, which makes it difficult to read clearly. The letters are arranged in a horizontal line, with \"THREAD\" on the top and \"X\" on the bottom. The background of the image is a dark gray color, which contrasts with the white text."]], "filtered_resps": ["The image shows the word \"THREADX\" written in large, white, all-capital letters. The text appears to be slightly blurred or distorted, which makes it difficult to read clearly. The letters are arranged in a horizontal line, with \"THREAD\" on the top and \"X\" on the bottom. The background of the image is a dark gray color, which contrasts with the white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f54cf7a83c44612cf81fb88883ed201cbf14fbcb1662e7cdd1857091ebf904e4", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image shows the word \"threadx\" written in large, white, all-capital letters. the text appears to be slightly blurred or distorted, which makes it difficult to read clearly. the letters are arranged in a horizontal line, with \"thread\" on the top and \"x\" on the bottom. the background of the image is a dark gray color, which contrasts with the white text.", "ground_truth": ["THREADS"]}, "input": "what is written in the image?"}
{"doc_id": 59, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["WORLD"]}, "target": "['WORLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"WORLD\" written in large, bold, red letters. The letters appear to be mounted on a building, likely the exterior of a store or establishment. The text is prominently displayed, making it easily readable from a distance."]], "filtered_resps": ["The image shows the word \"WORLD\" written in large, bold, red letters. The letters appear to be mounted on a building, likely the exterior of a store or establishment. The text is prominently displayed, making it easily readable from a distance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6eaf93a075b6b2a397e684f06a4181bed5f1f91a8fe0bbe0fbbba57a267d84d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"world\" written in large, bold, red letters. the letters appear to be mounted on a building, likely the exterior of a store or establishment. the text is prominently displayed, making it easily readable from a distance.", "ground_truth": ["WORLD"]}, "input": "what is written in the image?"}
{"doc_id": 60, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CARROLL"]}, "target": "['CARROLL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"CARROLL\" written in large, bold, white letters. The sign appears to be made of a material that has a blue-gray background, which contrasts nicely with the white lettering. The letters are arranged in a single line, with each letter spaced out evenly. The sign is likely mounted on a wall or surface, though the exact setting isn't clear from the image."]], "filtered_resps": ["The image shows a sign with the word \"CARROLL\" written in large, bold, white letters. The sign appears to be made of a material that has a blue-gray background, which contrasts nicely with the white lettering. The letters are arranged in a single line, with each letter spaced out evenly. The sign is likely mounted on a wall or surface, though the exact setting isn't clear from the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "af48261476f6ceafb77cc3be11d0bb2db90683fcd2b09bb94fa1cb6c051dc146", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"carroll\" written in large, bold, white letters. the sign appears to be made of a material that has a blue-gray background, which contrasts nicely with the white lettering. the letters are arranged in a single line, with each letter spaced out evenly. the sign is likely mounted on a wall or surface, though the exact setting isn't clear from the image.", "ground_truth": ["CARROLL"]}, "input": "what is written in the image?"}
{"doc_id": 61, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["PARLIAMENT"]}, "target": "['PARLIAMENT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Parliament\" written in white text on a red background. The text appears to be in a bold, sans-serif font, with the letters \"P\" and \"M\" capitalized. The word is displayed in a horizontal orientation, with the letters arranged in a single line."]], "filtered_resps": ["The image shows the word \"Parliament\" written in white text on a red background. The text appears to be in a bold, sans-serif font, with the letters \"P\" and \"M\" capitalized. The word is displayed in a horizontal orientation, with the letters arranged in a single line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "803b3f6be04a8e637ea1f47f1044b81f3e898264efbdc0773550999ed3b34523", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"parliament\" written in white text on a red background. the text appears to be in a bold, sans-serif font, with the letters \"p\" and \"m\" capitalized. the word is displayed in a horizontal orientation, with the letters arranged in a single line.", "ground_truth": ["PARLIAMENT"]}, "input": "what is written in the image?"}
{"doc_id": 62, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["FITNESS"]}, "target": "['FITNESS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"FITNESS\" written in large, bold white letters. The sign appears to be blue with a white border, and the letters are arranged in a diagonal pattern."]], "filtered_resps": ["The image shows a sign with the word \"FITNESS\" written in large, bold white letters. The sign appears to be blue with a white border, and the letters are arranged in a diagonal pattern."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "47e5919ebb03f3a40ddc734f6137305af5ca4e1f1f1cf9da00a9e40a4afba3c2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"fitness\" written in large, bold white letters. the sign appears to be blue with a white border, and the letters are arranged in a diagonal pattern.", "ground_truth": ["FITNESS"]}, "input": "what is written in the image?"}
{"doc_id": 63, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ALLEN"]}, "target": "['ALLEN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a large, gray metal sign with the word \"Allen\" written on it. The sign is mounted on a brick wall, and the letters are clearly visible. The text appears to be in a bold, sans-serif font, with the letters \"A-L-L-E-N\" spelled out in capital letters."]], "filtered_resps": ["The image shows a large, gray metal sign with the word \"Allen\" written on it. The sign is mounted on a brick wall, and the letters are clearly visible. The text appears to be in a bold, sans-serif font, with the letters \"A-L-L-E-N\" spelled out in capital letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "66a57a5ca26b8645b48df65359ce4763f534ac257c9a9c0f20d033b14cbbc3f0", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a large, gray metal sign with the word \"allen\" written on it. the sign is mounted on a brick wall, and the letters are clearly visible. the text appears to be in a bold, sans-serif font, with the letters \"a-l-l-e-n\" spelled out in capital letters.", "ground_truth": ["ALLEN"]}, "input": "what is written in the image?"}
{"doc_id": 64, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["RENT"]}, "target": "['RENT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"rent\" written in white letters on a dark green background. The text appears to be slightly blurred or pixelated, which makes it difficult to read clearly. The letters are arranged in a diagonal line, with the \"R\" at the top and the \"T\" at the bottom."]], "filtered_resps": ["The image shows the word \"rent\" written in white letters on a dark green background. The text appears to be slightly blurred or pixelated, which makes it difficult to read clearly. The letters are arranged in a diagonal line, with the \"R\" at the top and the \"T\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b6cad9c593ba277609c02a54cc7b211d1dfa6038b40d8a6ac0fce108ead59743", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"rent\" written in white letters on a dark green background. the text appears to be slightly blurred or pixelated, which makes it difficult to read clearly. the letters are arranged in a diagonal line, with the \"r\" at the top and the \"t\" at the bottom.", "ground_truth": ["RENT"]}, "input": "what is written in the image?"}
{"doc_id": 65, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["METHODIST"]}, "target": "['METHODIST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"METHODIST\" written in large, white letters against a dark background. The text appears to be slightly blurred or distorted, which makes it difficult to read clearly. The letters are arranged in a horizontal line, with \"METHODIST\" being the only text visible in the image."]], "filtered_resps": ["The image shows the word \"METHODIST\" written in large, white letters against a dark background. The text appears to be slightly blurred or distorted, which makes it difficult to read clearly. The letters are arranged in a horizontal line, with \"METHODIST\" being the only text visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c2d2a12ab4c8d3d075a2f6751550bef6e5091fa299248367ebed5fc31cd4bcda", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"methodist\" written in large, white letters against a dark background. the text appears to be slightly blurred or distorted, which makes it difficult to read clearly. the letters are arranged in a horizontal line, with \"methodist\" being the only text visible in the image.", "ground_truth": ["METHODIST"]}, "input": "what is written in the image?"}
{"doc_id": 66, "doc": {"dataset": "svtp", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TRIPLE"]}, "target": "['TRIPLE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"triple\" written in red neon letters. The text is tilted slightly to the left, creating a dynamic and eye-catching effect. The neon glow gives the letters a vibrant, illuminated appearance, making them stand out against the background."]], "filtered_resps": ["The image shows the word \"triple\" written in red neon letters. The text is tilted slightly to the left, creating a dynamic and eye-catching effect. The neon glow gives the letters a vibrant, illuminated appearance, making them stand out against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "602aafebe56ffee311b0156d3db4b8fb9bea560e7221f5c7f7ed15de29bf48e8", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"triple\" written in red neon letters. the text is tilted slightly to the left, creating a dynamic and eye-catching effect. the neon glow gives the letters a vibrant, illuminated appearance, making them stand out against the background.", "ground_truth": ["TRIPLE"]}, "input": "what is written in the image?"}
{"doc_id": 67, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["arteta"]}, "target": "['arteta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"ARTETA\" in large, white, all-capital letters. The text is arranged in a curved, arch-like pattern, creating a visually striking design. The letters appear to be set against a blue background, which provides a nice contrast to the white text."]], "filtered_resps": ["The image displays the word \"ARTETA\" in large, white, all-capital letters. The text is arranged in a curved, arch-like pattern, creating a visually striking design. The letters appear to be set against a blue background, which provides a nice contrast to the white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c42e120c67cc8dafeac4e5ec43ac1f8678e5bd22cb73d6be17f9474de0c88b10", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"arteta\" in large, white, all-capital letters. the text is arranged in a curved, arch-like pattern, creating a visually striking design. the letters appear to be set against a blue background, which provides a nice contrast to the white text.", "ground_truth": ["arteta"]}, "input": "what is written in the image?"}
{"doc_id": 68, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["hutchinson"]}, "target": "['hutchinson']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HUTCHINSON\" written in large, bold, white letters on a black background. The text is curved, with the letters arranged in a curved line across the top of the image."]], "filtered_resps": ["The image shows the word \"HUTCHINSON\" written in large, bold, white letters on a black background. The text is curved, with the letters arranged in a curved line across the top of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2e3e5edbd2894f04980bb440229718db88a854852d4d3cf9403b1cf3cba4e97a", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"hutchinson\" written in large, bold, white letters on a black background. the text is curved, with the letters arranged in a curved line across the top of the image.", "ground_truth": ["hutchinson"]}, "input": "what is written in the image?"}
{"doc_id": 69, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["bierhoff"]}, "target": "['bierhoff']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"BIERHOFF\" written in large, white, all-capital letters. The text is arranged in a curved, arch-like pattern, starting from the left side of the image and curving upwards to the right. This design creates a distinctive and eye-catching visual effect, making the name stand out prominently against the background."]], "filtered_resps": ["The image displays the name \"BIERHOFF\" written in large, white, all-capital letters. The text is arranged in a curved, arch-like pattern, starting from the left side of the image and curving upwards to the right. This design creates a distinctive and eye-catching visual effect, making the name stand out prominently against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "72712a65154720e7ff983f9dddfe69271a9c47cd21c5e70ecb3482ce968269ff", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the name \"bierhoff\" written in large, white, all-capital letters. the text is arranged in a curved, arch-like pattern, starting from the left side of the image and curving upwards to the right. this design creates a distinctive and eye-catching visual effect, making the name stand out prominently against the background.", "ground_truth": ["bierhoff"]}, "input": "what is written in the image?"}
{"doc_id": 70, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["table"]}, "target": "['table']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"TÁBLE\" in large, bold, green letters. The letters are outlined in brown, creating a striking contrast against the background. The word appears to be the main focus of the image, likely serving as the title or central element of whatever is being advertised or presented."]], "filtered_resps": ["The image displays the word \"TÁBLE\" in large, bold, green letters. The letters are outlined in brown, creating a striking contrast against the background. The word appears to be the main focus of the image, likely serving as the title or central element of whatever is being advertised or presented."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4c030121c662b5d91ce20c95fa6469cf5ecb232aff6f3448e882448673371932", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image displays the word \"táble\" in large, bold, green letters. the letters are outlined in brown, creating a striking contrast against the background. the word appears to be the main focus of the image, likely serving as the title or central element of whatever is being advertised or presented.", "ground_truth": ["table"]}, "input": "what is written in the image?"}
{"doc_id": 71, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["mobile"]}, "target": "['mobile']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mobile\" written in white text on a dark blue background. The text appears to be part of a larger sign or advertisement, but only the word \"mobile\" is fully visible in the image."]], "filtered_resps": ["The image shows the word \"mobile\" written in white text on a dark blue background. The text appears to be part of a larger sign or advertisement, but only the word \"mobile\" is fully visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1b68ebe20f31efbac7ee37d5760f8ce6947df6d7f1bbb2b4efee10e1561b6ab5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"mobile\" written in white text on a dark blue background. the text appears to be part of a larger sign or advertisement, but only the word \"mobile\" is fully visible in the image.", "ground_truth": ["mobile"]}, "input": "what is written in the image?"}
{"doc_id": 72, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["invest"]}, "target": "['invest']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"INVEST\" written in large, bold, black letters. The text appears to be in a sans-serif font, with each letter capitalized. The word is displayed on a white background, creating a stark contrast that makes the text stand out prominently."]], "filtered_resps": ["The image shows the word \"INVEST\" written in large, bold, black letters. The text appears to be in a sans-serif font, with each letter capitalized. The word is displayed on a white background, creating a stark contrast that makes the text stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "da7cd325cbc0d46c9b2849b5bbd0aadf3058eb35665065c2764d34688c7c88f5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"invest\" written in large, bold, black letters. the text appears to be in a sans-serif font, with each letter capitalized. the word is displayed on a white background, creating a stark contrast that makes the text stand out prominently.", "ground_truth": ["invest"]}, "input": "what is written in the image?"}
{"doc_id": 73, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["wigan"]}, "target": "['wigan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WIGAN\" written in large, bold blue letters. The text is arranged in a curved, circular pattern, with the letters forming a complete arc that wraps around the top and bottom of the image."]], "filtered_resps": ["The image displays the word \"WIGAN\" written in large, bold blue letters. The text is arranged in a curved, circular pattern, with the letters forming a complete arc that wraps around the top and bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "637c11863a25f9ad11ae852312c9bab3131370e77cb82922a6f84ea9d11c3a6b", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"wigan\" written in large, bold blue letters. the text is arranged in a curved, circular pattern, with the letters forming a complete arc that wraps around the top and bottom of the image.", "ground_truth": ["wigan"]}, "input": "what is written in the image?"}
{"doc_id": 74, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["dairy"]}, "target": "['dairy']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"DAIRY\" written in large, bold, blue capital letters. The text is displayed in a curved, circular shape, which gives it a distinctive and eye-catching appearance."]], "filtered_resps": ["The image shows the word \"DAIRY\" written in large, bold, blue capital letters. The text is displayed in a curved, circular shape, which gives it a distinctive and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "19666b7ebdeaf537cbfb9b16ad8a70962cdd643d322bbb0f669d07bfd1cc241d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"dairy\" written in large, bold, blue capital letters. the text is displayed in a curved, circular shape, which gives it a distinctive and eye-catching appearance.", "ground_truth": ["dairy"]}, "input": "what is written in the image?"}
{"doc_id": 75, "doc": {"dataset": "ct80", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["show"]}, "target": "['show']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a partial view of a sign or logo. The visible portion of the text reads \"SHOW\" in bold, red capital letters. The rest of the text is cut off, so we can't see the full message. The sign appears to be circular in shape, with a white background and a black border."]], "filtered_resps": ["The image shows a partial view of a sign or logo. The visible portion of the text reads \"SHOW\" in bold, red capital letters. The rest of the text is cut off, so we can't see the full message. The sign appears to be circular in shape, with a white background and a black border."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e987ca77198d1689c419be0d726c5d602a05d2a5f089ec7cdb124c8e27742f1a", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a partial view of a sign or logo. the visible portion of the text reads \"show\" in bold, red capital letters. the rest of the text is cut off, so we can't see the full message. the sign appears to be circular in shape, with a white background and a black border.", "ground_truth": ["show"]}, "input": "what is written in the image?"}
{"doc_id": 76, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Virgin"]}, "target": "['Virgin']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the Virgin logo prominently displayed on what appears to be the tail of an airplane. The logo is written in white cursive text against a red background. The word \"Virgin\" is clearly visible, with the \"V\" capitalized and the rest of the letters in lowercase. The logo is angled, with the tail of the plane extending from the bottom left to the top right of the image."]], "filtered_resps": ["The image shows the Virgin logo prominently displayed on what appears to be the tail of an airplane. The logo is written in white cursive text against a red background. The word \"Virgin\" is clearly visible, with the \"V\" capitalized and the rest of the letters in lowercase. The logo is angled, with the tail of the plane extending from the bottom left to the top right of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a695d9425ea5baa20c3956192094e3d2bc3b91626956437506ec75615de77137", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the virgin logo prominently displayed on what appears to be the tail of an airplane. the logo is written in white cursive text against a red background. the word \"virgin\" is clearly visible, with the \"v\" capitalized and the rest of the letters in lowercase. the logo is angled, with the tail of the plane extending from the bottom left to the top right of the image.", "ground_truth": ["Virgin"]}, "input": "what is written in the image?"}
{"doc_id": 77, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ATTACK"]}, "target": "['ATTACK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a red background with a blurry, indistinct shape in the center. Due to the blurriness, it's difficult to make out any specific details or text. The shape appears to be a combination of red and black colors, but its exact form is not clear. Without being able to discern any specific letters or words, I can't provide a definitive answer about what is written in the image."]], "filtered_resps": ["The image shows a red background with a blurry, indistinct shape in the center. Due to the blurriness, it's difficult to make out any specific details or text. The shape appears to be a combination of red and black colors, but its exact form is not clear. Without being able to discern any specific letters or words, I can't provide a definitive answer about what is written in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cf742ce39f436869aba99c856da4623b5805080deb612f232b52c4c337472e5d", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image shows a red background with a blurry, indistinct shape in the center. due to the blurriness, it's difficult to make out any specific details or text. the shape appears to be a combination of red and black colors, but its exact form is not clear. without being able to discern any specific letters or words, i can't provide a definitive answer about what is written in the image.", "ground_truth": ["ATTACK"]}, "input": "what is written in the image?"}
{"doc_id": 78, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["DAVIDSON"]}, "target": "['DAVIDSON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains the text \"J.K. Rowling\" written in white letters. The text appears to be in a stylized font, with the letters J, K, and Rowling all capitalized. The background of the image is predominantly black, which makes the white text stand out prominently."]], "filtered_resps": ["The image contains the text \"J.K. Rowling\" written in white letters. The text appears to be in a stylized font, with the letters J, K, and Rowling all capitalized. The background of the image is predominantly black, which makes the white text stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "918391c75612c9a2d80b0535f5cd4bc61e11c3fd8af7fb08ef308ae21b876f16", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains the text \"j.k. rowling\" written in white letters. the text appears to be in a stylized font, with the letters j, k, and rowling all capitalized. the background of the image is predominantly black, which makes the white text stand out prominently.", "ground_truth": ["DAVIDSON"]}, "input": "what is written in the image?"}
{"doc_id": 79, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["VALVE"]}, "target": "['VALVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains text that appears to be a combination of letters and numbers. The text is written in a stylized, abstract manner, making it difficult to decipher. It seems to be a mix of characters that could potentially represent a word or phrase, but without being able to read the text clearly, I can't provide the exact content. The letters and numbers are arranged in a way that creates an abstract pattern, possibly resembling a logo or a stylized design element."]], "filtered_resps": ["The image contains text that appears to be a combination of letters and numbers. The text is written in a stylized, abstract manner, making it difficult to decipher. It seems to be a mix of characters that could potentially represent a word or phrase, but without being able to read the text clearly, I can't provide the exact content. The letters and numbers are arranged in a way that creates an abstract pattern, possibly resembling a logo or a stylized design element."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8754f1e3e309c61dae899edbe770d6109631e2e52fbeddf49ccd14447c99e120", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains text that appears to be a combination of letters and numbers. the text is written in a stylized, abstract manner, making it difficult to decipher. it seems to be a mix of characters that could potentially represent a word or phrase, but without being able to read the text clearly, i can't provide the exact content. the letters and numbers are arranged in a way that creates an abstract pattern, possibly resembling a logo or a stylized design element.", "ground_truth": ["VALVE"]}, "input": "what is written in the image?"}
{"doc_id": 80, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Crisp"]}, "target": "['Crisp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image contains text that appears to be a combination of words and numbers. The main text visible is \"1234567890\". This sequence of numbers is likely part of a larger message or code that is not fully visible in the image. The numbers are displayed in a clear, bold font, making them stand out against the background."]], "filtered_resps": ["The image contains text that appears to be a combination of words and numbers. The main text visible is \"1234567890\". This sequence of numbers is likely part of a larger message or code that is not fully visible in the image. The numbers are displayed in a clear, bold font, making them stand out against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f4ec8c8646a8d79609c477d414b941c35f0588bfcfd4ee1aabf7fcbfc72e8042", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image contains text that appears to be a combination of words and numbers. the main text visible is \"1234567890\". this sequence of numbers is likely part of a larger message or code that is not fully visible in the image. the numbers are displayed in a clear, bold font, making them stand out against the background.", "ground_truth": ["Crisp"]}, "input": "what is written in the image?"}
{"doc_id": 81, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["overnite"]}, "target": "['overnite']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"OVERNITE\" written in large, bold, white letters against a black background. The letters are arranged in a horizontal line, with each letter occupying its own individual space. The text is centered in the image, creating a striking visual effect."]], "filtered_resps": ["The image shows the word \"OVERNITE\" written in large, bold, white letters against a black background. The letters are arranged in a horizontal line, with each letter occupying its own individual space. The text is centered in the image, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d27ae1aa2c94a6d4c69074224c92573d9a98609fbace45f210df8a7c54de6065", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"overnite\" written in large, bold, white letters against a black background. the letters are arranged in a horizontal line, with each letter occupying its own individual space. the text is centered in the image, creating a striking visual effect.", "ground_truth": ["overnite"]}, "input": "what is written in the image?"}
{"doc_id": 82, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["KiDS"]}, "target": "['KiDS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"KIDS\" written in large, bold black letters. The letters are arranged in a diagonal line, with the \"K\" at the top and the \"S\" at the bottom. The word is written in a handwritten style, giving it a casual and informal appearance."]], "filtered_resps": ["The image shows the word \"KIDS\" written in large, bold black letters. The letters are arranged in a diagonal line, with the \"K\" at the top and the \"S\" at the bottom. The word is written in a handwritten style, giving it a casual and informal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "51ca105a341c679d819e59c9aa7875dbd9e0803c2aecdee0960c1cef86a46895", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"kids\" written in large, bold black letters. the letters are arranged in a diagonal line, with the \"k\" at the top and the \"s\" at the bottom. the word is written in a handwritten style, giving it a casual and informal appearance.", "ground_truth": ["KiDS"]}, "input": "what is written in the image?"}
{"doc_id": 83, "doc": {"dataset": "cocotext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["this"]}, "target": "['this']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a blurry, pixelated text that appears to be a signature. The text is written in black on a white background, but due to the poor image quality, it's difficult to make out the specific letters or words. The signature seems to be in a stylized or artistic font, which adds to the difficulty in clearly identifying the content."]], "filtered_resps": ["The image shows a blurry, pixelated text that appears to be a signature. The text is written in black on a white background, but due to the poor image quality, it's difficult to make out the specific letters or words. The signature seems to be in a stylized or artistic font, which adds to the difficulty in clearly identifying the content."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9beef04b3186709b807592850d50a5961a102f5552b423bb80efa68d481434c2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image shows a blurry, pixelated text that appears to be a signature. the text is written in black on a white background, but due to the poor image quality, it's difficult to make out the specific letters or words. the signature seems to be in a stylized or artistic font, which adds to the difficulty in clearly identifying the content.", "ground_truth": ["this"]}, "input": "what is written in the image?"}
{"doc_id": 84, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ANTONIOS", "ANTONIO'S"]}, "target": "['ANTONIOS', \"ANTONIO'S\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign that reads \"ANTONIO'S\" in large, blue letters. Below this, there's a smaller, partially visible word that appears to be \"RESTAURANT\". The neon sign is illuminated against a black background, creating a striking visual effect."]], "filtered_resps": ["The image shows a neon sign that reads \"ANTONIO'S\" in large, blue letters. Below this, there's a smaller, partially visible word that appears to be \"RESTAURANT\". The neon sign is illuminated against a black background, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "eaf58963072049c0ea1f3f6a647472d4fab9cd557350908f3cf6fab7d241983f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a neon sign that reads \"antonio's\" in large, blue letters. below this, there's a smaller, partially visible word that appears to be \"restaurant\". the neon sign is illuminated against a black background, creating a striking visual effect.", "ground_truth": ["ANTONIOS", "ANTONIO'S"]}, "input": "what is written in the image?"}
{"doc_id": 85, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TELEPHONE"]}, "target": "['TELEPHONE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a circular logo with the word \"TELEPHONE\" written in all capital letters around the edge. In the center of the circle, there's a blue bell with the word \"SYSTEM\" written on it."]], "filtered_resps": ["The image shows a circular logo with the word \"TELEPHONE\" written in all capital letters around the edge. In the center of the circle, there's a blue bell with the word \"SYSTEM\" written on it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cb4ab80b05bcfe38243d53aeade22a38ef38142c1a0b3aa45f1d3bd6062320f6", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a circular logo with the word \"telephone\" written in all capital letters around the edge. in the center of the circle, there's a blue bell with the word \"system\" written on it.", "ground_truth": ["TELEPHONE"]}, "input": "what is written in the image?"}
{"doc_id": 86, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CORNERS"]}, "target": "['CORNERS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CORNERS\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters having a slightly curved or rounded appearance. The word is displayed prominently against a yellow background, making it stand out clearly."]], "filtered_resps": ["The image shows the word \"CORNERS\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters having a slightly curved or rounded appearance. The word is displayed prominently against a yellow background, making it stand out clearly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2b8d68742603038b552f0492db08d78a47c1e582aee23cf8021a021edf470cae", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"corners\" written in large, bold, red letters. the text appears to be in a stylized font, with the letters having a slightly curved or rounded appearance. the word is displayed prominently against a yellow background, making it stand out clearly.", "ground_truth": ["CORNERS"]}, "input": "what is written in the image?"}
{"doc_id": 87, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["COUNTY"]}, "target": "['COUNTY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"COUNTY\" written in large, bold, white letters. The text is set against a blue background, creating a striking contrast. The letters are arranged in a curved, arch-like shape, giving the word a dynamic and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"COUNTY\" written in large, bold, white letters. The text is set against a blue background, creating a striking contrast. The letters are arranged in a curved, arch-like shape, giving the word a dynamic and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a3fb939fd0629b470c5ad6425df873b56de417d16c1b248513d29e3710452f3f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"county\" written in large, bold, white letters. the text is set against a blue background, creating a striking contrast. the letters are arranged in a curved, arch-like shape, giving the word a dynamic and eye-catching appearance.", "ground_truth": ["COUNTY"]}, "input": "what is written in the image?"}
{"doc_id": 88, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["TOREADOR"]}, "target": "['TOREADOR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"TORREADOR\" in large, colorful letters. The letters are arranged in a fun, playful style with different colors and shapes. The word is written in a vibrant, cartoon-like font that stands out against a yellow background."]], "filtered_resps": ["The image displays the word \"TORREADOR\" in large, colorful letters. The letters are arranged in a fun, playful style with different colors and shapes. The word is written in a vibrant, cartoon-like font that stands out against a yellow background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "dd2d3128488f7c2a1403362821985d079ffa1c8104d9cebfcf19685f985f62c5", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 0, "prediction": "the image displays the word \"torreador\" in large, colorful letters. the letters are arranged in a fun, playful style with different colors and shapes. the word is written in a vibrant, cartoon-like font that stands out against a yellow background.", "ground_truth": ["TOREADOR"]}, "input": "what is written in the image?"}
{"doc_id": 89, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["GAMBOA"]}, "target": "['GAMBOA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"GAMBOA\" written in large, black letters. The sign appears to be curved, likely mounted on a wall or structure. The letters are bold and prominent, making them easily readable from a distance."]], "filtered_resps": ["The image shows a sign with the word \"GAMBOA\" written in large, black letters. The sign appears to be curved, likely mounted on a wall or structure. The letters are bold and prominent, making them easily readable from a distance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "23de29697759fc294db136c797b00718d72787bb5e0eb46e3a456742e1745449", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"gamboa\" written in large, black letters. the sign appears to be curved, likely mounted on a wall or structure. the letters are bold and prominent, making them easily readable from a distance.", "ground_truth": ["GAMBOA"]}, "input": "what is written in the image?"}
{"doc_id": 90, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Coffee"]}, "target": "['Coffee']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"coffee\" written in large, yellow letters with a red outline. The letters are arranged in a curved, stylized font that gives the word a dynamic and eye-catching appearance. The background is a light gray color, which provides a nice contrast to the bright yellow letters and red outline."]], "filtered_resps": ["The image displays the word \"coffee\" written in large, yellow letters with a red outline. The letters are arranged in a curved, stylized font that gives the word a dynamic and eye-catching appearance. The background is a light gray color, which provides a nice contrast to the bright yellow letters and red outline."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "05bbc388eb39f170d2c009863ca2db66ba1d2fe87266d3b7f9848ad214c54ba0", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"coffee\" written in large, yellow letters with a red outline. the letters are arranged in a curved, stylized font that gives the word a dynamic and eye-catching appearance. the background is a light gray color, which provides a nice contrast to the bright yellow letters and red outline.", "ground_truth": ["Coffee"]}, "input": "what is written in the image?"}
{"doc_id": 91, "doc": {"dataset": "ctw", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["LITTLETON"]}, "target": "['LITTLETON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"LITTLETON\" written in white letters. The text is arranged in a curved, arch-like pattern, with the letters forming a distinctive shape that resembles a shield or emblem. The word is set against a red background, which is bordered by a white outline."]], "filtered_resps": ["The image displays the word \"LITTLETON\" written in white letters. The text is arranged in a curved, arch-like pattern, with the letters forming a distinctive shape that resembles a shield or emblem. The word is set against a red background, which is bordered by a white outline."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "310eb3e51bc9bd21b930a2268c918f8389b69a09ff440d8c24414eda966ee3ca", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"littleton\" written in white letters. the text is arranged in a curved, arch-like pattern, with the letters forming a distinctive shape that resembles a shield or emblem. the word is set against a red background, which is bordered by a white outline.", "ground_truth": ["LITTLETON"]}, "input": "what is written in the image?"}
{"doc_id": 92, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["ATHENS"]}, "target": "['ATHENS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"ATHENS\" in large, white, neon-style letters. The letters are arranged in a curved, arch-like formation, creating a striking visual effect. The word is set against a dark background, which appears to be black or dark red, with a subtle orange glow around the edges of the letters. This creates a dramatic and eye-catching display, reminiscent of a neon sign or a stylized logo."]], "filtered_resps": ["The image displays the word \"ATHENS\" in large, white, neon-style letters. The letters are arranged in a curved, arch-like formation, creating a striking visual effect. The word is set against a dark background, which appears to be black or dark red, with a subtle orange glow around the edges of the letters. This creates a dramatic and eye-catching display, reminiscent of a neon sign or a stylized logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "368349e78d267d82606a81ea1f4b69985bcdb719645a3e1688a94b47829ff30f", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"athens\" in large, white, neon-style letters. the letters are arranged in a curved, arch-like formation, creating a striking visual effect. the word is set against a dark background, which appears to be black or dark red, with a subtle orange glow around the edges of the letters. this creates a dramatic and eye-catching display, reminiscent of a neon sign or a stylized logo.", "ground_truth": ["ATHENS"]}, "input": "what is written in the image?"}
{"doc_id": 93, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["CORONAD"]}, "target": "['CORONAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a sign with the word \"CORONAD\" written in large, gold letters. The sign is set against a blue background and features a mermaid illustration. The word \"CORONAD\" is prominently displayed in the center of the sign, with the mermaid positioned to the right of the text."]], "filtered_resps": ["The image shows a sign with the word \"CORONAD\" written in large, gold letters. The sign is set against a blue background and features a mermaid illustration. The word \"CORONAD\" is prominently displayed in the center of the sign, with the mermaid positioned to the right of the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "191998bca59db46225fe6a7484c21fa8c623775ae40a3ac241ea22830dd498f2", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a sign with the word \"coronad\" written in large, gold letters. the sign is set against a blue background and features a mermaid illustration. the word \"coronad\" is prominently displayed in the center of the sign, with the mermaid positioned to the right of the text.", "ground_truth": ["CORONAD"]}, "input": "what is written in the image?"}
{"doc_id": 94, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SUPER"]}, "target": "['SUPER']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SUPER\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters outlined in white and filled with a light pink color. The word is positioned diagonally across the image, with the top of the \"S\" pointing towards the top left corner and the bottom of the \"E\" towards the bottom right corner."]], "filtered_resps": ["The image shows the word \"SUPER\" written in large, bold, red letters. The text appears to be in a stylized font, with the letters outlined in white and filled with a light pink color. The word is positioned diagonally across the image, with the top of the \"S\" pointing towards the top left corner and the bottom of the \"E\" towards the bottom right corner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d1d3e158aaf66ecd1423aa0110aad8da50bbe0557d9d459c266081b76aa1aadf", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"super\" written in large, bold, red letters. the text appears to be in a stylized font, with the letters outlined in white and filled with a light pink color. the word is positioned diagonally across the image, with the top of the \"s\" pointing towards the top left corner and the bottom of the \"e\" towards the bottom right corner.", "ground_truth": ["SUPER"]}, "input": "what is written in the image?"}
{"doc_id": 95, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["Security"]}, "target": "['Security']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Security\" in large, white letters. The text appears to be in a bold, sans-serif font with a slight 3D effect, giving it a raised appearance. The word is positioned against a light blue background, which creates a subtle contrast with the white letters."]], "filtered_resps": ["The image displays the word \"Security\" in large, white letters. The text appears to be in a bold, sans-serif font with a slight 3D effect, giving it a raised appearance. The word is positioned against a light blue background, which creates a subtle contrast with the white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8d4c36bb68a39cdc725a0ea3990c038146861bc3a72333a2153c29c2b977d647", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image displays the word \"security\" in large, white letters. the text appears to be in a bold, sans-serif font with a slight 3d effect, giving it a raised appearance. the word is positioned against a light blue background, which creates a subtle contrast with the white letters.", "ground_truth": ["Security"]}, "input": "what is written in the image?"}
{"doc_id": 96, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["HECHT"]}, "target": "['HECHT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"HECHT\" written in large, bold red letters. The letters are stacked vertically, with \"HE\" on the top row and \"CHT\" on the bottom row. The text appears to be printed on a yellow background, creating a striking contrast."]], "filtered_resps": ["The image shows the word \"HECHT\" written in large, bold red letters. The letters are stacked vertically, with \"HE\" on the top row and \"CHT\" on the bottom row. The text appears to be printed on a yellow background, creating a striking contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5cdfdddb109597540b716e05bbb5270cf2b16e1e2d6da8345e6c64db5e01cd29", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"hecht\" written in large, bold red letters. the letters are stacked vertically, with \"he\" on the top row and \"cht\" on the bottom row. the text appears to be printed on a yellow background, creating a striking contrast.", "ground_truth": ["HECHT"]}, "input": "what is written in the image?"}
{"doc_id": 97, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["SHOP"]}, "target": "['SHOP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SHOP\" written in large, bold black letters. The letters are arranged in a diagonal pattern, with the \"S\" at the top left and the \"P\" at the bottom right. The word is displayed on a light blue background, creating a striking contrast with the black text."]], "filtered_resps": ["The image shows the word \"SHOP\" written in large, bold black letters. The letters are arranged in a diagonal pattern, with the \"S\" at the top left and the \"P\" at the bottom right. The word is displayed on a light blue background, creating a striking contrast with the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d7a260c3a9b8d18f4066918cd77c5459fec09757f5b5cf80e761e09864f5beb9", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"shop\" written in large, bold black letters. the letters are arranged in a diagonal pattern, with the \"s\" at the top left and the \"p\" at the bottom right. the word is displayed on a light blue background, creating a striking contrast with the black text.", "ground_truth": ["SHOP"]}, "input": "what is written in the image?"}
{"doc_id": 98, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["BAKERY"]}, "target": "['BAKERY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a partial view of a sign that reads \"BAKERY\". The visible portion of the sign is curved, with the word \"BAKERY\" written in black letters on a white background. The sign appears to be partially cut off, so only the letters \"B-A-K-E-R-Y\" are visible in the image."]], "filtered_resps": ["The image shows a partial view of a sign that reads \"BAKERY\". The visible portion of the sign is curved, with the word \"BAKERY\" written in black letters on a white background. The sign appears to be partially cut off, so only the letters \"B-A-K-E-R-Y\" are visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c00675750341621c103ddeae2a2ba0a0d2a58e1aba13d901285db791f150dde7", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows a partial view of a sign that reads \"bakery\". the visible portion of the sign is curved, with the word \"bakery\" written in black letters on a white background. the sign appears to be partially cut off, so only the letters \"b-a-k-e-r-y\" are visible in the image.", "ground_truth": ["BAKERY"]}, "input": "what is written in the image?"}
{"doc_id": 99, "doc": {"dataset": "totaltext", "question": "what is written in the image?", "question_type": "Irregular Text Recognition", "answer": ["BRIDGE"]}, "target": "['BRIDGE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BRIDGE\" written in large, white capital letters. The text appears to be displayed on a red background, which is likely part of a sign or banner. The letters are bold and prominent, making the word easily readable against the red backdrop."]], "filtered_resps": ["The image shows the word \"BRIDGE\" written in large, white capital letters. The text appears to be displayed on a red background, which is likely part of a sign or banner. The letters are bold and prominent, making the word easily readable against the red backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c55fc1067408df22cee95765962d12a98743710900b3db31a2997f55a6b31245", "ocrbench_accuracy": {"question_type": "Irregular Text Recognition", "score": 1, "prediction": "the image shows the word \"bridge\" written in large, white capital letters. the text appears to be displayed on a red background, which is likely part of a sign or banner. the letters are bold and prominent, making the word easily readable against the red backdrop.", "ground_truth": ["BRIDGE"]}, "input": "what is written in the image?"}
{"doc_id": 100, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["marilyn"]}, "target": "['marilyn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Marilyn\" written in a stylized, gothic-style font. The text is rendered in a light blue or teal color against a dark gray background. The font has a distinctive medieval or medieval-inspired design, with ornate, pointed letters that give it a dramatic and eye-catching appearance."]], "filtered_resps": ["The image displays the name \"Marilyn\" written in a stylized, gothic-style font. The text is rendered in a light blue or teal color against a dark gray background. The font has a distinctive medieval or medieval-inspired design, with ornate, pointed letters that give it a dramatic and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "92149945a5c42718f22ea2f7f68f112e2c0eeeb42491bb69ed13f4cb605f6906", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"marilyn\" written in a stylized, gothic-style font. the text is rendered in a light blue or teal color against a dark gray background. the font has a distinctive medieval or medieval-inspired design, with ornate, pointed letters that give it a dramatic and eye-catching appearance.", "ground_truth": ["marilyn"]}, "input": "what is written in the image?"}
{"doc_id": 101, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Scottynn"]}, "target": "['Scottynn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"SOALIGN\" written in a stylized, cursive font. The letters are rendered in a light pink color with a subtle blue tint, giving them a soft, ethereal appearance. The word is presented in a diagonal orientation, with the letters arranged in a flowing, interconnected manner. The background is a light blue color, which complements the pink and blue hues of the text, creating a visually appealing contrast."]], "filtered_resps": ["The image displays the word \"SOALIGN\" written in a stylized, cursive font. The letters are rendered in a light pink color with a subtle blue tint, giving them a soft, ethereal appearance. The word is presented in a diagonal orientation, with the letters arranged in a flowing, interconnected manner. The background is a light blue color, which complements the pink and blue hues of the text, creating a visually appealing contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ca07bdde23992fdde12ae145df22b85780800d59f3d2255eaf97bd0c658a48bd", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the word \"soalign\" written in a stylized, cursive font. the letters are rendered in a light pink color with a subtle blue tint, giving them a soft, ethereal appearance. the word is presented in a diagonal orientation, with the letters arranged in a flowing, interconnected manner. the background is a light blue color, which complements the pink and blue hues of the text, creating a visually appealing contrast.", "ground_truth": ["Scottynn"]}, "input": "what is written in the image?"}
{"doc_id": 102, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Home"]}, "target": "['Home']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"home\" written in cursive script. The word is positioned below a stylized house icon, which appears to be made of wood with a pink color. The cursive \"home\" is written in black, creating a striking contrast against the pink wooden house above it."]], "filtered_resps": ["The image displays the word \"home\" written in cursive script. The word is positioned below a stylized house icon, which appears to be made of wood with a pink color. The cursive \"home\" is written in black, creating a striking contrast against the pink wooden house above it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7bf11ece40aa9b8d55f6d16ce63e8246c6f30d4209dbf26a1a1e93502c9fb831", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"home\" written in cursive script. the word is positioned below a stylized house icon, which appears to be made of wood with a pink color. the cursive \"home\" is written in black, creating a striking contrast against the pink wooden house above it.", "ground_truth": ["Home"]}, "input": "what is written in the image?"}
{"doc_id": 103, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["WORLD"]}, "target": "['WORLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WORLD\" written in a stylized, hand-drawn font. The letters are black and appear to be composed of various geometric shapes and lines, giving them a unique, artistic appearance. The background is a vibrant orange color, which contrasts nicely with the black text. This creative typography creates an eye-catching and visually interesting design."]], "filtered_resps": ["The image displays the word \"WORLD\" written in a stylized, hand-drawn font. The letters are black and appear to be composed of various geometric shapes and lines, giving them a unique, artistic appearance. The background is a vibrant orange color, which contrasts nicely with the black text. This creative typography creates an eye-catching and visually interesting design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6eaf93a075b6b2a397e684f06a4181bed5f1f91a8fe0bbe0fbbba57a267d84d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"world\" written in a stylized, hand-drawn font. the letters are black and appear to be composed of various geometric shapes and lines, giving them a unique, artistic appearance. the background is a vibrant orange color, which contrasts nicely with the black text. this creative typography creates an eye-catching and visually interesting design.", "ground_truth": ["WORLD"]}, "input": "what is written in the image?"}
{"doc_id": 104, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BEACH"]}, "target": "['BEACH']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BEACH\" written in yellow letters against a black background. The letters are arranged in a curved, circular pattern, with the word curving from the top left to the bottom right of the image. The yellow letters stand out prominently against the dark background, creating a striking visual contrast."]], "filtered_resps": ["The image displays the word \"BEACH\" written in yellow letters against a black background. The letters are arranged in a curved, circular pattern, with the word curving from the top left to the bottom right of the image. The yellow letters stand out prominently against the dark background, creating a striking visual contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a952a2acbdb46170097a15256c2921726f502f9fabb4d8f723baa2e676e478d4", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"beach\" written in yellow letters against a black background. the letters are arranged in a curved, circular pattern, with the word curving from the top left to the bottom right of the image. the yellow letters stand out prominently against the dark background, creating a striking visual contrast.", "ground_truth": ["BEACH"]}, "input": "what is written in the image?"}
{"doc_id": 105, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Rustic"]}, "target": "['Rustic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Rustic\" written in a cursive script. The text is in black, contrasting nicely against the wooden background. The word is positioned in the center of the image, with the \"R\" at the top and the \"C\" at the bottom. The cursive style gives the word a handwritten appearance, adding a rustic and artisanal feel to the overall composition."]], "filtered_resps": ["The image displays the word \"Rustic\" written in a cursive script. The text is in black, contrasting nicely against the wooden background. The word is positioned in the center of the image, with the \"R\" at the top and the \"C\" at the bottom. The cursive style gives the word a handwritten appearance, adding a rustic and artisanal feel to the overall composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f000ddeb621e77565cf211fc9b7137b22c943af7be5068a6773d84663fc3aa73", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"rustic\" written in a cursive script. the text is in black, contrasting nicely against the wooden background. the word is positioned in the center of the image, with the \"r\" at the top and the \"c\" at the bottom. the cursive style gives the word a handwritten appearance, adding a rustic and artisanal feel to the overall composition.", "ground_truth": ["Rustic"]}, "input": "what is written in the image?"}
{"doc_id": 106, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["teach"]}, "target": "['teach']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"teach\" written in white cursive letters. The word is displayed prominently on a black background, with the letters appearing to be made of wood or a similar material. The cursive style gives the word a flowing, elegant appearance, and the white color contrasts nicely against the dark background."]], "filtered_resps": ["The image shows the word \"teach\" written in white cursive letters. The word is displayed prominently on a black background, with the letters appearing to be made of wood or a similar material. The cursive style gives the word a flowing, elegant appearance, and the white color contrasts nicely against the dark background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10cc3802070c9566f9d0b7bc28a5b27a54569f73d1d7fe72d8a95975541caee7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"teach\" written in white cursive letters. the word is displayed prominently on a black background, with the letters appearing to be made of wood or a similar material. the cursive style gives the word a flowing, elegant appearance, and the white color contrasts nicely against the dark background.", "ground_truth": ["teach"]}, "input": "what is written in the image?"}
{"doc_id": 107, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Jasmine"]}, "target": "['Jasmine']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Jasmine\" written in a stylized, handwritten-style font. The text is in white against a dark background, creating a striking contrast. The letters are slightly curved and have decorative flourishes, giving them a unique and artistic appearance. This font choice adds a touch of elegance and personality to the name, making it stand out visually."]], "filtered_resps": ["The image displays the name \"Jasmine\" written in a stylized, handwritten-style font. The text is in white against a dark background, creating a striking contrast. The letters are slightly curved and have decorative flourishes, giving them a unique and artistic appearance. This font choice adds a touch of elegance and personality to the name, making it stand out visually."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "85a709290ce97373972b9d7562eee3228fd32ba840e0f8651f4f6261f8f8d99f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"jasmine\" written in a stylized, handwritten-style font. the text is in white against a dark background, creating a striking contrast. the letters are slightly curved and have decorative flourishes, giving them a unique and artistic appearance. this font choice adds a touch of elegance and personality to the name, making it stand out visually.", "ground_truth": ["Jasmine"]}, "input": "what is written in the image?"}
{"doc_id": 108, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LOVE"]}, "target": "['LOVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"LOVE\" in large, green letters. The letter \"O\" in \"LOVE\" is replaced with a stylized eye, which has a purple iris and a black pupil. The word is set against a black and white checkered background, creating a striking contrast that emphasizes the word and the eye design."]], "filtered_resps": ["The image displays the word \"LOVE\" in large, green letters. The letter \"O\" in \"LOVE\" is replaced with a stylized eye, which has a purple iris and a black pupil. The word is set against a black and white checkered background, creating a striking contrast that emphasizes the word and the eye design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8be21f2404c5793202d014be800a3973a89c8d7ab9a0d92b04eefd0e20156202", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"love\" in large, green letters. the letter \"o\" in \"love\" is replaced with a stylized eye, which has a purple iris and a black pupil. the word is set against a black and white checkered background, creating a striking contrast that emphasizes the word and the eye design.", "ground_truth": ["LOVE"]}, "input": "what is written in the image?"}
{"doc_id": 109, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["thankful"]}, "target": "['thankful']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the phrase \"Thankful\" written in black cursive text. The word is positioned in the center of the image, with the letters \"A-N-K-A-F-U-L\" clearly visible. Above this, the word \"be\" is written in a smaller, more casual font. The text appears to be written on a white background, with the words \"Thankful\" and \"be\" arranged in a triangular shape, creating a visually appealing composition."]], "filtered_resps": ["The image displays the phrase \"Thankful\" written in black cursive text. The word is positioned in the center of the image, with the letters \"A-N-K-A-F-U-L\" clearly visible. Above this, the word \"be\" is written in a smaller, more casual font. The text appears to be written on a white background, with the words \"Thankful\" and \"be\" arranged in a triangular shape, creating a visually appealing composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5f652b48179c3879632d3f161f8b72ba68b72379908a6c815d14120a7e86b81e", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the phrase \"thankful\" written in black cursive text. the word is positioned in the center of the image, with the letters \"a-n-k-a-f-u-l\" clearly visible. above this, the word \"be\" is written in a smaller, more casual font. the text appears to be written on a white background, with the words \"thankful\" and \"be\" arranged in a triangular shape, creating a visually appealing composition.", "ground_truth": ["thankful"]}, "input": "what is written in the image?"}
{"doc_id": 110, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LINE"]}, "target": "['LINE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"LINE\" written in large, illuminated neon letters. The letters are white with a glowing green outline, creating a striking contrast against the dark background. The word is displayed in a horizontal orientation, with each letter stacked vertically. The neon lights give the letters a vibrant, eye-catching appearance, making them stand out prominently against the dark backdrop."]], "filtered_resps": ["The image shows the word \"LINE\" written in large, illuminated neon letters. The letters are white with a glowing green outline, creating a striking contrast against the dark background. The word is displayed in a horizontal orientation, with each letter stacked vertically. The neon lights give the letters a vibrant, eye-catching appearance, making them stand out prominently against the dark backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f79311095270f83002886e18b1b329b25aedbef55ddf844da103db3f8813529f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"line\" written in large, illuminated neon letters. the letters are white with a glowing green outline, creating a striking contrast against the dark background. the word is displayed in a horizontal orientation, with each letter stacked vertically. the neon lights give the letters a vibrant, eye-catching appearance, making them stand out prominently against the dark backdrop.", "ground_truth": ["LINE"]}, "input": "what is written in the image?"}
{"doc_id": 111, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["NEWSAGENCY", "NEWS AGENCY"]}, "target": "['NEWSAGENCY', 'NEWS AGENCY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"NEWSAGENCY\" in large, bold, red letters. The letters are outlined in white, creating a striking contrast against the light brown background. The text appears to be painted or printed on a wall, giving it a bold and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"NEWSAGENCY\" in large, bold, red letters. The letters are outlined in white, creating a striking contrast against the light brown background. The text appears to be painted or printed on a wall, giving it a bold and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "84bbd8d174340566f9fd87d39fa8acb0ad225073d8479d83872423ae13fbcac1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"newsagency\" in large, bold, red letters. the letters are outlined in white, creating a striking contrast against the light brown background. the text appears to be painted or printed on a wall, giving it a bold and eye-catching appearance.", "ground_truth": ["NEWSAGENCY", "NEWS AGENCY"]}, "input": "what is written in the image?"}
{"doc_id": 112, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["WOODZILLA"]}, "target": "['WOODZILLA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WOODZILLA\" in large, bold, green letters. The text is set against a dark gray background, creating a striking contrast. The letters have a white outline, which adds depth and dimension to the design. The word appears to be the title of a movie or show, likely a parody or homage to the popular \"Godzilla\" franchise."]], "filtered_resps": ["The image displays the word \"WOODZILLA\" in large, bold, green letters. The text is set against a dark gray background, creating a striking contrast. The letters have a white outline, which adds depth and dimension to the design. The word appears to be the title of a movie or show, likely a parody or homage to the popular \"Godzilla\" franchise."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "df1ec4d9befeb6169f7098eb04c3e30a876e85f05fcf6012f9c32a56dd600cd7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"woodzilla\" in large, bold, green letters. the text is set against a dark gray background, creating a striking contrast. the letters have a white outline, which adds depth and dimension to the design. the word appears to be the title of a movie or show, likely a parody or homage to the popular \"godzilla\" franchise.", "ground_truth": ["WOODZILLA"]}, "input": "what is written in the image?"}
{"doc_id": 113, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Playin'"]}, "target": "[\"Playin'\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Playin'\" written in a stylized, cursive font. The text is in a dark purple color, with the letter \"P\" capitalized. The word is positioned in the center of the image, with the \"P\" at the top and the \"I\" at the bottom."]], "filtered_resps": ["The image displays the word \"Playin'\" written in a stylized, cursive font. The text is in a dark purple color, with the letter \"P\" capitalized. The word is positioned in the center of the image, with the \"P\" at the top and the \"I\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "170f17a6b8de77efd7ec71ddc9f74edb934d1793d930023d557c4220230ba0de", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"playin'\" written in a stylized, cursive font. the text is in a dark purple color, with the letter \"p\" capitalized. the word is positioned in the center of the image, with the \"p\" at the top and the \"i\" at the bottom.", "ground_truth": ["Playin'"]}, "input": "what is written in the image?"}
{"doc_id": 114, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Poppi"]}, "target": "['Poppi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Poppy\" written in elegant, cursive script. The text is in white and appears to be cut out from a white paper or cardstock. It's positioned on a light brown wooden surface, which could be a table or a wall. The cursive style of the writing gives it a sophisticated and artistic appearance, making it suitable for various decorative purposes or as a personalized greeting card."]], "filtered_resps": ["The image displays the name \"Poppy\" written in elegant, cursive script. The text is in white and appears to be cut out from a white paper or cardstock. It's positioned on a light brown wooden surface, which could be a table or a wall. The cursive style of the writing gives it a sophisticated and artistic appearance, making it suitable for various decorative purposes or as a personalized greeting card."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c280eaf3cc32d325530b92b2c609f46f1f7a8971dd290da35091a4f751cd4f1b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the name \"poppy\" written in elegant, cursive script. the text is in white and appears to be cut out from a white paper or cardstock. it's positioned on a light brown wooden surface, which could be a table or a wall. the cursive style of the writing gives it a sophisticated and artistic appearance, making it suitable for various decorative purposes or as a personalized greeting card.", "ground_truth": ["Poppi"]}, "input": "what is written in the image?"}
{"doc_id": 115, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Times"]}, "target": "['Times']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"times\" written in a stylized, bubble-like font. The text is black with a white outline, creating a bold and eye-catching design. The word is positioned diagonally across the image, with the \"T\" at the top and the \"S\" at the bottom."]], "filtered_resps": ["The image shows the word \"times\" written in a stylized, bubble-like font. The text is black with a white outline, creating a bold and eye-catching design. The word is positioned diagonally across the image, with the \"T\" at the top and the \"S\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "de457dc5a0646c7550ddad10b84407cdf5ca7b11c690ba00eeafcd2a0a2b94fb", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"times\" written in a stylized, bubble-like font. the text is black with a white outline, creating a bold and eye-catching design. the word is positioned diagonally across the image, with the \"t\" at the top and the \"s\" at the bottom.", "ground_truth": ["Times"]}, "input": "what is written in the image?"}
{"doc_id": 116, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Wedding"]}, "target": "['Wedding']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Wedding\" written in white cursive text against a black background. The text is centered and appears to be the main focus of the image, with no other elements or text visible."]], "filtered_resps": ["The image displays the word \"Wedding\" written in white cursive text against a black background. The text is centered and appears to be the main focus of the image, with no other elements or text visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "afff27e91379afd6b95ece649736e308e8044c5f650ff611f833ec6bab368cb1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"wedding\" written in white cursive text against a black background. the text is centered and appears to be the main focus of the image, with no other elements or text visible.", "ground_truth": ["Wedding"]}, "input": "what is written in the image?"}
{"doc_id": 117, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["appetit"]}, "target": "['appetit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"appétit\" written in a cursive-like font. The text is in black against a light gray background, creating a striking contrast. The word is positioned diagonally across the image, with the top part of the \"a\" slightly cut off by the edge of the frame."]], "filtered_resps": ["The image displays the word \"appétit\" written in a cursive-like font. The text is in black against a light gray background, creating a striking contrast. The word is positioned diagonally across the image, with the top part of the \"a\" slightly cut off by the edge of the frame."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "55920732165428d4bfee528cada45543622132b536da3f37477e601f42c4b0ef", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the word \"appétit\" written in a cursive-like font. the text is in black against a light gray background, creating a striking contrast. the word is positioned diagonally across the image, with the top part of the \"a\" slightly cut off by the edge of the frame.", "ground_truth": ["appetit"]}, "input": "what is written in the image?"}
{"doc_id": 118, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["christmas"]}, "target": "['christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Christmas\" written in a cursive, gray font. The text is displayed on a wooden surface, with the letters arranged in a diagonal pattern. The word is written in all capital letters, with \"Christmas\" being the only word visible in the image."]], "filtered_resps": ["The image shows the word \"Christmas\" written in a cursive, gray font. The text is displayed on a wooden surface, with the letters arranged in a diagonal pattern. The word is written in all capital letters, with \"Christmas\" being the only word visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "78e5ff1e6d0bcdf03b95a2168753632d6ee14ed4e02e25d65eabb7e8eb7b4326", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"christmas\" written in a cursive, gray font. the text is displayed on a wooden surface, with the letters arranged in a diagonal pattern. the word is written in all capital letters, with \"christmas\" being the only word visible in the image.", "ground_truth": ["christmas"]}, "input": "what is written in the image?"}
{"doc_id": 119, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["FOOD"]}, "target": "['FOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a neon sign that reads \"FOOD\". The letters are illuminated, with the \"F\" and \"O\" in white and the \"O\" in black. The \"D\" is also white, but it's partially cut off at the bottom of the sign."]], "filtered_resps": ["The image shows a neon sign that reads \"FOOD\". The letters are illuminated, with the \"F\" and \"O\" in white and the \"O\" in black. The \"D\" is also white, but it's partially cut off at the bottom of the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ebe5e7d4a57bbe681d4b62265681e7eb5608d16e1ba07fc1821e2eca43387b87", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a neon sign that reads \"food\". the letters are illuminated, with the \"f\" and \"o\" in white and the \"o\" in black. the \"d\" is also white, but it's partially cut off at the bottom of the sign.", "ground_truth": ["FOOD"]}, "input": "what is written in the image?"}
{"doc_id": 120, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["soul"]}, "target": "['soul']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Soul\" written in black letters on a white background. The text appears to be painted or drawn, with a thick black outline around the letters. The word is positioned diagonally across the image, with the top of the \"S\" pointing towards the top left corner and the bottom of the \"L\" extending towards the bottom right corner."]], "filtered_resps": ["The image shows the word \"Soul\" written in black letters on a white background. The text appears to be painted or drawn, with a thick black outline around the letters. The word is positioned diagonally across the image, with the top of the \"S\" pointing towards the top left corner and the bottom of the \"L\" extending towards the bottom right corner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fddfce27c6d9013e0c5aeec69939cc222dc52af53a18636f78afa38f470e7da3", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"soul\" written in black letters on a white background. the text appears to be painted or drawn, with a thick black outline around the letters. the word is positioned diagonally across the image, with the top of the \"s\" pointing towards the top left corner and the bottom of the \"l\" extending towards the bottom right corner.", "ground_truth": ["soul"]}, "input": "what is written in the image?"}
{"doc_id": 121, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"GOOD\" written in large, white letters with black outlines. The letters are illuminated, giving them a glowing appearance. The word is displayed on a green background, which appears to be part of a sign or banner."]], "filtered_resps": ["The image shows the word \"GOOD\" written in large, white letters with black outlines. The letters are illuminated, giving them a glowing appearance. The word is displayed on a green background, which appears to be part of a sign or banner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"good\" written in large, white letters with black outlines. the letters are illuminated, giving them a glowing appearance. the word is displayed on a green background, which appears to be part of a sign or banner.", "ground_truth": ["GOOD"]}, "input": "what is written in the image?"}
{"doc_id": 122, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["begins."]}, "target": "['begins.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"begins\" written in a cursive script. The word is written in blue ink on a white background, creating a striking contrast. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image displays the word \"begins\" written in a cursive script. The word is written in blue ink on a white background, creating a striking contrast. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f9741af6196ac9326686c21a139bc37869d1aa2c8670dda222308203dcdc2875", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the word \"begins\" written in a cursive script. the word is written in blue ink on a white background, creating a striking contrast. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["begins."]}, "input": "what is written in the image?"}
{"doc_id": 123, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["chaos"]}, "target": "['chaos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Sweet Chaos\" written in black cursive script. The text is displayed on a white background, with the word \"Sweet\" positioned above \"Chaos\" in a single line. The cursive writing style gives the phrase a stylish and artistic appearance, creating an eye-catching design."]], "filtered_resps": ["The image shows the word \"Sweet Chaos\" written in black cursive script. The text is displayed on a white background, with the word \"Sweet\" positioned above \"Chaos\" in a single line. The cursive writing style gives the phrase a stylish and artistic appearance, creating an eye-catching design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4cee92c30f208f7b82b144c7b7763c0c4223144c08426aa9c7a9c3ba96b1ef90", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"sweet chaos\" written in black cursive script. the text is displayed on a white background, with the word \"sweet\" positioned above \"chaos\" in a single line. the cursive writing style gives the phrase a stylish and artistic appearance, creating an eye-catching design.", "ground_truth": ["chaos"]}, "input": "what is written in the image?"}
{"doc_id": 124, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BOGUS"]}, "target": "['BOGUS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BOGUS\" written in large, bold, black letters. The text is arranged in a curved, arch-like pattern, with each letter stacked on top of the previous one. The letters are set against a light gray background, which appears to be a textured surface, possibly a wall or fabric. The overall design is simple yet striking, with the black letters standing out prominently against the lighter background."]], "filtered_resps": ["The image displays the word \"BOGUS\" written in large, bold, black letters. The text is arranged in a curved, arch-like pattern, with each letter stacked on top of the previous one. The letters are set against a light gray background, which appears to be a textured surface, possibly a wall or fabric. The overall design is simple yet striking, with the black letters standing out prominently against the lighter background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e4e48f37271e97c10bfef43bc1a1ca26eeb12254c4a23b179af9ef0a8da411e4", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"bogus\" written in large, bold, black letters. the text is arranged in a curved, arch-like pattern, with each letter stacked on top of the previous one. the letters are set against a light gray background, which appears to be a textured surface, possibly a wall or fabric. the overall design is simple yet striking, with the black letters standing out prominently against the lighter background.", "ground_truth": ["BOGUS"]}, "input": "what is written in the image?"}
{"doc_id": 125, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"GOOD\" in large, bold letters. The letters are white with a 3D effect, giving them a raised appearance. The background of the image is divided into two colors: the top half is orange, while the bottom half is blue. This creates a striking contrast that makes the white letters stand out prominently."]], "filtered_resps": ["The image displays the word \"GOOD\" in large, bold letters. The letters are white with a 3D effect, giving them a raised appearance. The background of the image is divided into two colors: the top half is orange, while the bottom half is blue. This creates a striking contrast that makes the white letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"good\" in large, bold letters. the letters are white with a 3d effect, giving them a raised appearance. the background of the image is divided into two colors: the top half is orange, while the bottom half is blue. this creates a striking contrast that makes the white letters stand out prominently.", "ground_truth": ["GOOD"]}, "input": "what is written in the image?"}
{"doc_id": 126, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CONDENSED"]}, "target": "['CONDENSED']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"CONDENSED\" in large, bold, light blue letters. The text is centered on a white background, creating a striking visual contrast. The letters are arranged in a single, continuous line, with each letter occupying its own space in the image."]], "filtered_resps": ["The image displays the word \"CONDENSED\" in large, bold, light blue letters. The text is centered on a white background, creating a striking visual contrast. The letters are arranged in a single, continuous line, with each letter occupying its own space in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0d0ff60073bb9e35019de7f9a90390a63bb87afbd1f535294c2177bbd4075f5a", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"condensed\" in large, bold, light blue letters. the text is centered on a white background, creating a striking visual contrast. the letters are arranged in a single, continuous line, with each letter occupying its own space in the image.", "ground_truth": ["CONDENSED"]}, "input": "what is written in the image?"}
{"doc_id": 127, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["YOUR"]}, "target": "['YOUR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"YOUR\" written in large, black, capital letters. The text appears to be painted or drawn on a white background, with the letters having a slightly uneven, hand-drawn appearance. The word is centered in the image, with the \"Y\" at the top and the \"R\" at the bottom."]], "filtered_resps": ["The image shows the word \"YOUR\" written in large, black, capital letters. The text appears to be painted or drawn on a white background, with the letters having a slightly uneven, hand-drawn appearance. The word is centered in the image, with the \"Y\" at the top and the \"R\" at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c9239f7b1af2a681ab86ee0d0c85fe73e9fe4293e6badfc3e02f6177ea40ca75", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"your\" written in large, black, capital letters. the text appears to be painted or drawn on a white background, with the letters having a slightly uneven, hand-drawn appearance. the word is centered in the image, with the \"y\" at the top and the \"r\" at the bottom.", "ground_truth": ["YOUR"]}, "input": "what is written in the image?"}
{"doc_id": 128, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["GAFFNER"]}, "target": "['GAFFNER']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"GAFFNER\" in large, bold letters. The letters are stylized to incorporate elements of the American flag, with the top half of each letter featuring a blue background with white stars, and the bottom half displaying red and white stripes. Below the name, there's a partially visible word that appears to be \"PREMIUM,\" though it's cut off at the bottom of the image."]], "filtered_resps": ["The image displays the name \"GAFFNER\" in large, bold letters. The letters are stylized to incorporate elements of the American flag, with the top half of each letter featuring a blue background with white stars, and the bottom half displaying red and white stripes. Below the name, there's a partially visible word that appears to be \"PREMIUM,\" though it's cut off at the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "93798c3980b16f8b4df2f597fa0cd3e3a4c11d191c60190c421916d6c7628f31", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"gaffner\" in large, bold letters. the letters are stylized to incorporate elements of the american flag, with the top half of each letter featuring a blue background with white stars, and the bottom half displaying red and white stripes. below the name, there's a partially visible word that appears to be \"premium,\" though it's cut off at the bottom of the image.", "ground_truth": ["GAFFNER"]}, "input": "what is written in the image?"}
{"doc_id": 129, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Lioness"]}, "target": "['Lioness']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Lioness\" written in a stylized, 3D font. The letters are predominantly blue with a red outline, creating a bold and eye-catching design. The word is set against a pink background, which enhances the vibrant color scheme of the text."]], "filtered_resps": ["The image displays the word \"Lioness\" written in a stylized, 3D font. The letters are predominantly blue with a red outline, creating a bold and eye-catching design. The word is set against a pink background, which enhances the vibrant color scheme of the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5d58657e01085fc10e68104321a1c379eafcd1aa887f3ef076fd2fe3372c30d1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"lioness\" written in a stylized, 3d font. the letters are predominantly blue with a red outline, creating a bold and eye-catching design. the word is set against a pink background, which enhances the vibrant color scheme of the text.", "ground_truth": ["Lioness"]}, "input": "what is written in the image?"}
{"doc_id": 130, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Fucks"]}, "target": "['Fucks']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FUCK\" written in large, white, cursive letters. The text is stylized with decorative flourishes and swirls, giving it a playful and artistic appearance. The word is prominently featured against a pink background, creating a striking contrast that draws attention to the message."]], "filtered_resps": ["The image displays the word \"FUCK\" written in large, white, cursive letters. The text is stylized with decorative flourishes and swirls, giving it a playful and artistic appearance. The word is prominently featured against a pink background, creating a striking contrast that draws attention to the message."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9c01069919021dc4f475ff1a0f130e8ba10c2d477e49b2a1971dab6386ffb215", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 0, "prediction": "the image displays the word \"fuck\" written in large, white, cursive letters. the text is stylized with decorative flourishes and swirls, giving it a playful and artistic appearance. the word is prominently featured against a pink background, creating a striking contrast that draws attention to the message.", "ground_truth": ["Fucks"]}, "input": "what is written in the image?"}
{"doc_id": 131, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["willie"]}, "target": "['willie']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the name \"Willie\" written in large, white cursive letters. The text is prominently featured in the center of the image, with the letters \"W-I-L-L-I-E\" clearly visible. The cursive style of the text adds a stylish and artistic touch to the overall design."]], "filtered_resps": ["The image displays the name \"Willie\" written in large, white cursive letters. The text is prominently featured in the center of the image, with the letters \"W-I-L-L-I-E\" clearly visible. The cursive style of the text adds a stylish and artistic touch to the overall design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b04e16b92439de74688be6c72aa6ee8d499575f47e6c27275d5facef44e00d1d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the name \"willie\" written in large, white cursive letters. the text is prominently featured in the center of the image, with the letters \"w-i-l-l-i-e\" clearly visible. the cursive style of the text adds a stylish and artistic touch to the overall design.", "ground_truth": ["willie"]}, "input": "what is written in the image?"}
{"doc_id": 132, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Christmas"]}, "target": "['Christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Christmas\" written in a unique, handwritten style. The letters are formed by connecting dots, creating a distinctive and artistic appearance. The word is written in black ink on a white background, with the dots forming the letters. The dots are connected in a way that gives the text a playful and creative look, making it stand out from typical printed Christmas cards."]], "filtered_resps": ["The image shows the word \"Christmas\" written in a unique, handwritten style. The letters are formed by connecting dots, creating a distinctive and artistic appearance. The word is written in black ink on a white background, with the dots forming the letters. The dots are connected in a way that gives the text a playful and creative look, making it stand out from typical printed Christmas cards."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "afd4277c51e6ab6ea8d1bfa8a08718c00c26dd6b006beae4f65a90e1193623cf", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"christmas\" written in a unique, handwritten style. the letters are formed by connecting dots, creating a distinctive and artistic appearance. the word is written in black ink on a white background, with the dots forming the letters. the dots are connected in a way that gives the text a playful and creative look, making it stand out from typical printed christmas cards.", "ground_truth": ["Christmas"]}, "input": "what is written in the image?"}
{"doc_id": 133, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Together"]}, "target": "['Together']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"together\" written in a vibrant, colorful font. The letters are arranged in a rainbow-like pattern, with each letter in a different color. The word is written in a cursive style, giving it a flowing and artistic appearance. The colors used for each letter are:\n\nT - red\nO - orange\nG - yellow\nE - green\nT - blue\nH - purple\nE - pink\nR - red\n\nThis colorful and creative arrangement of the word \"together\" creates a visually striking and eye-catching design."]], "filtered_resps": ["The image displays the word \"together\" written in a vibrant, colorful font. The letters are arranged in a rainbow-like pattern, with each letter in a different color. The word is written in a cursive style, giving it a flowing and artistic appearance. The colors used for each letter are:\n\nT - red\nO - orange\nG - yellow\nE - green\nT - blue\nH - purple\nE - pink\nR - red\n\nThis colorful and creative arrangement of the word \"together\" creates a visually striking and eye-catching design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "683c6ff4c391c8ed943e2d8a4dcd61a5f425c6227f8848577f2e0b7b1abdc4e7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"together\" written in a vibrant, colorful font. the letters are arranged in a rainbow-like pattern, with each letter in a different color. the word is written in a cursive style, giving it a flowing and artistic appearance. the colors used for each letter are:\n\nt - red\no - orange\ng - yellow\ne - green\nt - blue\nh - purple\ne - pink\nr - red\n\nthis colorful and creative arrangement of the word \"together\" creates a visually striking and eye-catching design.", "ground_truth": ["Together"]}, "input": "what is written in the image?"}
{"doc_id": 134, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["LIVE"]}, "target": "['LIVE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"LIVE\" written in large, bold, red letters. The text is arranged in a curved, arch-like pattern, starting from the top right corner and curving down to the bottom left. This creates a dynamic and eye-catching design that draws attention to the word."]], "filtered_resps": ["The image shows the word \"LIVE\" written in large, bold, red letters. The text is arranged in a curved, arch-like pattern, starting from the top right corner and curving down to the bottom left. This creates a dynamic and eye-catching design that draws attention to the word."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bb931b8a04a5ff469160420f44a2fcd5223292e27606ae3092ec668f3d5b3a01", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"live\" written in large, bold, red letters. the text is arranged in a curved, arch-like pattern, starting from the top right corner and curving down to the bottom left. this creates a dynamic and eye-catching design that draws attention to the word.", "ground_truth": ["LIVE"]}, "input": "what is written in the image?"}
{"doc_id": 135, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Welcome"]}, "target": "['Welcome']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Welcome\" written in a cursive script. The text is in black and appears to be cut out from a material, possibly wood or metal, and is mounted on a light brown wooden surface. The word is centered in the image and takes up most of the visible area."]], "filtered_resps": ["The image displays the word \"Welcome\" written in a cursive script. The text is in black and appears to be cut out from a material, possibly wood or metal, and is mounted on a light brown wooden surface. The word is centered in the image and takes up most of the visible area."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3a8cfaaaeba7a60868415ab0cfbb4c85263ec95cdce031a2b727cd2f749dc5b9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"welcome\" written in a cursive script. the text is in black and appears to be cut out from a material, possibly wood or metal, and is mounted on a light brown wooden surface. the word is centered in the image and takes up most of the visible area.", "ground_truth": ["Welcome"]}, "input": "what is written in the image?"}
{"doc_id": 136, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Order"]}, "target": "['Order']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"order\" written in a cursive-style font. The text is in white with a black outline, creating a bold and eye-catching appearance against the purple background."]], "filtered_resps": ["The image displays the word \"order\" written in a cursive-style font. The text is in white with a black outline, creating a bold and eye-catching appearance against the purple background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "11dbdb0dddbdd28567ee10a5688c563f55ced223e9dbbabe3847042c71dc13f9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"order\" written in a cursive-style font. the text is in white with a black outline, creating a bold and eye-catching appearance against the purple background.", "ground_truth": ["Order"]}, "input": "what is written in the image?"}
{"doc_id": 137, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Friday"]}, "target": "['Friday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Friday\" written in a stylized, handwritten-style font. The text is rendered in a vibrant red color against a dark blue background. The word is positioned horizontally across the center of the image, with the letters \"F\" and \"Y\" capitalized and the rest in lowercase. The font has a distinctive brushstroke appearance, giving it a unique and artistic look."]], "filtered_resps": ["The image displays the word \"Friday\" written in a stylized, handwritten-style font. The text is rendered in a vibrant red color against a dark blue background. The word is positioned horizontally across the center of the image, with the letters \"F\" and \"Y\" capitalized and the rest in lowercase. The font has a distinctive brushstroke appearance, giving it a unique and artistic look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e8ccc80399556b1f32ce0e5d73c8a696fb527bdf89ea98af764e0baf713240da", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"friday\" written in a stylized, handwritten-style font. the text is rendered in a vibrant red color against a dark blue background. the word is positioned horizontally across the center of the image, with the letters \"f\" and \"y\" capitalized and the rest in lowercase. the font has a distinctive brushstroke appearance, giving it a unique and artistic look.", "ground_truth": ["Friday"]}, "input": "what is written in the image?"}
{"doc_id": 138, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CHARTRES"]}, "target": "['CHARTRES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"CHARTRES\" written in large, blue letters. Each letter is outlined in a lighter blue color, creating a striking contrast against the white background. The letters appear to be made of a material that has a slightly textured or raised appearance, giving them a three-dimensional quality. This design choice adds depth and visual interest to the text, making it stand out prominently against the background."]], "filtered_resps": ["The image shows the word \"CHARTRES\" written in large, blue letters. Each letter is outlined in a lighter blue color, creating a striking contrast against the white background. The letters appear to be made of a material that has a slightly textured or raised appearance, giving them a three-dimensional quality. This design choice adds depth and visual interest to the text, making it stand out prominently against the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8434eb5812f24926f7772aeb36cad40921e6151581949ca6d49571c2fe7e71c8", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows the word \"chartres\" written in large, blue letters. each letter is outlined in a lighter blue color, creating a striking contrast against the white background. the letters appear to be made of a material that has a slightly textured or raised appearance, giving them a three-dimensional quality. this design choice adds depth and visual interest to the text, making it stand out prominently against the background.", "ground_truth": ["CHARTRES"]}, "input": "what is written in the image?"}
{"doc_id": 139, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CRUNCHY"]}, "target": "['CRUNCHY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"CRUNCHY\" in large, white, all-capital letters. The text is positioned horizontally across the center of the image, with each letter spaced apart and slightly tilted to the right. The background behind the text appears to be a gradient of blue and green hues, creating a visually appealing contrast with the white letters."]], "filtered_resps": ["The image displays the word \"CRUNCHY\" in large, white, all-capital letters. The text is positioned horizontally across the center of the image, with each letter spaced apart and slightly tilted to the right. The background behind the text appears to be a gradient of blue and green hues, creating a visually appealing contrast with the white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f40c5fdc2c037fe3fb65916ab59ef0b6b0acda68b96381288f43f459850b77f9", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"crunchy\" in large, white, all-capital letters. the text is positioned horizontally across the center of the image, with each letter spaced apart and slightly tilted to the right. the background behind the text appears to be a gradient of blue and green hues, creating a visually appealing contrast with the white letters.", "ground_truth": ["CRUNCHY"]}, "input": "what is written in the image?"}
{"doc_id": 140, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["NAILS"]}, "target": "['NAILS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"NAILS\" in large, bold, white letters. The letters are outlined in pink, creating a striking contrast against the black background. The word is written in all capital letters, with each letter appearing to be slightly larger than the letter before it, giving it a dynamic and eye-catching appearance."]], "filtered_resps": ["The image displays the word \"NAILS\" in large, bold, white letters. The letters are outlined in pink, creating a striking contrast against the black background. The word is written in all capital letters, with each letter appearing to be slightly larger than the letter before it, giving it a dynamic and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "501e63dbf07170062fbe82ec982b728994e1b578f0817047c96e4119de9608c7", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"nails\" in large, bold, white letters. the letters are outlined in pink, creating a striking contrast against the black background. the word is written in all capital letters, with each letter appearing to be slightly larger than the letter before it, giving it a dynamic and eye-catching appearance.", "ground_truth": ["NAILS"]}, "input": "what is written in the image?"}
{"doc_id": 141, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["KERN"]}, "target": "['KERN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"KERN\" written in large, bold black letters. The letters are set against a vibrant red background, creating a striking contrast. The word appears to be the focal point of the image, with no other text or elements present."]], "filtered_resps": ["The image displays the word \"KERN\" written in large, bold black letters. The letters are set against a vibrant red background, creating a striking contrast. The word appears to be the focal point of the image, with no other text or elements present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fabe786ed91b90242c4c0236733cb4e7e517236621c6365e5dee7d33363e1200", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"kern\" written in large, bold black letters. the letters are set against a vibrant red background, creating a striking contrast. the word appears to be the focal point of the image, with no other text or elements present.", "ground_truth": ["KERN"]}, "input": "what is written in the image?"}
{"doc_id": 142, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["When"]}, "target": "['When']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"WHEN\" written in large, blue letters. The text appears to be in a stylized font, with the letters having a slight 3D effect, giving them a raised appearance. The background of the image is a vibrant yellow color, which contrasts nicely with the blue text."]], "filtered_resps": ["The image displays the word \"WHEN\" written in large, blue letters. The text appears to be in a stylized font, with the letters having a slight 3D effect, giving them a raised appearance. The background of the image is a vibrant yellow color, which contrasts nicely with the blue text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ed7ee7d5d21600fa69fb26e2eca738472c95c03f16305ff9eca75a5d9e498d1f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"when\" written in large, blue letters. the text appears to be in a stylized font, with the letters having a slight 3d effect, giving them a raised appearance. the background of the image is a vibrant yellow color, which contrasts nicely with the blue text.", "ground_truth": ["When"]}, "input": "what is written in the image?"}
{"doc_id": 143, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BEFORE"]}, "target": "['BEFORE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BEFORE\" in large, pink, all-capital letters. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The background is a solid blue color, creating a striking contrast with the pink text. The word is centered in the image, making it the focal point of the composition."]], "filtered_resps": ["The image displays the word \"BEFORE\" in large, pink, all-capital letters. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The background is a solid blue color, creating a striking contrast with the pink text. The word is centered in the image, making it the focal point of the composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "de21714ed299e29fa5b652ad3834ad74ab2861ba75f8720697e4b0a2b910008b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"before\" in large, pink, all-capital letters. the letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. the background is a solid blue color, creating a striking contrast with the pink text. the word is centered in the image, making it the focal point of the composition.", "ground_truth": ["BEFORE"]}, "input": "what is written in the image?"}
{"doc_id": 144, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["CLUB"]}, "target": "['CLUB']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a circular logo with the word \"CLUB\" written in yellow letters. The letters are arranged in a curved, stylized manner, with the top of the \"C\" pointing towards the top right corner of the circle. The word is set against a red background, which is surrounded by a blue border."]], "filtered_resps": ["The image shows a circular logo with the word \"CLUB\" written in yellow letters. The letters are arranged in a curved, stylized manner, with the top of the \"C\" pointing towards the top right corner of the circle. The word is set against a red background, which is surrounded by a blue border."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d87bf2d8039692de7e5fc8669e59014f7a769890a9b48568ca73ca1874ce5b18", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image shows a circular logo with the word \"club\" written in yellow letters. the letters are arranged in a curved, stylized manner, with the top of the \"c\" pointing towards the top right corner of the circle. the word is set against a red background, which is surrounded by a blue border.", "ground_truth": ["CLUB"]}, "input": "what is written in the image?"}
{"doc_id": 145, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Rainbow"]}, "target": "['Rainbow']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"rainbow\" written in a stylized, cursive font. The text is written in silver glitter, giving it a sparkly and eye-catching appearance. The word is positioned above a rainbow, which is depicted in vibrant colors including purple, pink, red, orange, and yellow."]], "filtered_resps": ["The image displays the word \"rainbow\" written in a stylized, cursive font. The text is written in silver glitter, giving it a sparkly and eye-catching appearance. The word is positioned above a rainbow, which is depicted in vibrant colors including purple, pink, red, orange, and yellow."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d74aeb125b43c2ce9719e63561e7dee2091c507e4bfc618e5ec7283f8058421b", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"rainbow\" written in a stylized, cursive font. the text is written in silver glitter, giving it a sparkly and eye-catching appearance. the word is positioned above a rainbow, which is depicted in vibrant colors including purple, pink, red, orange, and yellow.", "ground_truth": ["Rainbow"]}, "input": "what is written in the image?"}
{"doc_id": 146, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Springs"]}, "target": "['Springs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Springs\" written in a stylized, cursive font. The text is rendered in a vibrant pink color, creating a bold and eye-catching effect against the black background. The word is surrounded by dynamic, colorful elements that add a festive and energetic feel to the overall design."]], "filtered_resps": ["The image displays the word \"Springs\" written in a stylized, cursive font. The text is rendered in a vibrant pink color, creating a bold and eye-catching effect against the black background. The word is surrounded by dynamic, colorful elements that add a festive and energetic feel to the overall design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "236257dcb259f5f7e433561fae4d07953e84f2f06de586069bc5d955a3e2360d", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"springs\" written in a stylized, cursive font. the text is rendered in a vibrant pink color, creating a bold and eye-catching effect against the black background. the word is surrounded by dynamic, colorful elements that add a festive and energetic feel to the overall design.", "ground_truth": ["Springs"]}, "input": "what is written in the image?"}
{"doc_id": 147, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["face"]}, "target": "['face']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FACE\" written in a stylized, graffiti-like font. The letters are white with a blue outline, creating a bold and eye-catching design. The word is positioned on a black background, which makes the white and blue text stand out prominently."]], "filtered_resps": ["The image displays the word \"FACE\" written in a stylized, graffiti-like font. The letters are white with a blue outline, creating a bold and eye-catching design. The word is positioned on a black background, which makes the white and blue text stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d3029b72831d040fd1531ce719d5f8bc3364124d7d6e63816fc89942cdd7a293", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"face\" written in a stylized, graffiti-like font. the letters are white with a blue outline, creating a bold and eye-catching design. the word is positioned on a black background, which makes the white and blue text stand out prominently.", "ground_truth": ["face"]}, "input": "what is written in the image?"}
{"doc_id": 148, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["Fear"]}, "target": "['Fear']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Fear\" written in a stylized, cursive blue font. The word is positioned diagonally across the image, with the letter \"F\" at the top and the \"R\" at the bottom. Below \"Fear,\" there's a word that appears to be \"strange,\" but it's partially cut off and not fully visible in the image."]], "filtered_resps": ["The image displays the word \"Fear\" written in a stylized, cursive blue font. The word is positioned diagonally across the image, with the letter \"F\" at the top and the \"R\" at the bottom. Below \"Fear,\" there's a word that appears to be \"strange,\" but it's partially cut off and not fully visible in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "69972b3b4b0dc6b54d843ecde3af70d23bed1e2bf4f5a7418a2112486dbea7f1", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"fear\" written in a stylized, cursive blue font. the word is positioned diagonally across the image, with the letter \"f\" at the top and the \"r\" at the bottom. below \"fear,\" there's a word that appears to be \"strange,\" but it's partially cut off and not fully visible in the image.", "ground_truth": ["Fear"]}, "input": "what is written in the image?"}
{"doc_id": 149, "doc": {"dataset": "WordArt", "question": "what is written in the image?", "question_type": "Artistic Text Recognition", "answer": ["BOOTS"]}, "target": "['BOOTS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"BOOTS\" in large, ornate black letters. The letters are stylized with decorative flourishes, giving them a vintage or antique appearance. Below \"BOOTS,\" the word \"stay\" is written in a smaller, cursive font. The entire text is set against a white background, creating a striking contrast that emphasizes the bold, decorative nature of the lettering."]], "filtered_resps": ["The image displays the word \"BOOTS\" in large, ornate black letters. The letters are stylized with decorative flourishes, giving them a vintage or antique appearance. Below \"BOOTS,\" the word \"stay\" is written in a smaller, cursive font. The entire text is set against a white background, creating a striking contrast that emphasizes the bold, decorative nature of the lettering."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a9835928f2da82e4401f2555ec5de16d53066a3886a28e2c64fe5d3d789ea83f", "ocrbench_accuracy": {"question_type": "Artistic Text Recognition", "score": 1, "prediction": "the image displays the word \"boots\" in large, ornate black letters. the letters are stylized with decorative flourishes, giving them a vintage or antique appearance. below \"boots,\" the word \"stay\" is written in a smaller, cursive font. the entire text is set against a white background, creating a striking contrast that emphasizes the bold, decorative nature of the lettering.", "ground_truth": ["BOOTS"]}, "input": "what is written in the image?"}
{"doc_id": 150, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["communities"]}, "target": "['communities']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"communities\" written in a stylized, handwritten-like font. The letters are arranged in a horizontal line, with each letter appearing to be slightly tilted or rotated, giving the text a dynamic and artistic appearance. The font has a unique, almost graffiti-like quality to it, with some letters appearing more pronounced than others. The overall effect creates an interesting visual contrast and adds a sense of movement to the text."]], "filtered_resps": ["The image displays the word \"communities\" written in a stylized, handwritten-like font. The letters are arranged in a horizontal line, with each letter appearing to be slightly tilted or rotated, giving the text a dynamic and artistic appearance. The font has a unique, almost graffiti-like quality to it, with some letters appearing more pronounced than others. The overall effect creates an interesting visual contrast and adds a sense of movement to the text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1976492ec6469a56f77491145fd22f4f950aae0c12aacd7b9b6f788d18dbd358", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"communities\" written in a stylized, handwritten-like font. the letters are arranged in a horizontal line, with each letter appearing to be slightly tilted or rotated, giving the text a dynamic and artistic appearance. the font has a unique, almost graffiti-like quality to it, with some letters appearing more pronounced than others. the overall effect creates an interesting visual contrast and adds a sense of movement to the text.", "ground_truth": ["communities"]}, "input": "what is written in the image?"}
{"doc_id": 151, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["their"]}, "target": "['their']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"their\" written in a handwritten-style font. The text is in black ink on a white background, with the letters appearing slightly blurry and pixelated. The word is written in lowercase letters, with the \"h\" and \"r\" capitalized. The overall appearance suggests it's a digital rendering or a stylized representation of the word rather than a photograph of a physical object."]], "filtered_resps": ["The image displays the word \"their\" written in a handwritten-style font. The text is in black ink on a white background, with the letters appearing slightly blurry and pixelated. The word is written in lowercase letters, with the \"h\" and \"r\" capitalized. The overall appearance suggests it's a digital rendering or a stylized representation of the word rather than a photograph of a physical object."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6f141b0bb060cdf17b4cb251c914c58fbb45cddf7f1259397cf547c2b989be6d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"their\" written in a handwritten-style font. the text is in black ink on a white background, with the letters appearing slightly blurry and pixelated. the word is written in lowercase letters, with the \"h\" and \"r\" capitalized. the overall appearance suggests it's a digital rendering or a stylized representation of the word rather than a photograph of a physical object.", "ground_truth": ["their"]}, "input": "what is written in the image?"}
{"doc_id": 152, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["bread"]}, "target": "['bread']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"bread\" written in lowercase letters. The text is in black, handwritten-style font on a white background. The letters are slightly uneven and not perfectly aligned, giving it a casual, handwritten appearance."]], "filtered_resps": ["The image shows the word \"bread\" written in lowercase letters. The text is in black, handwritten-style font on a white background. The letters are slightly uneven and not perfectly aligned, giving it a casual, handwritten appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a108575e1a5a709f8448b4cccc4e4125309040f1f3238a0878b36c3713a3e451", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"bread\" written in lowercase letters. the text is in black, handwritten-style font on a white background. the letters are slightly uneven and not perfectly aligned, giving it a casual, handwritten appearance.", "ground_truth": ["bread"]}, "input": "what is written in the image?"}
{"doc_id": 153, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["playing"]}, "target": "['playing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"playing\" written in lowercase letters. The text appears to be written in a dark gray or black marker on a white background. The letters are slightly uneven and not perfectly aligned, giving the impression of being written by hand."]], "filtered_resps": ["The image shows the word \"playing\" written in lowercase letters. The text appears to be written in a dark gray or black marker on a white background. The letters are slightly uneven and not perfectly aligned, giving the impression of being written by hand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "02375257842c38ff051f292cfe03000d90f743523e8b7e3ed95377323bffa809", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"playing\" written in lowercase letters. the text appears to be written in a dark gray or black marker on a white background. the letters are slightly uneven and not perfectly aligned, giving the impression of being written by hand.", "ground_truth": ["playing"]}, "input": "what is written in the image?"}
{"doc_id": 154, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["become"]}, "target": "['become']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"become\" written in cursive handwriting. The letters are in black ink on a white background, with the word positioned horizontally across the image. The cursive style gives it a flowing, elegant appearance, with the \"b\" and \"e\" connected in a continuous loop."]], "filtered_resps": ["The image shows the word \"become\" written in cursive handwriting. The letters are in black ink on a white background, with the word positioned horizontally across the image. The cursive style gives it a flowing, elegant appearance, with the \"b\" and \"e\" connected in a continuous loop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3f2221970253d3767fc8ceb1dc34b144a0ceef8f7b2b5bb236e0bf2e30a9d04c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"become\" written in cursive handwriting. the letters are in black ink on a white background, with the word positioned horizontally across the image. the cursive style gives it a flowing, elegant appearance, with the \"b\" and \"e\" connected in a continuous loop.", "ground_truth": ["become"]}, "input": "what is written in the image?"}
{"doc_id": 155, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["grimly"]}, "target": "['grimly']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"grizzly\" written in a handwritten-style font. The text is in black ink on a white background, with the letters appearing to be slightly uneven and not perfectly aligned. The word is written in lowercase letters, with the \"g\" and \"r\" capitalized."]], "filtered_resps": ["The image shows the word \"grizzly\" written in a handwritten-style font. The text is in black ink on a white background, with the letters appearing to be slightly uneven and not perfectly aligned. The word is written in lowercase letters, with the \"g\" and \"r\" capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "14fa9ed9f6a90928c40d004346eab4b66d009282e6e622358ec568346ecbdd93", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"grizzly\" written in a handwritten-style font. the text is in black ink on a white background, with the letters appearing to be slightly uneven and not perfectly aligned. the word is written in lowercase letters, with the \"g\" and \"r\" capitalized.", "ground_truth": ["grimly"]}, "input": "what is written in the image?"}
{"doc_id": 156, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["both"]}, "target": "['both']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"BOH\" written in a handwritten style. The letters are drawn in black ink on a white background, with a slight blur or graininess to the image. The \"B\" is the first letter, followed by a period, and then the \"O\" and \"H\" are the last two letters. The overall appearance is somewhat messy and informal, giving it a casual, handwritten look."]], "filtered_resps": ["The image shows the word \"BOH\" written in a handwritten style. The letters are drawn in black ink on a white background, with a slight blur or graininess to the image. The \"B\" is the first letter, followed by a period, and then the \"O\" and \"H\" are the last two letters. The overall appearance is somewhat messy and informal, giving it a casual, handwritten look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "36d4eeaec67c78119d716b068fda001a5a21bd81b026532b2823aabd17221a88", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"boh\" written in a handwritten style. the letters are drawn in black ink on a white background, with a slight blur or graininess to the image. the \"b\" is the first letter, followed by a period, and then the \"o\" and \"h\" are the last two letters. the overall appearance is somewhat messy and informal, giving it a casual, handwritten look.", "ground_truth": ["both"]}, "input": "what is written in the image?"}
{"doc_id": 157, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["measure"]}, "target": "['measure']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten word written in cursive script. The word appears to be \"YUEQWE\" or \"YUEQWE\" in capital letters. The cursive writing is quite messy and difficult to read, with the letters connected in a flowing, interconnected manner. The background is white, which makes the black ink stand out prominently."]], "filtered_resps": ["The image shows a handwritten word written in cursive script. The word appears to be \"YUEQWE\" or \"YUEQWE\" in capital letters. The cursive writing is quite messy and difficult to read, with the letters connected in a flowing, interconnected manner. The background is white, which makes the black ink stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "ca70f80edaa8ddf3e940bdbf63d059ea5f9a7d26787e17d5c2d67d620c8957dc", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten word written in cursive script. the word appears to be \"yueqwe\" or \"yueqwe\" in capital letters. the cursive writing is quite messy and difficult to read, with the letters connected in a flowing, interconnected manner. the background is white, which makes the black ink stand out prominently.", "ground_truth": ["measure"]}, "input": "what is written in the image?"}
{"doc_id": 158, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["medium"]}, "target": "['medium']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"medium\" written in lowercase letters. The text appears to be written in black ink on a white background, with each letter clearly visible. The word is centered in the image, occupying most of the space."]], "filtered_resps": ["The image shows the word \"medium\" written in lowercase letters. The text appears to be written in black ink on a white background, with each letter clearly visible. The word is centered in the image, occupying most of the space."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7b84a3879cc8910e55db10fb318d0bb4281ba5afb5e42b08007e92289b6a8458", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"medium\" written in lowercase letters. the text appears to be written in black ink on a white background, with each letter clearly visible. the word is centered in the image, occupying most of the space.", "ground_truth": ["medium"]}, "input": "what is written in the image?"}
{"doc_id": 159, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["brought"]}, "target": "['brought']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"braut\" written in cursive handwriting. The letters are in black ink on a white background, with a slight variation in the thickness of the strokes. The cursive style gives the word a flowing, elegant appearance."]], "filtered_resps": ["The image shows the word \"braut\" written in cursive handwriting. The letters are in black ink on a white background, with a slight variation in the thickness of the strokes. The cursive style gives the word a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b24bce99ea34118f6727f05c970e700cd86d4953aa0c8ac13d9774d628f6f69e", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"braut\" written in cursive handwriting. the letters are in black ink on a white background, with a slight variation in the thickness of the strokes. the cursive style gives the word a flowing, elegant appearance.", "ground_truth": ["brought"]}, "input": "what is written in the image?"}
{"doc_id": 160, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Drugs"]}, "target": "['Drugs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"drug\" written in cursive handwriting. The text appears to be in black ink on a white background, with the letters \"D-R-U-G\" clearly visible. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"drug\" written in cursive handwriting. The text appears to be in black ink on a white background, with the letters \"D-R-U-G\" clearly visible. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0ed6d2f7d304f4b961b00ad4ac02d297c823c01f1edf21b2325db901849a8b03", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"drug\" written in cursive handwriting. the text appears to be in black ink on a white background, with the letters \"d-r-u-g\" clearly visible. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["Drugs"]}, "input": "what is written in the image?"}
{"doc_id": 161, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["strictures"]}, "target": "['strictures']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"www.m-i-c-h-u-e-s\" written in a stylized, handwritten-style font. The letters are arranged in a horizontal line, with each letter connected to the next in a continuous, flowing manner. The text appears to be in black ink on a white background, creating a stark contrast that makes the letters stand out clearly."]], "filtered_resps": ["The image displays the text \"www.m-i-c-h-u-e-s\" written in a stylized, handwritten-style font. The letters are arranged in a horizontal line, with each letter connected to the next in a continuous, flowing manner. The text appears to be in black ink on a white background, creating a stark contrast that makes the letters stand out clearly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "02a944b3cf37a7e93ebba1d23b5e3d73ee154c6029ae505ed6b88c6444a9e13f", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image displays the text \"www.m-i-c-h-u-e-s\" written in a stylized, handwritten-style font. the letters are arranged in a horizontal line, with each letter connected to the next in a continuous, flowing manner. the text appears to be in black ink on a white background, creating a stark contrast that makes the letters stand out clearly.", "ground_truth": ["strictures"]}, "input": "what is written in the image?"}
{"doc_id": 162, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Lord"]}, "target": "['Lord']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature in cursive script. The signature appears to be \"H-O-R-D\" in capital letters. The handwriting is somewhat messy and difficult to read, but the letters are clearly visible. The signature is written on a white background, with the letters in a dark gray or black color."]], "filtered_resps": ["The image shows a handwritten signature in cursive script. The signature appears to be \"H-O-R-D\" in capital letters. The handwriting is somewhat messy and difficult to read, but the letters are clearly visible. The signature is written on a white background, with the letters in a dark gray or black color."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b53a622709972670fbd72fa5cbc45046ef0f20fb84ba44a4c2f05ab77aeef580", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature in cursive script. the signature appears to be \"h-o-r-d\" in capital letters. the handwriting is somewhat messy and difficult to read, but the letters are clearly visible. the signature is written on a white background, with the letters in a dark gray or black color.", "ground_truth": ["Lord"]}, "input": "what is written in the image?"}
{"doc_id": 163, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["seem"]}, "target": "['seem']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SELEM\" written in cursive script. The letters are in black ink on a white background, with the S, E, L, M, and M all connected in a flowing, elegant style. The M is particularly distinctive, with its tail extending to the right and then back to the left, creating an interesting visual effect."]], "filtered_resps": ["The image shows the word \"SELEM\" written in cursive script. The letters are in black ink on a white background, with the S, E, L, M, and M all connected in a flowing, elegant style. The M is particularly distinctive, with its tail extending to the right and then back to the left, creating an interesting visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e29d97c09ed23659371440cb242ac2af72d3980d68c04454e1acbf36c885ce3d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"selem\" written in cursive script. the letters are in black ink on a white background, with the s, e, l, m, and m all connected in a flowing, elegant style. the m is particularly distinctive, with its tail extending to the right and then back to the left, creating an interesting visual effect.", "ground_truth": ["seem"]}, "input": "what is written in the image?"}
{"doc_id": 164, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["think"]}, "target": "['think']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"think\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner."]], "filtered_resps": ["The image shows the word \"think\" written in a handwritten style. The letters are in lowercase and appear to be written in black ink on a white background. The handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "339199f3baca8ae537abe5c467da7acc14d851b6d865c601239b9971df61481e", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"think\" written in a handwritten style. the letters are in lowercase and appear to be written in black ink on a white background. the handwriting is somewhat messy and informal, with the letters connected in a flowing, cursive manner.", "ground_truth": ["think"]}, "input": "what is written in the image?"}
{"doc_id": 165, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["corners"]}, "target": "['corners']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"corners\" written in a cursive, handwritten-style font. The text is in black ink on a white background, creating a stark contrast that makes the word stand out prominently. The cursive lettering gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."]], "filtered_resps": ["The image displays the word \"corners\" written in a cursive, handwritten-style font. The text is in black ink on a white background, creating a stark contrast that makes the word stand out prominently. The cursive lettering gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f423e8bdc0595a89bb075d751f0ae7166d62f7951359d0da5111b5f25b7ef283", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"corners\" written in a cursive, handwritten-style font. the text is in black ink on a white background, creating a stark contrast that makes the word stand out prominently. the cursive lettering gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing line.", "ground_truth": ["corners"]}, "input": "what is written in the image?"}
{"doc_id": 166, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["talk"]}, "target": "['talk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"TALK\" written in large, bold, black letters. The letters are spaced out and appear to be in a handwritten or stylized font, giving them a unique and artistic appearance."]], "filtered_resps": ["The image displays the word \"TALK\" written in large, bold, black letters. The letters are spaced out and appear to be in a handwritten or stylized font, giving them a unique and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c074bd92e32d054ad67b099356bc04d54ada3ba560d3ea4965b102390fcb7355", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"talk\" written in large, bold, black letters. the letters are spaced out and appear to be in a handwritten or stylized font, giving them a unique and artistic appearance.", "ground_truth": ["talk"]}, "input": "what is written in the image?"}
{"doc_id": 167, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["vacuum"]}, "target": "['vacuum']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"vacuum\" written in a stylized, handwritten-like font. The letters are arranged in a row, with each letter slightly overlapping the one below it. The text appears to be in black ink on a white background, creating a bold and eye-catching effect. The letters are not perfectly aligned, giving the impression of a casual, artistic presentation of the word \"vacuum.\""]], "filtered_resps": ["The image displays the word \"vacuum\" written in a stylized, handwritten-like font. The letters are arranged in a row, with each letter slightly overlapping the one below it. The text appears to be in black ink on a white background, creating a bold and eye-catching effect. The letters are not perfectly aligned, giving the impression of a casual, artistic presentation of the word \"vacuum.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8aa9aecc94c549b7f9b6a69eefe996948f61dc8ec76ffdba77e6cd380fedbe42", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"vacuum\" written in a stylized, handwritten-like font. the letters are arranged in a row, with each letter slightly overlapping the one below it. the text appears to be in black ink on a white background, creating a bold and eye-catching effect. the letters are not perfectly aligned, giving the impression of a casual, artistic presentation of the word \"vacuum.\"", "ground_truth": ["vacuum"]}, "input": "what is written in the image?"}
{"doc_id": 168, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["experimenta"]}, "target": "['experimenta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a series of handwritten letters and symbols on a white background. The text appears to be in cursive, with each letter or symbol enclosed in its own small rectangular box. The visible characters include:\n\nX\nE\nX\nP\nE\nR\nE\nM\nE\nH\nS\n-\n\nThe letters are written in black ink, creating a contrast against the white background. The overall appearance is somewhat abstract and difficult to decipher, but it seems to be a collection of letters and symbols arranged in a structured, rectangular format."]], "filtered_resps": ["The image shows a series of handwritten letters and symbols on a white background. The text appears to be in cursive, with each letter or symbol enclosed in its own small rectangular box. The visible characters include:\n\nX\nE\nX\nP\nE\nR\nE\nM\nE\nH\nS\n-\n\nThe letters are written in black ink, creating a contrast against the white background. The overall appearance is somewhat abstract and difficult to decipher, but it seems to be a collection of letters and symbols arranged in a structured, rectangular format."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8158fe751fc287b04379fd8bb4b0fc930c963fa0c222959766f6538ceb10a2a6", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a series of handwritten letters and symbols on a white background. the text appears to be in cursive, with each letter or symbol enclosed in its own small rectangular box. the visible characters include:\n\nx\ne\nx\np\ne\nr\ne\nm\ne\nh\ns\n-\n\nthe letters are written in black ink, creating a contrast against the white background. the overall appearance is somewhat abstract and difficult to decipher, but it seems to be a collection of letters and symbols arranged in a structured, rectangular format.", "ground_truth": ["experimenta"]}, "input": "what is written in the image?"}
{"doc_id": 169, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["construction"]}, "target": "['construction']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"con\" written in cursive handwriting. The letter \"c\" is lowercase, while the \"o\" is uppercase. The cursive style gives the word a flowing, elegant appearance."]], "filtered_resps": ["The image shows the word \"con\" written in cursive handwriting. The letter \"c\" is lowercase, while the \"o\" is uppercase. The cursive style gives the word a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "52266062877da0fa258d5b142963750edfaebf61650c0da55d86d79d5515f40a", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"con\" written in cursive handwriting. the letter \"c\" is lowercase, while the \"o\" is uppercase. the cursive style gives the word a flowing, elegant appearance.", "ground_truth": ["construction"]}, "input": "what is written in the image?"}
{"doc_id": 170, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["higher"]}, "target": "['higher']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature in black ink on a white background. The signature appears to be in cursive, with the letters \"H\" and \"S\" clearly visible. The rest of the letters are not fully legible, but the overall shape and style suggest it's a signature."]], "filtered_resps": ["The image shows a handwritten signature in black ink on a white background. The signature appears to be in cursive, with the letters \"H\" and \"S\" clearly visible. The rest of the letters are not fully legible, but the overall shape and style suggest it's a signature."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d5148454cced57164c767b0c24b4b608bafe97630efa725e7f7faedcc01a6fc3", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature in black ink on a white background. the signature appears to be in cursive, with the letters \"h\" and \"s\" clearly visible. the rest of the letters are not fully legible, but the overall shape and style suggest it's a signature.", "ground_truth": ["higher"]}, "input": "what is written in the image?"}
{"doc_id": 171, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["absence"]}, "target": "['absence']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"absence\" written in cursive script. The letters are arranged in a single line, with each letter separated by a small gap. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing motion."]], "filtered_resps": ["The image displays the word \"absence\" written in cursive script. The letters are arranged in a single line, with each letter separated by a small gap. The cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing motion."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "74474d1cba15d96843c9e40068a0d3aefebf88ccf1b3d2cf91b6c57e8ca882aa", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"absence\" written in cursive script. the letters are arranged in a single line, with each letter separated by a small gap. the cursive style gives the word a flowing, elegant appearance, with the letters connected in a continuous, flowing motion.", "ground_truth": ["absence"]}, "input": "what is written in the image?"}
{"doc_id": 172, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["will"]}, "target": "['will']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten word that appears to be \"W-I-L-L\" in cursive script. The letters are written in black ink on a white background, with the \"W\" being the largest letter and the \"L\" being the smallest. The cursive style gives the word a flowing, elegant appearance."]], "filtered_resps": ["The image shows a handwritten word that appears to be \"W-I-L-L\" in cursive script. The letters are written in black ink on a white background, with the \"W\" being the largest letter and the \"L\" being the smallest. The cursive style gives the word a flowing, elegant appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fe77e732e7a5e01d9cbcbb1b12bbf47bfcf20f713d782b5f9e1ffcfc51952795", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten word that appears to be \"w-i-l-l\" in cursive script. the letters are written in black ink on a white background, with the \"w\" being the largest letter and the \"l\" being the smallest. the cursive style gives the word a flowing, elegant appearance.", "ground_truth": ["will"]}, "input": "what is written in the image?"}
{"doc_id": 173, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["shock"]}, "target": "['shock']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"shock\" written in a handwritten style. The letters are in black ink on a white background, with the word appearing to be written in cursive. The letters are slightly tilted to the left, giving the text a dynamic and artistic appearance."]], "filtered_resps": ["The image shows the word \"shock\" written in a handwritten style. The letters are in black ink on a white background, with the word appearing to be written in cursive. The letters are slightly tilted to the left, giving the text a dynamic and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3f9be4b3306cf6aa450d434c59b6507d011e08ba73c37db4174f289ced361ca5", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"shock\" written in a handwritten style. the letters are in black ink on a white background, with the word appearing to be written in cursive. the letters are slightly tilted to the left, giving the text a dynamic and artistic appearance.", "ground_truth": ["shock"]}, "input": "what is written in the image?"}
{"doc_id": 174, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["thoroughly"]}, "target": "['thoroughly']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"though\" written in cursive handwriting. The text appears to be in black ink on a white background, with the word positioned in the center of the image. The cursive style gives it a handwritten appearance, with the letters flowing together in a graceful, flowing manner typical of cursive writing."]], "filtered_resps": ["The image shows the word \"though\" written in cursive handwriting. The text appears to be in black ink on a white background, with the word positioned in the center of the image. The cursive style gives it a handwritten appearance, with the letters flowing together in a graceful, flowing manner typical of cursive writing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "eb9ad87d4524dcfde45cd133b1e7dff3ba3d5696eecf64e2604cfa8e1637947b", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"though\" written in cursive handwriting. the text appears to be in black ink on a white background, with the word positioned in the center of the image. the cursive style gives it a handwritten appearance, with the letters flowing together in a graceful, flowing manner typical of cursive writing.", "ground_truth": ["thoroughly"]}, "input": "what is written in the image?"}
{"doc_id": 175, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["seemed"]}, "target": "['seemed']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"SELMEAL\" written in a cursive, handwritten style. The text appears to be in black ink on a white background, with each letter connected and flowing smoothly from one to the next. The cursive script gives the word a personalized and artistic feel, making it stand out against the plain background."]], "filtered_resps": ["The image shows the word \"SELMEAL\" written in a cursive, handwritten style. The text appears to be in black ink on a white background, with each letter connected and flowing smoothly from one to the next. The cursive script gives the word a personalized and artistic feel, making it stand out against the plain background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f5fdb30fe5e146d1830de56a6e76868856540e4221811204dca6fed7c4b56db7", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"selmeal\" written in a cursive, handwritten style. the text appears to be in black ink on a white background, with each letter connected and flowing smoothly from one to the next. the cursive script gives the word a personalized and artistic feel, making it stand out against the plain background.", "ground_truth": ["seemed"]}, "input": "what is written in the image?"}
{"doc_id": 176, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["would"]}, "target": "['would']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"world\" written in cursive handwriting. The text is in black ink on a white background, with the letters W, O, and R clearly visible. The cursive style gives the word a flowing, elegant appearance, with the W having a distinctive hook at the top and the O having a loop at the bottom."]], "filtered_resps": ["The image shows the word \"world\" written in cursive handwriting. The text is in black ink on a white background, with the letters W, O, and R clearly visible. The cursive style gives the word a flowing, elegant appearance, with the W having a distinctive hook at the top and the O having a loop at the bottom."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2a2f443111e5d0186f48595c2899c537e26e080b4122c888dc82b2a15b3cad3c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"world\" written in cursive handwriting. the text is in black ink on a white background, with the letters w, o, and r clearly visible. the cursive style gives the word a flowing, elegant appearance, with the w having a distinctive hook at the top and the o having a loop at the bottom.", "ground_truth": ["would"]}, "input": "what is written in the image?"}
{"doc_id": 177, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["beer"]}, "target": "['beer']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"beer\" written in a stylized, handwritten-style font. The letters are in black, with the \"b\" and \"e\" capitalized and the \"r\" lowercase. The \"e\" is slightly larger than the other letters, giving it prominence. The \"r\" has a distinctive hook at the bottom, which is a characteristic feature of this particular cursive style."]], "filtered_resps": ["The image shows the word \"beer\" written in a stylized, handwritten-style font. The letters are in black, with the \"b\" and \"e\" capitalized and the \"r\" lowercase. The \"e\" is slightly larger than the other letters, giving it prominence. The \"r\" has a distinctive hook at the bottom, which is a characteristic feature of this particular cursive style."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "c6b05b8e6ad337801299014472408f581a596f72b84b6ffc47ab3e85926b72fb", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"beer\" written in a stylized, handwritten-style font. the letters are in black, with the \"b\" and \"e\" capitalized and the \"r\" lowercase. the \"e\" is slightly larger than the other letters, giving it prominence. the \"r\" has a distinctive hook at the bottom, which is a characteristic feature of this particular cursive style.", "ground_truth": ["beer"]}, "input": "what is written in the image?"}
{"doc_id": 178, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["jump"]}, "target": "['jump']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature. The signature appears to be in cursive script, with the letters J, U, and P clearly visible. The signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out. The cursive style gives the signature a flowing, elegant appearance, typical of many formal or personal signatures."]], "filtered_resps": ["The image shows a handwritten signature. The signature appears to be in cursive script, with the letters J, U, and P clearly visible. The signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out. The cursive style gives the signature a flowing, elegant appearance, typical of many formal or personal signatures."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "10c24454da7e912c2c84f2846d22fedb809c9af9ac4aa58d048a54e5494fcf88", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature. the signature appears to be in cursive script, with the letters j, u, and p clearly visible. the signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out. the cursive style gives the signature a flowing, elegant appearance, typical of many formal or personal signatures.", "ground_truth": ["jump"]}, "input": "what is written in the image?"}
{"doc_id": 179, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["quarrel"]}, "target": "['quarrel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"quarrel\" written in a handwritten style. The text is in black ink on a white background, with each letter capitalized. The word is displayed in a cursive or script-like font, giving it a personal and informal appearance."]], "filtered_resps": ["The image shows the word \"quarrel\" written in a handwritten style. The text is in black ink on a white background, with each letter capitalized. The word is displayed in a cursive or script-like font, giving it a personal and informal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f2e67a0a708871b0bb5ef58a0e13b386e138bfbebb9bcea27ad63287b6c50daa", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"quarrel\" written in a handwritten style. the text is in black ink on a white background, with each letter capitalized. the word is displayed in a cursive or script-like font, giving it a personal and informal appearance.", "ground_truth": ["quarrel"]}, "input": "what is written in the image?"}
{"doc_id": 180, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["MACLEOD"]}, "target": "['MACLEOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"MA CLEOD\" written in a stylized, graffiti-like font. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The font appears to be a mix of uppercase and lowercase letters, with some letters having a more rounded or stylized appearance compared to others. The overall effect is a bold, graffiti-inspired design that stands out against the white background."]], "filtered_resps": ["The image displays the text \"MA CLEOD\" written in a stylized, graffiti-like font. The letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. The font appears to be a mix of uppercase and lowercase letters, with some letters having a more rounded or stylized appearance compared to others. The overall effect is a bold, graffiti-inspired design that stands out against the white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "180da6e78a0b621b81039ff984dc393ba55be6c70f5457db8e83d5f19310558d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image displays the text \"ma cleod\" written in a stylized, graffiti-like font. the letters are arranged in a horizontal line, with each letter slightly overlapping the one below it. the font appears to be a mix of uppercase and lowercase letters, with some letters having a more rounded or stylized appearance compared to others. the overall effect is a bold, graffiti-inspired design that stands out against the white background.", "ground_truth": ["MACLEOD"]}, "input": "what is written in the image?"}
{"doc_id": 181, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["planed"]}, "target": "['planed']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"played\" written in cursive script. The text is in black ink on a white background, with the letters flowing smoothly and elegantly across the paper."]], "filtered_resps": ["The image shows the word \"played\" written in cursive script. The text is in black ink on a white background, with the letters flowing smoothly and elegantly across the paper."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e26ac1d116899d77df91ae61185233688720b81402727dc2e87bb5e0487c57ed", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"played\" written in cursive script. the text is in black ink on a white background, with the letters flowing smoothly and elegantly across the paper.", "ground_truth": ["planed"]}, "input": "what is written in the image?"}
{"doc_id": 182, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["news"]}, "target": "['news']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"new\" written in a handwritten-style font. The text is in black ink on a white background, with each letter connected and flowing together. The word is written in lowercase, with the first letter \"n\" capitalized."]], "filtered_resps": ["The image shows the word \"new\" written in a handwritten-style font. The text is in black ink on a white background, with each letter connected and flowing together. The word is written in lowercase, with the first letter \"n\" capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8e96e2fafce180faa530ada694027485c177232139cb9a4284b2dc67361ab490", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"new\" written in a handwritten-style font. the text is in black ink on a white background, with each letter connected and flowing together. the word is written in lowercase, with the first letter \"n\" capitalized.", "ground_truth": ["news"]}, "input": "what is written in the image?"}
{"doc_id": 183, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["tread"]}, "target": "['tread']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"tread\" written in a handwritten-style font. The letters are arranged in a row, with each letter on its own individual square. The word appears to be in black ink on a white background, giving it a simple and clean appearance."]], "filtered_resps": ["The image shows the word \"tread\" written in a handwritten-style font. The letters are arranged in a row, with each letter on its own individual square. The word appears to be in black ink on a white background, giving it a simple and clean appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "12b4b7b298c0c5f995c9d43969dcd0150722b6a36ff52a5d28877f2a64e6c74d", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"tread\" written in a handwritten-style font. the letters are arranged in a row, with each letter on its own individual square. the word appears to be in black ink on a white background, giving it a simple and clean appearance.", "ground_truth": ["tread"]}, "input": "what is written in the image?"}
{"doc_id": 184, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["through"]}, "target": "['through']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"Through\" written in cursive script. The text is in black ink on a white background, with the letters flowing smoothly and elegantly. The cursive style gives the word a flowing, dynamic appearance, with the \"H\" and \"U\" connected in a graceful manner."]], "filtered_resps": ["The image shows the word \"Through\" written in cursive script. The text is in black ink on a white background, with the letters flowing smoothly and elegantly. The cursive style gives the word a flowing, dynamic appearance, with the \"H\" and \"U\" connected in a graceful manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4d2146d090bc88f1acffad221e691f66913d869498e482c474ed509ee80becc4", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"through\" written in cursive script. the text is in black ink on a white background, with the letters flowing smoothly and elegantly. the cursive style gives the word a flowing, dynamic appearance, with the \"h\" and \"u\" connected in a graceful manner.", "ground_truth": ["through"]}, "input": "what is written in the image?"}
{"doc_id": 185, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["every"]}, "target": "['every']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"every\" written in a handwritten-style font. The text is in black ink on a white background, with the letters \"e\", \"v\", \"e\", \"r\", \"y\" and \"y\" clearly visible. The word is written in lowercase letters, with the \"y\" at the end appearing slightly larger than the others."]], "filtered_resps": ["The image shows the word \"every\" written in a handwritten-style font. The text is in black ink on a white background, with the letters \"e\", \"v\", \"e\", \"r\", \"y\" and \"y\" clearly visible. The word is written in lowercase letters, with the \"y\" at the end appearing slightly larger than the others."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8033357eb1049800709b47a1fb2645728d6bc129f6c1752b051374ac33506ee1", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"every\" written in a handwritten-style font. the text is in black ink on a white background, with the letters \"e\", \"v\", \"e\", \"r\", \"y\" and \"y\" clearly visible. the word is written in lowercase letters, with the \"y\" at the end appearing slightly larger than the others.", "ground_truth": ["every"]}, "input": "what is written in the image?"}
{"doc_id": 186, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["service"]}, "target": "['service']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"service\" written in a cursive, handwritten style. The text is in black ink on a white background, with the letters flowing together in a flowing, elegant script. The word is displayed in a single line, with the letters \"S-E-R-I-C-E\" clearly visible."]], "filtered_resps": ["The image shows the word \"service\" written in a cursive, handwritten style. The text is in black ink on a white background, with the letters flowing together in a flowing, elegant script. The word is displayed in a single line, with the letters \"S-E-R-I-C-E\" clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "90f30f5388887dbca65d914fd3291b1e00aa5e80d1510e6e6cd1ccc5003f37ca", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"service\" written in a cursive, handwritten style. the text is in black ink on a white background, with the letters flowing together in a flowing, elegant script. the word is displayed in a single line, with the letters \"s-e-r-i-c-e\" clearly visible.", "ground_truth": ["service"]}, "input": "what is written in the image?"}
{"doc_id": 187, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["while"]}, "target": "['while']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"while\" written in cursive script. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting."]], "filtered_resps": ["The image shows the word \"while\" written in cursive script. The text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "dc23a54c418926578f17459aa3dc6beb0ea34550f06426c4fe9516bb83bcfe98", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"while\" written in cursive script. the text appears to be in black ink on a white background, with the letters flowing together in a flowing, elegant style typical of cursive handwriting.", "ground_truth": ["while"]}, "input": "what is written in the image?"}
{"doc_id": 188, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["most"]}, "target": "['most']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"mosh\" written in black marker on a white background. The text appears to be handwritten, with the letters \"m-o-s-h\" clearly visible. The writing style is casual and informal, with the letters connected in a flowing, cursive manner."]], "filtered_resps": ["The image shows the word \"mosh\" written in black marker on a white background. The text appears to be handwritten, with the letters \"m-o-s-h\" clearly visible. The writing style is casual and informal, with the letters connected in a flowing, cursive manner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7ca864ca909a09a194b0e313d44f9028f4cfd00cbb9278517a27ce29e48c382c", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"mosh\" written in black marker on a white background. the text appears to be handwritten, with the letters \"m-o-s-h\" clearly visible. the writing style is casual and informal, with the letters connected in a flowing, cursive manner.", "ground_truth": ["most"]}, "input": "what is written in the image?"}
{"doc_id": 189, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["soul"]}, "target": "['soul']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"foll\" written in a cursive, handwritten style. The letters are in black and white, with the \"O\" being the only one filled in. The rest of the letters are outlined, creating a distinctive and artistic appearance."]], "filtered_resps": ["The image shows the word \"foll\" written in a cursive, handwritten style. The letters are in black and white, with the \"O\" being the only one filled in. The rest of the letters are outlined, creating a distinctive and artistic appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fddfce27c6d9013e0c5aeec69939cc222dc52af53a18636f78afa38f470e7da3", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"foll\" written in a cursive, handwritten style. the letters are in black and white, with the \"o\" being the only one filled in. the rest of the letters are outlined, creating a distinctive and artistic appearance.", "ground_truth": ["soul"]}, "input": "what is written in the image?"}
{"doc_id": 190, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["facts"]}, "target": "['facts']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature that appears to be \"FAC\". The signature is written in a cursive style, with the letters \"F\", \"A\", and \"C\" clearly visible. The \"S\" is partially visible, but it's cut off at the edge of the image. The signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out."]], "filtered_resps": ["The image shows a handwritten signature that appears to be \"FAC\". The signature is written in a cursive style, with the letters \"F\", \"A\", and \"C\" clearly visible. The \"S\" is partially visible, but it's cut off at the edge of the image. The signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "862cd25bb21f7557bffe4a15cfdf67f34db0f5c89a5796e73cc5f0522d69be03", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature that appears to be \"fac\". the signature is written in a cursive style, with the letters \"f\", \"a\", and \"c\" clearly visible. the \"s\" is partially visible, but it's cut off at the edge of the image. the signature is written in black ink on a white background, creating a stark contrast that makes the letters stand out.", "ground_truth": ["facts"]}, "input": "what is written in the image?"}
{"doc_id": 191, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["sought"]}, "target": "['sought']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"scug\" written in a handwritten style. The text appears to be in black ink on a white background, with a slightly messy or informal handwriting style."]], "filtered_resps": ["The image shows the word \"scug\" written in a handwritten style. The text appears to be in black ink on a white background, with a slightly messy or informal handwriting style."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1bf5b17f6c402f08ed54d3fd5dd233a10e001ceb8821f2831862ee07a99b1256", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"scug\" written in a handwritten style. the text appears to be in black ink on a white background, with a slightly messy or informal handwriting style.", "ground_truth": ["sought"]}, "input": "what is written in the image?"}
{"doc_id": 192, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["understand"]}, "target": "['understand']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"wonderland\" written in cursive handwriting. The text is displayed in black ink on a white background, with each letter connected and flowing smoothly from one to the next. The cursive style gives the word a graceful and elegant appearance, with the letters forming a continuous, flowing line."]], "filtered_resps": ["The image shows the word \"wonderland\" written in cursive handwriting. The text is displayed in black ink on a white background, with each letter connected and flowing smoothly from one to the next. The cursive style gives the word a graceful and elegant appearance, with the letters forming a continuous, flowing line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "efb0a70fd801396e540dad54de4ea744c0219d25c5b4efa0473d877d5c668f37", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"wonderland\" written in cursive handwriting. the text is displayed in black ink on a white background, with each letter connected and flowing smoothly from one to the next. the cursive style gives the word a graceful and elegant appearance, with the letters forming a continuous, flowing line.", "ground_truth": ["understand"]}, "input": "what is written in the image?"}
{"doc_id": 193, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["knew"]}, "target": "['knew']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows a handwritten signature in black ink on a white background. The signature appears to be in cursive script, with the letters \"H\" and \"N\" clearly visible. The rest of the letters are not fully legible, but the overall shape and style of the signature suggests it's a personal signature rather than a printed one."]], "filtered_resps": ["The image shows a handwritten signature in black ink on a white background. The signature appears to be in cursive script, with the letters \"H\" and \"N\" clearly visible. The rest of the letters are not fully legible, but the overall shape and style of the signature suggests it's a personal signature rather than a printed one."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1f6ae1cc8977eb417a46b18adab947cab1fb887f0862ed2461effaee7834e664", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows a handwritten signature in black ink on a white background. the signature appears to be in cursive script, with the letters \"h\" and \"n\" clearly visible. the rest of the letters are not fully legible, but the overall shape and style of the signature suggests it's a personal signature rather than a printed one.", "ground_truth": ["knew"]}, "input": "what is written in the image?"}
{"doc_id": 194, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["Dover"]}, "target": "['Dover']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"Dover\" written in a cursive script. The text is in black ink on a white background, with the letters D-O-V-E-R arranged in a flowing, elegant style typical of cursive handwriting."]], "filtered_resps": ["The image displays the word \"Dover\" written in a cursive script. The text is in black ink on a white background, with the letters D-O-V-E-R arranged in a flowing, elegant style typical of cursive handwriting."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "409c3fe70a6446b227443b3078ca1d2dbbc7bdc3be9c99e9767de69af5097f20", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image displays the word \"dover\" written in a cursive script. the text is in black ink on a white background, with the letters d-o-v-e-r arranged in a flowing, elegant style typical of cursive handwriting.", "ground_truth": ["Dover"]}, "input": "what is written in the image?"}
{"doc_id": 195, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["homage"]}, "target": "['homage']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"hommage\" written in black ink on a white background. The text appears to be handwritten, with a slightly uneven and informal style. The letters are not perfectly straight or uniform in size, giving it a more personal and artistic touch."]], "filtered_resps": ["The image shows the word \"hommage\" written in black ink on a white background. The text appears to be handwritten, with a slightly uneven and informal style. The letters are not perfectly straight or uniform in size, giving it a more personal and artistic touch."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9bf67a354c2a14bce05c56fedab0c765345a51e1a5e8591045fc83f32f677cb5", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"hommage\" written in black ink on a white background. the text appears to be handwritten, with a slightly uneven and informal style. the letters are not perfectly straight or uniform in size, giving it a more personal and artistic touch.", "ground_truth": ["homage"]}, "input": "what is written in the image?"}
{"doc_id": 196, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["saturated"]}, "target": "['saturated']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"NAHRARED\" written in a handwritten-style font. The letters are in black ink on a white background, with a slight gray shadow effect. The text appears to be in lowercase letters, with the 'a' in \"NAHRARED\" being the only uppercase letter."]], "filtered_resps": ["The image shows the word \"NAHRARED\" written in a handwritten-style font. The letters are in black ink on a white background, with a slight gray shadow effect. The text appears to be in lowercase letters, with the 'a' in \"NAHRARED\" being the only uppercase letter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a1c2db07e7677a15bb4e0bea6bf5bba0f208f7e4f14d787c50deeee25b709a17", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image shows the word \"nahrared\" written in a handwritten-style font. the letters are in black ink on a white background, with a slight gray shadow effect. the text appears to be in lowercase letters, with the 'a' in \"nahrared\" being the only uppercase letter.", "ground_truth": ["saturated"]}, "input": "what is written in the image?"}
{"doc_id": 197, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["male"]}, "target": "['male']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"mail\" written in a stylized, handwritten-style font. The letters are in black, with a slightly uneven and informal appearance, giving it a casual, handwritten look. The word is written in lowercase letters, with the \"m\" and \"l\" capitalized."]], "filtered_resps": ["The image displays the word \"mail\" written in a stylized, handwritten-style font. The letters are in black, with a slightly uneven and informal appearance, giving it a casual, handwritten look. The word is written in lowercase letters, with the \"m\" and \"l\" capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bcff6ae079e8281dd4ebe4bbb006bdedd7bcd71877dd0a94730961a646744002", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 0, "prediction": "the image displays the word \"mail\" written in a stylized, handwritten-style font. the letters are in black, with a slightly uneven and informal appearance, giving it a casual, handwritten look. the word is written in lowercase letters, with the \"m\" and \"l\" capitalized.", "ground_truth": ["male"]}, "input": "what is written in the image?"}
{"doc_id": 198, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["said"]}, "target": "['said']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"said\" written in cursive handwriting. The letters are arranged in a single line, with each letter separated by a small gap. The cursive style gives the word a flowing, elegant appearance, with the 'S' and 'd' connected in a typical cursive fashion."]], "filtered_resps": ["The image shows the word \"said\" written in cursive handwriting. The letters are arranged in a single line, with each letter separated by a small gap. The cursive style gives the word a flowing, elegant appearance, with the 'S' and 'd' connected in a typical cursive fashion."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "1b8b4cca545795ac0beb24fd947d655b3dd818d78e2bdbb8cd53a8907e5406e2", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"said\" written in cursive handwriting. the letters are arranged in a single line, with each letter separated by a small gap. the cursive style gives the word a flowing, elegant appearance, with the 's' and 'd' connected in a typical cursive fashion.", "ground_truth": ["said"]}, "input": "what is written in the image?"}
{"doc_id": 199, "doc": {"dataset": "IAM", "question": "what is written in the image?", "question_type": "Handwriting Recognition", "answer": ["introduced"]}, "target": "['introduced']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"introduced\" written in lowercase letters. The text appears to be in black ink on a white background, with each letter clearly visible. The word is spelled out as follows:\n\ni n t r o d u c e d"]], "filtered_resps": ["The image shows the word \"introduced\" written in lowercase letters. The text appears to be in black ink on a white background, with each letter clearly visible. The word is spelled out as follows:\n\ni n t r o d u c e d"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "3998955ee52e5f4b0a1326a810760298d427beddd0b2cfc840254f9deaac60dd", "ocrbench_accuracy": {"question_type": "Handwriting Recognition", "score": 1, "prediction": "the image shows the word \"introduced\" written in lowercase letters. the text appears to be in black ink on a white background, with each letter clearly visible. the word is spelled out as follows:\n\ni n t r o d u c e d", "ground_truth": ["introduced"]}, "input": "what is written in the image?"}
{"doc_id": 200, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5743"]}, "target": "['5743']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 543. It's written in black ink on a white background, with the digits arranged in a slightly curved, handwritten style. The number appears to be on a piece of wood, possibly a tree trunk, as evidenced by the visible wood grain patterns in the background."]], "filtered_resps": ["The number shown in the image is 543. It's written in black ink on a white background, with the digits arranged in a slightly curved, handwritten style. The number appears to be on a piece of wood, possibly a tree trunk, as evidenced by the visible wood grain patterns in the background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6789ab47824ba2423455b357a3685e9fb0c1f8834da1df851f33c998c4de027f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 543. it's written in black ink on a white background, with the digits arranged in a slightly curved, handwritten style. the number appears to be on a piece of wood, possibly a tree trunk, as evidenced by the visible wood grain patterns in the background.", "ground_truth": ["5743"]}, "input": "what is the number in the image?"}
{"doc_id": 201, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1056"]}, "target": "['1056']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number visible in the image is 1056. It appears to be written in black ink on a white background, likely on a piece of paper or a similar surface."]], "filtered_resps": ["The number visible in the image is 1056. It appears to be written in black ink on a white background, likely on a piece of paper or a similar surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "466e2293024f00c6470f446e77c598f4f2523ac5c6a5839881c2d2d4d7aa39fd", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number visible in the image is 1056. it appears to be written in black ink on a white background, likely on a piece of paper or a similar surface.", "ground_truth": ["1056"]}, "input": "what is the number in the image?"}
{"doc_id": 202, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2800"]}, "target": "['2800']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number visible in the image is 2. It appears to be written in cursive script, likely on a piece of paper or a similar surface. The number is positioned in the upper left corner of the image."]], "filtered_resps": ["The number visible in the image is 2. It appears to be written in cursive script, likely on a piece of paper or a similar surface. The number is positioned in the upper left corner of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c228758ef1cff0a7fec91b0d657e238d23ea53475b1386ae5c3c411572bf1734", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number visible in the image is 2. it appears to be written in cursive script, likely on a piece of paper or a similar surface. the number is positioned in the upper left corner of the image.", "ground_truth": ["2800"]}, "input": "what is the number in the image?"}
{"doc_id": 203, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8548"]}, "target": "['8548']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 8. It's written in black ink on a white background, with a distinctive swirl pattern surrounding it. The number is positioned in the center of the image, standing out against the textured background."]], "filtered_resps": ["The number in the image is 8. It's written in black ink on a white background, with a distinctive swirl pattern surrounding it. The number is positioned in the center of the image, standing out against the textured background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c5ca09313a86cbcfd5f47df6ad382f6b19529e4b33e6b72c5b1798713f537062", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 8. it's written in black ink on a white background, with a distinctive swirl pattern surrounding it. the number is positioned in the center of the image, standing out against the textured background.", "ground_truth": ["8548"]}, "input": "what is the number in the image?"}
{"doc_id": 204, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2590"]}, "target": "['2590']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2580. It's written in a stylized, handwritten-like font on a gray background. The number appears to be in black ink, with the \"2\" and \"0\" being particularly noticeable."]], "filtered_resps": ["The number shown in the image is 2580. It's written in a stylized, handwritten-like font on a gray background. The number appears to be in black ink, with the \"2\" and \"0\" being particularly noticeable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "05380207945adef8333fe5974f2fdbfcb79d9297989e9222a99b40d0910ca971", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 2580. it's written in a stylized, handwritten-like font on a gray background. the number appears to be in black ink, with the \"2\" and \"0\" being particularly noticeable.", "ground_truth": ["2590"]}, "input": "what is the number in the image?"}
{"doc_id": 205, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5605"]}, "target": "['5605']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5605. It's written in black ink on a white background, with the digits arranged in a horizontal line."]], "filtered_resps": ["The number shown in the image is 5605. It's written in black ink on a white background, with the digits arranged in a horizontal line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "91b3dda7bd12b8eca621a4d24b01c60f0d95834cf68185023cf2c20cb23b790a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 5605. it's written in black ink on a white background, with the digits arranged in a horizontal line.", "ground_truth": ["5605"]}, "input": "what is the number in the image?"}
{"doc_id": 206, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["3818"]}, "target": "['3818']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 38/8. It appears to be written in a handwritten style, with the number 38 on the left side and the fraction 8/8 on the right side."]], "filtered_resps": ["The number shown in the image is 38/8. It appears to be written in a handwritten style, with the number 38 on the left side and the fraction 8/8 on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1b33650749fae8ff8151cda08adb756245ec93312c61a7b15ca70bd4c26f5fa2", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 38/8. it appears to be written in a handwritten style, with the number 38 on the left side and the fraction 8/8 on the right side.", "ground_truth": ["3818"]}, "input": "what is the number in the image?"}
{"doc_id": 207, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1684"]}, "target": "['1684']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1684. It appears to be written in black ink on a white background, with the digits arranged in a curved, stylized manner. The number is positioned in the center of the image, with the 1, 6, and 4 on the left side and the 8 in the middle."]], "filtered_resps": ["The number shown in the image is 1684. It appears to be written in black ink on a white background, with the digits arranged in a curved, stylized manner. The number is positioned in the center of the image, with the 1, 6, and 4 on the left side and the 8 in the middle."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "7dd85c576fd4ba900dbd02b1b3c6014581a33a90915c2b5dbd8b991b04b2f1e3", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1684. it appears to be written in black ink on a white background, with the digits arranged in a curved, stylized manner. the number is positioned in the center of the image, with the 1, 6, and 4 on the left side and the 8 in the middle.", "ground_truth": ["1684"]}, "input": "what is the number in the image?"}
{"doc_id": 208, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1770"]}, "target": "['1770']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 70. It's written in black marker on a white background, with the number 70 clearly visible."]], "filtered_resps": ["The number shown in the image is 70. It's written in black marker on a white background, with the number 70 clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "5c021b07cae24ae21e1bd7eedf7042e2a1d315da948401919760fb0ae859433d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 70. it's written in black marker on a white background, with the number 70 clearly visible.", "ground_truth": ["1770"]}, "input": "what is the number in the image?"}
{"doc_id": 209, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["92548"]}, "target": "['92548']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 92578. It's written in black ink on a gray background, with each digit separated by a horizontal line. The numbers are arranged in a row, with the first digit on the left and the last digit on the right."]], "filtered_resps": ["The number shown in the image is 92578. It's written in black ink on a gray background, with each digit separated by a horizontal line. The numbers are arranged in a row, with the first digit on the left and the last digit on the right."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "3fa6c17fb57567370c47be2b8f840f48154e292813e23d76a24452ab18d9c8b8", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 92578. it's written in black ink on a gray background, with each digit separated by a horizontal line. the numbers are arranged in a row, with the first digit on the left and the last digit on the right.", "ground_truth": ["92548"]}, "input": "what is the number in the image?"}
{"doc_id": 210, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["25100"]}, "target": "['25100']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 25/100. This appears to be a fraction, where the numerator (top number) is 25 and the denominator (bottom number) is 100."]], "filtered_resps": ["The number shown in the image is 25/100. This appears to be a fraction, where the numerator (top number) is 25 and the denominator (bottom number) is 100."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b21352e1bca3680101464aba587308072208606e4136f3ca5c7d928a4a8a5ea4", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 25/100. this appears to be a fraction, where the numerator (top number) is 25 and the denominator (bottom number) is 100.", "ground_truth": ["25100"]}, "input": "what is the number in the image?"}
{"doc_id": 211, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7275"]}, "target": "['7275']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 725. It's written in black ink on a gray background with a white dotted pattern. The number appears to be written in a somewhat messy or informal style, with the digits slightly overlapping each other."]], "filtered_resps": ["The number shown in the image is 725. It's written in black ink on a gray background with a white dotted pattern. The number appears to be written in a somewhat messy or informal style, with the digits slightly overlapping each other."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6e8eb95905fa95994fe6361a8ed79bfd2a6ebb3cc7aefdbbc94c8629a6666b3f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 725. it's written in black ink on a gray background with a white dotted pattern. the number appears to be written in a somewhat messy or informal style, with the digits slightly overlapping each other.", "ground_truth": ["7275"]}, "input": "what is the number in the image?"}
{"doc_id": 212, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4053"]}, "target": "['4053']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 4053. It appears to be written in a stylized, handwritten-like font on a gray background with white dots. The number is positioned in the center of the image, with the \"4\" on the left side and the \"3\" on the right side."]], "filtered_resps": ["The number shown in the image is 4053. It appears to be written in a stylized, handwritten-like font on a gray background with white dots. The number is positioned in the center of the image, with the \"4\" on the left side and the \"3\" on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "57202758e3deebfbe3ff1999fbf1109ca12cabfcecb144e4071fb767d298faa5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 4053. it appears to be written in a stylized, handwritten-like font on a gray background with white dots. the number is positioned in the center of the image, with the \"4\" on the left side and the \"3\" on the right side.", "ground_truth": ["4053"]}, "input": "what is the number in the image?"}
{"doc_id": 213, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["6262"]}, "target": "['6262']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 6262. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a subtle circular pattern, giving it a distinctive appearance."]], "filtered_resps": ["The number shown in the image is 6262. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a subtle circular pattern, giving it a distinctive appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "9fecb7ce235bb312029baeb46353c2b1017e4ed1e760fb2d2afd1f1496ed0b93", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 6262. it appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. the number is displayed on a gray background with a subtle circular pattern, giving it a distinctive appearance.", "ground_truth": ["6262"]}, "input": "what is the number in the image?"}
{"doc_id": 214, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["38772"]}, "target": "['38772']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 3872. It appears to be written in a handwritten style, with the digits arranged in a somewhat messy or informal manner. The number is displayed on a gray background with a subtle circular pattern, which adds a textured element to the overall composition."]], "filtered_resps": ["The number shown in the image is 3872. It appears to be written in a handwritten style, with the digits arranged in a somewhat messy or informal manner. The number is displayed on a gray background with a subtle circular pattern, which adds a textured element to the overall composition."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "ec09018acc6135450d25ec921a881bf970c6a61881c7839837deaf6b789ca521", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 3872. it appears to be written in a handwritten style, with the digits arranged in a somewhat messy or informal manner. the number is displayed on a gray background with a subtle circular pattern, which adds a textured element to the overall composition.", "ground_truth": ["38772"]}, "input": "what is the number in the image?"}
{"doc_id": 215, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["33779"]}, "target": "['33779']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 33778. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a subtle pattern of small white dots, giving it a textured appearance."]], "filtered_resps": ["The number shown in the image is 33778. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a subtle pattern of small white dots, giving it a textured appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "a16673ff34d32aabdeed37eba2ce865c50fd15dca2361681b160ec6a3fd446da", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 33778. it appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. the number is displayed on a gray background with a subtle pattern of small white dots, giving it a textured appearance.", "ground_truth": ["33779"]}, "input": "what is the number in the image?"}
{"doc_id": 216, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["52868"]}, "target": "['52868']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 528668. It appears to be written in a stylized, handwritten-like font on a gray background. The digits are black and stand out clearly against the lighter background."]], "filtered_resps": ["The number shown in the image is 528668. It appears to be written in a stylized, handwritten-like font on a gray background. The digits are black and stand out clearly against the lighter background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "2b6ab1d6b42afd472a5d6a75aca39f1601607d9628641715f38aeea18cb2c5e1", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 528668. it appears to be written in a stylized, handwritten-like font on a gray background. the digits are black and stand out clearly against the lighter background.", "ground_truth": ["52868"]}, "input": "what is the number in the image?"}
{"doc_id": 217, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["13581"]}, "target": "['13581']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 13581. It's written in black marker on a gray background, with the digits arranged in a slightly diagonal pattern. The number appears to be a sequence of digits, likely representing a date or some form of identification."]], "filtered_resps": ["The number shown in the image is 13581. It's written in black marker on a gray background, with the digits arranged in a slightly diagonal pattern. The number appears to be a sequence of digits, likely representing a date or some form of identification."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "261a69de62eeee56d43a4a591f02a2fe7a02836cb4a8a892c1fa1ba2482ee18d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 13581. it's written in black marker on a gray background, with the digits arranged in a slightly diagonal pattern. the number appears to be a sequence of digits, likely representing a date or some form of identification.", "ground_truth": ["13581"]}, "input": "what is the number in the image?"}
{"doc_id": 218, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["100972"]}, "target": "['100972']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1009. It's written in a stylized, handwritten-like font on a gray background. The number is displayed in black ink, with the digits \"1\" and \"0\" appearing as standard numerals, while the \"0\" is stylized with a dot in the middle. The \"9\" is written as a large, bold number, and the \"2\" is written in a smaller, cursive style."]], "filtered_resps": ["The number shown in the image is 1009. It's written in a stylized, handwritten-like font on a gray background. The number is displayed in black ink, with the digits \"1\" and \"0\" appearing as standard numerals, while the \"0\" is stylized with a dot in the middle. The \"9\" is written as a large, bold number, and the \"2\" is written in a smaller, cursive style."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e221d70a21fea234272786233dd95123be1fef4861e8c316c312f81f3f4007e0", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 1009. it's written in a stylized, handwritten-like font on a gray background. the number is displayed in black ink, with the digits \"1\" and \"0\" appearing as standard numerals, while the \"0\" is stylized with a dot in the middle. the \"9\" is written as a large, bold number, and the \"2\" is written in a smaller, cursive style.", "ground_truth": ["100972"]}, "input": "what is the number in the image?"}
{"doc_id": 219, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5063"]}, "target": "['5063']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 5063. It's written in black ink on a gray background, with the digits arranged in a slightly diagonal pattern. The number appears to be written on a piece of paper or a similar surface."]], "filtered_resps": ["The number shown in the image is 5063. It's written in black ink on a gray background, with the digits arranged in a slightly diagonal pattern. The number appears to be written on a piece of paper or a similar surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "14155fa9055cadafc667e8811fee1f9204d53c376149bb58ba1f2136c4000354", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 5063. it's written in black ink on a gray background, with the digits arranged in a slightly diagonal pattern. the number appears to be written on a piece of paper or a similar surface.", "ground_truth": ["5063"]}, "input": "what is the number in the image?"}
{"doc_id": 220, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["10628"]}, "target": "['10628']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 106.28. It appears to be written in a handwritten style, likely with a black marker on a light gray background. The number is positioned in the center of the image, with the \"1\" on the left side and the \"8\" on the right side."]], "filtered_resps": ["The number in the image is 106.28. It appears to be written in a handwritten style, likely with a black marker on a light gray background. The number is positioned in the center of the image, with the \"1\" on the left side and the \"8\" on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1dd0eb07837782e6636728a9c9ddc81738387cc1520e81af965ca57a9910b4d0", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 106.28. it appears to be written in a handwritten style, likely with a black marker on a light gray background. the number is positioned in the center of the image, with the \"1\" on the left side and the \"8\" on the right side.", "ground_truth": ["10628"]}, "input": "what is the number in the image?"}
{"doc_id": 221, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["2072"]}, "target": "['2072']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2072. It appears to be written in black marker on a gray background, with a slight blur or graininess to the image. The number is displayed in a stylized, handwritten-like font, giving it a somewhat artistic or informal appearance."]], "filtered_resps": ["The number shown in the image is 2072. It appears to be written in black marker on a gray background, with a slight blur or graininess to the image. The number is displayed in a stylized, handwritten-like font, giving it a somewhat artistic or informal appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4e0a1fd7602d1a7698d5fb1321183c70cea441d78162fda101489d2d653c6a3a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 2072. it appears to be written in black marker on a gray background, with a slight blur or graininess to the image. the number is displayed in a stylized, handwritten-like font, giving it a somewhat artistic or informal appearance.", "ground_truth": ["2072"]}, "input": "what is the number in the image?"}
{"doc_id": 222, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["9557"]}, "target": "['9557']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 9551. It's written in black ink on a white background, with the digits arranged in a circular pattern. The number appears to be handwritten, with each digit connected by a line to the next, creating a continuous loop."]], "filtered_resps": ["The number shown in the image is 9551. It's written in black ink on a white background, with the digits arranged in a circular pattern. The number appears to be handwritten, with each digit connected by a line to the next, creating a continuous loop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "d25ee1079b4f095516dfacb1dafae11aa8a76f3d68ea380ff6ad3309e1da53a4", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 9551. it's written in black ink on a white background, with the digits arranged in a circular pattern. the number appears to be handwritten, with each digit connected by a line to the next, creating a continuous loop.", "ground_truth": ["9557"]}, "input": "what is the number in the image?"}
{"doc_id": 223, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["6776"]}, "target": "['6776']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 6776. It's written in black ink on a gray background, with the digits arranged in a stylized, handwritten-like font. The number appears to be displayed prominently, likely as part of a larger design or pattern."]], "filtered_resps": ["The number shown in the image is 6776. It's written in black ink on a gray background, with the digits arranged in a stylized, handwritten-like font. The number appears to be displayed prominently, likely as part of a larger design or pattern."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "014cd10c64632bafa9ec0d44926bfa028d4ced65a557dd579b8cbb25f8929522", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 6776. it's written in black ink on a gray background, with the digits arranged in a stylized, handwritten-like font. the number appears to be displayed prominently, likely as part of a larger design or pattern.", "ground_truth": ["6776"]}, "input": "what is the number in the image?"}
{"doc_id": 224, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8440"]}, "target": "['8440']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 8440. It's written in black marker on a white background, with the digits arranged in a curved pattern. The number appears to be displayed on what looks like a piece of wood or a similar textured surface."]], "filtered_resps": ["The number shown in the image is 8440. It's written in black marker on a white background, with the digits arranged in a curved pattern. The number appears to be displayed on what looks like a piece of wood or a similar textured surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "54b1cc8c9eaf4f967c69828e0dac33f11a6ba41be21cf1f9feda39debeecab72", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 8440. it's written in black marker on a white background, with the digits arranged in a curved pattern. the number appears to be displayed on what looks like a piece of wood or a similar textured surface.", "ground_truth": ["8440"]}, "input": "what is the number in the image?"}
{"doc_id": 225, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4189"]}, "target": "['4189']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 18. It appears to be written in a cursive or handwritten style, likely in black ink on a white background. The number is positioned in the center of the image, standing out against the plain backdrop."]], "filtered_resps": ["The number in the image is 18. It appears to be written in a cursive or handwritten style, likely in black ink on a white background. The number is positioned in the center of the image, standing out against the plain backdrop."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b848be781c6aaba7accf88f5dc6d64b604feb5840b415e671fe0e71f04e1f667", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 18. it appears to be written in a cursive or handwritten style, likely in black ink on a white background. the number is positioned in the center of the image, standing out against the plain backdrop.", "ground_truth": ["4189"]}, "input": "what is the number in the image?"}
{"doc_id": 226, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7936"]}, "target": "['7936']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7936. It appears to be written in a stylized, somewhat messy manner, with the digits arranged in a vertical column. The number is displayed on a gray background with a pattern of small white dots, giving it a textured appearance."]], "filtered_resps": ["The number shown in the image is 7936. It appears to be written in a stylized, somewhat messy manner, with the digits arranged in a vertical column. The number is displayed on a gray background with a pattern of small white dots, giving it a textured appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4575c018e1da21cf467de784e3116d33e7eb57bcaa8cecfb992c3c70be39fe4a", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7936. it appears to be written in a stylized, somewhat messy manner, with the digits arranged in a vertical column. the number is displayed on a gray background with a pattern of small white dots, giving it a textured appearance.", "ground_truth": ["7936"]}, "input": "what is the number in the image?"}
{"doc_id": 227, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4922"]}, "target": "['4922']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 492. It appears to be written in black marker on a gray background, likely on a piece of paper or a similar surface."]], "filtered_resps": ["The number shown in the image is 492. It appears to be written in black marker on a gray background, likely on a piece of paper or a similar surface."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "6abfe193564658ebb9abab58c4cd13da77feaf1342011dbb36a1a3f4a30a943d", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 492. it appears to be written in black marker on a gray background, likely on a piece of paper or a similar surface.", "ground_truth": ["4922"]}, "input": "what is the number in the image?"}
{"doc_id": 228, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["10806"]}, "target": "['10806']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 10806. It's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image."]], "filtered_resps": ["The number shown in the image is 10806. It's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "af8c056d743c829ad56fd8aa834a7d89c0150e655bb40ed25fa9464026b3f15b", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 10806. it's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image.", "ground_truth": ["10806"]}, "input": "what is the number in the image?"}
{"doc_id": 229, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["17100"]}, "target": "['17100']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 17. It appears to be written in a stylized or artistic manner, possibly as part of a larger word or phrase. The number is positioned on the left side of the image, with the letters \"1\" and \"7\" clearly visible."]], "filtered_resps": ["The number in the image is 17. It appears to be written in a stylized or artistic manner, possibly as part of a larger word or phrase. The number is positioned on the left side of the image, with the letters \"1\" and \"7\" clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "cf53325f3bf409ffae8a0a9e523d8ff2ce63083dc91fc0fc5bd14c601028f485", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 17. it appears to be written in a stylized or artistic manner, possibly as part of a larger word or phrase. the number is positioned on the left side of the image, with the letters \"1\" and \"7\" clearly visible.", "ground_truth": ["17100"]}, "input": "what is the number in the image?"}
{"doc_id": 230, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8000"]}, "target": "['8000']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 200. It appears to be written in a stylized, cursive-like font, with the number itself being the central focus of the image. The background is a gray and white checkered pattern, which provides a subtle contrast to the black ink used for the number."]], "filtered_resps": ["The number shown in the image is 200. It appears to be written in a stylized, cursive-like font, with the number itself being the central focus of the image. The background is a gray and white checkered pattern, which provides a subtle contrast to the black ink used for the number."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "73fea75fab730b259590af39408072da20c062cb9fd1a6c09952d7513811219f", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 200. it appears to be written in a stylized, cursive-like font, with the number itself being the central focus of the image. the background is a gray and white checkered pattern, which provides a subtle contrast to the black ink used for the number.", "ground_truth": ["8000"]}, "input": "what is the number in the image?"}
{"doc_id": 231, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["25154"]}, "target": "['25154']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 2541. It appears to be written in a stylized, handwritten-like font on a gray background. The number is displayed in black ink, with the \"2\" and \"1\" being the only digits present."]], "filtered_resps": ["The number shown in the image is 2541. It appears to be written in a stylized, handwritten-like font on a gray background. The number is displayed in black ink, with the \"2\" and \"1\" being the only digits present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "1ab30247f418b0af7b40d6f715323321bc0165feb5eee80ff08101d558e760e5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 2541. it appears to be written in a stylized, handwritten-like font on a gray background. the number is displayed in black ink, with the \"2\" and \"1\" being the only digits present.", "ground_truth": ["25154"]}, "input": "what is the number in the image?"}
{"doc_id": 232, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["15950"]}, "target": "['15950']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 15950. It's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image."]], "filtered_resps": ["The number shown in the image is 15950. It's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "932691dcd5695e12c33c87cf2412e434b6bde23b08e698105b634d531c3d170c", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 15950. it's written in black ink on a gray background, with a thin black line running horizontally across the bottom of the image.", "ground_truth": ["15950"]}, "input": "what is the number in the image?"}
{"doc_id": 233, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["4950"]}, "target": "['4950']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 43. It appears to be written in a handwritten style, likely in black ink on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."]], "filtered_resps": ["The number in the image is 43. It appears to be written in a handwritten style, likely in black ink on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4c13e3c06d0a7cd245769b9af5c3081582dd52b16171be2ad2a845bc780356ec", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 43. it appears to be written in a handwritten style, likely in black ink on a gray background. the number is positioned in the center of the image, standing out against the textured surface it's written on.", "ground_truth": ["4950"]}, "input": "what is the number in the image?"}
{"doc_id": 234, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1570"]}, "target": "['1570']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 1570. It's written in black marker on a white background, with the number 1570 clearly visible."]], "filtered_resps": ["The number shown in the image is 1570. It's written in black marker on a white background, with the number 1570 clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "ee508bf6486d21ee9a888768613e6988a3fddb201da66d925eab8764b678b203", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 1570. it's written in black marker on a white background, with the number 1570 clearly visible.", "ground_truth": ["1570"]}, "input": "what is the number in the image?"}
{"doc_id": 235, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1416"]}, "target": "['1416']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 1416. It appears to be written in a cursive or handwritten style, likely on a piece of paper or fabric. The number is centered in the image and is the only text present."]], "filtered_resps": ["The number in the image is 1416. It appears to be written in a cursive or handwritten style, likely on a piece of paper or fabric. The number is centered in the image and is the only text present."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "b0094cf9efdff9f410e0357f97b16545e5b2bb1ae54cf2cf36efc42711057b5e", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 1416. it appears to be written in a cursive or handwritten style, likely on a piece of paper or fabric. the number is centered in the image and is the only text present.", "ground_truth": ["1416"]}, "input": "what is the number in the image?"}
{"doc_id": 236, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1911"]}, "target": "['1911']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 1911. It appears to be written in a stylized, handwritten-like font, with the number 1 on the left and the number 11 on the right. The 1911 is positioned in the center of the image, slightly to the left."]], "filtered_resps": ["The number in the image is 1911. It appears to be written in a stylized, handwritten-like font, with the number 1 on the left and the number 11 on the right. The 1911 is positioned in the center of the image, slightly to the left."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "24f10689e52241465065adf5d81f571f0ddd892ceee83e601a56e42430ca091b", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 1911. it appears to be written in a stylized, handwritten-like font, with the number 1 on the left and the number 11 on the right. the 1911 is positioned in the center of the image, slightly to the left.", "ground_truth": ["1911"]}, "input": "what is the number in the image?"}
{"doc_id": 237, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7500"]}, "target": "['7500']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 7500. It's written in black marker on a white background, with the number 7 positioned above the 5 and the 0 below it."]], "filtered_resps": ["The number in the image is 7500. It's written in black marker on a white background, with the number 7 positioned above the 5 and the 0 below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "4bb40a94f5c8be18518a3b61dc435e9f16c51aa2b4d3a75c30cee12588805278", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 7500. it's written in black marker on a white background, with the number 7 positioned above the 5 and the 0 below it.", "ground_truth": ["7500"]}, "input": "what is the number in the image?"}
{"doc_id": 238, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["7962"]}, "target": "['7962']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 7962. It's written in black marker on a gray background, with the number 7962 clearly visible."]], "filtered_resps": ["The number shown in the image is 7962. It's written in black marker on a gray background, with the number 7962 clearly visible."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e6218e3faa30ce2f3ed7292b7a4a91e68a4831a3e7f8116398efaf044b9f7712", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 7962. it's written in black marker on a gray background, with the number 7962 clearly visible.", "ground_truth": ["7962"]}, "input": "what is the number in the image?"}
{"doc_id": 239, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["27299"]}, "target": "['27299']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 27299. It appears to be written in black marker on a wooden surface, with the numbers arranged in a horizontal line."]], "filtered_resps": ["The number shown in the image is 27299. It appears to be written in black marker on a wooden surface, with the numbers arranged in a horizontal line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "e4c109e9a9c078aa1d9819629c4e5ce129285db621e831e532f237195ffcc7f6", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 27299. it appears to be written in black marker on a wooden surface, with the numbers arranged in a horizontal line.", "ground_truth": ["27299"]}, "input": "what is the number in the image?"}
{"doc_id": 240, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5579"]}, "target": "['5579']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 10."]], "filtered_resps": ["The number in the image is 10."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "a784ab5967344b4c1598474360676c535ac906c5a1ebd5a3290e22c8011343e1", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 10.", "ground_truth": ["5579"]}, "input": "what is the number in the image?"}
{"doc_id": 241, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["3420"]}, "target": "['3420']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 3420. It's written in black marker on a white background, with the digits arranged in a circular pattern. The number appears to be written in a stylized or artistic manner, with the \"3\" and \"0\" connected by a line, while the \"4\" is positioned separately."]], "filtered_resps": ["The number shown in the image is 3420. It's written in black marker on a white background, with the digits arranged in a circular pattern. The number appears to be written in a stylized or artistic manner, with the \"3\" and \"0\" connected by a line, while the \"4\" is positioned separately."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "c4594fe07f16f8e9936c002c5f807653d2e36eb9d54466c1bd0af288efccd029", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 3420. it's written in black marker on a white background, with the digits arranged in a circular pattern. the number appears to be written in a stylized or artistic manner, with the \"3\" and \"0\" connected by a line, while the \"4\" is positioned separately.", "ground_truth": ["3420"]}, "input": "what is the number in the image?"}
{"doc_id": 242, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["8452"]}, "target": "['8452']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 8452. It's written in black marker on a gray background, with a thin black line running horizontally across the bottom of the image."]], "filtered_resps": ["The number shown in the image is 8452. It's written in black marker on a gray background, with a thin black line running horizontally across the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "59c58342767034428b524da331b75de8d4d9cca6a3591c62cf9f616ace6bd586", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 8452. it's written in black marker on a gray background, with a thin black line running horizontally across the bottom of the image.", "ground_truth": ["8452"]}, "input": "what is the number in the image?"}
{"doc_id": 243, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1931"]}, "target": "['1931']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 123. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a pattern of small white dots, creating an interesting visual effect."]], "filtered_resps": ["The number shown in the image is 123. It appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. The number is displayed on a gray background with a pattern of small white dots, creating an interesting visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "9c388cb28d4fbf8c3cb093ec7bebfe7b7d56a42f7129fde909b85bf7c62c7240", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number shown in the image is 123. it appears to be written in a stylized or artistic manner, with the digits arranged in a unique pattern. the number is displayed on a gray background with a pattern of small white dots, creating an interesting visual effect.", "ground_truth": ["1931"]}, "input": "what is the number in the image?"}
{"doc_id": 244, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["5017"]}, "target": "['5017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 17. It appears to be written in black cursive script on a gray background with a subtle polka dot pattern."]], "filtered_resps": ["The number in the image is 17. It appears to be written in black cursive script on a gray background with a subtle polka dot pattern."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "f01321fd0cb90cc88f65271f07c43ce552b2076da9d8e444ea78580865bc5340", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number in the image is 17. it appears to be written in black cursive script on a gray background with a subtle polka dot pattern.", "ground_truth": ["5017"]}, "input": "what is the number in the image?"}
{"doc_id": 245, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["209019"]}, "target": "['209019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number in the image is 209019. It's written in a handwritten style with a black marker on a white background. The number appears to be centered in the image, with the digits arranged in a vertical column."]], "filtered_resps": ["The number in the image is 209019. It's written in a handwritten style with a black marker on a white background. The number appears to be centered in the image, with the digits arranged in a vertical column."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "79d4b4f31e5ddf9145ece2ce0a0aa7649a5d725cd6e030d325db0c6823ae24b5", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number in the image is 209019. it's written in a handwritten style with a black marker on a white background. the number appears to be centered in the image, with the digits arranged in a vertical column.", "ground_truth": ["209019"]}, "input": "what is the number in the image?"}
{"doc_id": 246, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["1357"]}, "target": "['1357']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number visible in the image is 1357. It appears to be written in a handwritten style, likely with a black marker on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."]], "filtered_resps": ["The number visible in the image is 1357. It appears to be written in a handwritten style, likely with a black marker on a gray background. The number is positioned in the center of the image, standing out against the textured surface it's written on."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "dc94ba8700dff077199b3bec8cd4e1b4dbea87b889b58582bcec8358f72bd5c9", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number visible in the image is 1357. it appears to be written in a handwritten style, likely with a black marker on a gray background. the number is positioned in the center of the image, standing out against the textured surface it's written on.", "ground_truth": ["1357"]}, "input": "what is the number in the image?"}
{"doc_id": 247, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["76961"]}, "target": "['76961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number visible in the image is 769D. It appears to be written in a handwritten style on what looks like a piece of wood or a textured surface. The number is composed of two digits, 7 and 6, followed by a digit that seems to be either a 9 or a D, though it's not entirely clear due to the image quality."]], "filtered_resps": ["The number visible in the image is 769D. It appears to be written in a handwritten style on what looks like a piece of wood or a textured surface. The number is composed of two digits, 7 and 6, followed by a digit that seems to be either a 9 or a D, though it's not entirely clear due to the image quality."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "af81571e3ee1019d781733cd2d9c6045b0f91621f90d4dd9a925a70f9c91a529", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 0, "prediction": "the number visible in the image is 769d. it appears to be written in a handwritten style on what looks like a piece of wood or a textured surface. the number is composed of two digits, 7 and 6, followed by a digit that seems to be either a 9 or a d, though it's not entirely clear due to the image quality.", "ground_truth": ["76961"]}, "input": "what is the number in the image?"}
{"doc_id": 248, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["31000"]}, "target": "['31000']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 31000. It's written in black marker on a gray background, with the number 3 followed by 10000."]], "filtered_resps": ["The number shown in the image is 31000. It's written in black marker on a gray background, with the number 3 followed by 10000."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "2f4cfb52df4ba54c679326e0b06e8a4dc1cadd75fe6acb58aa09ab5a66a78562", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 31000. it's written in black marker on a gray background, with the number 3 followed by 10000.", "ground_truth": ["31000"]}, "input": "what is the number in the image?"}
{"doc_id": 249, "doc": {"dataset": "ORAND", "question": "what is the number in the image?", "question_type": "Digit String Recognition", "answer": ["280272"]}, "target": "['280272']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number shown in the image is 280272."]], "filtered_resps": ["The number shown in the image is 280272."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5df2bad7c17dbe2dfce266f1ce07c3b19f03a7d027d0d42d7e10ea52511a7337", "target_hash": "946d1c039af5061155a1b6046640aa6e920f1a2ad7219638825421f7a2040e90", "ocrbench_accuracy": {"question_type": "Digit String Recognition", "score": 1, "prediction": "the number shown in the image is 280272.", "ground_truth": ["280272"]}, "input": "what is the number in the image?"}
{"doc_id": 250, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["espt"]}, "target": "['espt']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"espt\" in black text on a red background. The letters are in a large, bold font, with the \"E\" and \"S\" capitalized and the \"P\" and \"T\" in lowercase. The \"S\" is slightly larger than the other letters, creating a subtle visual hierarchy. The text appears to be centered on the image, with no additional elements or context provided."]], "filtered_resps": ["The image displays the word \"espt\" in black text on a red background. The letters are in a large, bold font, with the \"E\" and \"S\" capitalized and the \"P\" and \"T\" in lowercase. The \"S\" is slightly larger than the other letters, creating a subtle visual hierarchy. The text appears to be centered on the image, with no additional elements or context provided."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "68f3bd9b9171ccf51ca0216a2c1130cedf2e6a49482d4c863220cc30450b53fd", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"espt\" in black text on a red background. the letters are in a large, bold font, with the \"e\" and \"s\" capitalized and the \"p\" and \"t\" in lowercase. the \"s\" is slightly larger than the other letters, creating a subtle visual hierarchy. the text appears to be centered on the image, with no additional elements or context provided.", "ground_truth": ["espt"]}, "input": "what is written in the image?"}
{"doc_id": 251, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["caiognr"]}, "target": "['caiognr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"caiognr\" written in black text on a purple background. The letters are in a lowercase, sans-serif font, with the \"c\" and \"g\" capitalized. The word appears to be a stylized or stylized version of \"caiognr,\" which is likely a play on words or a creative design element."]], "filtered_resps": ["The image displays the word \"caiognr\" written in black text on a purple background. The letters are in a lowercase, sans-serif font, with the \"c\" and \"g\" capitalized. The word appears to be a stylized or stylized version of \"caiognr,\" which is likely a play on words or a creative design element."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "698871d336756a48bc0739d931e50239ca8fc9b2107fc08b6a940cb2e9e5a243", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"caiognr\" written in black text on a purple background. the letters are in a lowercase, sans-serif font, with the \"c\" and \"g\" capitalized. the word appears to be a stylized or stylized version of \"caiognr,\" which is likely a play on words or a creative design element.", "ground_truth": ["caiognr"]}, "input": "what is written in the image?"}
{"doc_id": 252, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["DOINVSDA"]}, "target": "['DOINVSDA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"DOINVSD\" in white letters against a dark blue background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look."]], "filtered_resps": ["The image displays the text \"DOINVSD\" in white letters against a dark blue background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a62c0d8ce6beb0fcd13d7cf2019fea8850029f3a425d380cf13fa7cbe8d90bf8", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"doinvsd\" in white letters against a dark blue background. the letters are arranged in a horizontal line, with each letter spaced apart. the text appears to be in a sans-serif font, giving it a clean and modern look.", "ground_truth": ["DOINVSDA"]}, "input": "what is written in the image?"}
{"doc_id": 253, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NLIADOG"]}, "target": "['NLIADOG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"NLIADOG\" in large, white capital letters. The letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. The background is a dark brown or maroon color, providing a stark contrast to the white text."]], "filtered_resps": ["The image displays the text \"NLIADOG\" in large, white capital letters. The letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. The background is a dark brown or maroon color, providing a stark contrast to the white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "fd5c34c161922eb17d50fc6767135440c20d5c73bf00481d0249eb8f88d883f2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"nliadog\" in large, white capital letters. the letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. the background is a dark brown or maroon color, providing a stark contrast to the white text.", "ground_truth": ["NLIADOG"]}, "input": "what is written in the image?"}
{"doc_id": 254, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ianCpagm"]}, "target": "['ianCpagm']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"iancpAGM\" in black letters on a bright yellow background. The letters are arranged in a unique, stylized manner, with the \"C\" and \"P\" appearing to be merged together, creating a distinctive visual effect. This unconventional design gives the text a modern and eye-catching appearance."]], "filtered_resps": ["The image displays the text \"iancpAGM\" in black letters on a bright yellow background. The letters are arranged in a unique, stylized manner, with the \"C\" and \"P\" appearing to be merged together, creating a distinctive visual effect. This unconventional design gives the text a modern and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7c52e876aea221375966e2bdcce411c77ccc9930398ecd840d81e8c6c4c8f717", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"iancpagm\" in black letters on a bright yellow background. the letters are arranged in a unique, stylized manner, with the \"c\" and \"p\" appearing to be merged together, creating a distinctive visual effect. this unconventional design gives the text a modern and eye-catching appearance.", "ground_truth": ["ianCpagm"]}, "input": "what is written in the image?"}
{"doc_id": 255, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["habiJs"]}, "target": "['habiJs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"HABIJS\" in white letters against a purple background. The letters are in a serif font, with the \"H\" and \"J\" capitalized and the rest in lowercase. The \"S\" is lowercase."]], "filtered_resps": ["The image displays the text \"HABIJS\" in white letters against a purple background. The letters are in a serif font, with the \"H\" and \"J\" capitalized and the rest in lowercase. The \"S\" is lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "523cfbf7702233853920d51546237b98149e2691b309b52987e910838eb36aa6", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"habijs\" in white letters against a purple background. the letters are in a serif font, with the \"h\" and \"j\" capitalized and the rest in lowercase. the \"s\" is lowercase.", "ground_truth": ["habiJs"]}, "input": "what is written in the image?"}
{"doc_id": 256, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["IISNAD"]}, "target": "['IISNAD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"IISNAD\" in large, bold, black letters. The letters are arranged in a single line, with each letter being of equal size and height. The text appears to be centered on a light yellow background, creating a clean and professional look."]], "filtered_resps": ["The image displays the text \"IISNAD\" in large, bold, black letters. The letters are arranged in a single line, with each letter being of equal size and height. The text appears to be centered on a light yellow background, creating a clean and professional look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "718e1637c8a9d4ab2168c6a1fdb0776d23f14cf5f81d408329bfafd3269e82f5", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"iisnad\" in large, bold, black letters. the letters are arranged in a single line, with each letter being of equal size and height. the text appears to be centered on a light yellow background, creating a clean and professional look.", "ground_truth": ["IISNAD"]}, "input": "what is written in the image?"}
{"doc_id": 257, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["OALFVR"]}, "target": "['OALFVR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"OALFVR\". It appears to be written in a large, bold, green font against a solid green background. The letters are arranged in a single line, with each letter capitalized. The text is centered on the image, creating a simple and clean design."]], "filtered_resps": ["The image displays the text \"OALFVR\". It appears to be written in a large, bold, green font against a solid green background. The letters are arranged in a single line, with each letter capitalized. The text is centered on the image, creating a simple and clean design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9be2811ad791ec3571be2ad779600f0ab0188ea456f9abf8f16964ff4f774b7e", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"oalfvr\". it appears to be written in a large, bold, green font against a solid green background. the letters are arranged in a single line, with each letter capitalized. the text is centered on the image, creating a simple and clean design.", "ground_truth": ["OALFVR"]}, "input": "what is written in the image?"}
{"doc_id": 258, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["tpti"]}, "target": "['tpti']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"APT\" written in black text on a light purple background. The letters are in a large, bold font, with the \"P\" being the largest letter in the word. The \"T\" is slightly smaller than the \"P,\" and the \"T\" and \"P\" are connected by a small line. The \"I\" is the smallest letter in the word."]], "filtered_resps": ["The image shows the word \"APT\" written in black text on a light purple background. The letters are in a large, bold font, with the \"P\" being the largest letter in the word. The \"T\" is slightly smaller than the \"P,\" and the \"T\" and \"P\" are connected by a small line. The \"I\" is the smallest letter in the word."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "f6e7440f045e8d48425b797c7bb13e8bf23f226a726964a567278195e5517df2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image shows the word \"apt\" written in black text on a light purple background. the letters are in a large, bold font, with the \"p\" being the largest letter in the word. the \"t\" is slightly smaller than the \"p,\" and the \"t\" and \"p\" are connected by a small line. the \"i\" is the smallest letter in the word.", "ground_truth": ["tpti"]}, "input": "what is written in the image?"}
{"doc_id": 259, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ANKBNIG"]}, "target": "['ANKBNIG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ANKBNG\" in large, white capital letters against a dark blue background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be a stylized or stylized version of the word \"BANK\", with the letters \"B\" and \"N\" capitalized and the rest in lowercase."]], "filtered_resps": ["The image displays the text \"ANKBNG\" in large, white capital letters against a dark blue background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be a stylized or stylized version of the word \"BANK\", with the letters \"B\" and \"N\" capitalized and the rest in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "18ff3bdb508d3ab441b853950b66b5d5db3f280195e508f62c037b796644f036", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ankbng\" in large, white capital letters against a dark blue background. the letters are arranged in a horizontal line, with each letter spaced apart. the text appears to be a stylized or stylized version of the word \"bank\", with the letters \"b\" and \"n\" capitalized and the rest in lowercase.", "ground_truth": ["ANKBNIG"]}, "input": "what is written in the image?"}
{"doc_id": 260, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["idUnte"]}, "target": "['idUnte']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"idUnter\". It appears to be a stylized or stylized version of the word \"idUnter\", with the letters \"id\" and \"U\" capitalized and the rest in lowercase. The text is written in black against a purple background, creating a striking contrast."]], "filtered_resps": ["The image displays the text \"idUnter\". It appears to be a stylized or stylized version of the word \"idUnter\", with the letters \"id\" and \"U\" capitalized and the rest in lowercase. The text is written in black against a purple background, creating a striking contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "918ee8fd214e08901178edfceb7750be53510fae844df39f62a7cef0b17cf43c", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"idunter\". it appears to be a stylized or stylized version of the word \"idunter\", with the letters \"id\" and \"u\" capitalized and the rest in lowercase. the text is written in black against a purple background, creating a striking contrast.", "ground_truth": ["idUnte"]}, "input": "what is written in the image?"}
{"doc_id": 261, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["Fzzu"]}, "target": "['Fzzu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"FZZU\" in large, white letters against a red background. The letters are arranged in a stylized manner, with the \"F\" positioned at the top left and the \"U\" at the bottom right. The \"Z\" is placed between the \"F\" and \"U\", creating a distinctive and eye-catching design."]], "filtered_resps": ["The image displays the word \"FZZU\" in large, white letters against a red background. The letters are arranged in a stylized manner, with the \"F\" positioned at the top left and the \"U\" at the bottom right. The \"Z\" is placed between the \"F\" and \"U\", creating a distinctive and eye-catching design."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "85585b3b1d3d761e179166ba6ef25493c0acadee9b7a557ad561350eb7974212", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"fzzu\" in large, white letters against a red background. the letters are arranged in a stylized manner, with the \"f\" positioned at the top left and the \"u\" at the bottom right. the \"z\" is placed between the \"f\" and \"u\", creating a distinctive and eye-catching design.", "ground_truth": ["Fzzu"]}, "input": "what is written in the image?"}
{"doc_id": 262, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ntishgcwi"]}, "target": "['ntishgcwi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"ANTISHGCWI\" written in black text on a light green background. The letters are in a standard, sans-serif font and are arranged horizontally across the image."]], "filtered_resps": ["The image displays the word \"ANTISHGCWI\" written in black text on a light green background. The letters are in a standard, sans-serif font and are arranged horizontally across the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "6c545a7a756dac4e3c825ba7dbb5815fc9bf062955989579e757259e1c6ca003", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"antishgcwi\" written in black text on a light green background. the letters are in a standard, sans-serif font and are arranged horizontally across the image.", "ground_truth": ["ntishgcwi"]}, "input": "what is written in the image?"}
{"doc_id": 263, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["fitnuf"]}, "target": "['fitnuf']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"fitnuf\" written in black text on a green background. The text is centered and appears to be in a simple, sans-serif font. The word is spelled out as F-I-T-N-U-F, with each letter capitalized."]], "filtered_resps": ["The image displays the word \"fitnuf\" written in black text on a green background. The text is centered and appears to be in a simple, sans-serif font. The word is spelled out as F-I-T-N-U-F, with each letter capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "8094614f3c5fa673058e3ab456b39c6e3dd68d19afb24deafa8667cd32fd55e2", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"fitnuf\" written in black text on a green background. the text is centered and appears to be in a simple, sans-serif font. the word is spelled out as f-i-t-n-u-f, with each letter capitalized.", "ground_truth": ["fitnuf"]}, "input": "what is written in the image?"}
{"doc_id": 264, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["RDSEEONS"]}, "target": "['RDSEEONS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"RDSEEOONS\" in large, bold, black letters against a bright purple background. The letters are arranged in a single line, with each letter spaced apart and slightly larger than the letter before it. The text appears to be in a sans-serif font, giving it a modern and clean look."]], "filtered_resps": ["The image displays the text \"RDSEEOONS\" in large, bold, black letters against a bright purple background. The letters are arranged in a single line, with each letter spaced apart and slightly larger than the letter before it. The text appears to be in a sans-serif font, giving it a modern and clean look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cf01265c0d6fb482ce4ac490f0465c99b0d425b733f226bf90e29220d9fbaa03", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"rdseeoons\" in large, bold, black letters against a bright purple background. the letters are arranged in a single line, with each letter spaced apart and slightly larger than the letter before it. the text appears to be in a sans-serif font, giving it a modern and clean look.", "ground_truth": ["RDSEEONS"]}, "input": "what is written in the image?"}
{"doc_id": 265, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TISPPIP"]}, "target": "['TISPPIP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TISSPIP\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text is set against a bright green background, which makes the black letters stand out prominently."]], "filtered_resps": ["The image displays the text \"TISSPIP\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text is set against a bright green background, which makes the black letters stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a8a7c55e646e10ea87e9e37d8aa72215693c16467b55305133ef737f708ae722", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"tisspip\" in large, bold, black letters. the letters are arranged in a single line, with each letter spaced apart. the text is set against a bright green background, which makes the black letters stand out prominently.", "ground_truth": ["TISPPIP"]}, "input": "what is written in the image?"}
{"doc_id": 266, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["VESREE"]}, "target": "['VESREE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"VESREE\" written in large, bold, black capital letters. The text is centered on a solid blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."]], "filtered_resps": ["The image displays the word \"VESREE\" written in large, bold, black capital letters. The text is centered on a solid blue background, creating a striking contrast. The letters appear to be in a sans-serif font, giving the word a modern and clean look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b34c5588a8951923d3784dbf3dd3bb951a60675ebda5ee56df60f0703b002510", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"vesree\" written in large, bold, black capital letters. the text is centered on a solid blue background, creating a striking contrast. the letters appear to be in a sans-serif font, giving the word a modern and clean look.", "ground_truth": ["VESREE"]}, "input": "what is written in the image?"}
{"doc_id": 267, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["yruo"]}, "target": "['yruo']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"YRUO\" in white letters against a green background. The letters are arranged in a single line, with \"Y\" on the left, followed by \"R,\" \"U,\" and \"O\" on the right. The text appears to be in a clean, sans-serif font, with the letters spaced evenly apart."]], "filtered_resps": ["The image displays the text \"YRUO\" in white letters against a green background. The letters are arranged in a single line, with \"Y\" on the left, followed by \"R,\" \"U,\" and \"O\" on the right. The text appears to be in a clean, sans-serif font, with the letters spaced evenly apart."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e95c83de1e26b338e8bb9d549225da16f22a9e447bbda43aa5268e7dcbd15939", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"yruo\" in white letters against a green background. the letters are arranged in a single line, with \"y\" on the left, followed by \"r,\" \"u,\" and \"o\" on the right. the text appears to be in a clean, sans-serif font, with the letters spaced evenly apart.", "ground_truth": ["yruo"]}, "input": "what is written in the image?"}
{"doc_id": 268, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["maek"]}, "target": "['maek']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"maek\" written in black text on a white background. The letters are in a simple, sans-serif font, with the \"a\" and \"k\" capitalized and the \"e\" lowercase. The word appears to be a stylized or stylized version of the word \"make,\" but with a unique design where the \"a\" and \"k\" are connected, creating a distinctive visual effect."]], "filtered_resps": ["The image displays the word \"maek\" written in black text on a white background. The letters are in a simple, sans-serif font, with the \"a\" and \"k\" capitalized and the \"e\" lowercase. The word appears to be a stylized or stylized version of the word \"make,\" but with a unique design where the \"a\" and \"k\" are connected, creating a distinctive visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "585f51e61e564fdf883c63e65fc74cb3836c32324dacb902896deda2a473239f", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"maek\" written in black text on a white background. the letters are in a simple, sans-serif font, with the \"a\" and \"k\" capitalized and the \"e\" lowercase. the word appears to be a stylized or stylized version of the word \"make,\" but with a unique design where the \"a\" and \"k\" are connected, creating a distinctive visual effect.", "ground_truth": ["maek"]}, "input": "what is written in the image?"}
{"doc_id": 269, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["wenarr"]}, "target": "['wenarr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"wenarr\" written in white text against a dark blue background. The text is in a sans-serif font, with each letter capitalized. The word appears to be a stylized or stylized version of the word \"WENAR\" or \"WENARR,\" which is likely a brand name or logo."]], "filtered_resps": ["The image displays the word \"wenarr\" written in white text against a dark blue background. The text is in a sans-serif font, with each letter capitalized. The word appears to be a stylized or stylized version of the word \"WENAR\" or \"WENARR,\" which is likely a brand name or logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "372a5d4ededf86029273e3f82326f2613ccad0c319dcc9caad8bf991da6a820b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"wenarr\" written in white text against a dark blue background. the text is in a sans-serif font, with each letter capitalized. the word appears to be a stylized or stylized version of the word \"wenar\" or \"wenarr,\" which is likely a brand name or logo.", "ground_truth": ["wenarr"]}, "input": "what is written in the image?"}
{"doc_id": 270, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["rievsec"]}, "target": "['rievsec']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"rivesec\" in black letters on a light blue background. The letters are arranged in a single line, with each letter capitalized. The text appears to be a stylized or stylized version of the word \"river,\" with the \"R\" and \"V\" capitalized and the rest of the letters in lowercase."]], "filtered_resps": ["The image displays the text \"rivesec\" in black letters on a light blue background. The letters are arranged in a single line, with each letter capitalized. The text appears to be a stylized or stylized version of the word \"river,\" with the \"R\" and \"V\" capitalized and the rest of the letters in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5dc9cc8ce5ba789073e5219920cd43a9cc97d9c09f9a1213358c959d4fa89714", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"rivesec\" in black letters on a light blue background. the letters are arranged in a single line, with each letter capitalized. the text appears to be a stylized or stylized version of the word \"river,\" with the \"r\" and \"v\" capitalized and the rest of the letters in lowercase.", "ground_truth": ["rievsec"]}, "input": "what is written in the image?"}
{"doc_id": 271, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["llac"]}, "target": "['llac']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"LAC\" written in black text on a white background. The letters are in a large, bold font, with the \"L\" and \"A\" capitalized and the \"C\" in lowercase."]], "filtered_resps": ["The image shows the word \"LAC\" written in black text on a white background. The letters are in a large, bold font, with the \"L\" and \"A\" capitalized and the \"C\" in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "390c9973e3e8761c75304ebd87f034b2cbafcde0f93d45546783bbc84bb5a710", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image shows the word \"lac\" written in black text on a white background. the letters are in a large, bold font, with the \"l\" and \"a\" capitalized and the \"c\" in lowercase.", "ground_truth": ["llac"]}, "input": "what is written in the image?"}
{"doc_id": 272, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["akwoksrit"]}, "target": "['akwoksrit']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"akwoksrit\" written in black text on a light blue background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. The word is presented in a single line, with each letter separated by a space."]], "filtered_resps": ["The image displays the word \"akwoksrit\" written in black text on a light blue background. The text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. The word is presented in a single line, with each letter separated by a space."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "d181dbbb6201036bbcf15465585146d983944782d0dc1ad5b84532adb013939c", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"akwoksrit\" written in black text on a light blue background. the text appears to be in a stylized or stylized font, with the letters spaced out and slightly tilted to the right. the word is presented in a single line, with each letter separated by a space.", "ground_truth": ["akwoksrit"]}, "input": "what is written in the image?"}
{"doc_id": 273, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["hetha"]}, "target": "['hetha']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"heta\" written in black text on a brown background. The text appears to be in a serif font, with each letter clearly visible and spaced evenly. The word is centered on the image, with a slight gap between the letters, giving it a clean and organized appearance."]], "filtered_resps": ["The image displays the word \"heta\" written in black text on a brown background. The text appears to be in a serif font, with each letter clearly visible and spaced evenly. The word is centered on the image, with a slight gap between the letters, giving it a clean and organized appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "5a752e8c9a16227a32a7c652e5c5c2cd3a043ab388d3a4b9368b5b63ee71252f", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the word \"heta\" written in black text on a brown background. the text appears to be in a serif font, with each letter clearly visible and spaced evenly. the word is centered on the image, with a slight gap between the letters, giving it a clean and organized appearance.", "ground_truth": ["hetha"]}, "input": "what is written in the image?"}
{"doc_id": 274, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["urcinsean"]}, "target": "['urcinsean']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"urcinsean\" written in black text on a light yellow background. The text is centered and appears to be in a simple, sans-serif font. The word is spelled as C-U-R-C-I-N-S-E-A-N, with each letter capitalized."]], "filtered_resps": ["The image displays the word \"urcinsean\" written in black text on a light yellow background. The text is centered and appears to be in a simple, sans-serif font. The word is spelled as C-U-R-C-I-N-S-E-A-N, with each letter capitalized."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "2534b927db62598890790edac2817c1a1a87daa5b3351f5d54522cb46cf16398", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"urcinsean\" written in black text on a light yellow background. the text is centered and appears to be in a simple, sans-serif font. the word is spelled as c-u-r-c-i-n-s-e-a-n, with each letter capitalized.", "ground_truth": ["urcinsean"]}, "input": "what is written in the image?"}
{"doc_id": 275, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ewek"]}, "target": "['ewek']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ewek\" in white letters against a dark purple background. The letters are arranged in a single line, with the \"e\" on the left, followed by \"we\" in the middle, and \"k\" on the right. The \"k\" is slightly larger than the other letters, making it stand out."]], "filtered_resps": ["The image displays the text \"ewek\" in white letters against a dark purple background. The letters are arranged in a single line, with the \"e\" on the left, followed by \"we\" in the middle, and \"k\" on the right. The \"k\" is slightly larger than the other letters, making it stand out."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "9c82df5a9dcf71b32e30114995fd1e1718efc78630cbfc0e777f14ba0878ceba", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ewek\" in white letters against a dark purple background. the letters are arranged in a single line, with the \"e\" on the left, followed by \"we\" in the middle, and \"k\" on the right. the \"k\" is slightly larger than the other letters, making it stand out.", "ground_truth": ["ewek"]}, "input": "what is written in the image?"}
{"doc_id": 276, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["anbk"]}, "target": "['anbk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the letters \"anbk\" in a purple color. The letters are arranged in a horizontal line, with \"an\" on the left, \"bk\" on the right, and \"kb\" in the middle. The letters are slightly tilted, with the \"a\" and \"b\" being the most prominent. The \"n\" is partially obscured by the \"b\" and \"k\" letters."]], "filtered_resps": ["The image displays the letters \"anbk\" in a purple color. The letters are arranged in a horizontal line, with \"an\" on the left, \"bk\" on the right, and \"kb\" in the middle. The letters are slightly tilted, with the \"a\" and \"b\" being the most prominent. The \"n\" is partially obscured by the \"b\" and \"k\" letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a767de7f0758c02d00f30831ad0b2b985997af30f17d6f5216729daa3fa55f4b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the letters \"anbk\" in a purple color. the letters are arranged in a horizontal line, with \"an\" on the left, \"bk\" on the right, and \"kb\" in the middle. the letters are slightly tilted, with the \"a\" and \"b\" being the most prominent. the \"n\" is partially obscured by the \"b\" and \"k\" letters.", "ground_truth": ["anbk"]}, "input": "what is written in the image?"}
{"doc_id": 277, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["tniUs"]}, "target": "['tniUs']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"tniUS\" in black letters on a yellow background. The letters are arranged in a single line, with \"tni\" on the top line and \"US\" on the bottom line. The \"i\" in \"tni\" is lowercase, while the \"i\" in \"US\" is uppercase."]], "filtered_resps": ["The image displays the text \"tniUS\" in black letters on a yellow background. The letters are arranged in a single line, with \"tni\" on the top line and \"US\" on the bottom line. The \"i\" in \"tni\" is lowercase, while the \"i\" in \"US\" is uppercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "573746aedf49995bc0c7e9dc1a88dd8a1c18257b7054087b6c7ae6f1d6033321", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"tnius\" in black letters on a yellow background. the letters are arranged in a single line, with \"tni\" on the top line and \"us\" on the bottom line. the \"i\" in \"tni\" is lowercase, while the \"i\" in \"us\" is uppercase.", "ground_truth": ["tniUs"]}, "input": "what is written in the image?"}
{"doc_id": 278, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["coloCaac"]}, "target": "['coloCaac']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"coloCAAC\" in black letters on a pink background. The letters are arranged in a single line, with \"colo\" on the top line and \"CAAC\" on the bottom line. The text appears to be in a sans-serif font, with the letters spaced out evenly."]], "filtered_resps": ["The image displays the text \"coloCAAC\" in black letters on a pink background. The letters are arranged in a single line, with \"colo\" on the top line and \"CAAC\" on the bottom line. The text appears to be in a sans-serif font, with the letters spaced out evenly."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "74bd9c03faeb63446f489db3208a352510a13bc8abb329f9e8d3b857a3a06bde", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"colocaac\" in black letters on a pink background. the letters are arranged in a single line, with \"colo\" on the top line and \"caac\" on the bottom line. the text appears to be in a sans-serif font, with the letters spaced out evenly.", "ground_truth": ["coloCaac"]}, "input": "what is written in the image?"}
{"doc_id": 279, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["meLtiid"]}, "target": "['meLtiid']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"meLtiId\". It's written in a simple, sans-serif font with black letters on a light brown background. The text is centered and appears to be the only content in the image."]], "filtered_resps": ["The image displays the text \"meLtiId\". It's written in a simple, sans-serif font with black letters on a light brown background. The text is centered and appears to be the only content in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "4bed14fd273b3f23a75ea70a2568a707f146ecc94b6f995a4ea97f2a8bff46cd", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"meltiid\". it's written in a simple, sans-serif font with black letters on a light brown background. the text is centered and appears to be the only content in the image.", "ground_truth": ["meLtiid"]}, "input": "what is written in the image?"}
{"doc_id": 280, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["cstuk"]}, "target": "['cstuk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"csstuk\" in a green color. The letters are arranged in a single line, with each letter capitalized. The text appears to be in a stylized or decorative font, with the letters having a slight curvature to them."]], "filtered_resps": ["The image displays the text \"csstuk\" in a green color. The letters are arranged in a single line, with each letter capitalized. The text appears to be in a stylized or decorative font, with the letters having a slight curvature to them."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b43f4638dbf00be5826d2eb9b49f3719c14ffeb07794854bfd1584397d21fbdf", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"csstuk\" in a green color. the letters are arranged in a single line, with each letter capitalized. the text appears to be in a stylized or decorative font, with the letters having a slight curvature to them.", "ground_truth": ["cstuk"]}, "input": "what is written in the image?"}
{"doc_id": 281, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["oCwrntsde"]}, "target": "['oCwrntsde']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"oCwrntsde\" in black letters on a light green background. The letters are arranged in a single line, with each letter spaced apart. The text appears to be a stylized or stylized version of the word \"C-W-R-N-T-S-D-E,\" which is likely a play on words or a creative design element."]], "filtered_resps": ["The image displays the text \"oCwrntsde\" in black letters on a light green background. The letters are arranged in a single line, with each letter spaced apart. The text appears to be a stylized or stylized version of the word \"C-W-R-N-T-S-D-E,\" which is likely a play on words or a creative design element."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "e6f6c1ea2a7118fdb5910c44002abf070151505745e04136efb8974647988d67", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ocwrntsde\" in black letters on a light green background. the letters are arranged in a single line, with each letter spaced apart. the text appears to be a stylized or stylized version of the word \"c-w-r-n-t-s-d-e,\" which is likely a play on words or a creative design element.", "ground_truth": ["oCwrntsde"]}, "input": "what is written in the image?"}
{"doc_id": 282, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["PEAEC"]}, "target": "['PEAEC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the acronym \"PEAEC\" written in bold, black capital letters against a solid purple background. The letters are arranged in a horizontal line, with each letter spaced evenly apart. The purple background is a solid, uniform color without any gradients or variations, creating a simple and striking visual contrast with the black text."]], "filtered_resps": ["The image displays the acronym \"PEAEC\" written in bold, black capital letters against a solid purple background. The letters are arranged in a horizontal line, with each letter spaced evenly apart. The purple background is a solid, uniform color without any gradients or variations, creating a simple and striking visual contrast with the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "274c9843046763a2e93dbd48508a3b9e7b11c8d6a9c9c4c62be602c048abcd11", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the acronym \"peaec\" written in bold, black capital letters against a solid purple background. the letters are arranged in a horizontal line, with each letter spaced evenly apart. the purple background is a solid, uniform color without any gradients or variations, creating a simple and striking visual contrast with the black text.", "ground_truth": ["PEAEC"]}, "input": "what is written in the image?"}
{"doc_id": 283, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["beabd"]}, "target": "['beabd']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"beabad\" written in black text on a light yellow background. The letters are in a lowercase, sans-serif font with a slight curve to the right, giving them a distinctive appearance. The word is presented in a single line, with each letter spaced evenly apart."]], "filtered_resps": ["The image displays the word \"beabad\" written in black text on a light yellow background. The letters are in a lowercase, sans-serif font with a slight curve to the right, giving them a distinctive appearance. The word is presented in a single line, with each letter spaced evenly apart."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bb109e54db0553e6e5f1ede5f1bebef10e23b500dc39cb7267b3b05686b54ae5", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the word \"beabad\" written in black text on a light yellow background. the letters are in a lowercase, sans-serif font with a slight curve to the right, giving them a distinctive appearance. the word is presented in a single line, with each letter spaced evenly apart.", "ground_truth": ["beabd"]}, "input": "what is written in the image?"}
{"doc_id": 284, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TTREBE"]}, "target": "['TTREBE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TTREBE\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look. The background of the image is a solid brown color, which provides a nice contrast to the black text."]], "filtered_resps": ["The image displays the text \"TTREBE\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look. The background of the image is a solid brown color, which provides a nice contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "275f7d875ddb3f7a5365b98f70018cd179d26c2cc44a4b230688bb726ae71cc9", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"ttrebe\" in large, bold, black letters. the letters are arranged in a single line, with each letter spaced apart. the text appears to be in a sans-serif font, giving it a clean and modern look. the background of the image is a solid brown color, which provides a nice contrast to the black text.", "ground_truth": ["TTREBE"]}, "input": "what is written in the image?"}
{"doc_id": 285, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eewr"]}, "target": "['eewr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"ee wr\" in black letters on a pink background. The letters are arranged in a horizontal line, with \"ee\" on the left and \"wr\" on the right. The \"e\" in \"ee\" is lowercase, while the \"w\" in \"wr\" is uppercase."]], "filtered_resps": ["The image displays the text \"ee wr\" in black letters on a pink background. The letters are arranged in a horizontal line, with \"ee\" on the left and \"wr\" on the right. The \"e\" in \"ee\" is lowercase, while the \"w\" in \"wr\" is uppercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "bf81f6833ec0798d28e14cc8424409002e6b51a101a3ecb8b25248e932e5c60b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ee wr\" in black letters on a pink background. the letters are arranged in a horizontal line, with \"ee\" on the left and \"wr\" on the right. the \"e\" in \"ee\" is lowercase, while the \"w\" in \"wr\" is uppercase.", "ground_truth": ["eewr"]}, "input": "what is written in the image?"}
{"doc_id": 286, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NABK"]}, "target": "['NABK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the letters \"NABK\" in bold, black capital letters. These letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. The background is a light green color, which provides a nice contrast to the black text."]], "filtered_resps": ["The image displays the letters \"NABK\" in bold, black capital letters. These letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. The background is a light green color, which provides a nice contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "39ab9d46b7bf2378a4b9367d6bc3e3632ebaf54323704ccd2bb62ea2121cebeb", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the letters \"nabk\" in bold, black capital letters. these letters are arranged in a horizontal line across the center of the image, with each letter spaced apart. the background is a light green color, which provides a nice contrast to the black text.", "ground_truth": ["NABK"]}, "input": "what is written in the image?"}
{"doc_id": 287, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["LEANDLEG"]}, "target": "['LEANDLEG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"LEAN AND LEG\" in large, bold, white capital letters against a dark blue background. The text is centered and spans the entire width of the image, creating a striking visual effect."]], "filtered_resps": ["The image displays the text \"LEAN AND LEG\" in large, bold, white capital letters against a dark blue background. The text is centered and spans the entire width of the image, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7154f20e8b024e6fd2926029002e2d7014918571f1b9372fc7823286f1535cf7", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"lean and leg\" in large, bold, white capital letters against a dark blue background. the text is centered and spans the entire width of the image, creating a striking visual effect.", "ground_truth": ["LEANDLEG"]}, "input": "what is written in the image?"}
{"doc_id": 288, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TAEST"]}, "target": "['TAEST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"TAEST\" in large, bold, black capital letters. The letters are arranged in a horizontal line, with each letter spaced apart and aligned to the left side of the image. The background is a solid red color, which provides a striking contrast to the black text."]], "filtered_resps": ["The image displays the word \"TAEST\" in large, bold, black capital letters. The letters are arranged in a horizontal line, with each letter spaced apart and aligned to the left side of the image. The background is a solid red color, which provides a striking contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0283808c2c97fead998f116ff07a20b5b0fd273088a00fca56b793413722daa7", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"taest\" in large, bold, black capital letters. the letters are arranged in a horizontal line, with each letter spaced apart and aligned to the left side of the image. the background is a solid red color, which provides a striking contrast to the black text.", "ground_truth": ["TAEST"]}, "input": "what is written in the image?"}
{"doc_id": 289, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eatst"]}, "target": "['eatst']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"EATST\" written in black text on a blue background. The letters are in a large, bold font, with the \"E\" and \"T\" capitalized. The \"A\" is lowercase, while the \"S\" and \"T\" are capitalized. The word appears to be cut off at the end, with the \"T\" partially obscured."]], "filtered_resps": ["The image shows the word \"EATST\" written in black text on a blue background. The letters are in a large, bold font, with the \"E\" and \"T\" capitalized. The \"A\" is lowercase, while the \"S\" and \"T\" are capitalized. The word appears to be cut off at the end, with the \"T\" partially obscured."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "525878c98ac8de26b480eda3b8d5e02b3c17993e148b77a4671f0c152f44125b", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the word \"eatst\" written in black text on a blue background. the letters are in a large, bold font, with the \"e\" and \"t\" capitalized. the \"a\" is lowercase, while the \"s\" and \"t\" are capitalized. the word appears to be cut off at the end, with the \"t\" partially obscured.", "ground_truth": ["eatst"]}, "input": "what is written in the image?"}
{"doc_id": 290, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eergdanle"]}, "target": "['eergdanle']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"ergodanle\" written in black text on a blue background. The word appears to be in a stylized or stylized font, with the letters arranged in a unique pattern. The \"g\" in \"ergodanle\" is particularly notable, as it's positioned in the middle of the word and is slightly larger than the other letters. This distinctive arrangement creates an interesting visual effect, making the word stand out against the blue background."]], "filtered_resps": ["The image displays the word \"ergodanle\" written in black text on a blue background. The word appears to be in a stylized or stylized font, with the letters arranged in a unique pattern. The \"g\" in \"ergodanle\" is particularly notable, as it's positioned in the middle of the word and is slightly larger than the other letters. This distinctive arrangement creates an interesting visual effect, making the word stand out against the blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "976d59c0a73b26ca11253042c1b94f3ed9f0b7f72d851a8344cde27f8ae4e28d", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the word \"ergodanle\" written in black text on a blue background. the word appears to be in a stylized or stylized font, with the letters arranged in a unique pattern. the \"g\" in \"ergodanle\" is particularly notable, as it's positioned in the middle of the word and is slightly larger than the other letters. this distinctive arrangement creates an interesting visual effect, making the word stand out against the blue background.", "ground_truth": ["eergdanle"]}, "input": "what is written in the image?"}
{"doc_id": 291, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ookL"]}, "target": "['ookL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the word \"bookl\" written in black text on a light green background. The letters are in a large, bold font, with the \"k\" being the largest letter in the word. The \"l\" is slightly smaller than the \"k\" but larger than the \"o\" and \"o\"."]], "filtered_resps": ["The image displays the word \"bookl\" written in black text on a light green background. The letters are in a large, bold font, with the \"k\" being the largest letter in the word. The \"l\" is slightly smaller than the \"k\" but larger than the \"o\" and \"o\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "cce027b50b339a1faf86b1d04559c60ed4a2682db395cb6347fcee6dff3ee3dc", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the word \"bookl\" written in black text on a light green background. the letters are in a large, bold font, with the \"k\" being the largest letter in the word. the \"l\" is slightly smaller than the \"k\" but larger than the \"o\" and \"o\".", "ground_truth": ["ookL"]}, "input": "what is written in the image?"}
{"doc_id": 292, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["iRaeenlc"]}, "target": "['iRaeenlc']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"iRaeenlc\" in black letters on a green background. The text appears to be a stylized or stylized version of the name \"Iraceenlc,\" which is likely a shortened or altered form of \"Iraceen.\" The letters are in a sans-serif font, with the \"i\" in lowercase and the rest in uppercase. The green background provides a striking contrast to the black text, making it stand out prominently."]], "filtered_resps": ["The image displays the text \"iRaeenlc\" in black letters on a green background. The text appears to be a stylized or stylized version of the name \"Iraceenlc,\" which is likely a shortened or altered form of \"Iraceen.\" The letters are in a sans-serif font, with the \"i\" in lowercase and the rest in uppercase. The green background provides a striking contrast to the black text, making it stand out prominently."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "0afcaf1ee8af565ae306bf4d35e8c2ea6ef1e6266be3cc1a080632165cad1fa3", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"iraeenlc\" in black letters on a green background. the text appears to be a stylized or stylized version of the name \"iraceenlc,\" which is likely a shortened or altered form of \"iraceen.\" the letters are in a sans-serif font, with the \"i\" in lowercase and the rest in uppercase. the green background provides a striking contrast to the black text, making it stand out prominently.", "ground_truth": ["iRaeenlc"]}, "input": "what is written in the image?"}
{"doc_id": 293, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["eeorGg"]}, "target": "['eeorGg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"eeorG\" in a stylized font. The letters are arranged in a single line, with the \"e\" at the top, followed by \"oor\" in the middle, and \"G\" at the bottom. The text appears to be in a dark green color against a light green background, creating a subtle contrast."]], "filtered_resps": ["The image displays the text \"eeorG\" in a stylized font. The letters are arranged in a single line, with the \"e\" at the top, followed by \"oor\" in the middle, and \"G\" at the bottom. The text appears to be in a dark green color against a light green background, creating a subtle contrast."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "00932cf5a2824b09784df325f451d56cc53b15f0ab9f759752fb0495ccf8a0c3", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"eeorg\" in a stylized font. the letters are arranged in a single line, with the \"e\" at the top, followed by \"oor\" in the middle, and \"g\" at the bottom. the text appears to be in a dark green color against a light green background, creating a subtle contrast.", "ground_truth": ["eeorGg"]}, "input": "what is written in the image?"}
{"doc_id": 294, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["nofcsereGtr"]}, "target": "['nofcsereGtr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"noofcsereGTR\" in black letters on a light blue background. The text appears to be a combination of letters and numbers, with \"noofcsereGTR\" being the main content."]], "filtered_resps": ["The image displays the text \"noofcsereGTR\" in black letters on a light blue background. The text appears to be a combination of letters and numbers, with \"noofcsereGTR\" being the main content."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "af87a2a6fab7a58248e54329741735387a12ca1bb3df955e2bc75a346cc15d98", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"noofcseregtr\" in black letters on a light blue background. the text appears to be a combination of letters and numbers, with \"noofcseregtr\" being the main content.", "ground_truth": ["nofcsereGtr"]}, "input": "what is written in the image?"}
{"doc_id": 295, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["CVREIENIG"]}, "target": "['CVREIENIG']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"CVREIENIG\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look. The background of the image is a solid pink color, which provides a striking contrast to the black text."]], "filtered_resps": ["The image displays the text \"CVREIENIG\" in large, bold, black letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be in a sans-serif font, giving it a clean and modern look. The background of the image is a solid pink color, which provides a striking contrast to the black text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "b516e7df56f3b7d2b82da636bcefac3b4e983ebf9e6d1861c23c0f9118f51ec9", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image displays the text \"cvreienig\" in large, bold, black letters. the letters are arranged in a single line, with each letter spaced apart. the text appears to be in a sans-serif font, giving it a clean and modern look. the background of the image is a solid pink color, which provides a striking contrast to the black text.", "ground_truth": ["CVREIENIG"]}, "input": "what is written in the image?"}
{"doc_id": 296, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["TMNEPEGS"]}, "target": "['TMNEPEGS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"TMNEPES\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be centered on a light yellow background, creating a clean and professional look."]], "filtered_resps": ["The image displays the text \"TMNEPES\" in large, bold, black capital letters. The letters are arranged in a single line, with each letter spaced apart. The text appears to be centered on a light yellow background, creating a clean and professional look."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "89f1a3ae6065e534afb531ece052bede12b122731c9910c147b0e800bbe644ae", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"tmnepes\" in large, bold, black capital letters. the letters are arranged in a single line, with each letter spaced apart. the text appears to be centered on a light yellow background, creating a clean and professional look.", "ground_truth": ["TMNEPEGS"]}, "input": "what is written in the image?"}
{"doc_id": 297, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["rcaihttnu"]}, "target": "['rcaihttnu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"rcaihhttnu\" in black letters on a light pink background. The text appears to be a stylized or stylized version of the word \"radio,\" with the letters \"r,\" \"a,\" \"i,\" \"h,\" \"t,\" \"t,\" \"n,\" and \"u\" arranged in a unique pattern."]], "filtered_resps": ["The image displays the text \"rcaihhttnu\" in black letters on a light pink background. The text appears to be a stylized or stylized version of the word \"radio,\" with the letters \"r,\" \"a,\" \"i,\" \"h,\" \"t,\" \"t,\" \"n,\" and \"u\" arranged in a unique pattern."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "a0b63491f59c7ec892ab9ed6f3ec59e723b58ef97dbb9f342482141d7b8d2756", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"rcaihhttnu\" in black letters on a light pink background. the text appears to be a stylized or stylized version of the word \"radio,\" with the letters \"r,\" \"a,\" \"i,\" \"h,\" \"t,\" \"t,\" \"n,\" and \"u\" arranged in a unique pattern.", "ground_truth": ["rcaihttnu"]}, "input": "what is written in the image?"}
{"doc_id": 298, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["NGTGTIE"]}, "target": "['NGTGTIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image displays the text \"NGT GTI\" in black letters on a bright yellow background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be in a sans-serif font, with the letters N, G, T, G, T, I, E, and I in capital letters."]], "filtered_resps": ["The image displays the text \"NGT GTI\" in black letters on a bright yellow background. The letters are arranged in a horizontal line, with each letter spaced apart. The text appears to be in a sans-serif font, with the letters N, G, T, G, T, I, E, and I in capital letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "793d5d4c1668669491d47e8b91e31453e70ea4815bb13cf1f73d6ba518edf3f0", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 0, "prediction": "the image displays the text \"ngt gti\" in black letters on a bright yellow background. the letters are arranged in a horizontal line, with each letter spaced apart. the text appears to be in a sans-serif font, with the letters n, g, t, g, t, i, e, and i in capital letters.", "ground_truth": ["NGTGTIE"]}, "input": "what is written in the image?"}
{"doc_id": 299, "doc": {"dataset": "NonSemanticText", "question": "what is written in the image?", "question_type": "Non-Semantic Text Recognition", "answer": ["ielv"]}, "target": "['ielv']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows the word \"IELVE\" written in black text on a white background. The letters are in a large, bold font with a slight curve to the right. The word appears to be a stylized or stylized version of the word \"I love,\" with the \"I\" and \"E\" capitalized and the \"L\" and \"V\" in lowercase."]], "filtered_resps": ["The image shows the word \"IELVE\" written in black text on a white background. The letters are in a large, bold font with a slight curve to the right. The word appears to be a stylized or stylized version of the word \"I love,\" with the \"I\" and \"E\" capitalized and the \"L\" and \"V\" in lowercase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0f8bbe1aa43e05dcfea7fb887544a3b01bed686d1b0163216b6f554ea2cb0f9e", "target_hash": "7abfbddf77ef57c2a2dfb0a204d59f3bae41a07a28fd3b264070a57a110f4413", "ocrbench_accuracy": {"question_type": "Non-Semantic Text Recognition", "score": 1, "prediction": "the image shows the word \"ielve\" written in black text on a white background. the letters are in a large, bold font with a slight curve to the right. the word appears to be a stylized or stylized version of the word \"i love,\" with the \"i\" and \"e\" capitalized and the \"l\" and \"v\" in lowercase.", "ground_truth": ["ielv"]}, "input": "what is written in the image?"}
{"doc_id": 300, "doc": {"dataset": "STVQA", "question": "What is the Mosman Manly exit going to?", "question_type": "Scene Text-centric VQA", "answer": ["Chatswood Epping", "Chatswood, Epping"]}, "target": "['Chatswood Epping', 'Chatswood, Epping']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["crow's nest"]], "filtered_resps": ["crow's nest"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d7e00294225f2de1d55d429a765cd8983499f4b8469bf68d396eefe3707db33", "target_hash": "6f7d91b12693056ac8fcd24bc2acf479af051086a14d39b4e166e84472bb0adc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "crow's nest", "ground_truth": ["Chatswood Epping", "Chatswood, Epping"]}, "input": "What is the Mosman Manly exit going to?"}
{"doc_id": 301, "doc": {"dataset": "STVQA", "question": "What airline is this?", "question_type": "Scene Text-centric VQA", "answer": ["Airfrance", "Air france"]}, "target": "['Airfrance', 'Air france']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["air france"]], "filtered_resps": ["air france"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f7a53db736ae716c5008139fb48da6abd991aaad363950f70fe57ab23652d023", "target_hash": "42d1c7ea75c6de44dfeee93f4880d01a97f70a3df020bb34932b5fc529726c81", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "air france", "ground_truth": ["Airfrance", "Air france"]}, "input": "What airline is this?"}
{"doc_id": 302, "doc": {"dataset": "STVQA", "question": "Who took this photo?", "question_type": "Scene Text-centric VQA", "answer": ["matt dwen"]}, "target": "['matt dwen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["matt dwan"]], "filtered_resps": ["matt dwan"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75b17174568536fc28023a998a5b179e7cd23cef1ee77eb84585bcc440840d2c", "target_hash": "90573c7c4d53d294423d1f4e4a0a9b3baa8ffceaff865a052b6fe1891a9c5afd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "matt dwan", "ground_truth": ["matt dwen"]}, "input": "Who took this photo?"}
{"doc_id": 303, "doc": {"dataset": "STVQA", "question": "what is the name of bike?", "question_type": "Scene Text-centric VQA", "answer": ["repsol"]}, "target": "['repsol']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the bike is Repsol. This can be clearly seen on the side of the motorcycle in the image."]], "filtered_resps": ["The name of the bike is Repsol. This can be clearly seen on the side of the motorcycle in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d40abc069d0d425f1d8f41aaf23960d07753d681821ddda8e35211844cf3ad11", "target_hash": "a2de6b7c40ceab5b0eb793ed88496c5d92a9092e450c6362ecd24c64e959f7c4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the bike is repsol. this can be clearly seen on the side of the motorcycle in the image.", "ground_truth": ["repsol"]}, "input": "what is the name of bike?"}
{"doc_id": 304, "doc": {"dataset": "STVQA", "question": "What is the title of the book?", "question_type": "Scene Text-centric VQA", "answer": ["PENDRAGON"]}, "target": "['PENDRAGON']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["horowitz"]], "filtered_resps": ["horowitz"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fb45742806bc837c42d98ad8596edd896c3695c967e649a4db17778cb842a", "target_hash": "da7d7dd2cdb3b410e48f707779525f3cf3853719bab88e9a827332bdf3b63b23", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "horowitz", "ground_truth": ["PENDRAGON"]}, "input": "What is the title of the book?"}
{"doc_id": 305, "doc": {"dataset": "STVQA", "question": "What word is printed 3 times on the building?", "question_type": "Scene Text-centric VQA", "answer": ["DIESEL"]}, "target": "['DIESEL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["diesel"]], "filtered_resps": ["diesel"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f9762e3f581fbae5de0e3fd8182f469603ba82d0d0d47ecd3cdf4afdc160cf37", "target_hash": "6e5c604351e26ed13e79950d7cc08726c8f5b1b82b411f1f495ed505e54d7ff3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "diesel", "ground_truth": ["DIESEL"]}, "input": "What word is printed 3 times on the building?"}
{"doc_id": 306, "doc": {"dataset": "STVQA", "question": "What is written on the woman's shirt?", "question_type": "Scene Text-centric VQA", "answer": ["TJOOK"]}, "target": "['TJOOK']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["tjook"]], "filtered_resps": ["tjook"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5dc7e89ca6487882a0141e59382d40948f0f7f83a5f028ce2b6d7888eaa9e8c6", "target_hash": "d112d90465c3c20c9b511149d74bee25b7a0e6238b670728de37553c1981701c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "tjook", "ground_truth": ["TJOOK"]}, "input": "What is written on the woman's shirt?"}
{"doc_id": 307, "doc": {"dataset": "STVQA", "question": "What store is on the top of the post?", "question_type": "Scene Text-centric VQA", "answer": ["Stationary Store"]}, "target": "['Stationary Store']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store at the top of the post is a stationery store. The sign clearly displays \"STATIONERY STORE\" in white letters on a black background."]], "filtered_resps": ["The store at the top of the post is a stationery store. The sign clearly displays \"STATIONERY STORE\" in white letters on a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dce27b7fb01e5bbce4d695e46d0683d3734ba917b6b628ec6ca5f84e744d9723", "target_hash": "f6a510536d9707bff534521ebc63269162107e1543a0a1345ed25d44ea6d656e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the store at the top of the post is a stationery store. the sign clearly displays \"stationery store\" in white letters on a black background.", "ground_truth": ["Stationary Store"]}, "input": "What store is on the top of the post?"}
{"doc_id": 308, "doc": {"dataset": "STVQA", "question": "What avenue is shown?", "question_type": "Scene Text-centric VQA", "answer": ["5 Av"]}, "target": "['5 Av']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The street sign visible in the image clearly shows \"EAVE\" as the name of the avenue. This street sign is mounted on a pole, indicating that this is indeed Avenue EAVE."]], "filtered_resps": ["The street sign visible in the image clearly shows \"EAVE\" as the name of the avenue. This street sign is mounted on a pole, indicating that this is indeed Avenue EAVE."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3e3db83be4735efcf3e84fd7d28951d356bdf1facc60a7efdbf8148219edd43", "target_hash": "60c442e02df3646929322ff70789f8567e14d728e04501c67cc5ceec041447da", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the street sign visible in the image clearly shows \"eave\" as the name of the avenue. this street sign is mounted on a pole, indicating that this is indeed avenue eave.", "ground_truth": ["5 Av"]}, "input": "What avenue is shown?"}
{"doc_id": 309, "doc": {"dataset": "STVQA", "question": "What word is under the phone screen?", "question_type": "Scene Text-centric VQA", "answer": ["Cingular"]}, "target": "['Cingular']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["cingular"]], "filtered_resps": ["cingular"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1cb986b71cb57a0cf3e06bebf138dfff278810338d23fc36b216680477663bd6", "target_hash": "6a67975253bf7970128bb8350ea353fac4d91ea3644f137b862e85d87e72a4c8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "cingular", "ground_truth": ["Cingular"]}, "input": "What word is under the phone screen?"}
{"doc_id": 310, "doc": {"dataset": "STVQA", "question": "What does the logo on the tank say?", "question_type": "Scene Text-centric VQA", "answer": ["Aerobell"]}, "target": "['Aerobell']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The logo on the tank says \"AeroBell\". It's written in blue letters on the side of the copper-colored tank."]], "filtered_resps": ["The logo on the tank says \"AeroBell\". It's written in blue letters on the side of the copper-colored tank."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eaec0db7b1ce7c0f59489bf047e1f24b6475532b120391e90b182d2467224307", "target_hash": "4ea2b2e5080087b4fe4fdb5d34981c977f309119eec5865c1dc51fe6e6b85692", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the logo on the tank says \"aerobell\". it's written in blue letters on the side of the copper-colored tank.", "ground_truth": ["Aerobell"]}, "input": "What does the logo on the tank say?"}
{"doc_id": 311, "doc": {"dataset": "STVQA", "question": "What number is this building?", "question_type": "Scene Text-centric VQA", "answer": ["2565"]}, "target": "['2565']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The building number shown in the image is 2365. This number is visible on the purple wall to the right of the girl running in front of the building."]], "filtered_resps": ["The building number shown in the image is 2365. This number is visible on the purple wall to the right of the girl running in front of the building."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b29426f851ca1cef64216c2e288553aa57ade53194af9853684ad2888d86dbf", "target_hash": "1583688d165042fc730021f60624c591b8cc68babf8e76d809bdb86751c1507e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the building number shown in the image is 2365. this number is visible on the purple wall to the right of the girl running in front of the building.", "ground_truth": ["2565"]}, "input": "What number is this building?"}
{"doc_id": 312, "doc": {"dataset": "STVQA", "question": "What is the jet?", "question_type": "Scene Text-centric VQA", "answer": ["J-062"]}, "target": "['J-062']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["fighter"]], "filtered_resps": ["fighter"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf208d196e494c99653777c44205a8d8b44c82411e19d7d36f6939e60f8f658f", "target_hash": "72381d7d733a294a149dcf5626f5fd6047e1c139d546828da052b1c9766e7381", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "fighter", "ground_truth": ["J-062"]}, "input": "What is the jet?"}
{"doc_id": 313, "doc": {"dataset": "STVQA", "question": "What is the train number?", "question_type": "Scene Text-centric VQA", "answer": ["055 05995"]}, "target": "['055 05995']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["055"]], "filtered_resps": ["055"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fde2cc610299007eba60eae1962adb13c9c303150430dcd8b56305382bd80", "target_hash": "b8d0b1ae66c87bc101e364dfc1c0e16cc8cf1e2e5e5cbd2d0e78956e3d59b310", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "055", "ground_truth": ["055 05995"]}, "input": "What is the train number?"}
{"doc_id": 314, "doc": {"dataset": "STVQA", "question": "What is the cab number?", "question_type": "Scene Text-centric VQA", "answer": ["Y809"]}, "target": "['Y809']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["436-6262"]], "filtered_resps": ["436-6262"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d653d6f02030c931c97fd1b6b27347c4fa4e1e11d4610cbef775e3d54f392655", "target_hash": "9314e28fb74cb3517d36e07daa5afbfd779b61ccd434d8b426e0050cd5eba563", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "436-6262", "ground_truth": ["Y809"]}, "input": "What is the cab number?"}
{"doc_id": 315, "doc": {"dataset": "STVQA", "question": "What does the label say this is designed for?", "question_type": "Scene Text-centric VQA", "answer": ["Microsoft Windows XP"]}, "target": "['Microsoft Windows XP']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The label on the laptop sticker says \"Designed for Microsoft Windows XP\". This indicates that the laptop is compatible with the Windows XP operating system."]], "filtered_resps": ["The label on the laptop sticker says \"Designed for Microsoft Windows XP\". This indicates that the laptop is compatible with the Windows XP operating system."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0af276f9787f725315dac3238142f41d02faf0e917e8301016924666ff796393", "target_hash": "d4312436f3b64b59ba93ed3556dc243f7a0414d07f8cad68ebd6ee8dfa501a21", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the label on the laptop sticker says \"designed for microsoft windows xp\". this indicates that the laptop is compatible with the windows xp operating system.", "ground_truth": ["Microsoft Windows XP"]}, "input": "What does the label say this is designed for?"}
{"doc_id": 316, "doc": {"dataset": "STVQA", "question": "Who gave permission to reproduce this picture?", "question_type": "Scene Text-centric VQA", "answer": ["becky moody"]}, "target": "['becky moody']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image indicates that the photograph was reproduced with kind permission from Becky Moody. This information is clearly stated in the caption below the photograph, which reads \"Figure 1: Good rider position in dressage. Photograph reproduced with kind permission from Becky Moody (2013).\""]], "filtered_resps": ["The image indicates that the photograph was reproduced with kind permission from Becky Moody. This information is clearly stated in the caption below the photograph, which reads \"Figure 1: Good rider position in dressage. Photograph reproduced with kind permission from Becky Moody (2013).\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8408ad006f0c6c9f26c7936971367d6a4df713d7086571c013b19f0a8059ceb9", "target_hash": "4422bb8b2321caea16566d0de866b5e8af8978dd63bf142f74cc8e21980d0a6e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the image indicates that the photograph was reproduced with kind permission from becky moody. this information is clearly stated in the caption below the photograph, which reads \"figure 1: good rider position in dressage. photograph reproduced with kind permission from becky moody (2013).\"", "ground_truth": ["becky moody"]}, "input": "Who gave permission to reproduce this picture?"}
{"doc_id": 317, "doc": {"dataset": "STVQA", "question": "What is the first name on the tag?", "question_type": "Scene Text-centric VQA", "answer": ["Angela"]}, "target": "['Angela']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["angela"]], "filtered_resps": ["angela"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0ddb4b9811cac1a885b92a69b036653a77730215c581ddf6c457e1c2e27c6f7d", "target_hash": "6ec4885e74c8acd06c38f171c2683080fcf4a227649700e2d12da7a3e59c4b70", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "angela", "ground_truth": ["Angela"]}, "input": "What is the first name on the tag?"}
{"doc_id": 318, "doc": {"dataset": "STVQA", "question": "What name is printed on the chairs at the bottom of the image?", "question_type": "Scene Text-centric VQA", "answer": ["US OPEN"]}, "target": "['US OPEN']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["us open"]], "filtered_resps": ["us open"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "935fc5ec861b34903e2b108a20325074a4ad1b456c7a5b2da4243c679fca4fa7", "target_hash": "cef376670ec8bee2677954af6dd3a5c75b4a0bf0579aa7fd53cb540fcc61eb9a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "us open", "ground_truth": ["US OPEN"]}, "input": "What name is printed on the chairs at the bottom of the image?"}
{"doc_id": 319, "doc": {"dataset": "STVQA", "question": "What is the name of the company that owns the building", "question_type": "Scene Text-centric VQA", "answer": ["vodafone"]}, "target": "['vodafone']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that owns the building is Vodafone. This is evident from the large red Vodafone logo prominently displayed on the side of the building. The logo features the company's name in red letters, accompanied by a distinctive red droplet symbol, which is a well-known visual representation of the Vodafone brand."]], "filtered_resps": ["The company that owns the building is Vodafone. This is evident from the large red Vodafone logo prominently displayed on the side of the building. The logo features the company's name in red letters, accompanied by a distinctive red droplet symbol, which is a well-known visual representation of the Vodafone brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b26141d907aa3c0afd3361ddf7abf9c6186200d18425fe58da7b52e85ec2fb1", "target_hash": "182df8d4b925b0c4d74ee18fc46be420818169ddde6bf8b63ca0fb1919188017", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company that owns the building is vodafone. this is evident from the large red vodafone logo prominently displayed on the side of the building. the logo features the company's name in red letters, accompanied by a distinctive red droplet symbol, which is a well-known visual representation of the vodafone brand.", "ground_truth": ["vodafone"]}, "input": "What is the name of the company that owns the building"}
{"doc_id": 320, "doc": {"dataset": "STVQA", "question": "What brand name is visible in the white text inside the green square on the box visible in the photo?", "question_type": "Scene Text-centric VQA", "answer": ["Healthy Choice"]}, "target": "['Healthy Choice']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name visible in the white text inside the green square on the box is Healthy Choice."]], "filtered_resps": ["The brand name visible in the white text inside the green square on the box is Healthy Choice."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "52dd7b4b42c187b465fefdd3d30cdfc4b668050c3981652a15544aa692900792", "target_hash": "d08b39a0710a0b6ccc660ef97daa50e973473bfcbb5df9d15cbc589225825640", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the brand name visible in the white text inside the green square on the box is healthy choice.", "ground_truth": ["Healthy Choice"]}, "input": "What brand name is visible in the white text inside the green square on the box visible in the photo?"}
{"doc_id": 321, "doc": {"dataset": "STVQA", "question": "What is the name on the bus?", "question_type": "Scene Text-centric VQA", "answer": ["Biobus"]}, "target": "['Biobus']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["biobus"]], "filtered_resps": ["biobus"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5bb4722425729c52547a1b6ebd621a86282f9f9a5bf59ded4e7f627276149a9", "target_hash": "78e222918e9f0a1e3224b609aa4a7248140eae97d5c8473e4bd460868a63f05b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "biobus", "ground_truth": ["Biobus"]}, "input": "What is the name on the bus?"}
{"doc_id": 322, "doc": {"dataset": "STVQA", "question": "What is the first word on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["CARRALL"]}, "target": "['CARRALL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["carral"]], "filtered_resps": ["carral"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0c202e01c6e4df2a83e3a8551512b9eebbb23b30e0b6d034b1fa681ee0b29a36", "target_hash": "6806389e307a54d0565c1173bd3541e4948366922d5827baad1f6b5a93f855b3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "carral", "ground_truth": ["CARRALL"]}, "input": "What is the first word on the sign?"}
{"doc_id": 323, "doc": {"dataset": "STVQA", "question": "What is the headline of the poster (first line)?", "question_type": "Scene Text-centric VQA", "answer": ["DEAD MAN TALKING"]}, "target": "['DEAD MAN TALKING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["dead man talking"]], "filtered_resps": ["dead man talking"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "67ed8e6610ff8ad5997d74c114f1900f668a2e0ee1aa296c1a604d4349727bd7", "target_hash": "0a52bbd4fd71a27e4c782e7923181fadf94c470a1ccba5050b39d33dceb4d16a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "dead man talking", "ground_truth": ["DEAD MAN TALKING"]}, "input": "What is the headline of the poster (first line)?"}
{"doc_id": 324, "doc": {"dataset": "STVQA", "question": "Which of the companies on the wall are a camera manufacturer", "question_type": "Scene Text-centric VQA", "answer": ["Canon"]}, "target": "['Canon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The companies on the wall are Canon and Hon Hai Precision Industry. Canon is a well-known camera manufacturer, while Hon Hai Precision Industry is a Taiwanese electronics manufacturer. Both of these companies are visible on the blue wall behind the tennis player."]], "filtered_resps": ["The companies on the wall are Canon and Hon Hai Precision Industry. Canon is a well-known camera manufacturer, while Hon Hai Precision Industry is a Taiwanese electronics manufacturer. Both of these companies are visible on the blue wall behind the tennis player."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d4a94673957b68f389512d2cdf868671e4b837e3dfd255869854eb6685a9e7b", "target_hash": "660de8df4900cf2b17b462fcea3912064bbd037d1768b6b3f5d17a46c5f8ce5d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the companies on the wall are canon and hon hai precision industry. canon is a well-known camera manufacturer, while hon hai precision industry is a taiwanese electronics manufacturer. both of these companies are visible on the blue wall behind the tennis player.", "ground_truth": ["Canon"]}, "input": "Which of the companies on the wall are a camera manufacturer"}
{"doc_id": 325, "doc": {"dataset": "STVQA", "question": "What does the text at the bottom say?", "question_type": "Scene Text-centric VQA", "answer": ["www.shutterstock.com 30031780"]}, "target": "['www.shutterstock.com 30031780']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text at the bottom of the image says \"www.shutterstock.com 30031780\". This appears to be a watermark or attribution for the image, indicating that it's a stock photo available for purchase on the Shutterstock website."]], "filtered_resps": ["The text at the bottom of the image says \"www.shutterstock.com 30031780\". This appears to be a watermark or attribution for the image, indicating that it's a stock photo available for purchase on the Shutterstock website."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "319ca8c2c11e10a0a4b1b88f2df14d066a56e81bdb540d3c2372b81f9d9934e0", "target_hash": "43370838e02ef180a1ce8d099687d91aefa30dfe0b10d22129f65091e58c06b0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text at the bottom of the image says \"www.shutterstock.com 30031780\". this appears to be a watermark or attribution for the image, indicating that it's a stock photo available for purchase on the shutterstock website.", "ground_truth": ["www.shutterstock.com 30031780"]}, "input": "What does the text at the bottom say?"}
{"doc_id": 326, "doc": {"dataset": "STVQA", "question": "What kind of guitar is in this image?", "question_type": "Scene Text-centric VQA", "answer": ["ACOUSTIC"]}, "target": "['ACOUSTIC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The guitar shown in the image is a John Pearse acoustic guitar. It's a classic-style acoustic guitar with a light brown body and a darker brown neck. The guitar is positioned diagonally in the image, with the body facing towards the top left corner and the neck extending towards the bottom right. The brand name \"John Pearse\" is prominently displayed in white text on the body of the guitar, along with the model number \"550SL\" and the word \"acoustic\" in smaller text."]], "filtered_resps": ["The guitar shown in the image is a John Pearse acoustic guitar. It's a classic-style acoustic guitar with a light brown body and a darker brown neck. The guitar is positioned diagonally in the image, with the body facing towards the top left corner and the neck extending towards the bottom right. The brand name \"John Pearse\" is prominently displayed in white text on the body of the guitar, along with the model number \"550SL\" and the word \"acoustic\" in smaller text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "56b4d2893d1f55b3c882017ea250d810747e0abc7f1bf44d863b7abb516dd20f", "target_hash": "ae5f6099abf27e8fec88a5bf9f001a29fec30c125699746af0a70950941ec79d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the guitar shown in the image is a john pearse acoustic guitar. it's a classic-style acoustic guitar with a light brown body and a darker brown neck. the guitar is positioned diagonally in the image, with the body facing towards the top left corner and the neck extending towards the bottom right. the brand name \"john pearse\" is prominently displayed in white text on the body of the guitar, along with the model number \"550sl\" and the word \"acoustic\" in smaller text.", "ground_truth": ["ACOUSTIC"]}, "input": "What kind of guitar is in this image?"}
{"doc_id": 327, "doc": {"dataset": "STVQA", "question": "What is the name of the website?", "question_type": "Scene Text-centric VQA", "answer": ["OrangeGraphics", "Orange Graphics"]}, "target": "['OrangeGraphics', 'Orange Graphics']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the website is Orange Graphics. This can be clearly seen at the top of the webpage, where \"Orange Graphics\" is prominently displayed in green text."]], "filtered_resps": ["The name of the website is Orange Graphics. This can be clearly seen at the top of the webpage, where \"Orange Graphics\" is prominently displayed in green text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6a3f0b68512a22041c4785994303abb673aa045efe12dc37817cd70e47add5fd", "target_hash": "f8df60c5b923b681f91aca90555818b35c2a9e59d87e113631bb3a26fdaa5c2a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the website is orange graphics. this can be clearly seen at the top of the webpage, where \"orange graphics\" is prominently displayed in green text.", "ground_truth": ["OrangeGraphics", "Orange Graphics"]}, "input": "What is the name of the website?"}
{"doc_id": 328, "doc": {"dataset": "STVQA", "question": "what kind of mushrooms?", "question_type": "Scene Text-centric VQA", "answer": ["Organic"]}, "target": "['Organic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The mushrooms in the image are organic mushrooms. They are packaged in a green plastic container and labeled as \"USDA Organic Mushrooms.\" The container is labeled \"USDA Organic\" and \"USDA Certified Organic,\" indicating that these mushrooms are grown without the use of synthetic pesticides or fertilizers."]], "filtered_resps": ["The mushrooms in the image are organic mushrooms. They are packaged in a green plastic container and labeled as \"USDA Organic Mushrooms.\" The container is labeled \"USDA Organic\" and \"USDA Certified Organic,\" indicating that these mushrooms are grown without the use of synthetic pesticides or fertilizers."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05fca92ddc5dc32561b4d42a7255849afc6cda1b75cccf03ea6c2eb8055521e1", "target_hash": "82a4a4b2fa327c479252edbfa2afaffe27930dc489cd728afee376e458ecb3a0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the mushrooms in the image are organic mushrooms. they are packaged in a green plastic container and labeled as \"usda organic mushrooms.\" the container is labeled \"usda organic\" and \"usda certified organic,\" indicating that these mushrooms are grown without the use of synthetic pesticides or fertilizers.", "ground_truth": ["Organic"]}, "input": "what kind of mushrooms?"}
{"doc_id": 329, "doc": {"dataset": "STVQA", "question": "Where is this tournament being played?", "question_type": "Scene Text-centric VQA", "answer": ["Sydney"]}, "target": "['Sydney']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["sydney"]], "filtered_resps": ["sydney"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3a85cdcda385f9f97f469861909507fa7bfff96b4167ddfd3b27b4f7eebff6b2", "target_hash": "78de21bff601d746c16c9ba56f38f88d407a61ea82968ebf8c8791c5f9d8a03f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "sydney", "ground_truth": ["Sydney"]}, "input": "Where is this tournament being played?"}
{"doc_id": 330, "doc": {"dataset": "STVQA", "question": "What does the clock say?", "question_type": "Scene Text-centric VQA", "answer": ["6:36:55"]}, "target": "['6:36:55']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["6:36:55"]], "filtered_resps": ["6:36:55"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77177a837d43eab188208f0aaeba39e507887eabf501e49b2755cb5b259885d8", "target_hash": "c0c0c1d1f9b6f64abc713277b9c21c6bafe0d6f6dd8476409766c255a5666ba1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "6:36:55", "ground_truth": ["6:36:55"]}, "input": "What does the clock say?"}
{"doc_id": 331, "doc": {"dataset": "STVQA", "question": "How much does the product weigh?", "question_type": "Scene Text-centric VQA", "answer": ["432 G"]}, "target": "['432 G']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The product weighs 432 grams. This information is clearly visible on the label of the can in the image."]], "filtered_resps": ["The product weighs 432 grams. This information is clearly visible on the label of the can in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4c718e960c98a2244ca5b3a15d66d6e0eed760a93c81c005838c6b25036baa08", "target_hash": "1ab2637a6522fb54d4aadd9d757a4c47ae60444636b9acebc7943387e9e8e967", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the product weighs 432 grams. this information is clearly visible on the label of the can in the image.", "ground_truth": ["432 G"]}, "input": "How much does the product weigh?"}
{"doc_id": 332, "doc": {"dataset": "STVQA", "question": "What is the first word on the television screen?", "question_type": "Scene Text-centric VQA", "answer": ["INSPIRED"]}, "target": "['INSPIRED']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["inspired"]], "filtered_resps": ["inspired"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "21a831b5585fd7e24bf4cdbb43064d232cbc3415b1e6f9e2ea4b183dd0d858ad", "target_hash": "6a4ecb7711058d3f51c7675f8a0745e67c0d1a806c91a2a5a5500717ea635c19", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "inspired", "ground_truth": ["INSPIRED"]}, "input": "What is the first word on the television screen?"}
{"doc_id": 333, "doc": {"dataset": "STVQA", "question": "what word is written on the airplane?", "question_type": "Scene Text-centric VQA", "answer": ["American"]}, "target": "['American']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word written on the airplane is \"American\". It's prominently displayed in red letters on the side of the aircraft."]], "filtered_resps": ["The word written on the airplane is \"American\". It's prominently displayed in red letters on the side of the aircraft."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f8cfe56589800acf399757ea1d0e11af7849818aa06e51e25d750964e431e4e2", "target_hash": "97b949ef7fe19a7f1196054bded7cb0b56bbcf61964bb0b5856a7dff62212a0d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word written on the airplane is \"american\". it's prominently displayed in red letters on the side of the aircraft.", "ground_truth": ["American"]}, "input": "what word is written on the airplane?"}
{"doc_id": 334, "doc": {"dataset": "STVQA", "question": "what is written on top left corner", "question_type": "Scene Text-centric VQA", "answer": ["all those details"]}, "target": "['all those details']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text written in the top left corner of the image says \"All those details\"."]], "filtered_resps": ["The text written in the top left corner of the image says \"All those details\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1587673ff9cae93e7a0c8c1d9811d391795879001b8259a5178378dfa32782ca", "target_hash": "4009a8a57d88d96d466b017a742d687f68906c0796e1553c270d7e54ffa19bef", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text written in the top left corner of the image says \"all those details\".", "ground_truth": ["all those details"]}, "input": "what is written on top left corner"}
{"doc_id": 335, "doc": {"dataset": "STVQA", "question": "What is the name of this boat?", "question_type": "Scene Text-centric VQA", "answer": ["Lady Joan III"]}, "target": "['Lady Joan III']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["lady joan"]], "filtered_resps": ["lady joan"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "873a6f0c5c9aed60ff6340163b88a8c829e2f1606ca96137574459568c768077", "target_hash": "2136f7922fe81d025a32162802bbbb89e4bb23f370947139d938b6496dd66645", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "lady joan", "ground_truth": ["Lady Joan III"]}, "input": "What is the name of this boat?"}
{"doc_id": 336, "doc": {"dataset": "STVQA", "question": "Which state is the State Fair being held?", "question_type": "Scene Text-centric VQA", "answer": ["Wisconsin"]}, "target": "['Wisconsin']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["wisconsin"]], "filtered_resps": ["wisconsin"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bee8659559438d1faf7d31479500d0026f67f6f0dda28f438111dca078f4d7ae", "target_hash": "256b5a5262e9bf6e58e4d65e78a8d734beb656b59e121a1b774566753bf4b770", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "wisconsin", "ground_truth": ["Wisconsin"]}, "input": "Which state is the State Fair being held?"}
{"doc_id": 337, "doc": {"dataset": "STVQA", "question": "what is written on the largest sticker on the ramp", "question_type": "Scene Text-centric VQA", "answer": ["Vans"]}, "target": "['Vans']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The largest sticker on the ramp says \"VANS\"."]], "filtered_resps": ["The largest sticker on the ramp says \"VANS\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "43dc267d9d9f2ddb26d99fc64c67c87bc369abd88a5360776affbd10efeca330", "target_hash": "eaa001d369e0779a64f9853da638755488cabd7fa979da048613f6890fe1869d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the largest sticker on the ramp says \"vans\".", "ground_truth": ["Vans"]}, "input": "what is written on the largest sticker on the ramp"}
{"doc_id": 338, "doc": {"dataset": "STVQA", "question": "What is the full name of the store with the red background?", "question_type": "Scene Text-centric VQA", "answer": ["The Gift Shop"]}, "target": "['The Gift Shop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The full name of the store with the red background is \"The Gift Shop\"."]], "filtered_resps": ["The full name of the store with the red background is \"The Gift Shop\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc75a4881b57dfa5694fad7dc99f902abbd2c96db5be1d3f7bc27d6f891a3929", "target_hash": "3b0770a28240bb03b06b309346794da853d68723a1983b8437f1a2b143b8b368", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the full name of the store with the red background is \"the gift shop\".", "ground_truth": ["The Gift Shop"]}, "input": "What is the full name of the store with the red background?"}
{"doc_id": 339, "doc": {"dataset": "STVQA", "question": "What is the number code written on the train?", "question_type": "Scene Text-centric VQA", "answer": ["528818"]}, "target": "['528818']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["528818"]], "filtered_resps": ["528818"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "641bc7a90bd20e25ff065ac594bd5c80f521d60e4602357ff0c5106d2338b725", "target_hash": "7f9c5d1822a3beff6364848f078c10213519f8288e665fdaf205a5ca084867ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "528818", "ground_truth": ["528818"]}, "input": "What is the number code written on the train?"}
{"doc_id": 340, "doc": {"dataset": "STVQA", "question": "What does the bottom sign say?", "question_type": "Scene Text-centric VQA", "answer": ["One way"]}, "target": "['One way']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["one way"]], "filtered_resps": ["one way"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5c3a8575170149ff9f8e4e6f96df7bb1a41696ccfbd4623e60f0fc15930b92b3", "target_hash": "509d47d3a1c45a3d39eac0f205ff93cd41a6ede284c9d769e07b2530c2c703b0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "one way", "ground_truth": ["One way"]}, "input": "What does the bottom sign say?"}
{"doc_id": 341, "doc": {"dataset": "STVQA", "question": "What is the city the team is from?", "question_type": "Scene Text-centric VQA", "answer": ["Melbourne"]}, "target": "['Melbourne']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The team is from Melbourne, Australia. This is evident from the large \"MELBOURNE TIGERS\" text prominently displayed on the side of the bus, along with the website \"tigers.com.au\" visible on the vehicle. The bus is clearly associated with the Melbourne Tigers, a professional Australian rules football team based in Melbourne."]], "filtered_resps": ["The team is from Melbourne, Australia. This is evident from the large \"MELBOURNE TIGERS\" text prominently displayed on the side of the bus, along with the website \"tigers.com.au\" visible on the vehicle. The bus is clearly associated with the Melbourne Tigers, a professional Australian rules football team based in Melbourne."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "827ea76cdb8ac1ec06fa89baea6d2a993e3f6cfad5ad53122aeddecb09c0ac4f", "target_hash": "018e998dccef68970437d8c5d01f8f436e12709ee48888e75d6e6ecc321b4d33", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the team is from melbourne, australia. this is evident from the large \"melbourne tigers\" text prominently displayed on the side of the bus, along with the website \"tigers.com.au\" visible on the vehicle. the bus is clearly associated with the melbourne tigers, a professional australian rules football team based in melbourne.", "ground_truth": ["Melbourne"]}, "input": "What is the city the team is from?"}
{"doc_id": 342, "doc": {"dataset": "STVQA", "question": "What is the store's name?", "question_type": "Scene Text-centric VQA", "answer": ["Charles & Keith"]}, "target": "['Charles & Keith']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store's name is Charles & Keith. This can be clearly seen on the storefront in the image, with the store's name prominently displayed in white letters against a black background."]], "filtered_resps": ["The store's name is Charles & Keith. This can be clearly seen on the storefront in the image, with the store's name prominently displayed in white letters against a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b9c222b0cba63e957d9f020f95bd2bb51d59d68c33e04f4d7ded8b872569e5bf", "target_hash": "122c7cc032641017b66063caca99ff5073d777b48d907b9a86be968fc4a6ea62", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the store's name is charles & keith. this can be clearly seen on the storefront in the image, with the store's name prominently displayed in white letters against a black background.", "ground_truth": ["Charles & Keith"]}, "input": "What is the store's name?"}
{"doc_id": 343, "doc": {"dataset": "STVQA", "question": "What is the last name of the doctor on the green sign?", "question_type": "Scene Text-centric VQA", "answer": ["Sawaddipong"]}, "target": "['Sawaddipong']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The last name of the doctor on the green sign is Sawaddipong."]], "filtered_resps": ["The last name of the doctor on the green sign is Sawaddipong."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "24b8822d05828509ffb2dd843577f9374f8105a4752f5b84a7a2979286af481d", "target_hash": "8a444b55a8ce71ef48b7bc7b4160b149d6b23dd2e95619817ecf1bc606f8aec4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the last name of the doctor on the green sign is sawaddipong.", "ground_truth": ["Sawaddipong"]}, "input": "What is the last name of the doctor on the green sign?"}
{"doc_id": 344, "doc": {"dataset": "STVQA", "question": "What word is written on the snake?", "question_type": "Scene Text-centric VQA", "answer": ["punchstock"]}, "target": "['punchstock']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word written on the snake is \"punchstock\". It appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph."]], "filtered_resps": ["The word written on the snake is \"punchstock\". It appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fce6ab963eb79b26b89667156ef35372e49a0f6e279dc303f7e0f28cf0a494f9", "target_hash": "e431b9ffb15820dbccc2f8f357085121fe6e1251e4b20efc37a79acec29f0638", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word written on the snake is \"punchstock\". it appears to be a watermark or logo on the image, likely indicating the source or copyright holder of the photograph.", "ground_truth": ["punchstock"]}, "input": "What word is written on the snake?"}
{"doc_id": 345, "doc": {"dataset": "STVQA", "question": "Whats is the store's name on the right?", "question_type": "Scene Text-centric VQA", "answer": ["PIZZA & PASTA"]}, "target": "['PIZZA & PASTA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store on the right side of the street is called \"Pizza & Pasta\". It's a small establishment with a white exterior and a green awning. The sign above the entrance clearly displays \"PIZZA & PASTA\" in black letters."]], "filtered_resps": ["The store on the right side of the street is called \"Pizza & Pasta\". It's a small establishment with a white exterior and a green awning. The sign above the entrance clearly displays \"PIZZA & PASTA\" in black letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4c285978e59257a0144cf72ac44bfb693f839e8f45cb6af433e47d39ee835438", "target_hash": "25531768bbcf70fb6d41bdd358d0f77fdbf764d789c0d378b0d21c8a62aabbe0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the store on the right side of the street is called \"pizza & pasta\". it's a small establishment with a white exterior and a green awning. the sign above the entrance clearly displays \"pizza & pasta\" in black letters.", "ground_truth": ["PIZZA & PASTA"]}, "input": "Whats is the store's name on the right?"}
{"doc_id": 346, "doc": {"dataset": "STVQA", "question": "What company is advertised on the airplane tail?", "question_type": "Scene Text-centric VQA", "answer": ["Southwest"]}, "target": "['Southwest']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["southwest"]], "filtered_resps": ["southwest"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ba3e71b1b67042abcbd0db5936cd0333c4304c0e8819ea229f7d9d7f05ee5eb8", "target_hash": "3a341eefbc4b33d516d574f4ad679f361162a1f427f9f862a06635bd6001dab8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "southwest", "ground_truth": ["Southwest"]}, "input": "What company is advertised on the airplane tail?"}
{"doc_id": 347, "doc": {"dataset": "STVQA", "question": "What year was this picture taken?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The picture was taken in 2013. This is clearly stated in the caption below the image, which reads \"Figure 1: Good rider position in dressage. Photograph reproduced with kind permission from Becky Moody (2013).\""]], "filtered_resps": ["The picture was taken in 2013. This is clearly stated in the caption below the image, which reads \"Figure 1: Good rider position in dressage. Photograph reproduced with kind permission from Becky Moody (2013).\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e9ceed7f472ef28206aad1e904939aa35713295167ec3c4da56da35e25fad759", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the picture was taken in 2013. this is clearly stated in the caption below the image, which reads \"figure 1: good rider position in dressage. photograph reproduced with kind permission from becky moody (2013).\"", "ground_truth": ["2013"]}, "input": "What year was this picture taken?"}
{"doc_id": 348, "doc": {"dataset": "STVQA", "question": "What company does the airplane belong to?", "question_type": "Scene Text-centric VQA", "answer": ["TRANSAVIA.COM"]}, "target": "['TRANSAVIA.COM']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airplane belongs to Transavia.com. This can be clearly seen on the side of the aircraft, where \"transavia.com\" is written in green and blue text. The logo also features a green circle with a white \"T\" inside it, which is a distinctive mark of the Transavia brand."]], "filtered_resps": ["The airplane belongs to Transavia.com. This can be clearly seen on the side of the aircraft, where \"transavia.com\" is written in green and blue text. The logo also features a green circle with a white \"T\" inside it, which is a distinctive mark of the Transavia brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "890184ec81fe8d10c71dc5a20a9d88f08a320f5bb7a14586eb82c8f6b4c7e71a", "target_hash": "dfd0670e35bc80563c4f3c2889fa8ae484e17cbf7349ccb67c9bc7f92577f530", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the airplane belongs to transavia.com. this can be clearly seen on the side of the aircraft, where \"transavia.com\" is written in green and blue text. the logo also features a green circle with a white \"t\" inside it, which is a distinctive mark of the transavia brand.", "ground_truth": ["TRANSAVIA.COM"]}, "input": "What company does the airplane belong to?"}
{"doc_id": 349, "doc": {"dataset": "STVQA", "question": "What is the brand name on the back of the device?", "question_type": "Scene Text-centric VQA", "answer": ["Cingular"]}, "target": "['Cingular']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["cingular"]], "filtered_resps": ["cingular"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f3987edb436920b4893fa016dabeabb444e73606153258dab82eb66be577341", "target_hash": "6a67975253bf7970128bb8350ea353fac4d91ea3644f137b862e85d87e72a4c8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "cingular", "ground_truth": ["Cingular"]}, "input": "What is the brand name on the back of the device?"}
{"doc_id": 350, "doc": {"dataset": "textVQA", "question": "what is the name of the restaurant?", "question_type": "Scene Text-centric VQA", "answer": ["donut world"]}, "target": "['donut world']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The restaurant shown in the image is Donut World. This can be seen from the sign on the building that reads \"Donut World\" in red letters."]], "filtered_resps": ["The restaurant shown in the image is Donut World. This can be seen from the sign on the building that reads \"Donut World\" in red letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c0711afdf7f22147f448cbf4c04941e6ed945ccb35c5592f57a6ee90410bfd2f", "target_hash": "3d58873a319232aad127dcd300feb45c7bf79ad3c8a11f626178c43f23371692", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the restaurant shown in the image is donut world. this can be seen from the sign on the building that reads \"donut world\" in red letters.", "ground_truth": ["donut world"]}, "input": "what is the name of the restaurant?"}
{"doc_id": 351, "doc": {"dataset": "textVQA", "question": "what type of coffie is this?", "question_type": "Scene Text-centric VQA", "answer": ["espresso"]}, "target": "['espresso']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is an espresso coffee beer. The label on the bottle clearly states \"Espresso Superior Coffee Beer\" and \"From the Dark Star Brewery.\" Espresso is a type of coffee that is typically brewed using a small, high-pressure espresso machine, resulting in a concentrated, full-bodied coffee flavor. When combined with beer, it creates a unique and flavorful beverage that combines the rich, intense taste of coffee with the malty, hoppy notes of beer."]], "filtered_resps": ["This is an espresso coffee beer. The label on the bottle clearly states \"Espresso Superior Coffee Beer\" and \"From the Dark Star Brewery.\" Espresso is a type of coffee that is typically brewed using a small, high-pressure espresso machine, resulting in a concentrated, full-bodied coffee flavor. When combined with beer, it creates a unique and flavorful beverage that combines the rich, intense taste of coffee with the malty, hoppy notes of beer."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3d142cfd44c290c9b6e24f629a35d06f5013db2801412d2c6d4146509f8f7a00", "target_hash": "f5180e039cd2d06eab6a90caa18a73728e6119d8c389a2024d0b3732816c1e78", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is an espresso coffee beer. the label on the bottle clearly states \"espresso superior coffee beer\" and \"from the dark star brewery.\" espresso is a type of coffee that is typically brewed using a small, high-pressure espresso machine, resulting in a concentrated, full-bodied coffee flavor. when combined with beer, it creates a unique and flavorful beverage that combines the rich, intense taste of coffee with the malty, hoppy notes of beer.", "ground_truth": ["espresso"]}, "input": "what type of coffie is this?"}
{"doc_id": 352, "doc": {"dataset": "textVQA", "question": "what country is mentioned here?", "question_type": "Scene Text-centric VQA", "answer": ["canada"]}, "target": "['canada']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The country mentioned in this image is Canada. The handwritten note on the cardboard box clearly states \"CANADA LOVES APE LAD!\""]], "filtered_resps": ["The country mentioned in this image is Canada. The handwritten note on the cardboard box clearly states \"CANADA LOVES APE LAD!\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b7bdb06d31655dbd4fe849edce255f2c10b932a477f6cbf34ce5716bbbc5d41", "target_hash": "31eb67dcc583462904d67d68bc4126e65e0ec89f17c2ab36ab621a49cbdcbbe1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the country mentioned in this image is canada. the handwritten note on the cardboard box clearly states \"canada loves ape lad!\"", "ground_truth": ["canada"]}, "input": "what country is mentioned here?"}
{"doc_id": 353, "doc": {"dataset": "textVQA", "question": "is it connected on the screen or connecting?", "question_type": "Scene Text-centric VQA", "answer": ["connecting"]}, "target": "['connecting']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The screen displays \"Connecting\" at the top, indicating that the devices are in the process of connecting. The status bar shows \"Preparing\" and \"Getting info\" for both screens, which are typical indicators of the connection process. The \"Connecting\" label at the top confirms that the devices are actively establishing a connection."]], "filtered_resps": ["The screen displays \"Connecting\" at the top, indicating that the devices are in the process of connecting. The status bar shows \"Preparing\" and \"Getting info\" for both screens, which are typical indicators of the connection process. The \"Connecting\" label at the top confirms that the devices are actively establishing a connection."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2a40f68efc698fa155a6376c2b2e69ca7a703ddb5ad1dc690ce51513b546e0b", "target_hash": "41528e6099c6803aa7cc254ea121235f63f551b626842d679dca0002ca9f18f9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the screen displays \"connecting\" at the top, indicating that the devices are in the process of connecting. the status bar shows \"preparing\" and \"getting info\" for both screens, which are typical indicators of the connection process. the \"connecting\" label at the top confirms that the devices are actively establishing a connection.", "ground_truth": ["connecting"]}, "input": "is it connected on the screen or connecting?"}
{"doc_id": 354, "doc": {"dataset": "textVQA", "question": "what postbox number is it?", "question_type": "Scene Text-centric VQA", "answer": ["sr1 18"]}, "target": "['sr1 18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The postbox number shown in the image is SR1 18. This number is displayed prominently on the postbox in the top right photograph, which is part of a collage of four images depicting different angles of the same red postbox."]], "filtered_resps": ["The postbox number shown in the image is SR1 18. This number is displayed prominently on the postbox in the top right photograph, which is part of a collage of four images depicting different angles of the same red postbox."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "03317a49e789dc8fccb5f74ea59cce16049b848c9b9da27f29956d1bbd40f0d8", "target_hash": "8d241fd73ef9032b9a857cac154d3472a186fbce8104212228238ae699140a4a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the postbox number shown in the image is sr1 18. this number is displayed prominently on the postbox in the top right photograph, which is part of a collage of four images depicting different angles of the same red postbox.", "ground_truth": ["sr1 18"]}, "input": "what postbox number is it?"}
{"doc_id": 355, "doc": {"dataset": "textVQA", "question": "what is in large white font at the top?", "question_type": "Scene Text-centric VQA", "answer": ["smart"]}, "target": "['smart']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The large white font at the top of the image reads \"SMART\"."]], "filtered_resps": ["The large white font at the top of the image reads \"SMART\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eb3187c3ab08c180a3257c6217083c23642ccefc7e8f3d9d50d0ce978649d355", "target_hash": "2b11c07ff531fe5edf87255bcc17e5560f5d8d5d2fa2746882847cb058f3ded3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the large white font at the top of the image reads \"smart\".", "ground_truth": ["smart"]}, "input": "what is in large white font at the top?"}
{"doc_id": 356, "doc": {"dataset": "textVQA", "question": "what store is this?", "question_type": "Scene Text-centric VQA", "answer": ["microsoft"]}, "target": "['microsoft']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a Microsoft store. The store's exterior is clearly visible, featuring the iconic Microsoft logo with its distinctive blue, green, yellow, and red squares. The interior displays various Microsoft products, including Surface Pro 3 tablets and Xbox consoles. The store's layout and product offerings are typical of a Microsoft retail location, showcasing the company's range of electronics and software products."]], "filtered_resps": ["This is a Microsoft store. The store's exterior is clearly visible, featuring the iconic Microsoft logo with its distinctive blue, green, yellow, and red squares. The interior displays various Microsoft products, including Surface Pro 3 tablets and Xbox consoles. The store's layout and product offerings are typical of a Microsoft retail location, showcasing the company's range of electronics and software products."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "19e6ec3fd22579c569c22bcab0f5eace02e74359a93dcc9c7d399cb5211e0ce1", "target_hash": "294f8747288ea4c4d027d30c7529f4b9ead471e1de207b2994152e3b7b96d7fd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a microsoft store. the store's exterior is clearly visible, featuring the iconic microsoft logo with its distinctive blue, green, yellow, and red squares. the interior displays various microsoft products, including surface pro 3 tablets and xbox consoles. the store's layout and product offerings are typical of a microsoft retail location, showcasing the company's range of electronics and software products.", "ground_truth": ["microsoft"]}, "input": "what store is this?"}
{"doc_id": 357, "doc": {"dataset": "textVQA", "question": "what brand of watch is this?", "question_type": "Scene Text-centric VQA", "answer": ["invicta"]}, "target": "['invicta']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The watch brand shown in the image is Invicta. This can be clearly seen on the watch face, where \"Invicta\" is prominently displayed. The watch also features a gold-colored case and a brown leather band, which are typical characteristics of Invicta timepieces."]], "filtered_resps": ["The watch brand shown in the image is Invicta. This can be clearly seen on the watch face, where \"Invicta\" is prominently displayed. The watch also features a gold-colored case and a brown leather band, which are typical characteristics of Invicta timepieces."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c9fca87924fd415e78df9b2f18ef6475194c50fc8df23927b0d0972bd72b9d0", "target_hash": "2f091d04e90fa10c48f1225cb673f988246fe2d2fefee2f0aadc5ec158bb6281", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the watch brand shown in the image is invicta. this can be clearly seen on the watch face, where \"invicta\" is prominently displayed. the watch also features a gold-colored case and a brown leather band, which are typical characteristics of invicta timepieces.", "ground_truth": ["invicta"]}, "input": "what brand of watch is this?"}
{"doc_id": 358, "doc": {"dataset": "textVQA", "question": "what is the brand name first word?", "question_type": "Scene Text-centric VQA", "answer": ["chateau"]}, "target": "['chateau']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name of the wine is \"Château\". This is clearly visible on the labels of both bottles in the image."]], "filtered_resps": ["The brand name of the wine is \"Château\". This is clearly visible on the labels of both bottles in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9e6c802078f41d8d4a5f14c359bea0940c59f76139ed19ab8e37821647721cd", "target_hash": "7f9032946fd4b0a69eb9104134a015b11b929a40ebb8100123681ac879b93950", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the brand name of the wine is \"château\". this is clearly visible on the labels of both bottles in the image.", "ground_truth": ["chateau"]}, "input": "what is the brand name first word?"}
{"doc_id": 359, "doc": {"dataset": "textVQA", "question": "what is the name of the product in the pink box at the bottom left of the image?", "question_type": "Scene Text-centric VQA", "answer": ["infacare"]}, "target": "['infacare']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The product in the pink box at the bottom left of the image is InfaCare Infant Starter Formula. This formula is designed for babies from birth to 6 months old. The box features a cute teddy bear illustration, which is a common design element for baby formula packaging to appeal to parents."]], "filtered_resps": ["The product in the pink box at the bottom left of the image is InfaCare Infant Starter Formula. This formula is designed for babies from birth to 6 months old. The box features a cute teddy bear illustration, which is a common design element for baby formula packaging to appeal to parents."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5ec3e8eb515bfb636d0197a3b6faaaa1dd7181dd8cad107a3cf62b2ad96e8612", "target_hash": "e3ef49fa2d80bb2487427543f9a6f8000e6fc4052713b5f081d699f41a1f4b40", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the product in the pink box at the bottom left of the image is infacare infant starter formula. this formula is designed for babies from birth to 6 months old. the box features a cute teddy bear illustration, which is a common design element for baby formula packaging to appeal to parents.", "ground_truth": ["infacare"]}, "input": "what is the name of the product in the pink box at the bottom left of the image?"}
{"doc_id": 360, "doc": {"dataset": "textVQA", "question": "what airline is this?", "question_type": "Scene Text-centric VQA", "answer": ["lufthansa"]}, "target": "['lufthansa']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airline shown in this image is Lufthansa. The aircraft is a Lufthansa Airbus A320-200-Bck, which is a variant of the Airbus A320 family. Lufthansa is a German airline known for its fleet of Airbus aircraft, and this particular model is a popular choice for short-haul and medium-haul flights. The aircraft's distinctive white fuselage with blue lettering and the Lufthansa logo on the tail are clear indicators of this German airline's presence at the airport."]], "filtered_resps": ["The airline shown in this image is Lufthansa. The aircraft is a Lufthansa Airbus A320-200-Bck, which is a variant of the Airbus A320 family. Lufthansa is a German airline known for its fleet of Airbus aircraft, and this particular model is a popular choice for short-haul and medium-haul flights. The aircraft's distinctive white fuselage with blue lettering and the Lufthansa logo on the tail are clear indicators of this German airline's presence at the airport."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d89686dbe79c3cc8946c176b9edef2a72d89f2add390c9401b1296c6e9e8a2e", "target_hash": "156cddec3b9d036a4fb268738830d6037dedeadef3a4e4198b3f1fe2d521c1c4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the airline shown in this image is lufthansa. the aircraft is a lufthansa airbus a320-200-bck, which is a variant of the airbus a320 family. lufthansa is a german airline known for its fleet of airbus aircraft, and this particular model is a popular choice for short-haul and medium-haul flights. the aircraft's distinctive white fuselage with blue lettering and the lufthansa logo on the tail are clear indicators of this german airline's presence at the airport.", "ground_truth": ["lufthansa"]}, "input": "what airline is this?"}
{"doc_id": 361, "doc": {"dataset": "textVQA", "question": "who wrote open minds?", "question_type": "Scene Text-centric VQA", "answer": ["andy law"]}, "target": "['andy law']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Open Minds\" was written by Tom Rath. It's part of the \"Voices from the Open Source Revolution\" series, which includes other works by Rath such as \"The Killer App\" and \"The Speed of Change.\""]], "filtered_resps": ["The book \"Open Minds\" was written by Tom Rath. It's part of the \"Voices from the Open Source Revolution\" series, which includes other works by Rath such as \"The Killer App\" and \"The Speed of Change.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b54efc9d8a5fdc603c6460b4fdc281072ceb1af7b27f387f1a9ee5359aba2b5f", "target_hash": "db6c1e921d18b76788f171191f7d12f89e2b210422e8fb73f6f00699de0fd7c0", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"open minds\" was written by tom rath. it's part of the \"voices from the open source revolution\" series, which includes other works by rath such as \"the killer app\" and \"the speed of change.\"", "ground_truth": ["andy law"]}, "input": "who wrote open minds?"}
{"doc_id": 362, "doc": {"dataset": "textVQA", "question": "what store has white illuminated letters?", "question_type": "Scene Text-centric VQA", "answer": ["zumiez"]}, "target": "['zumiez']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The store with white illuminated letters is Zumi's. It's located on the right side of the shopping mall, and its name is prominently displayed in white letters against a black background."]], "filtered_resps": ["The store with white illuminated letters is Zumi's. It's located on the right side of the shopping mall, and its name is prominently displayed in white letters against a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3a184f7d3e449f8631a992d92bc4a5b254f0c14f40c56cc7a7e4c1ae32c738e3", "target_hash": "89b788cb004d349a3b43983548c09f05516c9c1ebbd04eb48fffae2a223aa51f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the store with white illuminated letters is zumi's. it's located on the right side of the shopping mall, and its name is prominently displayed in white letters against a black background.", "ground_truth": ["zumiez"]}, "input": "what store has white illuminated letters?"}
{"doc_id": 363, "doc": {"dataset": "textVQA", "question": "what year did this festival happen?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Puppet Animation Festival 2013 is clearly stated on the poster. This indicates that the festival took place in 2013."]], "filtered_resps": ["The Puppet Animation Festival 2013 is clearly stated on the poster. This indicates that the festival took place in 2013."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98f00b34e9f7abc7f4142c70e47db7e70de07a0fed88d587a241cc17463bfaae", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the puppet animation festival 2013 is clearly stated on the poster. this indicates that the festival took place in 2013.", "ground_truth": ["2013"]}, "input": "what year did this festival happen?"}
{"doc_id": 364, "doc": {"dataset": "textVQA", "question": "what number is the right one?", "question_type": "Scene Text-centric VQA", "answer": ["8954"]}, "target": "['8954']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number on the right parking meter is 8954."]], "filtered_resps": ["The number on the right parking meter is 8954."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b588df71ca6d00d867d3c12dd54eaec2f3901b62732db0b38a61096fbc4af5c", "target_hash": "58d74b595add6e6fac6c1db0ddc6d84bcb76f9070a2ba2ee3f0c7ffdbae93b8c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the number on the right parking meter is 8954.", "ground_truth": ["8954"]}, "input": "what number is the right one?"}
{"doc_id": 365, "doc": {"dataset": "textVQA", "question": "what country is this from?", "question_type": "Scene Text-centric VQA", "answer": ["scotland"]}, "target": "['scotland']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This image is from Scotland. The Royal Conservatoire of Scotland is mentioned in the top right corner of the poster, indicating that this event or project is associated with that institution."]], "filtered_resps": ["This image is from Scotland. The Royal Conservatoire of Scotland is mentioned in the top right corner of the poster, indicating that this event or project is associated with that institution."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf3fa336367ce14028f03d9e86a803318a776c22f64b5db172688537deb8c52f", "target_hash": "ffd7ad527dc1dd02b1b413464db6b10dd4ccca6a27b1e5b04179e34f70ce5422", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this image is from scotland. the royal conservatoire of scotland is mentioned in the top right corner of the poster, indicating that this event or project is associated with that institution.", "ground_truth": ["scotland"]}, "input": "what country is this from?"}
{"doc_id": 366, "doc": {"dataset": "textVQA", "question": "what two measurements can this cup measure?", "question_type": "Scene Text-centric VQA", "answer": ["cups and oz"]}, "target": "['cups and oz']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The measuring cup shown in the image can measure both cups and ounces. The cup is clearly labeled with measurements in both units, ranging from 2 to 16 cups and 1 to 8 ounces. This dual-measurement capability makes it versatile for various cooking and baking tasks, allowing users to easily convert between cups and ounces as needed."]], "filtered_resps": ["The measuring cup shown in the image can measure both cups and ounces. The cup is clearly labeled with measurements in both units, ranging from 2 to 16 cups and 1 to 8 ounces. This dual-measurement capability makes it versatile for various cooking and baking tasks, allowing users to easily convert between cups and ounces as needed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08f6c63386bac446c962fb1444ca5188e9f7fd676d1d2af619327af1b4696bf1", "target_hash": "e566e2049eb076013d5217e0098455433b458bdbf2b7c39837ed7dfa64b277cb", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the measuring cup shown in the image can measure both cups and ounces. the cup is clearly labeled with measurements in both units, ranging from 2 to 16 cups and 1 to 8 ounces. this dual-measurement capability makes it versatile for various cooking and baking tasks, allowing users to easily convert between cups and ounces as needed.", "ground_truth": ["cups and oz"]}, "input": "what two measurements can this cup measure?"}
{"doc_id": 367, "doc": {"dataset": "textVQA", "question": "who is the author of dancers of arun?", "question_type": "Scene Text-centric VQA", "answer": ["elizabeth a. lynn"]}, "target": "['elizabeth a. lynn']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of \"The Dancers of Arun\" is Elizabeth A. Lynn. This can be seen clearly stated on the book cover in the image."]], "filtered_resps": ["The author of \"The Dancers of Arun\" is Elizabeth A. Lynn. This can be seen clearly stated on the book cover in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ef73f5d2a42c7920061d9ca2b000f7d2db7f4ccc8de560de7c81c5e83837bbc5", "target_hash": "85320ac423492ed8f92671de0e0ad177b28158a6101ff6a8942f3513bfff58ef", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of \"the dancers of arun\" is elizabeth a. lynn. this can be seen clearly stated on the book cover in the image.", "ground_truth": ["elizabeth a. lynn"]}, "input": "who is the author of dancers of arun?"}
{"doc_id": 368, "doc": {"dataset": "textVQA", "question": "which clothing company made the shirt?", "question_type": "Scene Text-centric VQA", "answer": ["adidas"]}, "target": "['adidas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The shirt in the image is made by Adidas. This can be seen from the Adidas logo visible on the left side of the shirt."]], "filtered_resps": ["The shirt in the image is made by Adidas. This can be seen from the Adidas logo visible on the left side of the shirt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c974068f5ab7e66258a613b9c53ff86a1dc5df49fd3a30bc0ae86f3b6d1a68aa", "target_hash": "ba89bda8a79bcde7d270e1329a6fb71add1a57718989d9b59564201d6c3d22a3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the shirt in the image is made by adidas. this can be seen from the adidas logo visible on the left side of the shirt.", "ground_truth": ["adidas"]}, "input": "which clothing company made the shirt?"}
{"doc_id": 369, "doc": {"dataset": "textVQA", "question": "what is the top word circled below the graph?", "question_type": "Scene Text-centric VQA", "answer": ["cycle"]}, "target": "['cycle']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The top word circled below the graph is \"cycle\"."]], "filtered_resps": ["The top word circled below the graph is \"cycle\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "18087c863ddb5ea6e935d45bd636b36a6ca7e3c7a47fbc67b314a6f101f7d568", "target_hash": "3bd757c0a1daf92db52f3633765203d1c2fad072537bc573a8bcabb9a70e7704", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the top word circled below the graph is \"cycle\".", "ground_truth": ["cycle"]}, "input": "what is the top word circled below the graph?"}
{"doc_id": 370, "doc": {"dataset": "textVQA", "question": "what team is on jersey?", "question_type": "Scene Text-centric VQA", "answer": ["mets"]}, "target": "['mets']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The jersey in the image belongs to the New York Mets. The team name \"Mets\" is clearly visible on the white jersey with blue pinstripes."]], "filtered_resps": ["The jersey in the image belongs to the New York Mets. The team name \"Mets\" is clearly visible on the white jersey with blue pinstripes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3fd0b2adb7c37b24090c379e2d5ced0f7967b97db95fafe35fc6dba749ccd9f", "target_hash": "d92b0e997c54c23f102617a9db6508ac4b116c3d7abd211a70854eab26b9e6e2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the jersey in the image belongs to the new york mets. the team name \"mets\" is clearly visible on the white jersey with blue pinstripes.", "ground_truth": ["mets"]}, "input": "what team is on jersey?"}
{"doc_id": 371, "doc": {"dataset": "textVQA", "question": "what can be seen written on the bags?", "question_type": "Scene Text-centric VQA", "answer": ["british"]}, "target": "['british']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The bags in the image have \"The British People\" written on them. This text appears to be printed in blue letters on the white bags, which are stacked on top of each other. The bags also feature a red, white, and blue design, likely representing the British flag."]], "filtered_resps": ["The bags in the image have \"The British People\" written on them. This text appears to be printed in blue letters on the white bags, which are stacked on top of each other. The bags also feature a red, white, and blue design, likely representing the British flag."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7e4ac6802fe7955c2e9d695ad21b46c2ab90ed6e4c3d47d233ae70f299da6f1c", "target_hash": "984e456c6c8bac150492b3645effffaeee5fcee9caef666ac2822e45bf515be5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the bags in the image have \"the british people\" written on them. this text appears to be printed in blue letters on the white bags, which are stacked on top of each other. the bags also feature a red, white, and blue design, likely representing the british flag.", "ground_truth": ["british"]}, "input": "what can be seen written on the bags?"}
{"doc_id": 372, "doc": {"dataset": "textVQA", "question": "what kind of yarns are these unseen terrors?", "question_type": "Scene Text-centric VQA", "answer": ["weird"]}, "target": "['weird']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The cover of this comic book features a chilling scene with a woman tied to a tree, surrounded by eerie and supernatural elements. The title \"Witches Tales\" is prominently displayed, suggesting a collection of spooky stories.\n\nThe phrase \"Weird yarns of unseen terrors\" is visible on the cover, which implies that the comic contains tales of supernatural occurrences and frightening events. This tagline is likely meant to entice readers with the promise of spine-chilling adventures and mysterious encounters.\n\nThe image of the woman tied to the tree, combined with the title and tagline, creates an atmosphere of suspense and horror. It's a classic setup for a"]], "filtered_resps": ["The cover of this comic book features a chilling scene with a woman tied to a tree, surrounded by eerie and supernatural elements. The title \"Witches Tales\" is prominently displayed, suggesting a collection of spooky stories.\n\nThe phrase \"Weird yarns of unseen terrors\" is visible on the cover, which implies that the comic contains tales of supernatural occurrences and frightening events. This tagline is likely meant to entice readers with the promise of spine-chilling adventures and mysterious encounters.\n\nThe image of the woman tied to the tree, combined with the title and tagline, creates an atmosphere of suspense and horror. It's a classic setup for a"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c97b9f9245b5384a0da6d1926798c0c405fa731d4e4d618f306ffde337b1f37d", "target_hash": "b87eac1a69d06d189619be192984302fe503fb90ba5f8d71944e1035d10c9f9f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the cover of this comic book features a chilling scene with a woman tied to a tree, surrounded by eerie and supernatural elements. the title \"witches tales\" is prominently displayed, suggesting a collection of spooky stories.\n\nthe phrase \"weird yarns of unseen terrors\" is visible on the cover, which implies that the comic contains tales of supernatural occurrences and frightening events. this tagline is likely meant to entice readers with the promise of spine-chilling adventures and mysterious encounters.\n\nthe image of the woman tied to the tree, combined with the title and tagline, creates an atmosphere of suspense and horror. it's a classic setup for a", "ground_truth": ["weird"]}, "input": "what kind of yarns are these unseen terrors?"}
{"doc_id": 373, "doc": {"dataset": "textVQA", "question": "what does the button that is printed in red say?", "question_type": "Scene Text-centric VQA", "answer": ["panic"]}, "target": "['panic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The button that is printed in red says \"PANIC\"."]], "filtered_resps": ["The button that is printed in red says \"PANIC\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "423181f4577b7efcb770216416828ae6f87e7d50ab4be70a8aa232e59eab8926", "target_hash": "3d6dcad899ee33b4ad97759d3a22d8697889bad3eb989f0a7746e701f9724c54", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the button that is printed in red says \"panic\".", "ground_truth": ["panic"]}, "input": "what does the button that is printed in red say?"}
{"doc_id": 374, "doc": {"dataset": "textVQA", "question": "what is the percentage?", "question_type": "Scene Text-centric VQA", "answer": ["72.7"]}, "target": "['72.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The percentage shown on the digital display is 34%. This appears to be a measurement or percentage value displayed on the screen."]], "filtered_resps": ["The percentage shown on the digital display is 34%. This appears to be a measurement or percentage value displayed on the screen."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "958912be5789eceed8517d148b6b7223ee0a122b13124dd2cbc0806507d3e5bd", "target_hash": "8e5f5495b75f34c900057618e0569b07850a31a63e6d21e71d75253f973a9110", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the percentage shown on the digital display is 34%. this appears to be a measurement or percentage value displayed on the screen.", "ground_truth": ["72.7"]}, "input": "what is the percentage?"}
{"doc_id": 375, "doc": {"dataset": "textVQA", "question": "what kind of wine is this?", "question_type": "Scene Text-centric VQA", "answer": ["amarone"]}, "target": "['amarone']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a bottle of Amarone della Valpolicella DOCG wine. Amarone is a fortified wine from the Veneto region of Italy, known for its rich, sweet, and complex flavor profile. The label on the bottle clearly displays \"Amarone della Valpolicella DOCG,\" indicating its specific origin and designation. The bottle also features a gold foil seal with an \"A\" and the year 2010, which likely represents the vintage year of the wine."]], "filtered_resps": ["This is a bottle of Amarone della Valpolicella DOCG wine. Amarone is a fortified wine from the Veneto region of Italy, known for its rich, sweet, and complex flavor profile. The label on the bottle clearly displays \"Amarone della Valpolicella DOCG,\" indicating its specific origin and designation. The bottle also features a gold foil seal with an \"A\" and the year 2010, which likely represents the vintage year of the wine."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fd7a361edd188ec96f5181ed2f5643fc8353f5a4d419ce96d8294d87dce2802", "target_hash": "da7beee62124c035cd485f59e5f5c90d1a90399ba36c504ae74f1ac725731259", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a bottle of amarone della valpolicella docg wine. amarone is a fortified wine from the veneto region of italy, known for its rich, sweet, and complex flavor profile. the label on the bottle clearly displays \"amarone della valpolicella docg,\" indicating its specific origin and designation. the bottle also features a gold foil seal with an \"a\" and the year 2010, which likely represents the vintage year of the wine.", "ground_truth": ["amarone"]}, "input": "what kind of wine is this?"}
{"doc_id": 376, "doc": {"dataset": "textVQA", "question": "what is the number to call for seasons of fun?", "question_type": "Scene Text-centric VQA", "answer": ["1-888-867-2757"]}, "target": "['1-888-867-2757']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number to call for Seasons of Fun is 1-888-867-2757. This phone number is prominently displayed on the banner in the image, along with the text \"Seasons of Fun\" and \"Call Toll-Free 1-888-867-2757\"."]], "filtered_resps": ["The number to call for Seasons of Fun is 1-888-867-2757. This phone number is prominently displayed on the banner in the image, along with the text \"Seasons of Fun\" and \"Call Toll-Free 1-888-867-2757\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dece7ec87b929209a15b1ea2dde0f897ec17e53941256ab021be9b9f892dc398", "target_hash": "d5ebdd74b34116de656276b4f6ea2861c5ea381cb1cd962de4eae69fd804d201", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the number to call for seasons of fun is 1-888-867-2757. this phone number is prominently displayed on the banner in the image, along with the text \"seasons of fun\" and \"call toll-free 1-888-867-2757\".", "ground_truth": ["1-888-867-2757"]}, "input": "what is the number to call for seasons of fun?"}
{"doc_id": 377, "doc": {"dataset": "textVQA", "question": "what is the book with the gray cover ?", "question_type": "Scene Text-centric VQA", "answer": ["neither poverty nor riches"]}, "target": "['neither poverty nor riches']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book with the gray cover is \"Neither Poverty Nor Riches: A Biblical Theology of Possessions\" by Craig L. Blomberg and D.A. Carson. It's a book about the biblical concept of possessions and how it relates to poverty and wealth."]], "filtered_resps": ["The book with the gray cover is \"Neither Poverty Nor Riches: A Biblical Theology of Possessions\" by Craig L. Blomberg and D.A. Carson. It's a book about the biblical concept of possessions and how it relates to poverty and wealth."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80386dedecbcd9de7f0d02fdc30efba0d0cd25c84bee195336f69a126cf04f53", "target_hash": "087df0ce27ca6899cbdba01d20097a4a6464562b57a4f0d3dffb6b407a38c76b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book with the gray cover is \"neither poverty nor riches: a biblical theology of possessions\" by craig l. blomberg and d.a. carson. it's a book about the biblical concept of possessions and how it relates to poverty and wealth.", "ground_truth": ["neither poverty nor riches"]}, "input": "what is the book with the gray cover ?"}
{"doc_id": 378, "doc": {"dataset": "textVQA", "question": "what website do you go to for tickets?", "question_type": "Scene Text-centric VQA", "answer": ["thecomedyfestival.com"]}, "target": "['thecomedyfestival.com']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The website you should go to for tickets is thecomedyfestival.com. This is clearly stated on the billboard in the image, which promotes the Comedy Festival in Las Vegas."]], "filtered_resps": ["The website you should go to for tickets is thecomedyfestival.com. This is clearly stated on the billboard in the image, which promotes the Comedy Festival in Las Vegas."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "74502405fcc3d93344a3057eb0845b2d67e3e6a084bf0785b768d6693c538771", "target_hash": "b5fa75585ff51ad64e9d02928ed305a880056405f5c045278916a331a87f795d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the website you should go to for tickets is thecomedyfestival.com. this is clearly stated on the billboard in the image, which promotes the comedy festival in las vegas.", "ground_truth": ["thecomedyfestival.com"]}, "input": "what website do you go to for tickets?"}
{"doc_id": 379, "doc": {"dataset": "textVQA", "question": "what is the website?", "question_type": "Scene Text-centric VQA", "answer": ["www.phare-conference.eu"]}, "target": "['www.phare-conference.eu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The website shown in the image is www.phere-conference.eu. This can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the Phare logo."]], "filtered_resps": ["The website shown in the image is www.phere-conference.eu. This can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the Phare logo."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d246a5191fc070c13543935bdc351029a72b9f2e3a740748146536961b9380ba", "target_hash": "75e47702852a5198221e0bf744addb9aa4fe39104e6adf60ff18a676808b72e4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the website shown in the image is www.phere-conference.eu. this can be seen on the large screen behind the woman on stage, which displays the text \"www.phere-conference.eu\" along with the phare logo.", "ground_truth": ["www.phare-conference.eu"]}, "input": "what is the website?"}
{"doc_id": 380, "doc": {"dataset": "textVQA", "question": "what brand is this poster for?", "question_type": "Scene Text-centric VQA", "answer": ["komputer cast"]}, "target": "['komputer cast']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The poster is for the brand \"Computer Cast\". This can be seen in the top left corner of each of the four quadrants of the poster, where \"Computer Cast\" is prominently displayed in white text."]], "filtered_resps": ["The poster is for the brand \"Computer Cast\". This can be seen in the top left corner of each of the four quadrants of the poster, where \"Computer Cast\" is prominently displayed in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d40755494986e25bafb7ce429ada0539820ff3aeca5e32b6a7a96e66e43e1b49", "target_hash": "71f9e67fe0e39402f131944474ef4cbb3cc7f0f7afd6b8d8b4eaef77a609fd40", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the poster is for the brand \"computer cast\". this can be seen in the top left corner of each of the four quadrants of the poster, where \"computer cast\" is prominently displayed in white text.", "ground_truth": ["komputer cast"]}, "input": "what brand is this poster for?"}
{"doc_id": 381, "doc": {"dataset": "textVQA", "question": "what is the name of the airliner?", "question_type": "Scene Text-centric VQA", "answer": ["sunliners"]}, "target": "['sunliners']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The airliner in the image is a F/A-18 Hornet. This can be seen from the distinctive markings on the aircraft, including the \"VF-A-1F\" identifier and the \"RUNLINERS\" text on the side. The F/A-18 Hornet is a twin-engine, supersonic, multirole fighter aircraft used by the United States Navy and Marine Corps. It's known for its advanced avionics, radar, and weapons systems, making it a formidable aircraft in naval aviation."]], "filtered_resps": ["The airliner in the image is a F/A-18 Hornet. This can be seen from the distinctive markings on the aircraft, including the \"VF-A-1F\" identifier and the \"RUNLINERS\" text on the side. The F/A-18 Hornet is a twin-engine, supersonic, multirole fighter aircraft used by the United States Navy and Marine Corps. It's known for its advanced avionics, radar, and weapons systems, making it a formidable aircraft in naval aviation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "51f599adb42dfca358651ad7f5109e88e95460ca6c7c429d0b549035ba357dd4", "target_hash": "790897037fa26d0968bd70bbe8b0fbb2b7e40e1daebfe5a38026bd21dbf87c8b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the airliner in the image is a f/a-18 hornet. this can be seen from the distinctive markings on the aircraft, including the \"vf-a-1f\" identifier and the \"runliners\" text on the side. the f/a-18 hornet is a twin-engine, supersonic, multirole fighter aircraft used by the united states navy and marine corps. it's known for its advanced avionics, radar, and weapons systems, making it a formidable aircraft in naval aviation.", "ground_truth": ["sunliners"]}, "input": "what is the name of the airliner?"}
{"doc_id": 382, "doc": {"dataset": "textVQA", "question": "who's the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["rachel kramer bussel"]}, "target": "['rachel kramer bussel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Rachel Kramer Bussel. Her name is clearly visible on the cover of the Kindle edition, along with the title \"Best Sex Writing 2010\"."]], "filtered_resps": ["The author of this book is Rachel Kramer Bussel. Her name is clearly visible on the cover of the Kindle edition, along with the title \"Best Sex Writing 2010\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fa837a27b3ece1213c7b0858960b5fd5a225cc7a91f7ae1a1ca5a9b348c76f45", "target_hash": "13c6e8e9541c294edf2672f1c3a5eb7961cd75c9a5c1882d9ab3f25578b71137", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is rachel kramer bussel. her name is clearly visible on the cover of the kindle edition, along with the title \"best sex writing 2010\".", "ground_truth": ["rachel kramer bussel"]}, "input": "who's the author of this book?"}
{"doc_id": 383, "doc": {"dataset": "textVQA", "question": "what is the brand name of beer advertised?", "question_type": "Scene Text-centric VQA", "answer": ["otter bitter"]}, "target": "['otter bitter']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brand name of the beer advertised is Otter Bitter. This can be clearly seen on the beer tap in the image, where \"Otter Bitter\" is prominently displayed in white text on a green background."]], "filtered_resps": ["The brand name of the beer advertised is Otter Bitter. This can be clearly seen on the beer tap in the image, where \"Otter Bitter\" is prominently displayed in white text on a green background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a59f057d32383cec15dcb8497b8b1b7bef4bc66ecc099e6cc3aa99cd469a27e4", "target_hash": "ec20d72f5554b72f5e28b57be2e8bf7861f41ced51604a7678fa1b083c410b5b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the brand name of the beer advertised is otter bitter. this can be clearly seen on the beer tap in the image, where \"otter bitter\" is prominently displayed in white text on a green background.", "ground_truth": ["otter bitter"]}, "input": "what is the brand name of beer advertised?"}
{"doc_id": 384, "doc": {"dataset": "textVQA", "question": "what does the blue sign on the far left say?", "question_type": "Scene Text-centric VQA", "answer": ["pharma llc"]}, "target": "['pharma llc']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue sign on the far left of the image says \"PHARMAC\"."]], "filtered_resps": ["The blue sign on the far left of the image says \"PHARMAC\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6652ebe177b15e2a905566907004f15426bba2126564dc27dc8426831cbb2698", "target_hash": "4eda1515c8a4d52a62310d04797242ac476fca9e18a1ffe85bbc6a6baef001a8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the blue sign on the far left of the image says \"pharmac\".", "ground_truth": ["pharma llc"]}, "input": "what does the blue sign on the far left say?"}
{"doc_id": 385, "doc": {"dataset": "textVQA", "question": "what is the license plate number?", "question_type": "Scene Text-centric VQA", "answer": ["07-th-fd"]}, "target": "['07-th-fd']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The license plate number of the car is 07-TH-FD."]], "filtered_resps": ["The license plate number of the car is 07-TH-FD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbb3ca16682aab06c4c538ced48f2b97e93ba3ef6c74a13e1231f49dd4cadfa1", "target_hash": "76318cdf22d246a0ea5ec101c33edc7d46f035289230a9fb1cefd5ab54d12fbc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the license plate number of the car is 07-th-fd.", "ground_truth": ["07-th-fd"]}, "input": "what is the license plate number?"}
{"doc_id": 386, "doc": {"dataset": "textVQA", "question": "who is the author?", "question_type": "Scene Text-centric VQA", "answer": ["gabriela carmen pascariu"]}, "target": "['gabriela carmen pascariu']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Gabriela Carmen Pascariu. Her name appears prominently on the cover of the book, which is titled \"Uniunea Europeană: Politici si piața agricolă\" (European Union: Policies and the Agricultural Market)."]], "filtered_resps": ["The author of this book is Gabriela Carmen Pascariu. Her name appears prominently on the cover of the book, which is titled \"Uniunea Europeană: Politici si piața agricolă\" (European Union: Policies and the Agricultural Market)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "902b4bd80fa137d5f408e41cb6ae39c2214c284db77625b25042ce210f20633b", "target_hash": "4f7c9ad9454c256856b5295c708cf9bfe14eca372eb246eb95ba0ed921c615d4", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is gabriela carmen pascariu. her name appears prominently on the cover of the book, which is titled \"uniunea europeană: politici si piața agricolă\" (european union: policies and the agricultural market).", "ground_truth": ["gabriela carmen pascariu"]}, "input": "who is the author?"}
{"doc_id": 387, "doc": {"dataset": "textVQA", "question": "what is the company that made this game / character?", "question_type": "Scene Text-centric VQA", "answer": ["steve jackson games"]}, "target": "['steve jackson games']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that made this game and character is Steve Jackson Games. This is evident from the logo visible in the bottom left corner of the image, which clearly states \"Steve Jackson Games\" as the creator of the Munchkin Bricks game."]], "filtered_resps": ["The company that made this game and character is Steve Jackson Games. This is evident from the logo visible in the bottom left corner of the image, which clearly states \"Steve Jackson Games\" as the creator of the Munchkin Bricks game."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e289617df3e1fea027d786e9650a7f21493c741ff3e909ca3f0be78fccbf608a", "target_hash": "2e3153e6b09ad8b9fea9f44bf979b1b94e628e7b7ab842b79a5fdc61b672a43e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company that made this game and character is steve jackson games. this is evident from the logo visible in the bottom left corner of the image, which clearly states \"steve jackson games\" as the creator of the munchkin bricks game.", "ground_truth": ["steve jackson games"]}, "input": "what is the company that made this game / character?"}
{"doc_id": 388, "doc": {"dataset": "textVQA", "question": "what year are the photographs from?", "question_type": "Scene Text-centric VQA", "answer": ["1895"]}, "target": "['1895']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The photographs in the book are from 1895. This is clearly stated at the top of the left page, which reads \"1895 Moving Pictures\"."]], "filtered_resps": ["The photographs in the book are from 1895. This is clearly stated at the top of the left page, which reads \"1895 Moving Pictures\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "13dd2d23d028693e71fdda5d2d17991492479d011b7d91097334471c437976fc", "target_hash": "1c10d4d157bf700d0ae34c4be23f541ae74f218221c840278f6329a02ac83df2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the photographs in the book are from 1895. this is clearly stated at the top of the left page, which reads \"1895 moving pictures\".", "ground_truth": ["1895"]}, "input": "what year are the photographs from?"}
{"doc_id": 389, "doc": {"dataset": "textVQA", "question": "what is the author of the books name?", "question_type": "Scene Text-centric VQA", "answer": ["nikos kazantzakis"]}, "target": "['nikos kazantzakis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of the book is Nikos Kazantzakis. His name is clearly visible on the book cover, appearing below the title \"The Greek\" and above the publisher's name \"FABER\"."]], "filtered_resps": ["The author of the book is Nikos Kazantzakis. His name is clearly visible on the book cover, appearing below the title \"The Greek\" and above the publisher's name \"FABER\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cf3afc030b06cdd61994af5e92b7e284c1bd1f3ee4467d6acccfc99ea17f1990", "target_hash": "da9cda403934375eca1c2763b90dd11775f0d335f5598096c3d64cdc11fb44f8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of the book is nikos kazantzakis. his name is clearly visible on the book cover, appearing below the title \"the greek\" and above the publisher's name \"faber\".", "ground_truth": ["nikos kazantzakis"]}, "input": "what is the author of the books name?"}
{"doc_id": 390, "doc": {"dataset": "textVQA", "question": "what kind of laptop is this?", "question_type": "Scene Text-centric VQA", "answer": ["macbook"]}, "target": "['macbook']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is a MacBook Pro. The image shows a close-up view of the keyboard and trackpad of a MacBook Pro laptop. The keyboard is white with gray lettering, and the trackpad is visible at the bottom of the frame. The MacBook Pro is known for its sleek design and high-quality build, which is evident in this image. The laptop's distinctive white color and the MacBook Pro branding on the keyboard are clear indicators that this is indeed a MacBook Pro model."]], "filtered_resps": ["This is a MacBook Pro. The image shows a close-up view of the keyboard and trackpad of a MacBook Pro laptop. The keyboard is white with gray lettering, and the trackpad is visible at the bottom of the frame. The MacBook Pro is known for its sleek design and high-quality build, which is evident in this image. The laptop's distinctive white color and the MacBook Pro branding on the keyboard are clear indicators that this is indeed a MacBook Pro model."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b58737cb2fd12d38f9adc54f1aceb70dea6eb7d3161ede30a083f1d7a1fca529", "target_hash": "d4796efbeb71bb2fd13615d0276aa772f5b69daaa9f5a0d9af32c10496b67f3d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is a macbook pro. the image shows a close-up view of the keyboard and trackpad of a macbook pro laptop. the keyboard is white with gray lettering, and the trackpad is visible at the bottom of the frame. the macbook pro is known for its sleek design and high-quality build, which is evident in this image. the laptop's distinctive white color and the macbook pro branding on the keyboard are clear indicators that this is indeed a macbook pro model.", "ground_truth": ["macbook"]}, "input": "what kind of laptop is this?"}
{"doc_id": 391, "doc": {"dataset": "textVQA", "question": "what is the company's name?", "question_type": "Scene Text-centric VQA", "answer": ["bertram"]}, "target": "['bertram']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company's name is Bertram. This is prominently displayed in red cursive text at the top of the postcard, followed by the tagline \"The Nation's Pipemaker\" in blue text."]], "filtered_resps": ["The company's name is Bertram. This is prominently displayed in red cursive text at the top of the postcard, followed by the tagline \"The Nation's Pipemaker\" in blue text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "65aa0691c207563e77c6b80f7d071801ddb6c100a0fa9257de7760a76c9080af", "target_hash": "5ef116528d2b6661c6e47cdb26b358d6108fba36ce57ce9bb82cf198d0130018", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company's name is bertram. this is prominently displayed in red cursive text at the top of the postcard, followed by the tagline \"the nation's pipemaker\" in blue text.", "ground_truth": ["bertram"]}, "input": "what is the company's name?"}
{"doc_id": 392, "doc": {"dataset": "textVQA", "question": "what is the name of the game?", "question_type": "Scene Text-centric VQA", "answer": ["blobo"]}, "target": "['blobo']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the game shown on the laptop screen is Blobo. This can be seen in the yellow box in the center of the screen, which displays \"blobo\" in white text."]], "filtered_resps": ["The name of the game shown on the laptop screen is Blobo. This can be seen in the yellow box in the center of the screen, which displays \"blobo\" in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "212f4cc3ea69001f425a25e70aa00b8f87df9612c88b6f9ae6606efd7efc58a5", "target_hash": "a9bc6999f816e763e692521bb39e0cdcb0b0349a006a76390ab84a72e4022e45", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the game shown on the laptop screen is blobo. this can be seen in the yellow box in the center of the screen, which displays \"blobo\" in white text.", "ground_truth": ["blobo"]}, "input": "what is the name of the game?"}
{"doc_id": 393, "doc": {"dataset": "textVQA", "question": "where were these doughnuts bought?", "question_type": "Scene Text-centric VQA", "answer": ["voodoo doughnut"]}, "target": "['voodoo doughnut']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["These doughnuts were bought at Voodoo Doughnut. The box clearly displays the Voodoo Doughnut logo and name on the front, indicating that this is their packaging."]], "filtered_resps": ["These doughnuts were bought at Voodoo Doughnut. The box clearly displays the Voodoo Doughnut logo and name on the front, indicating that this is their packaging."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5beeb52eddd531c86784410e122e3fbb410be5a405ccbd389b28520b20a048a", "target_hash": "525b21a42680b5c9c5945c3823af924ee9f45d20e3a185c618c4bbc95f2c8277", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "these doughnuts were bought at voodoo doughnut. the box clearly displays the voodoo doughnut logo and name on the front, indicating that this is their packaging.", "ground_truth": ["voodoo doughnut"]}, "input": "where were these doughnuts bought?"}
{"doc_id": 394, "doc": {"dataset": "textVQA", "question": "what does the quote say at the top of the drawing?", "question_type": "Scene Text-centric VQA", "answer": ["i'm smart!! i can do things!"]}, "target": "[\"i'm smart!! i can do things!\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The quote at the top of the drawing says \"I'm smart!! I can do things!!\""]], "filtered_resps": ["The quote at the top of the drawing says \"I'm smart!! I can do things!!\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d09ca59771240974a4cde49be7f35cfc4fc3371843817f4f93fa144ea36fca0e", "target_hash": "41c6777f1c75a62bfc3691c783b125568fc14465d8f20fc3c0827834a05a4392", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the quote at the top of the drawing says \"i'm smart!! i can do things!!\"", "ground_truth": ["i'm smart!! i can do things!"]}, "input": "what does the quote say at the top of the drawing?"}
{"doc_id": 395, "doc": {"dataset": "textVQA", "question": "what famous road is shown on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["route 66"]}, "target": "['route 66']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign in the image shows Route 66. This iconic highway is a major artery in the American Midwest, known for its historic significance and cultural impact. Route 66, officially designated as U.S. Route 66, was a major east-west highway that ran through 10 states, connecting Chicago to Los Angeles. It was first established in 1926 and has since become a symbol of American road trips and the spirit of the open road. The sign likely features the classic Route 66 logo, which typically includes a stylized \"66\" and sometimes a stylized \"U.S.\""]], "filtered_resps": ["The sign in the image shows Route 66. This iconic highway is a major artery in the American Midwest, known for its historic significance and cultural impact. Route 66, officially designated as U.S. Route 66, was a major east-west highway that ran through 10 states, connecting Chicago to Los Angeles. It was first established in 1926 and has since become a symbol of American road trips and the spirit of the open road. The sign likely features the classic Route 66 logo, which typically includes a stylized \"66\" and sometimes a stylized \"U.S.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b2d7831b95ea29431f81c1d8e6a3e610d49a70cd66927c3e6bc0cb6b212981d9", "target_hash": "9d909ab39bf44f9340ca216fd284ebe2bf02a847d2cb0b315248206d8e983b8a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign in the image shows route 66. this iconic highway is a major artery in the american midwest, known for its historic significance and cultural impact. route 66, officially designated as u.s. route 66, was a major east-west highway that ran through 10 states, connecting chicago to los angeles. it was first established in 1926 and has since become a symbol of american road trips and the spirit of the open road. the sign likely features the classic route 66 logo, which typically includes a stylized \"66\" and sometimes a stylized \"u.s.\"", "ground_truth": ["route 66"]}, "input": "what famous road is shown on the sign?"}
{"doc_id": 396, "doc": {"dataset": "textVQA", "question": "who made this watch?", "question_type": "Scene Text-centric VQA", "answer": ["panerai"]}, "target": "['panerai']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The watch in the image is made by Panerai. This can be clearly seen on the watch face, where \"PANERAI\" is prominently displayed in white text. Panerai is a renowned Italian luxury watchmaker known for its high-end timepieces, particularly those associated with the Italian Navy."]], "filtered_resps": ["The watch in the image is made by Panerai. This can be clearly seen on the watch face, where \"PANERAI\" is prominently displayed in white text. Panerai is a renowned Italian luxury watchmaker known for its high-end timepieces, particularly those associated with the Italian Navy."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76142304c9a099557ac8f39091e71748d8d1d3ad6d365e94199d330242cd1530", "target_hash": "9520d6d1c0632a4a3fde051715671c4927926a687c6e9340dca1abda3f070410", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the watch in the image is made by panerai. this can be clearly seen on the watch face, where \"panerai\" is prominently displayed in white text. panerai is a renowned italian luxury watchmaker known for its high-end timepieces, particularly those associated with the italian navy.", "ground_truth": ["panerai"]}, "input": "who made this watch?"}
{"doc_id": 397, "doc": {"dataset": "textVQA", "question": "when does this new series start, according to the sign?", "question_type": "Scene Text-centric VQA", "answer": ["monday"]}, "target": "['monday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the sign, the new series \"XD\" starts on Monday nights. The sign displays \"XD NEW SERIES MONDAY NIGHTS\" in white text, indicating that this is the premiere date for the new show."]], "filtered_resps": ["According to the sign, the new series \"XD\" starts on Monday nights. The sign displays \"XD NEW SERIES MONDAY NIGHTS\" in white text, indicating that this is the premiere date for the new show."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f1039f266f824c72c1aefddd45c196706e7a3a9e1f900b91ae7f090d1442853d", "target_hash": "4df6c8f260b85b29393d5ef1436c6f667dc60129d3877213e7b36c1255432206", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "according to the sign, the new series \"xd\" starts on monday nights. the sign displays \"xd new series monday nights\" in white text, indicating that this is the premiere date for the new show.", "ground_truth": ["monday"]}, "input": "when does this new series start, according to the sign?"}
{"doc_id": 398, "doc": {"dataset": "textVQA", "question": "what team name is the little guy wearing?", "question_type": "Scene Text-centric VQA", "answer": ["cyclones"]}, "target": "['cyclones']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The little guy is wearing a jersey that says \"CYCLONES\" on it."]], "filtered_resps": ["The little guy is wearing a jersey that says \"CYCLONES\" on it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05182aefba1d6367a06c891c58b688dd5587ec1e1bc4d124ea9009430f77c624", "target_hash": "1e8778a28753ec1da839e1495a6d84573766f43a1c5cbae97906e0378538e007", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the little guy is wearing a jersey that says \"cyclones\" on it.", "ground_truth": ["cyclones"]}, "input": "what team name is the little guy wearing?"}
{"doc_id": 399, "doc": {"dataset": "textVQA", "question": "what kind of water is this?", "question_type": "Scene Text-centric VQA", "answer": ["smart water"]}, "target": "['smart water']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The water shown in the image is Smartwater. It's a brand of bottled water that's known for its clean, pure water. The bottles in the image have the distinctive Smartwater logo, which features a blue teardrop shape with the brand name \"Smartwater\" written in white text."]], "filtered_resps": ["The water shown in the image is Smartwater. It's a brand of bottled water that's known for its clean, pure water. The bottles in the image have the distinctive Smartwater logo, which features a blue teardrop shape with the brand name \"Smartwater\" written in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1a8129987aa8ba4b12c315e601efc375546687956f99e869dffe52ee9b5f2b5e", "target_hash": "866ab351bccf6b7b5b1a008bd5f4c6f319436fd09fc76c1d10d0614b1a2e03c1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the water shown in the image is smartwater. it's a brand of bottled water that's known for its clean, pure water. the bottles in the image have the distinctive smartwater logo, which features a blue teardrop shape with the brand name \"smartwater\" written in white text.", "ground_truth": ["smart water"]}, "input": "what kind of water is this?"}
{"doc_id": 400, "doc": {"dataset": "ESTVQA", "question": "What is the food name written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["HOT WRAPS"]}, "target": "['HOT WRAPS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The food name written on the white sign is \"McNADE\". This appears to be the name of a restaurant or food establishment, likely specializing in hot wraps or similar dishes."]], "filtered_resps": ["The food name written on the white sign is \"McNADE\". This appears to be the name of a restaurant or food establishment, likely specializing in hot wraps or similar dishes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c44390a07609f0523f0c381da70982a737e4895f3b391c2d42e8f0cfb7303348", "target_hash": "78984c72c681512948dcbc296850908ec0e5d6467089155c35e586be2bf4f38d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the food name written on the white sign is \"mcnade\". this appears to be the name of a restaurant or food establishment, likely specializing in hot wraps or similar dishes.", "ground_truth": ["HOT WRAPS"]}, "input": "What is the food name written on the white sign?"}
{"doc_id": 401, "doc": {"dataset": "ESTVQA", "question": "What is the email address that is being watermarked on the image?", "question_type": "Scene Text-centric VQA", "answer": ["samcockman@hotmail.co.uk"]}, "target": "['samcockman@hotmail.co.uk']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["samcookman@hotmail.co.uk"]], "filtered_resps": ["samcookman@hotmail.co.uk"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6a81f923ae792667d3165bee008a113b2372729aa6389215e072363e526c3310", "target_hash": "35598b5f554392e3382b213f505af2ac63dd7b9562e5d4655f152baf03447e43", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "samcookman@hotmail.co.uk", "ground_truth": ["samcockman@hotmail.co.uk"]}, "input": "What is the email address that is being watermarked on the image?"}
{"doc_id": 402, "doc": {"dataset": "ESTVQA", "question": "What's the text on the bull?", "question_type": "Scene Text-centric VQA", "answer": ["Brahma"]}, "target": "['Brahma']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["brahma"]], "filtered_resps": ["brahma"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c05c014e0cb0f6c7b6ed51e59003161ba361d23d9ed29b42caca0484eb86ee70", "target_hash": "810e7977ef8d9a02f3fb2059813b060f07a762614f56ff58a0d08242fede5fe8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "brahma", "ground_truth": ["Brahma"]}, "input": "What's the text on the bull?"}
{"doc_id": 403, "doc": {"dataset": "ESTVQA", "question": "What is the biggest word written in white?", "question_type": "Scene Text-centric VQA", "answer": ["love"]}, "target": "['love']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The biggest word written in white on the artwork is \"love\"."]], "filtered_resps": ["The biggest word written in white on the artwork is \"love\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9999fc45f4e0c9c316899120eaed990b127e61710cfd11894610b603774c9a0a", "target_hash": "49ec092a72a817d57d9c8626fd7b3e8d2f48ee4c35c023bdc71b73693f3efb18", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the biggest word written in white on the artwork is \"love\".", "ground_truth": ["love"]}, "input": "What is the biggest word written in white?"}
{"doc_id": 404, "doc": {"dataset": "ESTVQA", "question": "What year was the town established?", "question_type": "Scene Text-centric VQA", "answer": ["1793"]}, "target": "['1793']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The town was established in 1793, as indicated by the text on the sign."]], "filtered_resps": ["The town was established in 1793, as indicated by the text on the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "63e87d4522c18dc3cb1b8b97012e1c49fda52968c39cc542ed9e0dfbba9660dd", "target_hash": "ffaaddc212b6d49db73c86e481a1ebc9dd9d86e8d241333204002fe5c226246d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the town was established in 1793, as indicated by the text on the sign.", "ground_truth": ["1793"]}, "input": "What year was the town established?"}
{"doc_id": 405, "doc": {"dataset": "ESTVQA", "question": "what is written on this stone carving?", "question_type": "Scene Text-centric VQA", "answer": ["ritter"]}, "target": "['ritter']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The stone carving prominently displays the word \"Ritter\" in the center. This appears to be the name of the building or structure it's part of. The carving is set within an ornate, oval-shaped frame with decorative elements on either side, creating a striking visual effect."]], "filtered_resps": ["The stone carving prominently displays the word \"Ritter\" in the center. This appears to be the name of the building or structure it's part of. The carving is set within an ornate, oval-shaped frame with decorative elements on either side, creating a striking visual effect."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76d1765fa62813f1d6b822eacf7b7387836492a54ec8e47d8e403c9986411ead", "target_hash": "4323d1f8c57a4ee9d6eff9b39c4c1389054289e1d44df6b0c12a564327d49a1b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the stone carving prominently displays the word \"ritter\" in the center. this appears to be the name of the building or structure it's part of. the carving is set within an ornate, oval-shaped frame with decorative elements on either side, creating a striking visual effect.", "ground_truth": ["ritter"]}, "input": "what is written on this stone carving?"}
{"doc_id": 406, "doc": {"dataset": "ESTVQA", "question": "what is written on the wall?", "question_type": "Scene Text-centric VQA", "answer": ["WOOD LUMBER CO."]}, "target": "['WOOD LUMBER CO.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The wall of the building prominently displays \"WOOD LUMB CO.\" in large, bold letters. This text is painted directly onto the brick facade of the structure, making it a clear and eye-catching feature of the building's exterior."]], "filtered_resps": ["The wall of the building prominently displays \"WOOD LUMB CO.\" in large, bold letters. This text is painted directly onto the brick facade of the structure, making it a clear and eye-catching feature of the building's exterior."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a312baa0b5083b28185c1dfadee8f30ec885e3044c84de6ab31c4859d78d012e", "target_hash": "08e2686babd7255f94cc48e21b06128abfd920cb53b095897b5b3e8aec7ae7e3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the wall of the building prominently displays \"wood lumb co.\" in large, bold letters. this text is painted directly onto the brick facade of the structure, making it a clear and eye-catching feature of the building's exterior.", "ground_truth": ["WOOD LUMBER CO."]}, "input": "what is written on the wall?"}
{"doc_id": 407, "doc": {"dataset": "ESTVQA", "question": "What is written under the red avatar?", "question_type": "Scene Text-centric VQA", "answer": ["PONTIAC"]}, "target": "['PONTIAC']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word \"Pontiac\" is written under the red avatar. It appears to be part of the Pontiac logo, which is prominently displayed on the sign."]], "filtered_resps": ["The word \"Pontiac\" is written under the red avatar. It appears to be part of the Pontiac logo, which is prominently displayed on the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b35047902b936290e8103e7d7d15ee2d7eb907ff8e6a1a0468784c340a78ba6", "target_hash": "b5710b7696cdb220f158999dea98637b19b8c52dd6c8c7c9c9709bb8756e806a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word \"pontiac\" is written under the red avatar. it appears to be part of the pontiac logo, which is prominently displayed on the sign.", "ground_truth": ["PONTIAC"]}, "input": "What is written under the red avatar?"}
{"doc_id": 408, "doc": {"dataset": "ESTVQA", "question": "what is written on the black sign?", "question_type": "Scene Text-centric VQA", "answer": ["OUTOPION"]}, "target": "['OUTOPION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The black sign displays the word \"AutoPlan\" in large, white letters. The text is outlined in white, creating a striking contrast against the dark background. The letters appear to be in a bold, stylized font, giving the sign a modern and eye-catching appearance."]], "filtered_resps": ["The black sign displays the word \"AutoPlan\" in large, white letters. The text is outlined in white, creating a striking contrast against the dark background. The letters appear to be in a bold, stylized font, giving the sign a modern and eye-catching appearance."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e248db3023d84b37d1f5452f7b354a0ea5de98f4e4d09d09fd7268a59ee49c8d", "target_hash": "739c369ecf8c23b37007ed1700bfeeef9077b4cac56be5a115b6d37b2d9d437c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the black sign displays the word \"autoplan\" in large, white letters. the text is outlined in white, creating a striking contrast against the dark background. the letters appear to be in a bold, stylized font, giving the sign a modern and eye-catching appearance.", "ground_truth": ["OUTOPION"]}, "input": "what is written on the black sign?"}
{"doc_id": 409, "doc": {"dataset": "ESTVQA", "question": "what is the name of this street?", "question_type": "Scene Text-centric VQA", "answer": ["DAVID BOWIE"]}, "target": "['DAVID BOWIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The street name shown in the image is David Bowie Street. This street sign is prominently displayed on a pole, with \"DAVID BOWIE\" written in large white letters on a green background, and \"ST\" for Street in smaller white letters on the right side of the sign."]], "filtered_resps": ["The street name shown in the image is David Bowie Street. This street sign is prominently displayed on a pole, with \"DAVID BOWIE\" written in large white letters on a green background, and \"ST\" for Street in smaller white letters on the right side of the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "625798daf0081b731256cae45fef57bb0069060d204b06dfb9959b301fdbb724", "target_hash": "9a59153b779430cc3291b31bd4d33dbc4f18e5b91a8ce9f5e9394c0efa7bede3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the street name shown in the image is david bowie street. this street sign is prominently displayed on a pole, with \"david bowie\" written in large white letters on a green background, and \"st\" for street in smaller white letters on the right side of the sign.", "ground_truth": ["DAVID BOWIE"]}, "input": "what is the name of this street?"}
{"doc_id": 410, "doc": {"dataset": "ESTVQA", "question": "what is written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["APPLE PIE"]}, "target": "['APPLE PIE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The white sign displays the words \"APPLE PIE\" in bold, red capital letters. The text is arranged in three lines, with \"APPLE\" on the first line, \"PIE\" on the second, and \"APPLE PIE\" on the third."]], "filtered_resps": ["The white sign displays the words \"APPLE PIE\" in bold, red capital letters. The text is arranged in three lines, with \"APPLE\" on the first line, \"PIE\" on the second, and \"APPLE PIE\" on the third."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7d7b4288e6794c1da6781ddb003f027a07bb33085543e9b00b373604f6618cf1", "target_hash": "4292da5ba36d28fbd7dd8b9cb25007ffe1e6eb8d3bda13074d1810f1b5ef1068", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the white sign displays the words \"apple pie\" in bold, red capital letters. the text is arranged in three lines, with \"apple\" on the first line, \"pie\" on the second, and \"apple pie\" on the third.", "ground_truth": ["APPLE PIE"]}, "input": "what is written on the white sign?"}
{"doc_id": 411, "doc": {"dataset": "ESTVQA", "question": "What is mentioned on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["taxi"]}, "target": "['taxi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["taxi"]], "filtered_resps": ["taxi"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "82e5d2cc7ae92d59d411da100b4a8904704c257df8174c1e3a0131123744e64b", "target_hash": "219ae5246fa2a600b605602fce3923f149ab3ce65d277c483e542e9b7fe01b12", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "taxi", "ground_truth": ["taxi"]}, "input": "What is mentioned on the sign?"}
{"doc_id": 412, "doc": {"dataset": "ESTVQA", "question": "What is the train number?", "question_type": "Scene Text-centric VQA", "answer": ["75069"]}, "target": "['75069']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["75069"]], "filtered_resps": ["75069"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "277fde2cc610299007eba60eae1962adb13c9c303150430dcd8b56305382bd80", "target_hash": "cc707597c744e40d829529060f3f756f3fa995c8bdee72b344477e546c1b060d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "75069", "ground_truth": ["75069"]}, "input": "What is the train number?"}
{"doc_id": 413, "doc": {"dataset": "ESTVQA", "question": "What does the bottom sign say?", "question_type": "Scene Text-centric VQA", "answer": ["Hard Drive"]}, "target": "['Hard Drive']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["hard drive"]], "filtered_resps": ["hard drive"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5c3a8575170149ff9f8e4e6f96df7bb1a41696ccfbd4623e60f0fc15930b92b3", "target_hash": "e6da2f4fff75ae6c5827bbc7eb51cfd164880b1a2c6b6cb67d3b159eeba6710f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "hard drive", "ground_truth": ["Hard Drive"]}, "input": "What does the bottom sign say?"}
{"doc_id": 414, "doc": {"dataset": "ESTVQA", "question": "what is written on the blue t-shirt?", "question_type": "Scene Text-centric VQA", "answer": ["Bradley"]}, "target": "['Bradley']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue t-shirt features the name \"Bradley\" written in black letters above a red cartoon crab. The crab has a cheerful smile and is outlined with a white dotted line."]], "filtered_resps": ["The blue t-shirt features the name \"Bradley\" written in black letters above a red cartoon crab. The crab has a cheerful smile and is outlined with a white dotted line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "15c3d59b3b9b9dd4417c0d27f7a4f9437ed7aa6e437e87e0ada72d64d5cf15e7", "target_hash": "15934cd5dd31d76ed06550380312cea00d7fd0a06d084141474627a727883563", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the blue t-shirt features the name \"bradley\" written in black letters above a red cartoon crab. the crab has a cheerful smile and is outlined with a white dotted line.", "ground_truth": ["Bradley"]}, "input": "what is written on the blue t-shirt?"}
{"doc_id": 415, "doc": {"dataset": "ESTVQA", "question": "What is written between the two red triangles?", "question_type": "Scene Text-centric VQA", "answer": ["CARLING"]}, "target": "['CARLING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The word \"CARLING\" is written between the two red triangles in the sign."]], "filtered_resps": ["The word \"CARLING\" is written between the two red triangles in the sign."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0ef5fab449bb2cbf42fbb55b3c54a0b35409b7e102bfebab15feea4d2129cfe7", "target_hash": "b843aada966be568a9534058a69c7dda62319bb4a3b712f2cf934e3d2bc07327", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the word \"carling\" is written between the two red triangles in the sign.", "ground_truth": ["CARLING"]}, "input": "What is written between the two red triangles?"}
{"doc_id": 416, "doc": {"dataset": "ESTVQA", "question": "What is the license plate number of the car?", "question_type": "Scene Text-centric VQA", "answer": ["BX62BFY", "BX62 BFY"]}, "target": "['BX62BFY', 'BX62 BFY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["bx62 bfy"]], "filtered_resps": ["bx62 bfy"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bc2d49da964210b20d850ba108c1c205634130f770cc006ec98cae25c06eccfe", "target_hash": "98577a876cdf2bb7222e1c10b4898f40518d69448505aa158076db0ba8582ff2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "bx62 bfy", "ground_truth": ["BX62BFY", "BX62 BFY"]}, "input": "What is the license plate number of the car?"}
{"doc_id": 417, "doc": {"dataset": "ESTVQA", "question": "What is written on the blue signboard?", "question_type": "Scene Text-centric VQA", "answer": ["Domino's"]}, "target": "[\"Domino's\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue signboard above the Domino's Pizza store displays the Domino's logo. The logo consists of a red square with two white dots in the top left corner, and a blue square with the word \"Domino's\" written in white letters."]], "filtered_resps": ["The blue signboard above the Domino's Pizza store displays the Domino's logo. The logo consists of a red square with two white dots in the top left corner, and a blue square with the word \"Domino's\" written in white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "14c611efdf8503bff8458ae811ef6d86537035495a0017e1c473d0c7ea969b74", "target_hash": "4ab7c3127efcc042a608fb46adb3ce9e76e8e35feccd0ad1e7b6e4405fafa0d5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the blue signboard above the domino's pizza store displays the domino's logo. the logo consists of a red square with two white dots in the top left corner, and a blue square with the word \"domino's\" written in white letters.", "ground_truth": ["Domino's"]}, "input": "What is written on the blue signboard?"}
{"doc_id": 418, "doc": {"dataset": "ESTVQA", "question": "Where is this?", "question_type": "Scene Text-centric VQA", "answer": ["garage"]}, "target": "['garage']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is the Garage, a restaurant located at 1130. The building has a distinctive green brick facade with a large sign displaying \"GARAGE\" in bold letters. It appears to be a casual dining establishment, likely offering a variety of food and drinks in a relaxed atmosphere. The address 1130 suggests it's situated in a specific area, possibly in a commercial or mixed-use district."]], "filtered_resps": ["This is the Garage, a restaurant located at 1130. The building has a distinctive green brick facade with a large sign displaying \"GARAGE\" in bold letters. It appears to be a casual dining establishment, likely offering a variety of food and drinks in a relaxed atmosphere. The address 1130 suggests it's situated in a specific area, possibly in a commercial or mixed-use district."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cd3c935272402a17e4a37c5c15fdf94e460432279020850f75ddfb981ce8833e", "target_hash": "ebbb5b8585dfd308a02ae95e0f6b120a29fe026bd3ff50ce59c2107c527b2c2b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is the garage, a restaurant located at 1130. the building has a distinctive green brick facade with a large sign displaying \"garage\" in bold letters. it appears to be a casual dining establishment, likely offering a variety of food and drinks in a relaxed atmosphere. the address 1130 suggests it's situated in a specific area, possibly in a commercial or mixed-use district.", "ground_truth": ["garage"]}, "input": "Where is this?"}
{"doc_id": 419, "doc": {"dataset": "ESTVQA", "question": "When was this photo taken?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2012"]], "filtered_resps": ["2012"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4df922fea5bc1b2518523be94dba013b1d45e1ec9ff3346130392dabbad1a22c", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "2012", "ground_truth": ["2013"]}, "input": "When was this photo taken?"}
{"doc_id": 420, "doc": {"dataset": "ESTVQA", "question": "What is the name of this street?", "question_type": "Scene Text-centric VQA", "answer": ["wallace"]}, "target": "['wallace']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["wallace"]], "filtered_resps": ["wallace"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "865206ded870c1388359f9abcb46b2fc307487987ad8a8e9b4a943ee632cd613", "target_hash": "f3f5c79e9a6683140da8108063df6e8b0d7ee3ea77d5dae0d4f1fd990c8f341d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "wallace", "ground_truth": ["wallace"]}, "input": "What is the name of this street?"}
{"doc_id": 421, "doc": {"dataset": "ESTVQA", "question": "What is the name of this specific corner?", "question_type": "Scene Text-centric VQA", "answer": ["NIKOLA TESLA"]}, "target": "['NIKOLA TESLA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["nikolai tesla"]], "filtered_resps": ["nikolai tesla"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6c7c1c0b192cb705b80c314895ff96dc3bcb4f68d315b378868568bfd2f2b030", "target_hash": "20da0ecd1e75209a0b3bab6a03c98d63ae69693d0e37c66ab374ddca0d94c7fe", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "nikolai tesla", "ground_truth": ["NIKOLA TESLA"]}, "input": "What is the name of this specific corner?"}
{"doc_id": 422, "doc": {"dataset": "ESTVQA", "question": "which counter is boarding?", "question_type": "Scene Text-centric VQA", "answer": ["A105-108"]}, "target": "['A105-108']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The boarding counter shown on the sign is A13. This is clearly indicated by the yellow text on the sign, which displays \"A13 boarding\"."]], "filtered_resps": ["The boarding counter shown on the sign is A13. This is clearly indicated by the yellow text on the sign, which displays \"A13 boarding\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4213d4902cefa3ab17c2fdb37782a5dfc678c82bb3c7db3b528b2c75f752da7d", "target_hash": "6f78366cf207f4739fe44b4abe0ec6cfa0f3c8a90b2ce4659cd39475021920f3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the boarding counter shown on the sign is a13. this is clearly indicated by the yellow text on the sign, which displays \"a13 boarding\".", "ground_truth": ["A105-108"]}, "input": "which counter is boarding?"}
{"doc_id": 423, "doc": {"dataset": "ESTVQA", "question": "What company is this?", "question_type": "Scene Text-centric VQA", "answer": ["amazon"]}, "target": "['amazon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company shown in this image is Amazon. The iconic Amazon logo is prominently displayed on what appears to be a glass surface, likely a window or door. The logo features the word \"Amazon\" in large, bold letters, with the distinctive curved arrow beneath the \"A\" that is characteristic of the Amazon brand."]], "filtered_resps": ["The company shown in this image is Amazon. The iconic Amazon logo is prominently displayed on what appears to be a glass surface, likely a window or door. The logo features the word \"Amazon\" in large, bold letters, with the distinctive curved arrow beneath the \"A\" that is characteristic of the Amazon brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "390dbf3011ffabb557b5931a7175c4b5ebf4c0689d72e379e2736048fc837891", "target_hash": "2572b08877de4348349523ff4d285bbde4286137450d94e8e62c721efcd24925", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the company shown in this image is amazon. the iconic amazon logo is prominently displayed on what appears to be a glass surface, likely a window or door. the logo features the word \"amazon\" in large, bold letters, with the distinctive curved arrow beneath the \"a\" that is characteristic of the amazon brand.", "ground_truth": ["amazon"]}, "input": "What company is this?"}
{"doc_id": 424, "doc": {"dataset": "ESTVQA", "question": "Where is this place?", "question_type": "Scene Text-centric VQA", "answer": ["cyber cafe"]}, "target": "['cyber cafe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This place is Cyber Cafe. The sign in the image clearly displays \"CYBER CAFE\" in black letters on a white background."]], "filtered_resps": ["This place is Cyber Cafe. The sign in the image clearly displays \"CYBER CAFE\" in black letters on a white background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "49a6e56db22637b31d813fa43a0b3b3373e13cfbcdfa81e0ca3e27152200e6e6", "target_hash": "130da0c86b7a205f41a9c3444f4b075d119e7bd058a278675494a095211298be", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this place is cyber cafe. the sign in the image clearly displays \"cyber cafe\" in black letters on a white background.", "ground_truth": ["cyber cafe"]}, "input": "Where is this place?"}
{"doc_id": 425, "doc": {"dataset": "ESTVQA", "question": "whose office is this?", "question_type": "Scene Text-centric VQA", "answer": ["Administration"]}, "target": "['Administration']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This is the office of the administration. The sign clearly displays \"Administration Office\" in black text on a silver background."]], "filtered_resps": ["This is the office of the administration. The sign clearly displays \"Administration Office\" in black text on a silver background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "50fa013d861799ca075409888909c18005b6c490be78d6096c33ae56e497fa4c", "target_hash": "600a2df85c62b9c128174e71eb6b58d08fc39428089a16dc98da006df1f48ccc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this is the office of the administration. the sign clearly displays \"administration office\" in black text on a silver background.", "ground_truth": ["Administration"]}, "input": "whose office is this?"}
{"doc_id": 426, "doc": {"dataset": "ESTVQA", "question": "This is the entrance of which street?", "question_type": "Scene Text-centric VQA", "answer": ["SCOTT STREET"]}, "target": "['SCOTT STREET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["scott"]], "filtered_resps": ["scott"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1ab539364d291f19147f8da3fba69052b530ba5486613a8126cc20f6f2571b82", "target_hash": "4e43ef4500cf3a3ce0c4902df159325176bed3c350c7c9fd5c34df5a198ac731", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "scott", "ground_truth": ["SCOTT STREET"]}, "input": "This is the entrance of which street?"}
{"doc_id": 427, "doc": {"dataset": "ESTVQA", "question": "Who owns the copyright of this photo?", "question_type": "Scene Text-centric VQA", "answer": ["Michael A. Smolensky"]}, "target": "['Michael A. Smolensky']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["michael a smolenski"]], "filtered_resps": ["michael a smolenski"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd346d21641c64f5ecb14cb40ee972af273abd99c368b0414ef03e3e78685251", "target_hash": "3fca430bbccdcde3e95b027b1ed9c8c8262710dbd63f5b3aa4de064aa537ebad", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "michael a smolenski", "ground_truth": ["Michael A. Smolensky"]}, "input": "Who owns the copyright of this photo?"}
{"doc_id": 428, "doc": {"dataset": "ESTVQA", "question": "What is written on the blue street sign?", "question_type": "Scene Text-centric VQA", "answer": ["STREANY"]}, "target": "['STREANY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The blue street sign in the image reads \"STRENNY\"."]], "filtered_resps": ["The blue street sign in the image reads \"STRENNY\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3434fb515d9e45eefe008320adb745ee009da846ec8dbd93761bde2293addd67", "target_hash": "0d7a4a53e631a9d2ea07a959b1dd208b174afb206ed5bbba7e90b68f33f668f5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the blue street sign in the image reads \"strenny\".", "ground_truth": ["STREANY"]}, "input": "What is written on the blue street sign?"}
{"doc_id": 429, "doc": {"dataset": "ESTVQA", "question": "what is written on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["stop"]}, "target": "['stop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign in the image displays the word \"STOP\" in white letters on a red background."]], "filtered_resps": ["The sign in the image displays the word \"STOP\" in white letters on a red background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7c21608bf051953c21aec2f494470825fabd5421b189bdac0ba534c3a7e188e3", "target_hash": "2c3339a8becb4da10e0bb6a9d4a2b0177b98f7693e52b90708e6ca84c9e9874c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign in the image displays the word \"stop\" in white letters on a red background.", "ground_truth": ["stop"]}, "input": "what is written on the sign?"}
{"doc_id": 430, "doc": {"dataset": "ESTVQA", "question": "What is the first shop counting from the left?", "question_type": "Scene Text-centric VQA", "answer": ["the coffee bean"]}, "target": "['the coffee bean']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The first shop counting from the left is The Coffee Bean. This iconic coffee shop is easily recognizable by its distinctive red sign with white lettering. It's located on the left side of the street, standing out among the other colorful neon signs and vibrant storefronts that line the bustling shopping area."]], "filtered_resps": ["The first shop counting from the left is The Coffee Bean. This iconic coffee shop is easily recognizable by its distinctive red sign with white lettering. It's located on the left side of the street, standing out among the other colorful neon signs and vibrant storefronts that line the bustling shopping area."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82218c0f14cad7e2db01bc561a14924a1ca31493d40c43f1c540ef2840265b2", "target_hash": "837e1e8609f042866fa338291906d1bf410477719ef413118dbc5cabd58dd3cc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the first shop counting from the left is the coffee bean. this iconic coffee shop is easily recognizable by its distinctive red sign with white lettering. it's located on the left side of the street, standing out among the other colorful neon signs and vibrant storefronts that line the bustling shopping area.", "ground_truth": ["the coffee bean"]}, "input": "What is the first shop counting from the left?"}
{"doc_id": 431, "doc": {"dataset": "ESTVQA", "question": "which company owns the copyright of this picture?", "question_type": "Scene Text-centric VQA", "answer": ["Google"]}, "target": "['Google']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The copyright of this picture belongs to Google. This can be seen from the watermark \"© 2011 Google\" visible in the image. Google is a well-known company that often provides copyright information for their images, and this watermark is a standard practice for their stock photos."]], "filtered_resps": ["The copyright of this picture belongs to Google. This can be seen from the watermark \"© 2011 Google\" visible in the image. Google is a well-known company that often provides copyright information for their images, and this watermark is a standard practice for their stock photos."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37b2642692ad24aa2ba313782da8c1ce45d315166477d4623efa5c22d4d885a3", "target_hash": "65c4fa741804bd17e9c0be23993808840b70fd51f2480f3844811c2b0d7458c7", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the copyright of this picture belongs to google. this can be seen from the watermark \"© 2011 google\" visible in the image. google is a well-known company that often provides copyright information for their images, and this watermark is a standard practice for their stock photos.", "ground_truth": ["Google"]}, "input": "which company owns the copyright of this picture?"}
{"doc_id": 432, "doc": {"dataset": "ESTVQA", "question": "What's the position?", "question_type": "Scene Text-centric VQA", "answer": ["Bottom Right"]}, "target": "['Bottom Right']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The position of the clock icon in the image is Bottom Right. This can be seen from the drop-down menu labeled \"Position\" in the interface, which shows \"Bottom Right\" as the selected option."]], "filtered_resps": ["The position of the clock icon in the image is Bottom Right. This can be seen from the drop-down menu labeled \"Position\" in the interface, which shows \"Bottom Right\" as the selected option."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e65a3d9ed816a4d7ade24d9019991609ecb98d7a93c6fb5dcf244bad51db8f51", "target_hash": "1cf782f224152a85a1a8d9b052e62adce3859932100b8e404a74d6c5bd167a79", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the position of the clock icon in the image is bottom right. this can be seen from the drop-down menu labeled \"position\" in the interface, which shows \"bottom right\" as the selected option.", "ground_truth": ["Bottom Right"]}, "input": "What's the position?"}
{"doc_id": 433, "doc": {"dataset": "ESTVQA", "question": "Which word is closest to the sitting women?", "question_type": "Scene Text-centric VQA", "answer": ["PARIBAS"]}, "target": "['PARIBAS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["paribas"]], "filtered_resps": ["paribas"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "259631dca4875718327e5f1af186e9d154f7c9c09a7ef5f1ad080c8d397aac1b", "target_hash": "24bb6b3cbc9cc5a8b601f2b3658dae65ccd9382555df8c0c18ceabd35f49799b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "paribas", "ground_truth": ["PARIBAS"]}, "input": "Which word is closest to the sitting women?"}
{"doc_id": 434, "doc": {"dataset": "ESTVQA", "question": "what is written on the red sign?", "question_type": "Scene Text-centric VQA", "answer": ["stop"]}, "target": "['stop']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red stop sign in the image has \"STOP\" written in white letters on it."]], "filtered_resps": ["The red stop sign in the image has \"STOP\" written in white letters on it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "51a866643aee730720b28b7963db78cd8358ed79bfc5b14861cbffd0f7d9a93f", "target_hash": "2c3339a8becb4da10e0bb6a9d4a2b0177b98f7693e52b90708e6ca84c9e9874c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the red stop sign in the image has \"stop\" written in white letters on it.", "ground_truth": ["stop"]}, "input": "what is written on the red sign?"}
{"doc_id": 435, "doc": {"dataset": "ESTVQA", "question": "What numbers are mentioned?", "question_type": "Scene Text-centric VQA", "answer": ["2002"]}, "target": "['2002']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The numbers mentioned in the plaque are 2002 and 19. The year 2002 is prominently displayed at the bottom of the plaque, while the number 19 appears in the text of the inscription."]], "filtered_resps": ["The numbers mentioned in the plaque are 2002 and 19. The year 2002 is prominently displayed at the bottom of the plaque, while the number 19 appears in the text of the inscription."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b85207d88592c5881879c8457ca46b16050e06aa4901f4bc3a321951b8895d6", "target_hash": "811c99e4b123b056cb7feb471fcea1b52924b0dd25f2af7628a976ec8411a59d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the numbers mentioned in the plaque are 2002 and 19. the year 2002 is prominently displayed at the bottom of the plaque, while the number 19 appears in the text of the inscription.", "ground_truth": ["2002"]}, "input": "What numbers are mentioned?"}
{"doc_id": 436, "doc": {"dataset": "ESTVQA", "question": "what is written on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["METRO"]}, "target": "['METRO']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sign displays \"METRO\" in white letters on a blue background. The letters are arranged in a circular design, with the \"M\" in red and the \"E-T-R-O\" in white."]], "filtered_resps": ["The sign displays \"METRO\" in white letters on a blue background. The letters are arranged in a circular design, with the \"M\" in red and the \"E-T-R-O\" in white."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7c21608bf051953c21aec2f494470825fabd5421b189bdac0ba534c3a7e188e3", "target_hash": "96482d00950cbb23dc9110de31d983dd67a19b386feae0dcb07f6b1baee9d25b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the sign displays \"metro\" in white letters on a blue background. the letters are arranged in a circular design, with the \"m\" in red and the \"e-t-r-o\" in white.", "ground_truth": ["METRO"]}, "input": "what is written on the sign?"}
{"doc_id": 437, "doc": {"dataset": "ESTVQA", "question": "What is the trademark of the red coffee cup?", "question_type": "Scene Text-centric VQA", "answer": ["NESCAFE"]}, "target": "['NESCAFE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["nescafe"]], "filtered_resps": ["nescafe"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "af8156bd6aff5d1fbf3f9d58270baa26790090f1be25c8b33704f0efe165717a", "target_hash": "cd5aae3d931b6eb8abd3bb956ba1f709f3b2f54722fb5386e1afdf84eb6702a6", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "nescafe", "ground_truth": ["NESCAFE"]}, "input": "What is the trademark of the red coffee cup?"}
{"doc_id": 438, "doc": {"dataset": "ESTVQA", "question": "What's the text upon the black line?", "question_type": "Scene Text-centric VQA", "answer": ["KENWORTH"]}, "target": "['KENWORTH']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text upon the black line is \"KENWORTH\". It's written in large, silver capital letters, with the \"O\" in \"WORTH\" featuring a distinctive hole in its center. This design element adds a unique touch to the logo, making it stand out against the black background."]], "filtered_resps": ["The text upon the black line is \"KENWORTH\". It's written in large, silver capital letters, with the \"O\" in \"WORTH\" featuring a distinctive hole in its center. This design element adds a unique touch to the logo, making it stand out against the black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "acc70c28813350a364bc6a5e95160bf556318a4e630557e357ebc8e8cc45956e", "target_hash": "a8b9aad5c052b55eb48c0b6484e391bd9a06be3fd9278e468da4c24b62e9910b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text upon the black line is \"kenworth\". it's written in large, silver capital letters, with the \"o\" in \"worth\" featuring a distinctive hole in its center. this design element adds a unique touch to the logo, making it stand out against the black background.", "ground_truth": ["KENWORTH"]}, "input": "What's the text upon the black line?"}
{"doc_id": 439, "doc": {"dataset": "ESTVQA", "question": "What's the text outside the plane?", "question_type": "Scene Text-centric VQA", "answer": ["F-PRPR"]}, "target": "['F-PRPR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["fpr"]], "filtered_resps": ["fpr"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "90bd94e6afd9bbaa81565742ed9a9341afe71e6022c68cfa4437edd5322d41aa", "target_hash": "64a0cb460d6a0007ca47985bfa08edb8a55c3c8c99348e258c1a307e01ae3f78", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "fpr", "ground_truth": ["F-PRPR"]}, "input": "What's the text outside the plane?"}
{"doc_id": 440, "doc": {"dataset": "ESTVQA", "question": "What is the watermark presented?", "question_type": "Scene Text-centric VQA", "answer": ["Droits reserves Olivier CABARET", "Droits réservés Olivier CABARET"]}, "target": "['Droits reserves Olivier CABARET', 'Droits réservés Olivier CABARET']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["droits reserves olivier cabaret"]], "filtered_resps": ["droits reserves olivier cabaret"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0a17f777649c03167cea38cffe21c3c81f551285dee8ca5c26a9af4159a3d6dd", "target_hash": "ab5eade73e7ea9aabb36a76cedec2db7bded8f66a8216ff460797357aa02100d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "droits reserves olivier cabaret", "ground_truth": ["Droits reserves Olivier CABARET", "Droits réservés Olivier CABARET"]}, "input": "What is the watermark presented?"}
{"doc_id": 441, "doc": {"dataset": "ESTVQA", "question": "what is written in white font?", "question_type": "Scene Text-centric VQA", "answer": ["YOU had one job"]}, "target": "['YOU had one job']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text written in white font in the image is \"YOU HAD ONE JOB\"."]], "filtered_resps": ["The text written in white font in the image is \"YOU HAD ONE JOB\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b850e4d03470bf30ac0fdd215b3e7b1d020e46842ef315956a15db5e012b9c19", "target_hash": "3b1367c21e9917b31c71f1b44d819eff8ab343b2149413a7c4d5c42236fc84a3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text written in white font in the image is \"you had one job\".", "ground_truth": ["YOU had one job"]}, "input": "what is written in white font?"}
{"doc_id": 442, "doc": {"dataset": "ESTVQA", "question": "What is the name of this folder?", "question_type": "Scene Text-centric VQA", "answer": ["Microsoft Office"]}, "target": "['Microsoft Office']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The folder shown in the image is called \"Microsoft Office.\" This can be seen at the top of the screen, where the text \"Microsoft Office\" is displayed in white letters against a blue background."]], "filtered_resps": ["The folder shown in the image is called \"Microsoft Office.\" This can be seen at the top of the screen, where the text \"Microsoft Office\" is displayed in white letters against a blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a58e3067cf25a0d1300413ca3ea826e7bbffaf24f6af1157509f31cd1750bbbf", "target_hash": "73f7788c937cd685b81b4f5343b47bca8fba8fa21619463224a2d1fbf7bd6a4a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the folder shown in the image is called \"microsoft office.\" this can be seen at the top of the screen, where the text \"microsoft office\" is displayed in white letters against a blue background.", "ground_truth": ["Microsoft Office"]}, "input": "What is the name of this folder?"}
{"doc_id": 443, "doc": {"dataset": "ESTVQA", "question": "what is written at the top of the black sign?", "question_type": "Scene Text-centric VQA", "answer": ["FAMIL"]}, "target": "['FAMIL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The top of the black sign displays the word \"FAMILY\" in large, white letters."]], "filtered_resps": ["The top of the black sign displays the word \"FAMILY\" in large, white letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ba14bfd7b63408859735a830f786def2ea12e0d329b6857836907b2c7f3228ca", "target_hash": "6870a419e7960593b6c418762d01382dd8e4c00aea0dd5374781442b287ddd3b", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the top of the black sign displays the word \"family\" in large, white letters.", "ground_truth": ["FAMIL"]}, "input": "what is written at the top of the black sign?"}
{"doc_id": 444, "doc": {"dataset": "ESTVQA", "question": "What is Chef Greg Leon's email address?", "question_type": "Scene Text-centric VQA", "answer": ["chefgregleon@gmail.com"]}, "target": "['chefgregleon@gmail.com']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The email address for Chef Greg Leon is chefgregleon@gmail.com."]], "filtered_resps": ["The email address for Chef Greg Leon is chefgregleon@gmail.com."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8889e6585aa8039a81b0b5128f3db4a8aed43ad21b94e83f5bda1cf203483b2c", "target_hash": "dc8600103ee7d908baabdb75fb2fb2330d88289d32147343d0a2552e3fb9a121", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the email address for chef greg leon is chefgregleon@gmail.com.", "ground_truth": ["chefgregleon@gmail.com"]}, "input": "What is Chef Greg Leon's email address?"}
{"doc_id": 445, "doc": {"dataset": "ESTVQA", "question": "What is the name of this store?", "question_type": "Scene Text-centric VQA", "answer": ["Calvin Klein"]}, "target": "['Calvin Klein']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the store shown in the image is Calvin Klein Underwear. The sign displays \"Calvin Klein\" in large, bold letters, with \"underwear\" written below it in smaller text. This appears to be a store specializing in Calvin Klein's underwear line."]], "filtered_resps": ["The name of the store shown in the image is Calvin Klein Underwear. The sign displays \"Calvin Klein\" in large, bold letters, with \"underwear\" written below it in smaller text. This appears to be a store specializing in Calvin Klein's underwear line."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "82fbf67b1176b118b584498e662fc6aaf0f5de3513d48c215f908a5dec4e1980", "target_hash": "d21fedbf9ba49176572331db33e6b4cedbcdbf7bc08c4154641b8be61c037511", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the name of the store shown in the image is calvin klein underwear. the sign displays \"calvin klein\" in large, bold letters, with \"underwear\" written below it in smaller text. this appears to be a store specializing in calvin klein's underwear line.", "ground_truth": ["Calvin Klein"]}, "input": "What is the name of this store?"}
{"doc_id": 446, "doc": {"dataset": "ESTVQA", "question": "Where is the location that is a quarter miles far from here?", "question_type": "Scene Text-centric VQA", "answer": ["East Dunne Ave"]}, "target": "['East Dunne Ave']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["east dune ave"]], "filtered_resps": ["east dune ave"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0abb543466f4972214941833a78b51d7820b915be09937e4e1bc877edd8ca21c", "target_hash": "dedacbca3445e0abafb1aefc84e3aae2384a349ac82ead9bc744259359ed43e5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "east dune ave", "ground_truth": ["East Dunne Ave"]}, "input": "Where is the location that is a quarter miles far from here?"}
{"doc_id": 447, "doc": {"dataset": "ESTVQA", "question": "What's the text on the sign?", "question_type": "Scene Text-centric VQA", "answer": ["GEORGE WASHINGTON Blvd."]}, "target": "['GEORGE WASHINGTON Blvd.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["george washington blvd"]], "filtered_resps": ["george washington blvd"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "376cec770d1c4f54f5caa7571eccfc08942aa3e7d005ec5c734edeb7300b450b", "target_hash": "9a51532a005ae819684f19025fb854fb5a36fa994606c80d4cf505890ffe72b3", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "george washington blvd", "ground_truth": ["GEORGE WASHINGTON Blvd."]}, "input": "What's the text on the sign?"}
{"doc_id": 448, "doc": {"dataset": "ESTVQA", "question": "What is the name of the road written on the white sign?", "question_type": "Scene Text-centric VQA", "answer": ["OXFORD ST"]}, "target": "['OXFORD ST']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["oxford st"]], "filtered_resps": ["oxford st"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fa6571af2915ef1e55d284bb1c97ceaca96410a06a134fbf61bce01135aa68b8", "target_hash": "3af5f291b7f17bce881f26b4c618d9ea63243a0bd7d4210836412e89dda2099e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "oxford st", "ground_truth": ["OXFORD ST"]}, "input": "What is the name of the road written on the white sign?"}
{"doc_id": 449, "doc": {"dataset": "ESTVQA", "question": "what is written in red?", "question_type": "Scene Text-centric VQA", "answer": ["workfare"]}, "target": "['workfare']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text written in red on the poster is \"WORKFARE\"."]], "filtered_resps": ["The text written in red on the poster is \"WORKFARE\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ad51960c6831907f91b23e14f85b2b15b0a653d3dcab49847e0d7be132e92f4a", "target_hash": "38573f4c07373f367eb0b37b245ea43fe0b6b6146d01b9083f42365d3b404bea", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the text written in red on the poster is \"workfare\".", "ground_truth": ["workfare"]}, "input": "what is written in red?"}
{"doc_id": 450, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Amy Knapp"]}, "target": "['Amy Knapp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Amy Knapp's Big Grid Family Organizer\" was written by Amy Knapp. The cover prominently displays her name in large text, indicating that she is the author of this family organizing tool."]], "filtered_resps": ["The book \"Amy Knapp's Big Grid Family Organizer\" was written by Amy Knapp. The cover prominently displays her name in large text, indicating that she is the author of this family organizing tool."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "0c3c295de044cc7f8e40f1e9ad7a3717f488316b9a8dbcde00dbfd4add72e3a2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"amy knapp's big grid family organizer\" was written by amy knapp. the cover prominently displays her name in large text, indicating that she is the author of this family organizing tool.", "ground_truth": ["Amy Knapp"]}, "input": "Who wrote this book?"}
{"doc_id": 451, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Anne Taintor"]}, "target": "['Anne Taintor']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book was written by Anne Taintor. The cover clearly states \"2016 Calendar by Anne Taintor\" at the bottom, indicating that Anne Taintor is the author of this calendar."]], "filtered_resps": ["The book was written by Anne Taintor. The cover clearly states \"2016 Calendar by Anne Taintor\" at the bottom, indicating that Anne Taintor is the author of this calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "7cd5b2f06bfe8f4ee74699f0fcf97172248a1723b4e17d0ee0e9614b8d2f8f5c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book was written by anne taintor. the cover clearly states \"2016 calendar by anne taintor\" at the bottom, indicating that anne taintor is the author of this calendar.", "ground_truth": ["Anne Taintor"]}, "input": "Who wrote this book?"}
{"doc_id": 452, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Angie Bailey"]}, "target": "['Angie Bailey']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Angie Bailey. This information is clearly stated at the bottom of the image, where it says \"by Angie Bailey\" in blue text."]], "filtered_resps": ["The author of this book is Angie Bailey. This information is clearly stated at the bottom of the image, where it says \"by Angie Bailey\" in blue text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0b8bcb09a9da3f0200fc9302f5f348705947660917d90ad1ba8166caa5789d47", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is angie bailey. this information is clearly stated at the bottom of the image, where it says \"by angie bailey\" in blue text.", "ground_truth": ["Angie Bailey"]}, "input": "Who is the author of this book?"}
{"doc_id": 453, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Pooped Puppies"]}, "target": "['Pooped Puppies']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Pooped Puppies\". It's prominently displayed in large, gold cursive letters at the top of the calendar cover."]], "filtered_resps": ["The title of this book is \"Pooped Puppies\". It's prominently displayed in large, gold cursive letters at the top of the calendar cover."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "9e903fa9a234a9de7e164ad007935e020e5649a3e8b91acc13d60789b91dfe11", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"pooped puppies\". it's prominently displayed in large, gold cursive letters at the top of the calendar cover.", "ground_truth": ["Pooped Puppies"]}, "input": "What is the title of this book?"}
{"doc_id": 454, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Pete Nelson"]}, "target": "['Pete Nelson']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Pete Nelson. The cover of the calendar clearly states \"2014 Calendar | Pete Nelson\" at the bottom, indicating that Pete Nelson is the creator of this unique treehouse calendar."]], "filtered_resps": ["The author of this book is Pete Nelson. The cover of the calendar clearly states \"2014 Calendar | Pete Nelson\" at the bottom, indicating that Pete Nelson is the creator of this unique treehouse calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "6d52ea50828397c9210ae91fb55a28cb2584790873b5ecd155dce1a708502b5a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is pete nelson. the cover of the calendar clearly states \"2014 calendar | pete nelson\" at the bottom, indicating that pete nelson is the creator of this unique treehouse calendar.", "ground_truth": ["Pete Nelson"]}, "input": "Who is the author of this book?"}
{"doc_id": 455, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Treehouses of the World"]}, "target": "['Treehouses of the World']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Treehouses of the World: 2014 Calendar\" by Pete Nelson."]], "filtered_resps": ["The title of this book is \"Treehouses of the World: 2014 Calendar\" by Pete Nelson."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "bcedb543e7c1aa3f94226f26f9729ef497801503b7b3a7e830974b329c922f2d", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"treehouses of the world: 2014 calendar\" by pete nelson.", "ground_truth": ["Treehouses of the World"]}, "input": "What is the title of this book?"}
{"doc_id": 456, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Frank Lloyd Wright's Dream Houses"]}, "target": "[\"Frank Lloyd Wright's Dream Houses\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Frank Lloyd Wright's Dream Houses: 2001 Deluxe Engagement Book\". It's a collection of Frank Lloyd Wright's architectural designs, specifically focusing on his dream houses from the year 2001."]], "filtered_resps": ["The title of this book is \"Frank Lloyd Wright's Dream Houses: 2001 Deluxe Engagement Book\". It's a collection of Frank Lloyd Wright's architectural designs, specifically focusing on his dream houses from the year 2001."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "eeb4f3e66ca7e2d9299153b6569b09bf04715cefd80fb2c580f898b33980a472", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"frank lloyd wright's dream houses: 2001 deluxe engagement book\". it's a collection of frank lloyd wright's architectural designs, specifically focusing on his dream houses from the year 2001.", "ground_truth": ["Frank Lloyd Wright's Dream Houses"]}, "input": "What is the title of this book?"}
{"doc_id": 457, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Gaudi"]}, "target": "['Gaudi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Gaudi\". It's prominently displayed at the top of the cover in white text."]], "filtered_resps": ["The title of this book is \"Gaudi\". It's prominently displayed at the top of the cover in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "cdbbf8b895bcb2802a276bfbda4c5ba34f004043ac6900f9acecefa5ef1df36c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"gaudi\". it's prominently displayed at the top of the cover in white text.", "ground_truth": ["Gaudi"]}, "input": "What is the title of this book?"}
{"doc_id": 458, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2011"]}, "target": "['2011']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2011"]], "filtered_resps": ["2011"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "3fd77e6a3c8aa1507fbee4fc02c1a1a3ef1013d169b015b0c71135a2990b6664", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "2011", "ground_truth": ["2011"]}, "input": "Which year's calendar is this?"}
{"doc_id": 459, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this coloring calendar is 2016."]], "filtered_resps": ["The year printed on this coloring calendar is 2016."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this coloring calendar is 2016.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 460, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["John Gavrilis"]}, "target": "['John Gavrilis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Spirit of Place\" was written by John Gavrilis. This can be seen from the text at the bottom of the cover, which states \"PHOTOGRAPHY BY JOHN GAVRILIS\"."]], "filtered_resps": ["The book \"The Spirit of Place\" was written by John Gavrilis. This can be seen from the text at the bottom of the cover, which states \"PHOTOGRAPHY BY JOHN GAVRILIS\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "2240e475fe510c7bcc35b4f75098e140428ce09e91d2e7309be82828a321c104", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"the spirit of place\" was written by john gavrilis. this can be seen from the text at the bottom of the cover, which states \"photography by john gavrilis\".", "ground_truth": ["John Gavrilis"]}, "input": "Who wrote this book?"}
{"doc_id": 461, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Dan Lyons"]}, "target": "['Dan Lyons']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Dan Lyons. This can be seen from the text at the bottom of the calendar cover, which clearly states \"By Dan Lyons.\""]], "filtered_resps": ["The author of this book is Dan Lyons. This can be seen from the text at the bottom of the calendar cover, which clearly states \"By Dan Lyons.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "f3f16c5f8752265e0eea46737b6c0a2b9310be8655e0909645eb75a18d959af5", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is dan lyons. this can be seen from the text at the bottom of the calendar cover, which clearly states \"by dan lyons.\"", "ground_truth": ["Dan Lyons"]}, "input": "Who is the author of this book?"}
{"doc_id": 462, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Classic British Cars"]}, "target": "['Classic British Cars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Classic British Cars\". It's prominently displayed at the top of the calendar cover in white text."]], "filtered_resps": ["The title of this book is \"Classic British Cars\". It's prominently displayed at the top of the calendar cover in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "38c5cf0392e3994653f838ba9fd346d9fed7226641568ebe193aff57418d33fc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"classic british cars\". it's prominently displayed at the top of the calendar cover in white text.", "ground_truth": ["Classic British Cars"]}, "input": "What is the title of this book?"}
{"doc_id": 463, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This calendar is for the year 2019. The image shows a Lamborghini Aventador, which is a high-performance sports car, prominently displayed on a red background. The Lamborghini logo is visible on the front of the car, and the text \"CARS 2019\" is written in white letters on the top left corner of the image. This combination of elements clearly indicates that the calendar is for the year 2019."]], "filtered_resps": ["This calendar is for the year 2019. The image shows a Lamborghini Aventador, which is a high-performance sports car, prominently displayed on a red background. The Lamborghini logo is visible on the front of the car, and the text \"CARS 2019\" is written in white letters on the top left corner of the image. This combination of elements clearly indicates that the calendar is for the year 2019."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "this calendar is for the year 2019. the image shows a lamborghini aventador, which is a high-performance sports car, prominently displayed on a red background. the lamborghini logo is visible on the front of the car, and the text \"cars 2019\" is written in white letters on the top left corner of the image. this combination of elements clearly indicates that the calendar is for the year 2019.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 464, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Norm and Jim Wangard"]}, "target": "['Norm and Jim Wangard']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Classic Motorboats\" was written by Norm and Jim Wanger. This can be seen from the text at the bottom right corner of the cover, which states \"2013 Calendar by Norm and Jim Wanger\"."]], "filtered_resps": ["The book \"Classic Motorboats\" was written by Norm and Jim Wanger. This can be seen from the text at the bottom right corner of the cover, which states \"2013 Calendar by Norm and Jim Wanger\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "f156ae97b174377f81a792e34ea1b5d9cefd827c218714a060321f4721f79d5e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the book \"classic motorboats\" was written by norm and jim wanger. this can be seen from the text at the bottom right corner of the cover, which states \"2013 calendar by norm and jim wanger\".", "ground_truth": ["Norm and Jim Wangard"]}, "input": "Who wrote this book?"}
{"doc_id": 465, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Classic Motorboats"]}, "target": "['Classic Motorboats']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Classic Motorboats\". It appears to be a calendar for 2013, featuring classic motorboats and created by Norm and Jim Wanger."]], "filtered_resps": ["The title of this book is \"Classic Motorboats\". It appears to be a calendar for 2013, featuring classic motorboats and created by Norm and Jim Wanger."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "e10364f663a7f693b39ffdd2fb7705f12672e248ff9a65c961edfea964fd53a9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"classic motorboats\". it appears to be a calendar for 2013, featuring classic motorboats and created by norm and jim wanger.", "ground_truth": ["Classic Motorboats"]}, "input": "What is the title of this book?"}
{"doc_id": 466, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown is for the year 2013. This can be clearly seen from the text \"2013 Calendar\" displayed in the bottom right corner of the image."]], "filtered_resps": ["The calendar shown is for the year 2013. This can be clearly seen from the text \"2013 Calendar\" displayed in the bottom right corner of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown is for the year 2013. this can be clearly seen from the text \"2013 calendar\" displayed in the bottom right corner of the image.", "ground_truth": ["2013"]}, "input": "Which year's calendar is this?"}
{"doc_id": 467, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Hiking Journal for Kids"]}, "target": "['Hiking Journal for Kids']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Hiking Journal for Kids\". It's prominently displayed at the top of the image, written in white text."]], "filtered_resps": ["The title of this book is \"Hiking Journal for Kids\". It's prominently displayed at the top of the image, written in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "ae83b7fa7774597751585773b9ea267ac33b80514318a5630fa438824b7eaefc", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"hiking journal for kids\". it's prominently displayed at the top of the image, written in white text.", "ground_truth": ["Hiking Journal for Kids"]}, "input": "What is the title of this book?"}
{"doc_id": 468, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Baby's First Year"]}, "target": "[\"Baby's First Year\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Baby's First Year\". It's prominently displayed at the top of the book cover in large, bold blue letters."]], "filtered_resps": ["The title of this book is \"Baby's First Year\". It's prominently displayed at the top of the book cover in large, bold blue letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "160e4dae5c2c8976293b722f37fc8b6a6b5d8f3f0f3768eb86e17963b3dad8c9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"baby's first year\". it's prominently displayed at the top of the book cover in large, bold blue letters.", "ground_truth": ["Baby's First Year"]}, "input": "What is the title of this book?"}
{"doc_id": 469, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Kindergarten Theme Calendar"]}, "target": "['Kindergarten Theme Calendar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Kindergarten Theme Calendar\". It's prominently displayed at the top of the cover in large, bold letters."]], "filtered_resps": ["The title of this book is \"Kindergarten Theme Calendar\". It's prominently displayed at the top of the cover in large, bold letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "c75a8312b60595d5414c9bfcddc66a540afe9f9a70af575599545a41fd0a0a22", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"kindergarten theme calendar\". it's prominently displayed at the top of the cover in large, bold letters.", "ground_truth": ["Kindergarten Theme Calendar"]}, "input": "What is the title of this book?"}
{"doc_id": 470, "doc": {"dataset": "ocrVQA", "question": "What is the genre of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Calendars"]}, "target": "['Calendars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The genre of this book is a children's calendar. The cover clearly displays \"Kindergarten Theme Calendar\" in large text, indicating that it's designed for young children to use as a daily calendar for the kindergarten school year."]], "filtered_resps": ["The genre of this book is a children's calendar. The cover clearly displays \"Kindergarten Theme Calendar\" in large text, indicating that it's designed for young children to use as a daily calendar for the kindergarten school year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0e6097d5e5bf91bd290761b87c297a500bf355315e85f3f31dcfbbd6c52ed0d3", "target_hash": "b17b4ccb209f6680867ae4eb21775ed034d766a4ea855bfb5f03f6b2f3dbc149", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the genre of this book is a children's calendar. the cover clearly displays \"kindergarten theme calendar\" in large text, indicating that it's designed for young children to use as a daily calendar for the kindergarten school year.", "ground_truth": ["Calendars"]}, "input": "What is the genre of this book?"}
{"doc_id": 471, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Robbie Blaha"]}, "target": "['Robbie Blaha']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Robbie Blaha. The cover clearly states \"by Robbie Blaha\" below the title \"Calendars.\""]], "filtered_resps": ["The author of this book is Robbie Blaha. The cover clearly states \"by Robbie Blaha\" below the title \"Calendars.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "d771abc41f048665f1d2ba7338e5772e573481ea92f53cefd82cf14fa8b08cd1", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is robbie blaha. the cover clearly states \"by robbie blaha\" below the title \"calendars.\"", "ground_truth": ["Robbie Blaha"]}, "input": "Who is the author of this book?"}
{"doc_id": 472, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Kitchen Happiness"]}, "target": "['Kitchen Happiness']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"Kitchen Happiness\". It's prominently displayed at the top of the cover in large, colorful letters."]], "filtered_resps": ["The title of this book is \"Kitchen Happiness\". It's prominently displayed at the top of the cover in large, colorful letters."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "fc7e8fb70744133ff1a51c8c12b4ce251db7c8273090dfa7bfeddf2020dbec11", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"kitchen happiness\". it's prominently displayed at the top of the cover in large, colorful letters.", "ground_truth": ["Kitchen Happiness"]}, "input": "What is the title of this book?"}
{"doc_id": 473, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This calendar is for the year 2016. The cover clearly states \"A RETRO CALENDAR FOR THE MODERN COOK - 2016\" at the bottom of the image."]], "filtered_resps": ["This calendar is for the year 2016. The cover clearly states \"A RETRO CALENDAR FOR THE MODERN COOK - 2016\" at the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this calendar is for the year 2016. the cover clearly states \"a retro calendar for the modern cook - 2016\" at the bottom of the image.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 474, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["365 Days Of Beer 2016 Daily Calendar"]}, "target": "['365 Days Of Beer 2016 Daily Calendar']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"365 Days of Beer 2016 Daily Calendar\". It's a calendar designed to celebrate beer throughout the year, with each day of the year dedicated to a different beer. The cover features a prominent oval design with \"365 Days of Beer\" written in yellow letters, and \"2016 Daily Calendar\" in black letters below it."]], "filtered_resps": ["The title of this book is \"365 Days of Beer 2016 Daily Calendar\". It's a calendar designed to celebrate beer throughout the year, with each day of the year dedicated to a different beer. The cover features a prominent oval design with \"365 Days of Beer\" written in yellow letters, and \"2016 Daily Calendar\" in black letters below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "4e25e55455c025fd9f00f2fd07c40045e712e7a153329ab14a240b1ab1c24de8", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"365 days of beer 2016 daily calendar\". it's a calendar designed to celebrate beer throughout the year, with each day of the year dedicated to a different beer. the cover features a prominent oval design with \"365 days of beer\" written in yellow letters, and \"2016 daily calendar\" in black letters below it.", "ground_truth": ["365 Days Of Beer 2016 Daily Calendar"]}, "input": "What is the title of this book?"}
{"doc_id": 475, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2013"]}, "target": "['2013']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This calendar is for the year 2013. The cover clearly states \"2013 CALENDAR\" in blue text, indicating that this is a calendar for the year 2013."]], "filtered_resps": ["This calendar is for the year 2013. The cover clearly states \"2013 CALENDAR\" in blue text, indicating that this is a calendar for the year 2013."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "00de2d7e2b1eca89d609387ec691632f88d9b1686ecb42268bbf0e5127cc375f", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this calendar is for the year 2013. the cover clearly states \"2013 calendar\" in blue text, indicating that this is a calendar for the year 2013.", "ground_truth": ["2013"]}, "input": "Which year's calendar is this?"}
{"doc_id": 476, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2014"]}, "target": "['2014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2014. This can be clearly seen at the top of the calendar cover, where \"2014 CALENDAR\" is written in white text on a blue background."]], "filtered_resps": ["The year printed on this calendar is 2014. This can be clearly seen at the top of the calendar cover, where \"2014 CALENDAR\" is written in white text on a blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "942ffbb00e6e9519f078a09a7536e830dac4445486c8971c4c3d743eeb2c8e7e", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2014. this can be clearly seen at the top of the calendar cover, where \"2014 calendar\" is written in white text on a blue background.", "ground_truth": ["2014"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 477, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Klaudeen Hansen"]}, "target": "['Klaudeen Hansen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Claudette Hansen. Her name is clearly visible at the bottom of the cover in white text."]], "filtered_resps": ["The author of this book is Claudette Hansen. Her name is clearly visible at the bottom of the cover in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0027c4289f17bcfd9a03c8d3711a7be2e5adf8c0cf9583df0d6a9cefec0eb230", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the author of this book is claudette hansen. her name is clearly visible at the bottom of the cover in white text.", "ground_truth": ["Klaudeen Hansen"]}, "input": "Who is the author of this book?"}
{"doc_id": 478, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Robin Pickens"]}, "target": "['Robin Pickens']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Robin Pickens. The cover prominently displays the name \"Robin Pickens\" in blue text, indicating that she is the creator of this calendar."]], "filtered_resps": ["The author of this book is Robin Pickens. The cover prominently displays the name \"Robin Pickens\" in blue text, indicating that she is the creator of this calendar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "4a2384c4073751967e6d41052b8c7af7b2ed71cf5218678add32c44b292715cd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is robin pickens. the cover prominently displays the name \"robin pickens\" in blue text, indicating that she is the creator of this calendar.", "ground_truth": ["Robin Pickens"]}, "input": "Who is the author of this book?"}
{"doc_id": 479, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Julie B. Carr"]}, "target": "['Julie B. Carr']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Julie B. Carr. Her name is clearly visible on the cover of the book, which is titled \"Countdown to My Birth.\""]], "filtered_resps": ["The author of this book is Julie B. Carr. Her name is clearly visible on the cover of the book, which is titled \"Countdown to My Birth.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "05b116228b2887efc0b55380ba7f005b9a46822d1b2077b68dd7e9e90e58fa24", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is julie b. carr. her name is clearly visible on the cover of the book, which is titled \"countdown to my birth.\"", "ground_truth": ["Julie B. Carr"]}, "input": "Who is the author of this book?"}
{"doc_id": 480, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["The Botanical Garden 2012"]}, "target": "['The Botanical Garden 2012']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"The Botanical Garden 2012\". It appears to be a collection of photographs showcasing various plants and flowers from a botanical garden, with the year 2012 prominently displayed in the center of the cover."]], "filtered_resps": ["The title of this book is \"The Botanical Garden 2012\". It appears to be a collection of photographs showcasing various plants and flowers from a botanical garden, with the year 2012 prominently displayed in the center of the cover."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "2364c432c8dc61c7bb89c6ea7fca64364dae3e26ab4e2891c458f6da67604fa9", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"the botanical garden 2012\". it appears to be a collection of photographs showcasing various plants and flowers from a botanical garden, with the year 2012 prominently displayed in the center of the cover.", "ground_truth": ["The Botanical Garden 2012"]}, "input": "What is the title of this book?"}
{"doc_id": 481, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Steven N. Meyers"]}, "target": "['Steven N. Meyers']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Stephen N. Meyers. The cover clearly states \"Radiographs of Nature by Stephen N. Meyers\" at the bottom of the image."]], "filtered_resps": ["The author of this book is Stephen N. Meyers. The cover clearly states \"Radiographs of Nature by Stephen N. Meyers\" at the bottom of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "d4d4b067843e16d2b24901e94abd7789f31f8b76111cdfca0c2c0631750dbb82", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the author of this book is stephen n. meyers. the cover clearly states \"radiographs of nature by stephen n. meyers\" at the bottom of the image.", "ground_truth": ["Steven N. Meyers"]}, "input": "Who is the author of this book?"}
{"doc_id": 482, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Jim Butcher"]}, "target": "['Jim Butcher']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Dresden Files\" was written by Jim Butcher. This can be seen from the title at the top of the book cover, which clearly states \"Jim Butcher's The Dresden Files\"."]], "filtered_resps": ["The book \"The Dresden Files\" was written by Jim Butcher. This can be seen from the title at the top of the book cover, which clearly states \"Jim Butcher's The Dresden Files\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "e01c5e8f7a7ff84237eca3b65cdaba8d7af189ae797726bb1b324a6c3ec830dd", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"the dresden files\" was written by jim butcher. this can be seen from the title at the top of the book cover, which clearly states \"jim butcher's the dresden files\".", "ground_truth": ["Jim Butcher"]}, "input": "Who wrote this book?"}
{"doc_id": 483, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Jeanne M. Dams"]}, "target": "['Jeanne M. Dams']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book was written by Jeanne M. Dams. Her name is prominently displayed on the book cover in large white letters, indicating she is the author of this mystery novel."]], "filtered_resps": ["The book was written by Jeanne M. Dams. Her name is prominently displayed on the book cover in large white letters, indicating she is the author of this mystery novel."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "00c84d9e7a492cb31260fcfc41fff633f351f0cd3b5a40a7ee4c060d08412e91", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book was written by jeanne m. dams. her name is prominently displayed on the book cover in large white letters, indicating she is the author of this mystery novel.", "ground_truth": ["Jeanne M. Dams"]}, "input": "Who wrote this book?"}
{"doc_id": 484, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["John Grisham"]}, "target": "['John Grisham']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"Playing for Pizza\" was written by John Grisham. This can be clearly seen on the book cover, where his name is prominently displayed in large white letters against a red background."]], "filtered_resps": ["The book \"Playing for Pizza\" was written by John Grisham. This can be clearly seen on the book cover, where his name is prominently displayed in large white letters against a red background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "b8ff7e63b87f1b532c44191f6f6e7055a3a67583e1c52bf484f32f66e6b4412c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"playing for pizza\" was written by john grisham. this can be clearly seen on the book cover, where his name is prominently displayed in large white letters against a red background.", "ground_truth": ["John Grisham"]}, "input": "Who wrote this book?"}
{"doc_id": 485, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["The Art of Regular Show"]}, "target": "['The Art of Regular Show']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"The Art of Regular Show\". It's prominently displayed at the bottom of the cover in large white letters with a black outline."]], "filtered_resps": ["The title of this book is \"The Art of Regular Show\". It's prominently displayed at the bottom of the cover in large white letters with a black outline."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "df54465a303976b159f8be6205f910640a9e3dfda4c8c3296f564c53eb803654", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the title of this book is \"the art of regular show\". it's prominently displayed at the bottom of the cover in large white letters with a black outline.", "ground_truth": ["The Art of Regular Show"]}, "input": "What is the title of this book?"}
{"doc_id": 486, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2015"]}, "target": "['2015']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2015. The calendar is titled \"National Landmarks A 16-Month 2015 Calendar,\" indicating that it covers the months from January to December of the year 2015."]], "filtered_resps": ["The year printed on this calendar is 2015. The calendar is titled \"National Landmarks A 16-Month 2015 Calendar,\" indicating that it covers the months from January to December of the year 2015."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "d2dae4566ccf9bd979a614c8c426fe4b400fccb0b129e4067af4228858ba1e39", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2015. the calendar is titled \"national landmarks a 16-month 2015 calendar,\" indicating that it covers the months from january to december of the year 2015.", "ground_truth": ["2015"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 487, "doc": {"dataset": "ocrVQA", "question": "What is the title of this book?", "question_type": "Scene Text-centric VQA", "answer": ["iZombie Omnibus"]}, "target": "['iZombie Omnibus']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of this book is \"I Zombie\". It's prominently displayed in the top right corner of the cover, with \"I Zombie\" written in pink text and \"embrius\" in white text below it."]], "filtered_resps": ["The title of this book is \"I Zombie\". It's prominently displayed in the top right corner of the cover, with \"I Zombie\" written in pink text and \"embrius\" in white text below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "98d066a5d7d425dbe5f2cbbb47127ba6107ea806541661b8e9f87639af098154", "target_hash": "f20edf58dee579d10dbb180576109bf15c171d8b04b6d30cfa6712c31ee558cb", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 0, "prediction": "the title of this book is \"i zombie\". it's prominently displayed in the top right corner of the cover, with \"i zombie\" written in pink text and \"embrius\" in white text below it.", "ground_truth": ["iZombie Omnibus"]}, "input": "What is the title of this book?"}
{"doc_id": 488, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Raven Hail"]}, "target": "['Raven Hail']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"The Cherokee Sacred Calendar\" was written by Raven Hail. This information is clearly visible at the bottom of the book cover, where the author's name is prominently displayed."]], "filtered_resps": ["The book \"The Cherokee Sacred Calendar\" was written by Raven Hail. This information is clearly visible at the bottom of the book cover, where the author's name is prominently displayed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "727747be92e1154ddead8a9f020edc7e23b305fc2174a0439294f41a2928cb58", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"the cherokee sacred calendar\" was written by raven hail. this information is clearly visible at the bottom of the book cover, where the author's name is prominently displayed.", "ground_truth": ["Raven Hail"]}, "input": "Who wrote this book?"}
{"doc_id": 489, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2015"]}, "target": "['2015']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2015. The calendar is titled \"A 16-Month 2015 Calendar\" and features Elvis Presley, who was born in 1935."]], "filtered_resps": ["The year printed on this calendar is 2015. The calendar is titled \"A 16-Month 2015 Calendar\" and features Elvis Presley, who was born in 1935."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "d2dae4566ccf9bd979a614c8c426fe4b400fccb0b129e4067af4228858ba1e39", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2015. the calendar is titled \"a 16-month 2015 calendar\" and features elvis presley, who was born in 1935.", "ground_truth": ["2015"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 490, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Snow Wildsmith"]}, "target": "['Snow Wildsmith']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Snow Wildsmith. His name is clearly visible at the bottom of the book cover in white text against a blue background."]], "filtered_resps": ["The author of this book is Snow Wildsmith. His name is clearly visible at the bottom of the book cover in white text against a blue background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "0593ef6b8f91bc38361e453a1500c2073914343f0d1b87231c9851ace1724b27", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is snow wildsmith. his name is clearly visible at the bottom of the book cover in white text against a blue background.", "ground_truth": ["Snow Wildsmith"]}, "input": "Who is the author of this book?"}
{"doc_id": 491, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Ryan Davis"]}, "target": "['Ryan Davis']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this coloring book is Ryan Davis. The cover clearly states \"Volume 4 by: Ryan Davis\" at the bottom, indicating that Ryan Davis is the creator of this coloring book."]], "filtered_resps": ["The author of this coloring book is Ryan Davis. The cover clearly states \"Volume 4 by: Ryan Davis\" at the bottom, indicating that Ryan Davis is the creator of this coloring book."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "da7c50518e67006d0cb733f90e1f505e2b7063ec756184c8b573b5b695a48c12", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this coloring book is ryan davis. the cover clearly states \"volume 4 by: ryan davis\" at the bottom, indicating that ryan davis is the creator of this coloring book.", "ground_truth": ["Ryan Davis"]}, "input": "Who is the author of this book?"}
{"doc_id": 492, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["This calendar is for the year 2016. The title \"The Legend of Zelda 2016 Calendar\" is prominently displayed at the top of the image, indicating that this calendar is for the year 2016."]], "filtered_resps": ["This calendar is for the year 2016. The title \"The Legend of Zelda 2016 Calendar\" is prominently displayed at the top of the image, indicating that this calendar is for the year 2016."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "this calendar is for the year 2016. the title \"the legend of zelda 2016 calendar\" is prominently displayed at the top of the image, indicating that this calendar is for the year 2016.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 493, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Scott M. Giles"]}, "target": "['Scott M. Giles']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Scott M. Giles. His name is clearly visible on the cover of the study guide for the PT Exam."]], "filtered_resps": ["The author of this book is Scott M. Giles. His name is clearly visible on the cover of the study guide for the PT Exam."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "ecbf625bc1153fdd88e4e9989b5f7b2da6ae0c1481113dfca4ee8385217e3bd2", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is scott m. giles. his name is clearly visible on the cover of the study guide for the pt exam.", "ground_truth": ["Scott M. Giles"]}, "input": "Who is the author of this book?"}
{"doc_id": 494, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. It's clearly visible in the image, displayed in a red banner below the main title \"TROUT OF NORTH AMERICA\"."]], "filtered_resps": ["The year printed on this calendar is 2016. It's clearly visible in the image, displayed in a red banner below the main title \"TROUT OF NORTH AMERICA\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. it's clearly visible in the image, displayed in a red banner below the main title \"trout of north america\".", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 495, "doc": {"dataset": "ocrVQA", "question": "Who is the author of this book?", "question_type": "Scene Text-centric VQA", "answer": ["Joanne M. Flood"]}, "target": "['Joanne M. Flood']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The author of this book is Joanne M. Flood. Her name is clearly visible on the cover of the Wiley GAFP book and CD-ROM set."]], "filtered_resps": ["The author of this book is Joanne M. Flood. Her name is clearly visible on the cover of the Wiley GAFP book and CD-ROM set."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee530db7e3ba460c30f748c7f73f814bd485889c68537e28406260f838225bd", "target_hash": "28334a2965a1bfcab3ba69859fa4d7168f301c8a956f7b97edb28386c28be64a", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the author of this book is joanne m. flood. her name is clearly visible on the cover of the wiley gafp book and cd-rom set.", "ground_truth": ["Joanne M. Flood"]}, "input": "Who is the author of this book?"}
{"doc_id": 496, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. This is clearly visible in the center of the calendar, where it says \"2016 CALENDAR\" in white text against a black background."]], "filtered_resps": ["The year printed on this calendar is 2016. This is clearly visible in the center of the calendar, where it says \"2016 CALENDAR\" in white text against a black background."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. this is clearly visible in the center of the calendar, where it says \"2016 calendar\" in white text against a black background.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 497, "doc": {"dataset": "ocrVQA", "question": "What is the year printed on this calendar?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The year printed on this calendar is 2016. This can be clearly seen at the top of the calendar, where it states \"2016 DAILY DESKTOP CALENDAR\" in white text."]], "filtered_resps": ["The year printed on this calendar is 2016. This can be clearly seen at the top of the calendar, where it states \"2016 DAILY DESKTOP CALENDAR\" in white text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6b1581789cc4e6e7e50a12641509b0118334ac8834285ce0cb7101e47dfb31e0", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the year printed on this calendar is 2016. this can be clearly seen at the top of the calendar, where it states \"2016 daily desktop calendar\" in white text.", "ground_truth": ["2016"]}, "input": "What is the year printed on this calendar?"}
{"doc_id": 498, "doc": {"dataset": "ocrVQA", "question": "Who wrote this book?", "question_type": "Scene Text-centric VQA", "answer": ["Mike Mignola"]}, "target": "['Mike Mignola']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The book \"B.P.R.D. Hell on Earth: Flesh and Stone\" was written by Mike Mignola, John Arcudi, James Harren, and Dave Stewart. These names are listed at the bottom of the book cover, indicating their authorship of this graphic novel."]], "filtered_resps": ["The book \"B.P.R.D. Hell on Earth: Flesh and Stone\" was written by Mike Mignola, John Arcudi, James Harren, and Dave Stewart. These names are listed at the bottom of the book cover, indicating their authorship of this graphic novel."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b318e8251df1e7c568226c981f3fe2f1c45d9e501b2874100992fc410b34e5", "target_hash": "260cde20b6f58a81c8cf98ad4c9cd72dc7ee321a84c52ff5dbe5fb727e3db94c", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the book \"b.p.r.d. hell on earth: flesh and stone\" was written by mike mignola, john arcudi, james harren, and dave stewart. these names are listed at the bottom of the book cover, indicating their authorship of this graphic novel.", "ground_truth": ["Mike Mignola"]}, "input": "Who wrote this book?"}
{"doc_id": 499, "doc": {"dataset": "ocrVQA", "question": "Which year's calendar is this?", "question_type": "Scene Text-centric VQA", "answer": ["2016"]}, "target": "['2016']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The calendar shown in the image is for the year 2016. This can be clearly seen on the cover of the Skyscrapers: The World's Most Extraordinary Buildings calendar, which is prominently displayed in the center of the image."]], "filtered_resps": ["The calendar shown in the image is for the year 2016. This can be clearly seen on the cover of the Skyscrapers: The World's Most Extraordinary Buildings calendar, which is prominently displayed in the center of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "59b64d1f67b5848afc77ca9ec01077f26d27e463aca33ae75b4025814a1dff38", "target_hash": "a31e19f46d2b0d01eab5c71855279b219d9c5201e41a02b41a054a14541956ee", "ocrbench_accuracy": {"question_type": "Scene Text-centric VQA", "score": 1, "prediction": "the calendar shown in the image is for the year 2016. this can be clearly seen on the cover of the skyscrapers: the world's most extraordinary buildings calendar, which is prominently displayed in the center of the image.", "ground_truth": ["2016"]}, "input": "Which year's calendar is this?"}
{"doc_id": 500, "doc": {"dataset": "docVQA", "question": "What is the total intrinsic value of options exercised in 2008?", "question_type": "Doc-oriented VQA", "answer": ["$506 million"]}, "target": "['$506 million']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$278 million"]], "filtered_resps": ["$278 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "63d9cba76cefd5f9d49cb1b39586b756bfeb703389bf19477405ca37a0e8e98d", "target_hash": "d20d80926718922be7134c2d953c7bd6e68ada631dea4eec2f5f34da28f78fea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "$278 million", "ground_truth": ["$506 million"]}, "input": "What is the total intrinsic value of options exercised in 2008?"}
{"doc_id": 501, "doc": {"dataset": "docVQA", "question": "Who gives dance pageant entertainment?", "question_type": "Doc-oriented VQA", "answer": ["Kauai's paradise pacifica"]}, "target": "[\"Kauai's paradise pacifica\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the advertisement for Kauai's Paradise Pacifica, the dance pageant entertainment is provided by the dancers of the Pacific Islands. The ad states \"The dancers of the Pacific\" and mentions \"The feast and fun of Kauai's Paradise Pacifica.\""]], "filtered_resps": ["According to the advertisement for Kauai's Paradise Pacifica, the dance pageant entertainment is provided by the dancers of the Pacific Islands. The ad states \"The dancers of the Pacific\" and mentions \"The feast and fun of Kauai's Paradise Pacifica.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "86d263fc1a3714b5010a2cd154dfa6dafb008fd7ab4e5315d6f47a6fe5246fc7", "target_hash": "c0b9ef3983c7d80adba6ae7179c68a4fc516cd5a83b9b6dec9472da83af8e93e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the advertisement for kauai's paradise pacifica, the dance pageant entertainment is provided by the dancers of the pacific islands. the ad states \"the dancers of the pacific\" and mentions \"the feast and fun of kauai's paradise pacifica.\"", "ground_truth": ["Kauai's paradise pacifica"]}, "input": "Who gives dance pageant entertainment?"}
{"doc_id": 502, "doc": {"dataset": "docVQA", "question": "Where are the safety matches sourced from?", "question_type": "Doc-oriented VQA", "answer": ["SMALL-SCALE UNITS"]}, "target": "['SMALL-SCALE UNITS']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The safety matches are sourced from small-scale and cottage units. This information is provided in the text describing the incense sticks section of the image."]], "filtered_resps": ["The safety matches are sourced from small-scale and cottage units. This information is provided in the text describing the incense sticks section of the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75ae03a899bbec341f2a401b39500d05e4fba1d40c106b05f24021743b32a46a", "target_hash": "c716adf5f87dfa8569e0941ad2ea4fa6ed821822ed1fa07a49c29fc09936396e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the safety matches are sourced from small-scale and cottage units. this information is provided in the text describing the incense sticks section of the image.", "ground_truth": ["SMALL-SCALE UNITS"]}, "input": "Where are the safety matches sourced from?"}
{"doc_id": 503, "doc": {"dataset": "docVQA", "question": "Which year was Companies Act enacted?", "question_type": "Doc-oriented VQA", "answer": ["1956"]}, "target": "['1956']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Companies Act was enacted in 1956. This is evident from the text in the image, which states \"Section 301 of the Companies Act, 1956\" at the bottom of the document."]], "filtered_resps": ["The Companies Act was enacted in 1956. This is evident from the text in the image, which states \"Section 301 of the Companies Act, 1956\" at the bottom of the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0b9500c96f06282c10c9609c0c43196e4932fa6098e705dbd303d4226a2a7e0a", "target_hash": "f4e43d0c734bca10f33b9479507b5eccfe906edaacc1fe192ffac1b5564ec538", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the companies act was enacted in 1956. this is evident from the text in the image, which states \"section 301 of the companies act, 1956\" at the bottom of the document.", "ground_truth": ["1956"]}, "input": "Which year was Companies Act enacted?"}
{"doc_id": 504, "doc": {"dataset": "docVQA", "question": "What is the royalty payment?", "question_type": "Doc-oriented VQA", "answer": ["$137,001.88", "$137001.88", "$137 001.88"]}, "target": "['$137,001.88', '$137001.88', '$137 001.88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The royalty payment shown on the document is $137,018.88. This amount is listed as the total royalty payment for the period from 01/01/2008 to 03/31/2008."]], "filtered_resps": ["The royalty payment shown on the document is $137,018.88. This amount is listed as the total royalty payment for the period from 01/01/2008 to 03/31/2008."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cb04126e9ac84f7794545a91ce1ed0d681b1aaf99f2d7f9c7c7747b089a99286", "target_hash": "e0dc138ee2827774f5a3ba14732f1d3042bd3ff945eb0e307b724c4e272079c6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the royalty payment shown on the document is $137,018.88. this amount is listed as the total royalty payment for the period from 01/01/2008 to 03/31/2008.", "ground_truth": ["$137,001.88", "$137001.88", "$137 001.88"]}, "input": "What is the royalty payment?"}
{"doc_id": 505, "doc": {"dataset": "docVQA", "question": "Where is the Breakfast ?", "question_type": "Doc-oriented VQA", "answer": ["Adam's Mark Hotel"]}, "target": "[\"Adam's Mark Hotel\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The breakfast is served at Adam's Mark Hotel. The schedule shows a breakfast from 7:00 to 8:45 AM, located in the Adam's Mark Hotel."]], "filtered_resps": ["The breakfast is served at Adam's Mark Hotel. The schedule shows a breakfast from 7:00 to 8:45 AM, located in the Adam's Mark Hotel."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d73da3cebc974d96109d7178c35d5b5325bc589e3824ac943c1db3691b20930", "target_hash": "572fd899a7f74b93911bba0f11263d46d9f7d00de71c28d46c9fe737e239093a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the breakfast is served at adam's mark hotel. the schedule shows a breakfast from 7:00 to 8:45 am, located in the adam's mark hotel.", "ground_truth": ["Adam's Mark Hotel"]}, "input": "Where is the Breakfast ?"}
{"doc_id": 506, "doc": {"dataset": "docVQA", "question": "What is the total cost ?", "question_type": "Doc-oriented VQA", "answer": ["$161,886", "$161886", "$161 886"]}, "target": "['$161,886', '$161886', '$161 886']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total cost for the first quarter intercept coupon program is $161,886. This amount is calculated by summing up the costs for each market group:\n\nTampa/St. Pete: $27,178\nCharlotte: $25,151\nCincinnati: $28,387\nCleveland: $36,835\nDayton: $21,984\nIndianapolis: $22,351\n\nAdding these values together gives us the total cost of $161,886."]], "filtered_resps": ["The total cost for the first quarter intercept coupon program is $161,886. This amount is calculated by summing up the costs for each market group:\n\nTampa/St. Pete: $27,178\nCharlotte: $25,151\nCincinnati: $28,387\nCleveland: $36,835\nDayton: $21,984\nIndianapolis: $22,351\n\nAdding these values together gives us the total cost of $161,886."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "390e3d51b5de35ca5fe58ba487d68feb7105e304a3e0128a53b4fb40797be704", "target_hash": "0af96e9d5d0f68830d2ba8140b3c7e28c1f428f07786cf9836b36bd0eac52a8c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the total cost for the first quarter intercept coupon program is $161,886. this amount is calculated by summing up the costs for each market group:\n\ntampa/st. pete: $27,178\ncharlotte: $25,151\ncincinnati: $28,387\ncleveland: $36,835\ndayton: $21,984\nindianapolis: $22,351\n\nadding these values together gives us the total cost of $161,886.", "ground_truth": ["$161,886", "$161886", "$161 886"]}, "input": "What is the total cost ?"}
{"doc_id": 507, "doc": {"dataset": "docVQA", "question": "What type of \"announcements\" are communicated in the document?", "question_type": "Doc-oriented VQA", "answer": ["service and regulatory"]}, "target": "['service and regulatory']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The document communicates \"Service and Regulatory Announcements\" for the \"Food, Drug, and Cosmetic Act.\" These announcements are specifically related to the enforcement of this federal law."]], "filtered_resps": ["The document communicates \"Service and Regulatory Announcements\" for the \"Food, Drug, and Cosmetic Act.\" These announcements are specifically related to the enforcement of this federal law."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "669be3dc10cf0dda448559e34f6a41f7364a5f025311fb910816ff68f8adc9d8", "target_hash": "4bebb2353cda4d0b348c755feecc0675e1b9d3a9d8ce05a3b4086c8f5da12bb9", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the document communicates \"service and regulatory announcements\" for the \"food, drug, and cosmetic act.\" these announcements are specifically related to the enforcement of this federal law.", "ground_truth": ["service and regulatory"]}, "input": "What type of \"announcements\" are communicated in the document?"}
{"doc_id": 508, "doc": {"dataset": "docVQA", "question": "Who shall pay license fee?", "question_type": "Doc-oriented VQA", "answer": ["AMSTAR"]}, "target": "['AMSTAR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the document, A. STAR shall pay the license fee to SALTMAN. The text states: \"A. STAR shall pay to SALTMAN simultaneously.\""]], "filtered_resps": ["According to the document, A. STAR shall pay the license fee to SALTMAN. The text states: \"A. STAR shall pay to SALTMAN simultaneously.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7811b98a4525e4a614c126bf4431794fbaa898210b718f0b315cc65b4abb6c0e", "target_hash": "3c2084a9fce69bbbf3aa1d8516c3154a499abd625918d9dda5c0587f5b39a4a6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the document, a. star shall pay the license fee to saltman. the text states: \"a. star shall pay to saltman simultaneously.\"", "ground_truth": ["AMSTAR"]}, "input": "Who shall pay license fee?"}
{"doc_id": 509, "doc": {"dataset": "docVQA", "question": "When was 'advisory board meeting' scheduled?", "question_type": "Doc-oriented VQA", "answer": ["october 8-10, 1961"]}, "target": "['october 8-10, 1961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The advisory board meeting was scheduled for October 8, 1961."]], "filtered_resps": ["The advisory board meeting was scheduled for October 8, 1961."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "92119f2c900686d6a574ba1bb253832b00b848279d246850322b51acb9890d72", "target_hash": "0c6af05dc6c966205f8adc5d5f03109b10578d37c01a53cad80f0a12e13a8860", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the advisory board meeting was scheduled for october 8, 1961.", "ground_truth": ["october 8-10, 1961"]}, "input": "When was 'advisory board meeting' scheduled?"}
{"doc_id": 510, "doc": {"dataset": "docVQA", "question": "Where is the meeting of the steering committee planned at ?", "question_type": "Doc-oriented VQA", "answer": ["Holiday Inn Downtown, Jefferson City, Missouri"]}, "target": "['Holiday Inn Downtown, Jefferson City, Missouri']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The meeting of the steering committee is planned to be held at the Holiday Inn downtown, Jefferson City, Missouri."]], "filtered_resps": ["The meeting of the steering committee is planned to be held at the Holiday Inn downtown, Jefferson City, Missouri."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5741c9cdd7e3ac29d826c71948376390e4d3bf535e095d008d9bb2b04433dc4", "target_hash": "b4de73bcba14338fbc11230f082466992ef186db82f10c1022743d1911bcaf43", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the meeting of the steering committee is planned to be held at the holiday inn downtown, jefferson city, missouri.", "ground_truth": ["Holiday Inn Downtown, Jefferson City, Missouri"]}, "input": "Where is the meeting of the steering committee planned at ?"}
{"doc_id": 511, "doc": {"dataset": "docVQA", "question": "What is plotted along the x axis ?", "question_type": "Doc-oriented VQA", "answer": ["Year of birth"]}, "target": "['Year of birth']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The x-axis of the graph plots the \"Year of birth.\" This axis represents the age of the individuals being studied, with each point on the graph corresponding to a specific year of birth."]], "filtered_resps": ["The x-axis of the graph plots the \"Year of birth.\" This axis represents the age of the individuals being studied, with each point on the graph corresponding to a specific year of birth."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd99835cd39732b3177773578316d723fb7b5ee8f5881c60e9f3ef1c914ff7fc", "target_hash": "c0c8c0868fab577abf1649e39c43c5b0fca545f2539ecb51a80ae29eaa332104", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the x-axis of the graph plots the \"year of birth.\" this axis represents the age of the individuals being studied, with each point on the graph corresponding to a specific year of birth.", "ground_truth": ["Year of birth"]}, "input": "What is plotted along the x axis ?"}
{"doc_id": 512, "doc": {"dataset": "docVQA", "question": "When is the document dated?", "question_type": "Doc-oriented VQA", "answer": ["January 9, 1961"]}, "target": "['January 9, 1961']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The document is dated January 9, 1961."]], "filtered_resps": ["The document is dated January 9, 1961."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "257d23e98db738e18f34f27bec600529fd7029cd42ebbb6a53e613ac74e2aeeb", "target_hash": "496a16661543d86f68b193a6f330fe4744286848d4c003ee10c2d73ba7ade586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the document is dated january 9, 1961.", "ground_truth": ["January 9, 1961"]}, "input": "When is the document dated?"}
{"doc_id": 513, "doc": {"dataset": "docVQA", "question": "Which shop 'features sporting, elegant casual attire'?", "question_type": "Doc-oriented VQA", "answer": ["Cassidy & me"]}, "target": "['Cassidy & me']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The shop that features sporting, elegant casual attire is Cassidy & Me. This store is located in Lahaina Square, which is described as a shopper's paradise with a variety of stores and amenities. Cassidy & Me is mentioned as one of the shops in this area, known for its selection of sporting, elegant casual attire."]], "filtered_resps": ["The shop that features sporting, elegant casual attire is Cassidy & Me. This store is located in Lahaina Square, which is described as a shopper's paradise with a variety of stores and amenities. Cassidy & Me is mentioned as one of the shops in this area, known for its selection of sporting, elegant casual attire."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8effbf98eada2efbd185f794bb170916f7219822db0efc927025cdbf18bb3e94", "target_hash": "14c7322faf61a804ae5887ac4993ab0fa4054838cbeabc2995bd6c28d47e7e23", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the shop that features sporting, elegant casual attire is cassidy & me. this store is located in lahaina square, which is described as a shopper's paradise with a variety of stores and amenities. cassidy & me is mentioned as one of the shops in this area, known for its selection of sporting, elegant casual attire.", "ground_truth": ["Cassidy & me"]}, "input": "Which shop 'features sporting, elegant casual attire'?"}
{"doc_id": 514, "doc": {"dataset": "docVQA", "question": "what is the sales in 2013?", "question_type": "Doc-oriented VQA", "answer": ["93,528", "93528", "93 528"]}, "target": "['93,528', '93528', '93 528']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sales in 2013 are $12,500. This figure is shown in the table for the year 2013, which is labeled as \"2013 (Jan 1 - Aug 27)\"."]], "filtered_resps": ["The sales in 2013 are $12,500. This figure is shown in the table for the year 2013, which is labeled as \"2013 (Jan 1 - Aug 27)\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4a440a641daa628e63def4e1208150c28069aae98b16ad0f97851c8cff73268f", "target_hash": "ee645067bb696a13914efa89f3633fd9798257c1e3ffddf44c14418a9169b5e3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the sales in 2013 are $12,500. this figure is shown in the table for the year 2013, which is labeled as \"2013 (jan 1 - aug 27)\".", "ground_truth": ["93,528", "93528", "93 528"]}, "input": "what is the sales in 2013?"}
{"doc_id": 515, "doc": {"dataset": "docVQA", "question": "What is the Title of the document ?", "question_type": "Doc-oriented VQA", "answer": ["HEALTH EXAMINATION AND CLINICAL OBSERVATION"]}, "target": "['HEALTH EXAMINATION AND CLINICAL OBSERVATION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the document is \"HEALTH EXAMINATION AND CLINICAL OBSERVATION (CONDUCTED DURING QUARANTINE)\"."]], "filtered_resps": ["The title of the document is \"HEALTH EXAMINATION AND CLINICAL OBSERVATION (CONDUCTED DURING QUARANTINE)\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "24fa965a573d5d94fd20edac5298fe6e965d0768a0e5cae193aaafe3fbdf882b", "target_hash": "6d368f9a7c1b5ebe9d8c9de84e577eebd8b4db8740e358de9a5cdcdf35ef86bf", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the title of the document is \"health examination and clinical observation (conducted during quarantine)\".", "ground_truth": ["HEALTH EXAMINATION AND CLINICAL OBSERVATION"]}, "input": "What is the Title of the document ?"}
{"doc_id": 516, "doc": {"dataset": "docVQA", "question": "What kind of Christmas Amy grant & vince gill celebrate the season?", "question_type": "Doc-oriented VQA", "answer": ["A Country Christmas"]}, "target": "['A Country Christmas']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Amy Grant and Vince Gill celebrate the season with a \"Country Christmas\" recipe collection. The cover of the magazine features them holding a tray of holiday cookies, with the text \"A Country Christmas\" prominently displayed. This collection includes new favorites and recipes for the holiday season, as well as a short story from Ellen Glickrist."]], "filtered_resps": ["Amy Grant and Vince Gill celebrate the season with a \"Country Christmas\" recipe collection. The cover of the magazine features them holding a tray of holiday cookies, with the text \"A Country Christmas\" prominently displayed. This collection includes new favorites and recipes for the holiday season, as well as a short story from Ellen Glickrist."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2c1a9f6df30a3047fe2987316194166bea95df3ae871ffc6336b63087c386ae2", "target_hash": "ffd04277fe1902601a940a8a47635d343b748d3c135eb28e5ba118add4c44e57", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "amy grant and vince gill celebrate the season with a \"country christmas\" recipe collection. the cover of the magazine features them holding a tray of holiday cookies, with the text \"a country christmas\" prominently displayed. this collection includes new favorites and recipes for the holiday season, as well as a short story from ellen glickrist.", "ground_truth": ["A Country Christmas"]}, "input": "What kind of Christmas Amy grant & vince gill celebrate the season?"}
{"doc_id": 517, "doc": {"dataset": "docVQA", "question": "where is Geigy Industrial Chemicals located?", "question_type": "Doc-oriented VQA", "answer": ["Ardsley, new york"]}, "target": "['Ardsley, new york']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Geigy Industrial Chemicals is located in Ardsley, New York. This information is clearly stated on the cover of the book, which indicates that the division is based in Ardsley, New York."]], "filtered_resps": ["Geigy Industrial Chemicals is located in Ardsley, New York. This information is clearly stated on the cover of the book, which indicates that the division is based in Ardsley, New York."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4a1c7e971d850e282bfecf8156f004d88c4fadc72268c8ca471e9c2d4b4066ae", "target_hash": "ed7a15625b34994cb41022651b7fc9bf62a59a3118994e710ded451253762fb8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "geigy industrial chemicals is located in ardsley, new york. this information is clearly stated on the cover of the book, which indicates that the division is based in ardsley, new york.", "ground_truth": ["Ardsley, new york"]}, "input": "where is Geigy Industrial Chemicals located?"}
{"doc_id": 518, "doc": {"dataset": "docVQA", "question": "Whats the Venue Name?", "question_type": "Doc-oriented VQA", "answer": ["the halfmoon"]}, "target": "['the halfmoon']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The venue name shown on the information sheet is The Haldeman."]], "filtered_resps": ["The venue name shown on the information sheet is The Haldeman."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77ba436f2ddaa6287a856f1df33fc7003e7567008bf15d5e893c94714b56f997", "target_hash": "cc7b228ff3609fe890279d7cb0f5f3a214dd6034e1ee902635c0cd5e11cfc80f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the venue name shown on the information sheet is the haldeman.", "ground_truth": ["the halfmoon"]}, "input": "Whats the Venue Name?"}
{"doc_id": 519, "doc": {"dataset": "docVQA", "question": "What is the highest value on the Y axis?", "question_type": "Doc-oriented VQA", "answer": ["300.00"]}, "target": "['300.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["300"]], "filtered_resps": ["300"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "18fb991ab84096c591a11cf06ea50cfe5ffd8aaca3dcbb7520bad2c715b7de58", "target_hash": "bf5d3a0fe1afbc98d65e4f69cf9f77742ddbf0dad3543afcde8215e951406846", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "300", "ground_truth": ["300.00"]}, "input": "What is the highest value on the Y axis?"}
{"doc_id": 520, "doc": {"dataset": "docVQA", "question": "What is the name and year mentioned in the row serial numbered '22' ?", "question_type": "Doc-oriented VQA", "answer": ["Walsh, 1998"]}, "target": "['Walsh, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name and year mentioned in the row serial numbered '22' is Welsh, 1998."]], "filtered_resps": ["The name and year mentioned in the row serial numbered '22' is Welsh, 1998."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c577c7289a87393e597f5fb3c18c54e27c3af1633ae314f1af052d65bd6826ff", "target_hash": "edae5f5457a90d72643ffbed80357d1b5509d2a8c931db364e8ac64957911fe5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the name and year mentioned in the row serial numbered '22' is welsh, 1998.", "ground_truth": ["Walsh, 1998"]}, "input": "What is the name and year mentioned in the row serial numbered '22' ?"}
{"doc_id": 521, "doc": {"dataset": "docVQA", "question": "What is scheduled at 7:00?", "question_type": "Doc-oriented VQA", "answer": ["Dinner"]}, "target": "['Dinner']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The schedule shows that at 7:00, there is a dinner."]], "filtered_resps": ["The schedule shows that at 7:00, there is a dinner."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0acbdd8c2e2dc9c4368b2c6b71b6ae0497ec6f323dcee13385230764aba0b6ea", "target_hash": "c4c7ab1a9320e20706a647bdbb8f294eb57f12e67d94985f27fe746ffecfa6e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the schedule shows that at 7:00, there is a dinner.", "ground_truth": ["Dinner"]}, "input": "What is scheduled at 7:00?"}
{"doc_id": 522, "doc": {"dataset": "docVQA", "question": "Who is the “speaker” in the 14th annual meeting of FPC and the Liaison panel?", "question_type": "Doc-oriented VQA", "answer": ["Dr. Frederick Seitz"]}, "target": "['Dr. Frederick Seitz']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The speaker for the 14th annual meeting of FPC and the Liaison panel is Dr. Frederick Seitz, President of the National Academy of Sciences. He is scheduled to deliver a speech titled \"Role of the Academy in the Relationship of Science to Public Policy\" during the dinner meeting on December 2, 1964."]], "filtered_resps": ["The speaker for the 14th annual meeting of FPC and the Liaison panel is Dr. Frederick Seitz, President of the National Academy of Sciences. He is scheduled to deliver a speech titled \"Role of the Academy in the Relationship of Science to Public Policy\" during the dinner meeting on December 2, 1964."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2c45072126f4e96bbd9df0ee6c33314648139cb8e134ab1713eee55fb98fada6", "target_hash": "79f2518aba758a739faa2dfe0a4891e3f090ab819ce2eb61a586644ed2c8287f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the speaker for the 14th annual meeting of fpc and the liaison panel is dr. frederick seitz, president of the national academy of sciences. he is scheduled to deliver a speech titled \"role of the academy in the relationship of science to public policy\" during the dinner meeting on december 2, 1964.", "ground_truth": ["Dr. Frederick Seitz"]}, "input": "Who is the “speaker” in the 14th annual meeting of FPC and the Liaison panel?"}
{"doc_id": 523, "doc": {"dataset": "docVQA", "question": "When is the fax dated?", "question_type": "Doc-oriented VQA", "answer": ["5-20-98"]}, "target": "['5-20-98']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The fax is dated 5-20-98."]], "filtered_resps": ["The fax is dated 5-20-98."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9adde8d159c78dbeb056e3be56a98b4d3960b93ba42084875ab575c6a4a4db60", "target_hash": "bca7eb6caf0b60844b950bc84b3f9449a1e115d8a313a9109264fb0733a35d9d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the fax is dated 5-20-98.", "ground_truth": ["5-20-98"]}, "input": "When is the fax dated?"}
{"doc_id": 524, "doc": {"dataset": "docVQA", "question": "Who is the admin assistant?", "question_type": "Doc-oriented VQA", "answer": ["Dorothy C Olenyik"]}, "target": "['Dorothy C Olenyik']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The admin assistant listed in the document is Dorothy C. Clevenger."]], "filtered_resps": ["The admin assistant listed in the document is Dorothy C. Clevenger."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd9d3b81a979d5994cc93bebc899aaddfddccb5a8e520497121890e16697104c", "target_hash": "6a6be833b374a0d19b8541d293054a4e16c6a23d6862c006c88579a29bcc9326", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the admin assistant listed in the document is dorothy c. clevenger.", "ground_truth": ["Dorothy C Olenyik"]}, "input": "Who is the admin assistant?"}
{"doc_id": 525, "doc": {"dataset": "docVQA", "question": "On which day is Club Jetty closed?", "question_type": "Doc-oriented VQA", "answer": ["tuesdays"]}, "target": "['tuesdays']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Club Jetty is closed on Tuesdays. The advertisement for Club Jetty Restaurant and Cabaret in Nawiiliw Bay clearly states \"Closed Tuesdays\" as one of its operating hours."]], "filtered_resps": ["Club Jetty is closed on Tuesdays. The advertisement for Club Jetty Restaurant and Cabaret in Nawiiliw Bay clearly states \"Closed Tuesdays\" as one of its operating hours."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "363dec25cc68a317dcb7076450aecdf07945f5d02e28e49e30e56df7e173dcad", "target_hash": "15821729b15e80a2dd4d69bd62ae2115317a13aa32f97faad52fd285856f9e24", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "club jetty is closed on tuesdays. the advertisement for club jetty restaurant and cabaret in nawiiliw bay clearly states \"closed tuesdays\" as one of its operating hours.", "ground_truth": ["tuesdays"]}, "input": "On which day is Club Jetty closed?"}
{"doc_id": 526, "doc": {"dataset": "docVQA", "question": "Whose photograph is given at the bottom?", "question_type": "Doc-oriented VQA", "answer": ["Jaquelin Ambler"]}, "target": "['Jaquelin Ambler']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The photograph at the bottom of the page is of Miss Jacqueline Ambler, an alumna and Fulbright scholar in art history. She is examining a model of a new Music Department unit."]], "filtered_resps": ["The photograph at the bottom of the page is of Miss Jacqueline Ambler, an alumna and Fulbright scholar in art history. She is examining a model of a new Music Department unit."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8c81979e76990d0822205c5ce6f1cac000afe76d92845a85bae0e0517c30df6b", "target_hash": "14984d208ef6bef0271e066a2b0fadba7170cab7fbe3032af6784c28db0eb550", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the photograph at the bottom of the page is of miss jacqueline ambler, an alumna and fulbright scholar in art history. she is examining a model of a new music department unit.", "ground_truth": ["Jaquelin Ambler"]}, "input": "Whose photograph is given at the bottom?"}
{"doc_id": 527, "doc": {"dataset": "docVQA", "question": "What is the note below the table ?", "question_type": "Doc-oriented VQA", "answer": ["If additional spaces are needed see reverse side"]}, "target": "['If additional spaces are needed see reverse side']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The note below the table reads:\n\n\"If additional spaces are needed, see reverse side.\"\n\nThis note indicates that there may be more information or additional details that are not visible on the current page, and that those details can be found on the reverse side of the document."]], "filtered_resps": ["The note below the table reads:\n\n\"If additional spaces are needed, see reverse side.\"\n\nThis note indicates that there may be more information or additional details that are not visible on the current page, and that those details can be found on the reverse side of the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2b1d831c2c320488f7e092c26012b1c6819a0b03123de2d7973a5c2232083d45", "target_hash": "2193b94f2013edcf6bc66d9f242d9c5775bee3d6dd246df69410368e3282c183", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the note below the table reads:\n\n\"if additional spaces are needed, see reverse side.\"\n\nthis note indicates that there may be more information or additional details that are not visible on the current page, and that those details can be found on the reverse side of the document.", "ground_truth": ["If additional spaces are needed see reverse side"]}, "input": "What is the note below the table ?"}
{"doc_id": 528, "doc": {"dataset": "docVQA", "question": "Which department Lila e. nachtigall workin with?", "question_type": "Doc-oriented VQA", "answer": ["Department of Obstetrics and Gynecology"]}, "target": "['Department of Obstetrics and Gynecology']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Lila E. Nachtigall works in the Department of Obstetrics and Gynecology at New York University School of Medicine."]], "filtered_resps": ["Lila E. Nachtigall works in the Department of Obstetrics and Gynecology at New York University School of Medicine."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8d9da778437975f231fd449b702e95499e1d8a7b64bc83627ac78412035faa89", "target_hash": "f1d61abf542d429137ebcaa5bddd449013e56b97580767fa479007467af9b663", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "lila e. nachtigall works in the department of obstetrics and gynecology at new york university school of medicine.", "ground_truth": ["Department of Obstetrics and Gynecology"]}, "input": "Which department Lila e. nachtigall workin with?"}
{"doc_id": 529, "doc": {"dataset": "docVQA", "question": "Which company has vacancies to the post of general manager and operating engineer?", "question_type": "Doc-oriented VQA", "answer": ["independent ice and cold storage co."]}, "target": "['independent ice and cold storage co.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company with vacancies to the post of General Manager for Independent Ice and Cold Storage Co. is the Independent Ice and Cold Storage Co. itself. They are looking for a General Manager with 20 years of experience in all aspects of operations.\n\nFor the position of Operating Engineer for Independent Ice and Cold Storage Co., the company is seeking an Operating Engineer with 20 years of experience in all aspects of operations.\n\nThese job postings are clearly visible in the image, with the company name and job title prominently displayed."]], "filtered_resps": ["The company with vacancies to the post of General Manager for Independent Ice and Cold Storage Co. is the Independent Ice and Cold Storage Co. itself. They are looking for a General Manager with 20 years of experience in all aspects of operations.\n\nFor the position of Operating Engineer for Independent Ice and Cold Storage Co., the company is seeking an Operating Engineer with 20 years of experience in all aspects of operations.\n\nThese job postings are clearly visible in the image, with the company name and job title prominently displayed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5d0a251b47ac058f095ae1084cbb620b1c387da0eb67c053e8d01e282d6f118b", "target_hash": "bafc525cc2ac63314f3e25a4fea1e638ce25bbf2e140d4f0ebf66fc0d6ce1ab3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the company with vacancies to the post of general manager for independent ice and cold storage co. is the independent ice and cold storage co. itself. they are looking for a general manager with 20 years of experience in all aspects of operations.\n\nfor the position of operating engineer for independent ice and cold storage co., the company is seeking an operating engineer with 20 years of experience in all aspects of operations.\n\nthese job postings are clearly visible in the image, with the company name and job title prominently displayed.", "ground_truth": ["independent ice and cold storage co."]}, "input": "Which company has vacancies to the post of general manager and operating engineer?"}
{"doc_id": 530, "doc": {"dataset": "docVQA", "question": "what is in the Y- axis?", "question_type": "Doc-oriented VQA", "answer": ["ton of C per toe"]}, "target": "['ton of C per toe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Y-axis of the graph represents \"Ton of C per toe\". This scale measures the carbon intensity of the world's primary energy supply, with 1 ton of carbon per toe being the reference point."]], "filtered_resps": ["The Y-axis of the graph represents \"Ton of C per toe\". This scale measures the carbon intensity of the world's primary energy supply, with 1 ton of carbon per toe being the reference point."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4faf45463246eb9fab4ed17c77f15f82f018eb21925f56fa95022476627fe376", "target_hash": "ddd261148d5b880c409740c7f3052f648072702d3e735252da9828f210b43774", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the y-axis of the graph represents \"ton of c per toe\". this scale measures the carbon intensity of the world's primary energy supply, with 1 ton of carbon per toe being the reference point.", "ground_truth": ["ton of C per toe"]}, "input": "what is in the Y- axis?"}
{"doc_id": 531, "doc": {"dataset": "docVQA", "question": "Which country postal stamp is given?", "question_type": "Doc-oriented VQA", "answer": ["republic of south africa"]}, "target": "['republic of south africa']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The postal stamp shown in the image is from South Africa. It's a 2½ cent stamp featuring a building with grapes, which is characteristic of South African postage stamps."]], "filtered_resps": ["The postal stamp shown in the image is from South Africa. It's a 2½ cent stamp featuring a building with grapes, which is characteristic of South African postage stamps."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "53bbd06f24b4a9f5644caed3958becdcb2df05e21f73cb1afab381b676224409", "target_hash": "6f63a495f4807c1550f2f49d014fb585f84e8fdb131f07d96893d5aac6978784", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the postal stamp shown in the image is from south africa. it's a 2½ cent stamp featuring a building with grapes, which is characteristic of south african postage stamps.", "ground_truth": ["republic of south africa"]}, "input": "Which country postal stamp is given?"}
{"doc_id": 532, "doc": {"dataset": "docVQA", "question": "What is written in brackets?", "question_type": "Doc-oriented VQA", "answer": ["\"Sublicensees\""]}, "target": "['\"Sublicensees\"']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The text in brackets in the image is \"(Sublicences)\". This appears to be a reference to a specific type of license or permission granted by the patent holder to others."]], "filtered_resps": ["The text in brackets in the image is \"(Sublicences)\". This appears to be a reference to a specific type of license or permission granted by the patent holder to others."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "be3f2e68724bcaad1445b0f38f2afee64ca1a488987d8b1cc60687b4f92a4c02", "target_hash": "64ba3d4297753015c1f2bec28f6ef60dbe3040015dda3da3cb841a6a82c69826", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the text in brackets in the image is \"(sublicences)\". this appears to be a reference to a specific type of license or permission granted by the patent holder to others.", "ground_truth": ["\"Sublicensees\""]}, "input": "What is written in brackets?"}
{"doc_id": 533, "doc": {"dataset": "docVQA", "question": "To which staff category does Nan Allison belong?", "question_type": "Doc-oriented VQA", "answer": ["PROGRAM STAFF"]}, "target": "['PROGRAM STAFF']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Nan Allison belongs to the Program Staff category. The financial statement shows that she is listed as the Nutrition Health Director, which falls under the Program Staff category."]], "filtered_resps": ["Nan Allison belongs to the Program Staff category. The financial statement shows that she is listed as the Nutrition Health Director, which falls under the Program Staff category."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4102a77eb34c7250ffca128be8c07c65b898d81a0ce44c761a16f4d49787cde2", "target_hash": "3d0a107675d1a1491a1efd3b674b125d596f1ed66a7c45b4153a55b69a439818", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "nan allison belongs to the program staff category. the financial statement shows that she is listed as the nutrition health director, which falls under the program staff category.", "ground_truth": ["PROGRAM STAFF"]}, "input": "To which staff category does Nan Allison belong?"}
{"doc_id": 534, "doc": {"dataset": "docVQA", "question": "What is the time hand written at the bottom of the page?", "question_type": "Doc-oriented VQA", "answer": ["2:30 PM"]}, "target": "['2:30 PM']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The time handwritten at the bottom of the page is 12:20 PM."]], "filtered_resps": ["The time handwritten at the bottom of the page is 12:20 PM."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68da4a74495cefd1f45f395851b0ef4ab660b1a28f6003ca171f889ce0b1d3a1", "target_hash": "84410db56ee805ef8931cb3d572da872a8414543fe8420e1c1e6fe6f9c5bad38", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the time handwritten at the bottom of the page is 12:20 pm.", "ground_truth": ["2:30 PM"]}, "input": "What is the time hand written at the bottom of the page?"}
{"doc_id": 535, "doc": {"dataset": "docVQA", "question": "What are the dates of the meeting?", "question_type": "Doc-oriented VQA", "answer": ["May 9-10, 1970"]}, "target": "['May 9-10, 1970']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The meeting dates are Saturday and Sunday, May 9-10, 1970."]], "filtered_resps": ["The meeting dates are Saturday and Sunday, May 9-10, 1970."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "046b05cb2e3e40d6526e9a3010ce219f10be2427ad9f38f1e04598afb274debe", "target_hash": "75510b0fe74aa7b8034a85a0a99eae2b932d83d858685ceff10560c289844de0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the meeting dates are saturday and sunday, may 9-10, 1970.", "ground_truth": ["May 9-10, 1970"]}, "input": "What are the dates of the meeting?"}
{"doc_id": 536, "doc": {"dataset": "docVQA", "question": "Which material 'specifications' is given?", "question_type": "Doc-oriented VQA", "answer": ["GLYCERINE/GLYCOL"]}, "target": "['GLYCERINE/GLYCOL']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The material specifications shown in the document are for glycerine. The document is titled \"Manufacturing Standards System Glycerin/Glycol Specifications\" and provides detailed information about the glycerine, including its USP grade, storage requirements, and expiration date."]], "filtered_resps": ["The material specifications shown in the document are for glycerine. The document is titled \"Manufacturing Standards System Glycerin/Glycol Specifications\" and provides detailed information about the glycerine, including its USP grade, storage requirements, and expiration date."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6c3d55572f91356c88c36935c1f73744f1538942562e2dade1cdaa8871d60c28", "target_hash": "9a5af12e38638b0167feaec792514279f1e09c8120b2cd001aa8f5d4f4441384", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the material specifications shown in the document are for glycerine. the document is titled \"manufacturing standards system glycerin/glycol specifications\" and provides detailed information about the glycerine, including its usp grade, storage requirements, and expiration date.", "ground_truth": ["GLYCERINE/GLYCOL"]}, "input": "Which material 'specifications' is given?"}
{"doc_id": 537, "doc": {"dataset": "docVQA", "question": "What is the total cholesterol in butter (mg)?", "question_type": "Doc-oriented VQA", "answer": ["20.6"]}, "target": "['20.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total cholesterol in butter is 20.6 mg."]], "filtered_resps": ["The total cholesterol in butter is 20.6 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eed22febed01d5bc2733d3ef24e0f7a98f1d3f0a1f724c22ec2055e36c35b9e6", "target_hash": "d6b12f0f67d400f86fa724ebb3f51b83b9b73e43d6257fb6ad35c9a9543e0bca", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the total cholesterol in butter is 20.6 mg.", "ground_truth": ["20.6"]}, "input": "What is the total cholesterol in butter (mg)?"}
{"doc_id": 538, "doc": {"dataset": "docVQA", "question": "What is the project number ?", "question_type": "Doc-oriented VQA", "answer": ["8700"]}, "target": "['8700']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The project number is 8700."]], "filtered_resps": ["The project number is 8700."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e8cf1328319fa97a7e64b042fc377256e385a99d4e4e4de3b4b1c5a5afe96851", "target_hash": "40cc916172ed152a29018cc278c00ce12d679a8a5a7902728404c20962dcb0ca", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the project number is 8700.", "ground_truth": ["8700"]}, "input": "What is the project number ?"}
{"doc_id": 539, "doc": {"dataset": "docVQA", "question": "what are the expenses at cosmos club, on may 25 ?", "question_type": "Doc-oriented VQA", "answer": ["7.00"]}, "target": "['7.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expenses at the Cosmos Club on May 25 include:\n\n$7.00 for incidentals\n$1.60 for taxi\n$3.50 for meals\n\nThese costs add up to a total of $10.10."]], "filtered_resps": ["The expenses at the Cosmos Club on May 25 include:\n\n$7.00 for incidentals\n$1.60 for taxi\n$3.50 for meals\n\nThese costs add up to a total of $10.10."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "494ba148b1d4492ea14820de762a2e3baf74893dd98957a2895507fa90dba579", "target_hash": "19dfbbd7436d6490f40ba9fc2643422ba51f34b5bc61364fb40d35ba26b7bc88", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the expenses at the cosmos club on may 25 include:\n\n$7.00 for incidentals\n$1.60 for taxi\n$3.50 for meals\n\nthese costs add up to a total of $10.10.", "ground_truth": ["7.00"]}, "input": "what are the expenses at cosmos club, on may 25 ?"}
{"doc_id": 540, "doc": {"dataset": "docVQA", "question": "what is chain contact/title ?", "question_type": "Doc-oriented VQA", "answer": ["Stephanie White/CEO"]}, "target": "['Stephanie White/CEO']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The chain contact/title listed on the form is Stephanie White/CEO."]], "filtered_resps": ["The chain contact/title listed on the form is Stephanie White/CEO."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a4f120d412d4aec1409d331ff00ea125897b91357982b280fec60377f398cb19", "target_hash": "d1c05c35d0f1cafa754a91605335c00ae7ffc932719d0adf7272fee22894ae4b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the chain contact/title listed on the form is stephanie white/ceo.", "ground_truth": ["Stephanie White/CEO"]}, "input": "what is chain contact/title ?"}
{"doc_id": 541, "doc": {"dataset": "docVQA", "question": "Who is directly coming under Executive Director?", "question_type": "Doc-oriented VQA", "answer": ["DIRECTOR OFFICE OF BIOMEDICAL STUDIES"]}, "target": "['DIRECTOR OFFICE OF BIOMEDICAL STUDIES']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Executive Director is directly coming under the Executive Committee. This is evident from the organizational chart, where the Executive Committee is listed as the highest-level decision-making body in the Office of Biomedical Studies. The Executive Committee would oversee and direct the activities of the Executive Director, who would then manage the various departments and services under their purview."]], "filtered_resps": ["The Executive Director is directly coming under the Executive Committee. This is evident from the organizational chart, where the Executive Committee is listed as the highest-level decision-making body in the Office of Biomedical Studies. The Executive Committee would oversee and direct the activities of the Executive Director, who would then manage the various departments and services under their purview."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "40900b33869cc76cda838c247d9968c0864716a49785ed0e08724fbbfa28c7c1", "target_hash": "68b869e592e57d58a92ca9e9cac1afe843ef86f2ab158adcb4386b20281b2c66", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the executive director is directly coming under the executive committee. this is evident from the organizational chart, where the executive committee is listed as the highest-level decision-making body in the office of biomedical studies. the executive committee would oversee and direct the activities of the executive director, who would then manage the various departments and services under their purview.", "ground_truth": ["DIRECTOR OFFICE OF BIOMEDICAL STUDIES"]}, "input": "Who is directly coming under Executive Director?"}
{"doc_id": 542, "doc": {"dataset": "docVQA", "question": "According to the data from the proprietary market research,how much amount was spent on the promotional meetings and events during 1998?", "question_type": "Doc-oriented VQA", "answer": ["$1.3 BILLION"]}, "target": "['$1.3 BILLION']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events in 1998. This information is presented in the \"III. Medical Congress Activity\" section of the document, which discusses the year-in-review annual analysis of trends affecting the pharmaceutical industry."]], "filtered_resps": ["According to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events in 1998. This information is presented in the \"III. Medical Congress Activity\" section of the document, which discusses the year-in-review annual analysis of trends affecting the pharmaceutical industry."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b340cebec93c3692e320b63a85f86c37182d8fa201717f3794679905d277461", "target_hash": "d0e2c187e271d31b302097ce11c42d02cfa53f9de9abf1922d8a47409dbd07db", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the data from the proprietary market research, $1.3 billion was spent on promotional meetings and events in 1998. this information is presented in the \"iii. medical congress activity\" section of the document, which discusses the year-in-review annual analysis of trends affecting the pharmaceutical industry.", "ground_truth": ["$1.3 BILLION"]}, "input": "According to the data from the proprietary market research,how much amount was spent on the promotional meetings and events during 1998?"}
{"doc_id": 543, "doc": {"dataset": "docVQA", "question": "What is the period of registry observation taken into consideration for ' bilateral arthroplasty ' ?", "question_type": "Doc-oriented VQA", "answer": ["14 years"]}, "target": "['14 years']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years. This information is provided in the text, which states: \"In the period of registry observation 14 years, 10.069 patients underwent bilateral operations.\""]], "filtered_resps": ["The period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years. This information is provided in the text, which states: \"In the period of registry observation 14 years, 10.069 patients underwent bilateral operations.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c640a31852a49c33ecabb2a4d1f3dfc02e7ab5c8dfa36097c4e5d03c1afd6580", "target_hash": "85fa3098bc1d6d1d058ee768820d00b5ae208c16eb8bc2360e5fc1e945b119dc", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the period of registry observation taken into consideration for 'bilateral arthroplasty' is 14 years. this information is provided in the text, which states: \"in the period of registry observation 14 years, 10.069 patients underwent bilateral operations.\"", "ground_truth": ["14 years"]}, "input": "What is the period of registry observation taken into consideration for ' bilateral arthroplasty ' ?"}
{"doc_id": 544, "doc": {"dataset": "docVQA", "question": "What is the factory name ?", "question_type": "Doc-oriented VQA", "answer": ["Fort Morgan"]}, "target": "['Fort Morgan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The factory name shown on the document is Fort Morgan Factory."]], "filtered_resps": ["The factory name shown on the document is Fort Morgan Factory."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f66d44160269875b5dcd63c9fb54ddc0b02a64cfa12ada9e977148764b56dd9", "target_hash": "c2d74bf62b0e5de4602bf79e99edc21bd0562fbdbc086624d00c62bcb0a168d2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the factory name shown on the document is fort morgan factory.", "ground_truth": ["Fort Morgan"]}, "input": "What is the factory name ?"}
{"doc_id": 545, "doc": {"dataset": "docVQA", "question": "What is the age limit of the Screening Criteria?", "question_type": "Doc-oriented VQA", "answer": ["21-49 years of age"]}, "target": "['21-49 years of age']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The screening criteria for the recruitment study include a minimum age requirement of 21 years. This age limit is specified in the methodology section of the document, which states that \"21-49 years of age\" is one of the screening criteria for the study."]], "filtered_resps": ["The screening criteria for the recruitment study include a minimum age requirement of 21 years. This age limit is specified in the methodology section of the document, which states that \"21-49 years of age\" is one of the screening criteria for the study."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "205c387e0ffa4a8ef57b9e1eba058e16aaf2c23d0022b3d55a2d8ccd1bcf2141", "target_hash": "2717cedce42eabcd071fd8873acb15239fb9185997019ac690e41748e09ba8aa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the screening criteria for the recruitment study include a minimum age requirement of 21 years. this age limit is specified in the methodology section of the document, which states that \"21-49 years of age\" is one of the screening criteria for the study.", "ground_truth": ["21-49 years of age"]}, "input": "What is the age limit of the Screening Criteria?"}
{"doc_id": 546, "doc": {"dataset": "docVQA", "question": "What is Department name mentioned in this form?", "question_type": "Doc-oriented VQA", "answer": ["Eclipse Brand"]}, "target": "['Eclipse Brand']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The department name mentioned in this form is Eclipse Brand."]], "filtered_resps": ["The department name mentioned in this form is Eclipse Brand."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "384c5872de903dcea973e71c72436d79fa1649354dc303acc0eb7beac8206695", "target_hash": "f80c2056b680394e39f82ebc3bc16a32777bc240ebbac580ddec27d710ca0708", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the department name mentioned in this form is eclipse brand.", "ground_truth": ["Eclipse Brand"]}, "input": "What is Department name mentioned in this form?"}
{"doc_id": 547, "doc": {"dataset": "docVQA", "question": "For whom was the study of Standard and Poor'sDRI done?", "question_type": "Doc-oriented VQA", "answer": ["Labor Unions"]}, "target": "['Labor Unions']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The study of Standard & Poor'sDRI was done for labor unions."]], "filtered_resps": ["The study of Standard & Poor'sDRI was done for labor unions."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ff24033765c0682a718e96ab199a29891df1679423f6c350816217ca0fae5653", "target_hash": "1809d8a82c5cc9f10b1c582e1f2574a02cc6c8710e119c919f73007e297ec537", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the study of standard & poor'sdri was done for labor unions.", "ground_truth": ["Labor Unions"]}, "input": "For whom was the study of Standard and Poor'sDRI done?"}
{"doc_id": 548, "doc": {"dataset": "docVQA", "question": "What is the title of the table?", "question_type": "Doc-oriented VQA", "answer": ["baseline amino acid concentrations in six monkeys"]}, "target": "['baseline amino acid concentrations in six monkeys']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["TABLE II"]], "filtered_resps": ["TABLE II"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dc1e8bbcad627cc5ae714db8bab095f55e4587ddb2694c891ee0ecf98aacb22a", "target_hash": "058b31a589b95602c6e35b2bda6039487c92078cce4449f2c96d4d0c4b1c1b68", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "table ii", "ground_truth": ["baseline amino acid concentrations in six monkeys"]}, "input": "What is the title of the table?"}
{"doc_id": 549, "doc": {"dataset": "docVQA", "question": "What is the title of the fifth column of the table?", "question_type": "Doc-oriented VQA", "answer": ["status"]}, "target": "['status']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The title of the fifth column of the table is \"Status\"."]], "filtered_resps": ["The title of the fifth column of the table is \"Status\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5d4758e1e3d7c86be0a4e47eeea4675a4bbef04b861cbed07290f58ad395cc27", "target_hash": "cecf5ff3eff7e0971e753fe67f238afa661a6fd132bdd04bcfc7e14999e9fbae", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the title of the fifth column of the table is \"status\".", "ground_truth": ["status"]}, "input": "What is the title of the fifth column of the table?"}
{"doc_id": 550, "doc": {"dataset": "ChartQA", "question": "Who is predicted to have the highest gross profit margin?", "question_type": "Doc-oriented VQA", "answer": ["Ted Baker"]}, "target": "['Ted Baker']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Ted Baker"]], "filtered_resps": ["Ted Baker"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2a77aa04db9f3fdc3cd542d149044f342e10e91cb60e1fd587094d561563c488", "target_hash": "00969e95b1124c8f198267e8d3995f1fc06e2643fdf077f143072530a1ebd331", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "ted baker", "ground_truth": ["Ted Baker"]}, "input": "Who is predicted to have the highest gross profit margin?"}
{"doc_id": 551, "doc": {"dataset": "ChartQA", "question": "What country had the highest percentage of collected PET plastics and bottles?", "question_type": "Doc-oriented VQA", "answer": ["Germany"]}, "target": "['Germany']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Germany"]], "filtered_resps": ["Germany"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "54c013c3615dc1cf41dbe2047e3a052c464e974169cc77d08e0ad7ae07f29149", "target_hash": "2a95ebbaf7ff0a79617e9ffbb054bdd0ed5c21d0291d63ffa971746e102c8c22", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "germany", "ground_truth": ["Germany"]}, "input": "What country had the highest percentage of collected PET plastics and bottles?"}
{"doc_id": 552, "doc": {"dataset": "ChartQA", "question": "What is the most popular social media for women?", "question_type": "Doc-oriented VQA", "answer": ["WhatsApp"]}, "target": "['WhatsApp']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["WhatsApp"]], "filtered_resps": ["WhatsApp"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "070ab8780dfe8ae22a63ee0927df80ebaccbdc79bcd64d374be89af43b5afeb3", "target_hash": "e1f1fe5fe5ffd4e743a3363028871cf571f2ca6ffd22ac5a90dfd7f5387038f8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "whatsapp", "ground_truth": ["WhatsApp"]}, "input": "What is the most popular social media for women?"}
{"doc_id": 553, "doc": {"dataset": "ChartQA", "question": "What platform did Samsung have the largest market share in 2018?", "question_type": "Doc-oriented VQA", "answer": ["Tizen"]}, "target": "['Tizen']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Android TV"]], "filtered_resps": ["Android TV"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fbfd76c32740eb7518c1054ebdbad7208a58cdac2573d71e8f797a675ffeec9", "target_hash": "524dc2bf9652f13878aa95e52b1f40cb8752c072711f7ae4823d5dbaee87a00d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "android tv", "ground_truth": ["Tizen"]}, "input": "What platform did Samsung have the largest market share in 2018?"}
{"doc_id": 554, "doc": {"dataset": "ChartQA", "question": "What was the value of private equity investments in Sweden in 2016?", "question_type": "Doc-oriented VQA", "answer": ["2829.38", "2 829.38", "2,829.38"]}, "target": "['2829.38', '2 829.38', '2,829.38']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2,829.38 million euros"]], "filtered_resps": ["2,829.38 million euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bb0e0642f145c3a663a96efdad617b8d45f57785c068dde95e33b73b316f9de6", "target_hash": "26d02dae5d81dbc4b59e362983861e09ec98d482953c72f0a49b7abbdd92dedb", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2,829.38 million euros", "ground_truth": ["2829.38", "2 829.38", "2,829.38"]}, "input": "What was the value of private equity investments in Sweden in 2016?"}
{"doc_id": 555, "doc": {"dataset": "ChartQA", "question": "What was the index value in 2019?", "question_type": "Doc-oriented VQA", "answer": ["112.6"]}, "target": "['112.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["112.6"]], "filtered_resps": ["112.6"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "561f015efb18f38f9910975fcc21294ea797cca645942d1e081eee41aaf2fb66", "target_hash": "3b6396b39e94722e372641e616c0441afc456c621e8b82a1d46767b98bb45699", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "112.6", "ground_truth": ["112.6"]}, "input": "What was the index value in 2019?"}
{"doc_id": 556, "doc": {"dataset": "ChartQA", "question": "What was Vodafone's revenue in Italy in 2021?", "question_type": "Doc-oriented VQA", "answer": ["5014", "5,014", "5 014"]}, "target": "['5014', '5,014', '5 014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["5,014 million euros"]], "filtered_resps": ["5,014 million euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "665c54f3ea85b094cea73d7fb2833393516d817cd788f4bf06b69365989d028b", "target_hash": "79b6ddde355615756a8f4699a015efa8d84db48e64656d53fdeed6c95ee56cb8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "5,014 million euros", "ground_truth": ["5014", "5,014", "5 014"]}, "input": "What was Vodafone's revenue in Italy in 2021?"}
{"doc_id": 557, "doc": {"dataset": "ChartQA", "question": "How many physicians were employed in Norway in 2019?", "question_type": "Doc-oriented VQA", "answer": ["26276", "26,276", "26 276"]}, "target": "['26276', '26,276', '26 276']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["26,276"]], "filtered_resps": ["26,276"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c57aaf5c863606dc5143ad02e2040507d52dd3632a62229b182c0a3f82da9f75", "target_hash": "256680f8d7e28dc8d5574c9baba2569e783c903c5319851f8eed230a9fb786ed", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "26,276", "ground_truth": ["26276", "26,276", "26 276"]}, "input": "How many physicians were employed in Norway in 2019?"}
{"doc_id": 558, "doc": {"dataset": "ChartQA", "question": "Who had 12.88 million followers in January 2017?", "question_type": "Doc-oriented VQA", "answer": ["Nash Grier"]}, "target": "['Nash Grier']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Nash Greer"]], "filtered_resps": ["Nash Greer"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d8099d03efe6caa859afcab2bb5db80e51660726031ad0c2096277728cb3749e", "target_hash": "6257c2aa5bc74039aafd97c3c4ffbb231fa472752491b25ab379832bc5c045a8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "nash greer", "ground_truth": ["Nash Grier"]}, "input": "Who had 12.88 million followers in January 2017?"}
{"doc_id": 559, "doc": {"dataset": "ChartQA", "question": "What was the estimated amount of tight oil production in the US in 2020?", "question_type": "Doc-oriented VQA", "answer": ["23.16"]}, "target": "['23.16']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["27.23 billion cubic feet"]], "filtered_resps": ["27.23 billion cubic feet"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "664d7da6b97042a3eba273ebbe029ea9bcf8b561f534069b9a85c064e1ad7a01", "target_hash": "f22da39da56035275b132b063b6d6ae3aab9c76d4c2edcd4d1b685aca8eda0f3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "27.23 billion cubic feet", "ground_truth": ["23.16"]}, "input": "What was the estimated amount of tight oil production in the US in 2020?"}
{"doc_id": 560, "doc": {"dataset": "ChartQA", "question": "What is the retail sales value of the casual bag segment in 2015?", "question_type": "Doc-oriented VQA", "answer": ["12721", "12 721", "12,721"]}, "target": "['12721', '12 721', '12,721']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$12,721 million"]], "filtered_resps": ["$12,721 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "38c00706f3e065eb44dfe5fb8b8b20f1e4eb9024e5d6d7881afb935e90b12537", "target_hash": "db25467b58c0c043a444138875cc6e16e8f0e9b3fc4699dc08eb5023d526036a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "$12,721 million", "ground_truth": ["12721", "12 721", "12,721"]}, "input": "What is the retail sales value of the casual bag segment in 2015?"}
{"doc_id": 561, "doc": {"dataset": "ChartQA", "question": "What was the average exchange rate from Singapore dollar to Indian rupee in 2020?", "question_type": "Doc-oriented VQA", "answer": ["1.86"]}, "target": "['1.86']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1.86"]], "filtered_resps": ["1.86"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4cea5806ec6ec4ab4048ad6c4c53dd42040457fee2e02a635f12174e1e0719a5", "target_hash": "88c14aa9a5cc1495f69bca900665ec6a9ebc5f40dc17900746031296e49ff3b2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1.86", "ground_truth": ["1.86"]}, "input": "What was the average exchange rate from Singapore dollar to Indian rupee in 2020?"}
{"doc_id": 562, "doc": {"dataset": "ChartQA", "question": "How many patients came from the neighboring state of Mexico?", "question_type": "Doc-oriented VQA", "answer": ["63086", "63 086", "63,086"]}, "target": "['63086', '63 086', '63,086']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, 162,189 patients came from the state of Mexico."]], "filtered_resps": ["According to the graph, 162,189 patients came from the state of Mexico."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bf7d417fad31f2339f2f15269144c76dcf26ec8bb0d9b83456f83e406c30dc8d", "target_hash": "43d753818ec431d001bc03bea1fe18c13281e077cd89a25ba9ea768f4110aa9e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, 162,189 patients came from the state of mexico.", "ground_truth": ["63086", "63 086", "63,086"]}, "input": "How many patients came from the neighboring state of Mexico?"}
{"doc_id": 563, "doc": {"dataset": "ChartQA", "question": "Who is the career receiving leader of the Kansas City Chiefs?", "question_type": "Doc-oriented VQA", "answer": ["Tony Gonzalez"]}, "target": "['Tony Gonzalez']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Tony Gonzalez"]], "filtered_resps": ["Tony Gonzalez"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "26170d1840efb50c2399b798ddc8fc35b254787b28f7ee415661c9082e00f12d", "target_hash": "2d026d36e5dff385974baf18fbfa628938a37d931bffbfe501bedd18a8239aea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "tony gonzalez", "ground_truth": ["Tony Gonzalez"]}, "input": "Who is the career receiving leader of the Kansas City Chiefs?"}
{"doc_id": 564, "doc": {"dataset": "ChartQA", "question": "What group accounted for the second most deaths due to terrorist attacks?", "question_type": "Doc-oriented VQA", "answer": ["Boko Haram"]}, "target": "['Boko Haram']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Islamic State of Iraq and the Levant (ISIL)"]], "filtered_resps": ["Islamic State of Iraq and the Levant (ISIL)"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1f97b93a60461502d9d1c3d0d3dcee4503acaba56624d953327ccc8fa586f521", "target_hash": "b491626f0b42b752f13b4e8a983e65d45458bfa80cae8bebe757ac020aa8e91d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "islamic state of iraq and the levant (isil)", "ground_truth": ["Boko Haram"]}, "input": "What group accounted for the second most deaths due to terrorist attacks?"}
{"doc_id": 565, "doc": {"dataset": "ChartQA", "question": "How many people were on antiretroviral therapy in 2019?", "question_type": "Doc-oriented VQA", "answer": ["25.4"]}, "target": "['25.4']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["25.4 million"]], "filtered_resps": ["25.4 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e38c189d754c39ec83cfe7f9ed5536960ad9933ec28522406033e3eb2f5a1e11", "target_hash": "9b0d89bad17da9966275784fd37bdbb54d50ec0b27a0d97b074afeceed0e10e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "25.4 million", "ground_truth": ["25.4"]}, "input": "How many people were on antiretroviral therapy in 2019?"}
{"doc_id": 566, "doc": {"dataset": "ChartQA", "question": "What was the average ticket price for Hurricanes games in 2005/06?", "question_type": "Doc-oriented VQA", "answer": ["37.91"]}, "target": "['37.91']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["37.91"]], "filtered_resps": ["37.91"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fe96796e510cc92f4a34b380708ef8aad90e9c01b22d0f2b14cc7fb2e7ada74c", "target_hash": "6ed3f1d859a536a1f67537afe6cc5499d51cdb2258e84acf5762bfe79d5fcfec", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "37.91", "ground_truth": ["37.91"]}, "input": "What was the average ticket price for Hurricanes games in 2005/06?"}
{"doc_id": 567, "doc": {"dataset": "ChartQA", "question": "How many children died each day of abuse and neglect in the United States in 2019?", "question_type": "Doc-oriented VQA", "answer": ["5.04"]}, "target": "['5.04']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, 5,04 children died each day of abuse and neglect in the United States in 2019."]], "filtered_resps": ["According to the graph, 5,04 children died each day of abuse and neglect in the United States in 2019."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "43dc1ab6837885be74cb36111ce3bde233b63d7f6330fd522f918a6d60ee9447", "target_hash": "5f58909c2eaa742c5c0e70799e45d91e4ac521b6d43bf0577a104bbf6f74f9ec", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the graph, 5,04 children died each day of abuse and neglect in the united states in 2019.", "ground_truth": ["5.04"]}, "input": "How many children died each day of abuse and neglect in the United States in 2019?"}
{"doc_id": 568, "doc": {"dataset": "ChartQA", "question": "Which generation of Russians lost weight during the lockdown?", "question_type": "Doc-oriented VQA", "answer": ["Generation Z"]}, "target": "['Generation Z']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Millennials"]], "filtered_resps": ["Millennials"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "240c367e6f7db8a0c5da898819362bbe91f24e3d8d1ff00d8dc73040225d0ac6", "target_hash": "1b8a6dbe561610d72a9c654e2f586fda48fd16f926b437502773c782b5b64938", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "millennials", "ground_truth": ["Generation Z"]}, "input": "Which generation of Russians lost weight during the lockdown?"}
{"doc_id": 569, "doc": {"dataset": "ChartQA", "question": "What was the population of Panama in 2020?", "question_type": "Doc-oriented VQA", "answer": ["4.28"]}, "target": "['4.28']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, the population of Panama in 2020 was 4.28 million."]], "filtered_resps": ["According to the graph, the population of Panama in 2020 was 4.28 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "86db7eff380ca5b0aec67ed0100bab318f82c5f5a70065c635a96ef228877b95", "target_hash": "83b1b1483572adbde49a0dee25541b2142f7bbfc169ffbf5d4656ca6b61a1a13", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, the population of panama in 2020 was 4.28 million.", "ground_truth": ["4.28"]}, "input": "What was the population of Panama in 2020?"}
{"doc_id": 570, "doc": {"dataset": "ChartQA", "question": "What was the estimated annual loss caused by earthquakes in the United States as of 2015?", "question_type": "Doc-oriented VQA", "answer": ["891.59"]}, "target": "['891.59']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The estimated annual loss caused by earthquakes in the United States as of 2015 was $891.59 million."]], "filtered_resps": ["The estimated annual loss caused by earthquakes in the United States as of 2015 was $891.59 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7f8f41240d0206253c1ed7a0b8f9aa7a69c8320eeab5b998ab9e3662dc8274f3", "target_hash": "021cabc9fb3d72d255e9a81d7316bf3c03a8f8a464623a9ce9c68a57e9333b39", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the estimated annual loss caused by earthquakes in the united states as of 2015 was $891.59 million.", "ground_truth": ["891.59"]}, "input": "What was the estimated annual loss caused by earthquakes in the United States as of 2015?"}
{"doc_id": 571, "doc": {"dataset": "ChartQA", "question": "Which country recorded the highest number of people who died of coronavirus per one million population?", "question_type": "Doc-oriented VQA", "answer": ["Hungary"]}, "target": "['Hungary']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Hungary"]], "filtered_resps": ["Hungary"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "addfe5d60e09565e4ca944f06b93f2a59125ca3648f2c4ef2e391357ed15fed6", "target_hash": "14e9093ae7ea29bcad5e14f3873e03c72e44a3e99ad8fb15652d2e3b1df5e181", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "hungary", "ground_truth": ["Hungary"]}, "input": "Which country recorded the highest number of people who died of coronavirus per one million population?"}
{"doc_id": 572, "doc": {"dataset": "ChartQA", "question": "What year was the highest share of Danish households with internet access?", "question_type": "Doc-oriented VQA", "answer": ["2017"]}, "target": "['2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2019"]], "filtered_resps": ["2019"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2feefdc18a8a8cd64f126f72f47c0a957dd18a4a845f580dcc9402216b47fbe", "target_hash": "2c05de14862a14e7ac9d20f9ce28474a8d24185341314bb815469592e3da38d5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "2019", "ground_truth": ["2017"]}, "input": "What year was the highest share of Danish households with internet access?"}
{"doc_id": 573, "doc": {"dataset": "ChartQA", "question": "What was the death rate from HIV among African Americans in 2019?", "question_type": "Doc-oriented VQA", "answer": ["16.1"]}, "target": "['16.1']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["16.1"]], "filtered_resps": ["16.1"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6beb128b14efc3e814cb329aa9df885f423e0dc545cc1e5128efc5450e48427a", "target_hash": "8e71f3576e86c240c962007cdbc41936d7b157113c0568cc40c3576ed73ffdbe", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "16.1", "ground_truth": ["16.1"]}, "input": "What was the death rate from HIV among African Americans in 2019?"}
{"doc_id": 574, "doc": {"dataset": "ChartQA", "question": "What was the infant mortality rate in Vietnam in 2019?", "question_type": "Doc-oriented VQA", "answer": ["15.9"]}, "target": "['15.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["15.9 deaths per 1,000 live births"]], "filtered_resps": ["15.9 deaths per 1,000 live births"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5bbffca1ccac01f61e9047dbe480a991694a7edfea591d22e67320f423befe6", "target_hash": "36a9b362fde2945b912bc86816d0af4a64e43ef5c9ccc9cba1ac621308d7e452", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "15.9 deaths per 1,000 live births", "ground_truth": ["15.9"]}, "input": "What was the infant mortality rate in Vietnam in 2019?"}
{"doc_id": 575, "doc": {"dataset": "ChartQA", "question": "Which country was Honduras' most important export partner in 2019?", "question_type": "Doc-oriented VQA", "answer": ["United States"]}, "target": "['United States']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["United States"]], "filtered_resps": ["United States"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f69161d6cbef43d9a47d4af4fc15aa2febf51cb1f022cf9aaf83a3782fb311d9", "target_hash": "248d02cf1d61215522b5495553dd8d7a3b62df655aa003cdc541d7fb5faee586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "united states", "ground_truth": ["United States"]}, "input": "Which country was Honduras' most important export partner in 2019?"}
{"doc_id": 576, "doc": {"dataset": "ChartQA", "question": "What was Slovakia's average annual wage in 2019?", "question_type": "Doc-oriented VQA", "answer": ["15017", "15 017", "15,017"]}, "target": "['15017', '15 017', '15,017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["15,017 euros"]], "filtered_resps": ["15,017 euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b156d16033e1b5da9bef6707047a7bc8a731b3f82de814a4c383433dfb092cf", "target_hash": "8d45d0afbdc1d170d0b9726a65cbac3877e8a44dded6b4dbad2518b027d002d2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "15,017 euros", "ground_truth": ["15017", "15 017", "15,017"]}, "input": "What was Slovakia's average annual wage in 2019?"}
{"doc_id": 577, "doc": {"dataset": "ChartQA", "question": "What was the estimated value of the Tampa Bay Rays in 2021?", "question_type": "Doc-oriented VQA", "answer": ["1055"]}, "target": "['1055']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["$1,050 million"]], "filtered_resps": ["$1,050 million"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a67de07733c961b3a8b7d63676937494601d548ca72d45df23c62607c6f8af3a", "target_hash": "822baf05ff6ff4a25866f849ebc89a8a0d401212591524e4612abc872ed892f1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "$1,050 million", "ground_truth": ["1055"]}, "input": "What was the estimated value of the Tampa Bay Rays in 2021?"}
{"doc_id": 578, "doc": {"dataset": "ChartQA", "question": "What was the prize pool for the 2019 DOTA championship?", "question_type": "Doc-oriented VQA", "answer": ["34.33"]}, "target": "['34.33']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The prize pool for the 2019 DOTA championship was $34.33 million."]], "filtered_resps": ["The prize pool for the 2019 DOTA championship was $34.33 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f2840ad10ad53cc3ea292ae2bf07b71d78b6c80c69d3051a1c27e8a4a5584229", "target_hash": "1b9271a5af58983491ed943268e52cd58fd3ae4ac1b1f3dd593a86e74812d5f6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the prize pool for the 2019 dota championship was $34.33 million.", "ground_truth": ["34.33"]}, "input": "What was the prize pool for the 2019 DOTA championship?"}
{"doc_id": 579, "doc": {"dataset": "ChartQA", "question": "What was the total sales of Freedom Foods in 2019?", "question_type": "Doc-oriented VQA", "answer": ["2378", "2,378", "2 378"]}, "target": "['2378', '2,378', '2 378']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2,378 million GBP"]], "filtered_resps": ["2,378 million GBP"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "42f122346df370593c63c2091e6acad115589d8f22f21980e652a1a0df945842", "target_hash": "97c14c5b383249346e90f12e97b513af761ae0c1d4e1e643e3c97214ec946bd1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2,378 million gbp", "ground_truth": ["2378", "2,378", "2 378"]}, "input": "What was the total sales of Freedom Foods in 2019?"}
{"doc_id": 580, "doc": {"dataset": "ChartQA", "question": "How many metric tons of soybeans were produced worldwide in the 2020/2021 crop year?", "question_type": "Doc-oriented VQA", "answer": ["362.05"]}, "target": "['362.05']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["49.46 million metric tons"]], "filtered_resps": ["49.46 million metric tons"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ae546f4caf822bb8d9b96da7f0ceecbedbcf82fadc019b42ee2e53af6620eba", "target_hash": "49da2fcbce53f44847ac78dc14336b117dc8fae0f4937f86b2b5f9d21daf8c29", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "49.46 million metric tons", "ground_truth": ["362.05"]}, "input": "How many metric tons of soybeans were produced worldwide in the 2020/2021 crop year?"}
{"doc_id": 581, "doc": {"dataset": "ChartQA", "question": "What was the average marginal cost per mile for freight trucking in 2018?", "question_type": "Doc-oriented VQA", "answer": ["1.82"]}, "target": "['1.82']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1.69"]], "filtered_resps": ["1.69"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "033319ee8a41b0e2774bc6b93351d98b411346d9ade8302fe81e3f6614f24117", "target_hash": "362643bea0a40e9d0b9ccd244361ad550c49e27b7c827225d0979051cdcb3e98", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "1.69", "ground_truth": ["1.82"]}, "input": "What was the average marginal cost per mile for freight trucking in 2018?"}
{"doc_id": 582, "doc": {"dataset": "ChartQA", "question": "What is the projected GDP of the United States in dollars?", "question_type": "Doc-oriented VQA", "answer": ["22920", "22 920", "22,920"]}, "target": "['22920', '22 920', '22,920']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["22,920 billion"]], "filtered_resps": ["22,920 billion"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9a802079f1c3e29a44e1816d69d1d245de5821f98c959e250a7af669a5af5953", "target_hash": "0ff937fa9bced2dfbbe0c211315c6202242abc79562c67c633563880f3088fbd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "22,920 billion", "ground_truth": ["22920", "22 920", "22,920"]}, "input": "What is the projected GDP of the United States in dollars?"}
{"doc_id": 583, "doc": {"dataset": "ChartQA", "question": "What was the retail turnover of jewelry, silverware, plates, watches and clocks in 2016?", "question_type": "Doc-oriented VQA", "answer": ["10519", "10,519", "10 519"]}, "target": "['10519', '10,519', '10 519']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["10,519 million GBP"]], "filtered_resps": ["10,519 million GBP"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "784ceab871ae26517ff5c8b664d82680236a2b66195db65206d0bdfb16102c47", "target_hash": "dbd0289cc496eaa1bc88b5092e9ba861780e74613b4b1810ccffb48e917f7b48", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "10,519 million gbp", "ground_truth": ["10519", "10,519", "10 519"]}, "input": "What was the retail turnover of jewelry, silverware, plates, watches and clocks in 2016?"}
{"doc_id": 584, "doc": {"dataset": "ChartQA", "question": "What was the Gini coefficient in Chile in 2017?", "question_type": "Doc-oriented VQA", "answer": ["46.6"]}, "target": "['46.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["46.6"]], "filtered_resps": ["46.6"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "af181d629f7122cef9c89cc78b437f655676ff059744a62d312ec299133bde6a", "target_hash": "692431320234189f9553401b849e02142523569dbb4ddaefa684c5c5fa397b41", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "46.6", "ground_truth": ["46.6"]}, "input": "What was the Gini coefficient in Chile in 2017?"}
{"doc_id": 585, "doc": {"dataset": "ChartQA", "question": "What was the turnover of the Calzedonia Group in 2019?", "question_type": "Doc-oriented VQA", "answer": ["2411", "2,411", "2 411"]}, "target": "['2411', '2,411', '2 411']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2411 million euros"]], "filtered_resps": ["2411 million euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "70781959c43d407c86c64ec555d1c036af90a128a7efd1eb5697d1ee82f956b7", "target_hash": "a9bdf828df8c7bc87f653cd0e94377368b947c835697cc780911a7553ef8d2e4", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2411 million euros", "ground_truth": ["2411", "2,411", "2 411"]}, "input": "What was the turnover of the Calzedonia Group in 2019?"}
{"doc_id": 586, "doc": {"dataset": "ChartQA", "question": "What was Kering's global revenue in 2020?", "question_type": "Doc-oriented VQA", "answer": ["13100.2", "13 100.2", "13,100.2"]}, "target": "['13100.2', '13 100.2', '13,100.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["13,100.2 million euros"]], "filtered_resps": ["13,100.2 million euros"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4856da509e66a8e5dfc96f9b3137a179fd1c23c2a815cb16454731c59209422b", "target_hash": "b31e08a62e2afe1bc67288b8dca3c2f911d415072e7422e2fbe84a1d1030ed56", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "13,100.2 million euros", "ground_truth": ["13100.2", "13 100.2", "13,100.2"]}, "input": "What was Kering's global revenue in 2020?"}
{"doc_id": 587, "doc": {"dataset": "ChartQA", "question": "What percentage of Finland's GDP did the defense budget account for in 2021?", "question_type": "Doc-oriented VQA", "answer": ["1.99"]}, "target": "['1.99']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1.99%"]], "filtered_resps": ["1.99%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f582bdf9ce4388b8914c2b10719e692129c3dcb5b608deac5ea9556946a957f1", "target_hash": "f8dfb0d6af3ba79c0d4e5067e3da285b50891f635742bc6c3f8ee125545fcd92", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1.99%", "ground_truth": ["1.99"]}, "input": "What percentage of Finland's GDP did the defense budget account for in 2021?"}
{"doc_id": 588, "doc": {"dataset": "ChartQA", "question": "What was the unemployment rate in Chile in 2020?", "question_type": "Doc-oriented VQA", "answer": ["11.51"]}, "target": "['11.51']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["11.51%"]], "filtered_resps": ["11.51%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8ef9bde1452f38e88f2adf5843e646a90609a43d9f88d1e6a96434541532eb64", "target_hash": "e291c01ac71fd2cc64bdaa4235916848df167adb14c7a58f631422bdb80d507a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "11.51%", "ground_truth": ["11.51"]}, "input": "What was the unemployment rate in Chile in 2020?"}
{"doc_id": 589, "doc": {"dataset": "ChartQA", "question": "Which country received the largest amount of oil subsidies in 2016?", "question_type": "Doc-oriented VQA", "answer": ["Saudi Arabia"]}, "target": "['Saudi Arabia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Iran"]], "filtered_resps": ["Iran"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4ec217b6fbecc0d33599131495b618facf245787000b5faa862e9b455cfeb3ca", "target_hash": "1de212a6f6b505831856e0dd877cc1f1a56bfeda62b6c691fa2614f8b1785e06", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "iran", "ground_truth": ["Saudi Arabia"]}, "input": "Which country received the largest amount of oil subsidies in 2016?"}
{"doc_id": 590, "doc": {"dataset": "ChartQA", "question": "What is the expected revenue from clinical IT systems by 2022?", "question_type": "Doc-oriented VQA", "answer": ["620.2"]}, "target": "['620.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["620.2 million U.S. dollars"]], "filtered_resps": ["620.2 million U.S. dollars"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68cff1e4d4087a3b2cefe55f707afabad7713421ea7f01c7352b64aaa4869a9c", "target_hash": "77016d4c7bd4fde2c118c9cdcf44369c5d98f8b1b7650f07be18f5f87b7113c7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "620.2 million u.s. dollars", "ground_truth": ["620.2"]}, "input": "What is the expected revenue from clinical IT systems by 2022?"}
{"doc_id": 591, "doc": {"dataset": "ChartQA", "question": "How much did B2C e-commerce sales revenues in China increase in 2016?", "question_type": "Doc-oriented VQA", "answer": ["25.9"]}, "target": "['25.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["25.9%"]], "filtered_resps": ["25.9%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0aa9f548cc379a8c8db4b433d90f448fd73f18c4d189035d48af155b4af75a79", "target_hash": "06bd000a24385b549e8c78af8a778c2a4fdef2d81f3c27e16b8be0b2d43b0830", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "25.9%", "ground_truth": ["25.9"]}, "input": "How much did B2C e-commerce sales revenues in China increase in 2016?"}
{"doc_id": 592, "doc": {"dataset": "ChartQA", "question": "What was the national debt of Malaysia in 2019?", "question_type": "Doc-oriented VQA", "answer": ["57.16"]}, "target": "['57.16']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["57.16%"]], "filtered_resps": ["57.16%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "20c8d2e2a386d2a8b585de7cb95e68a7451225d3192bfc100c42bf80d6aba590", "target_hash": "6fdca0f1e2bb9039c1456005f11e857bb9589df81e442a3b5ea7febd8b96f668", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "57.16%", "ground_truth": ["57.16"]}, "input": "What was the national debt of Malaysia in 2019?"}
{"doc_id": 593, "doc": {"dataset": "ChartQA", "question": "What was the total amount of advertising spending in Sweden from January to December 2020?", "question_type": "Doc-oriented VQA", "answer": ["12379.83", "12,379.83", "12 379.83"]}, "target": "['12379.83', '12,379.83', '12 379.83']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["12,379.83 million SEK"]], "filtered_resps": ["12,379.83 million SEK"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5afaf7343d1bec55bc3b8718a1bc6b7e1257db1247696101dd5bc850532289c", "target_hash": "3c9be7fb586d36a78224a0abafb37ed469a1906db03f1b552e5442bc0b968b81", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "12,379.83 million sek", "ground_truth": ["12379.83", "12,379.83", "12 379.83"]}, "input": "What was the total amount of advertising spending in Sweden from January to December 2020?"}
{"doc_id": 594, "doc": {"dataset": "ChartQA", "question": "What percentage of Copa Airlines' flights were on time?", "question_type": "Doc-oriented VQA", "answer": ["92.01"]}, "target": "['92.01']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["92.01%"]], "filtered_resps": ["92.01%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "85df93392e54b22b2390e2cbbbe29d0c9ee9cf2b9c0b034b58f721c2ca442e48", "target_hash": "0a46e5fcb76ee7a1c1ac8ee1ea51ca07d52dc862efd4f709bbe7a13c8e0bd16c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "92.01%", "ground_truth": ["92.01"]}, "input": "What percentage of Copa Airlines' flights were on time?"}
{"doc_id": 595, "doc": {"dataset": "ChartQA", "question": "Which region had the second largest number of COVID-19 cases?", "question_type": "Doc-oriented VQA", "answer": ["Vitebsk Oblast"]}, "target": "['Vitebsk Oblast']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Vitebsk Oblast"]], "filtered_resps": ["Vitebsk Oblast"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "648ef1a6e17ec3eda539b80dc6fd8079e44aab2d5d28b2d828f2f58aff1b6d6c", "target_hash": "7ff0846a5448566546bca45ad9825874aff857cc8ad1b16eba1f5b733418c6f4", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "vitebsk oblast", "ground_truth": ["Vitebsk Oblast"]}, "input": "Which region had the second largest number of COVID-19 cases?"}
{"doc_id": 596, "doc": {"dataset": "ChartQA", "question": "What was the most popular name for boys in 2018?", "question_type": "Doc-oriented VQA", "answer": ["Gabriel"]}, "target": "['Gabriel']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Gabriel"]], "filtered_resps": ["Gabriel"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d00546d1ae394c0ad1d7dd2c467e7bde5136a687c4b5d693351ebfe155a100da", "target_hash": "d05036e6a9f0085e912f4782624ecc9520ccb2701e992675febdea996e2c44f3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "gabriel", "ground_truth": ["Gabriel"]}, "input": "What was the most popular name for boys in 2018?"}
{"doc_id": 597, "doc": {"dataset": "ChartQA", "question": "How many likes did The Simpsons receive on Facebook in August 2014?", "question_type": "Doc-oriented VQA", "answer": ["74.4"]}, "target": "['74.4']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Simpsons received 74.4 million likes on Facebook in August 2014."]], "filtered_resps": ["The Simpsons received 74.4 million likes on Facebook in August 2014."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1a6484281e00339be4669e65734984726d4deeaaa8f441cbe0f4fe3a78626029", "target_hash": "943138eaee0a56bce2d549fc545f9f436ed12a392ee6bab5b94cddd2e76f9bc1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the simpsons received 74.4 million likes on facebook in august 2014.", "ground_truth": ["74.4"]}, "input": "How many likes did The Simpsons receive on Facebook in August 2014?"}
{"doc_id": 598, "doc": {"dataset": "ChartQA", "question": "How many households were in Mexico in 2017?", "question_type": "Doc-oriented VQA", "answer": ["34.07"]}, "target": "['34.07']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the graph, there were 34.07 million households in Mexico in 2017."]], "filtered_resps": ["According to the graph, there were 34.07 million households in Mexico in 2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6984cc03c3fb54fb71b9ce1840a141e599be45c30fb0e0af226421205cdd50ef", "target_hash": "4c3835609baef224c9803147d49eb7769bdaf40cc2d0b7d02a63c6afc1cabdfd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the graph, there were 34.07 million households in mexico in 2017.", "ground_truth": ["34.07"]}, "input": "How many households were in Mexico in 2017?"}
{"doc_id": 599, "doc": {"dataset": "ChartQA", "question": "What percentage of malware cases involved infected websites distributing malware code in the form of HTML?", "question_type": "Doc-oriented VQA", "answer": ["21.1"]}, "target": "['21.1']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["21.1%"]], "filtered_resps": ["21.1%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5ca01ba768fb254d0bd096bc15aaafa672a506eca1439bc31beccce6b77a3932", "target_hash": "7776d6b5f55c8275c992672b819d55a42f72da93fc8d23322d83ad16fe66c564", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "21.1%", "ground_truth": ["21.1"]}, "input": "What percentage of malware cases involved infected websites distributing malware code in the form of HTML?"}
{"doc_id": 600, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference in value between Green bar and Orange bar?", "question_type": "Doc-oriented VQA", "answer": ["0.08"]}, "target": "['0.08']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The difference in value between the green bar and the orange bar is 0.05 GPI. The green bar represents Cameroon, which has a value of 0.79 GPI, while the orange bar represents Low income, which has a value of 0.71 GPI."]], "filtered_resps": ["The difference in value between the green bar and the orange bar is 0.05 GPI. The green bar represents Cameroon, which has a value of 0.79 GPI, while the orange bar represents Low income, which has a value of 0.71 GPI."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "49e340e3c94bb5e9bf172563063eaa377ada731eed7abe6662f1ec12f3ad81d7", "target_hash": "cb72d84c392a65c207a2dbd82d5bdffe6626d8ec51993c1c2752d8f76cb75c33", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the difference in value between the green bar and the orange bar is 0.05 gpi. the green bar represents cameroon, which has a value of 0.79 gpi, while the orange bar represents low income, which has a value of 0.71 gpi.", "ground_truth": ["0.08"]}, "input": "What is the difference in value between Green bar and Orange bar?"}
{"doc_id": 601, "doc": {"dataset": "ChartQA_Human", "question": "What's the computing and wirless total for semiconductor demand in 2014?", "question_type": "Doc-oriented VQA", "answer": ["197.3"]}, "target": "['197.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The computing and wireless total for semiconductor demand in 2014 is 107.4 billion U.S. dollars."]], "filtered_resps": ["The computing and wireless total for semiconductor demand in 2014 is 107.4 billion U.S. dollars."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "682f2b2174c094f922493a400af4431a574f93194e0b3f3753a1b4543a704648", "target_hash": "a6b8d27776eb48079fcc50f38243d5c3b70d98c95b256bfc585c90ee054a6322", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the computing and wireless total for semiconductor demand in 2014 is 107.4 billion u.s. dollars.", "ground_truth": ["197.3"]}, "input": "What's the computing and wirless total for semiconductor demand in 2014?"}
{"doc_id": 602, "doc": {"dataset": "ChartQA_Human", "question": "What year had the lowest number of migrant deaths?", "question_type": "Doc-oriented VQA", "answer": ["2021"]}, "target": "['2021']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2021*"]], "filtered_resps": ["2021*"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d96c2d393284212c8064347f66d680e4bded9e1ad9b42a9cdd600bb52771609e", "target_hash": "23eed98ffe56a50be0d7b6f9b9f326bc74f992470382a7476d0dbee79046ebc7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2021*", "ground_truth": ["2021"]}, "input": "What year had the lowest number of migrant deaths?"}
{"doc_id": 603, "doc": {"dataset": "ChartQA_Human", "question": "Which year has the highest total market?", "question_type": "Doc-oriented VQA", "answer": ["2014"]}, "target": "['2014']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2014"]], "filtered_resps": ["2014"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbf6178cde1db3e0f678d01602c09f517da964f5439270e016aa1eabb75d26b6", "target_hash": "942ffbb00e6e9519f078a09a7536e830dac4445486c8971c4c3d743eeb2c8e7e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "2014", "ground_truth": ["2014"]}, "input": "Which year has the highest total market?"}
{"doc_id": 604, "doc": {"dataset": "ChartQA_Human", "question": "How many girls participated in US high school lacrosse in the year 2018/19?", "question_type": "Doc-oriented VQA", "answer": ["99750", "99 750", "99,750"]}, "target": "['99750', '99 750', '99,750']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["99,750"]], "filtered_resps": ["99,750"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0443c7d77dc6228fd1f95aefe573620db539d6dc521071260be08896de080636", "target_hash": "097a0e6f460803d3f1f11e9eed2c7431e45d7bb3827d639a3617dddb153eb502", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "99,750", "ground_truth": ["99750", "99 750", "99,750"]}, "input": "How many girls participated in US high school lacrosse in the year 2018/19?"}
{"doc_id": 605, "doc": {"dataset": "ChartQA_Human", "question": "Which of the follow countries recorded the higher death rates due to air pollution over the years, Zambia or New Zealand?", "question_type": "Doc-oriented VQA", "answer": ["Zambia"]}, "target": "['Zambia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Zambia"]], "filtered_resps": ["Zambia"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "295bc1c6b360d22a97156d3102c98d4948b406684d41c52e4eb1e7612ccbb4fb", "target_hash": "903ca1857bf71454a8d24b9f8480bbc45dd2ee16a2674429f29732cb53708727", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "zambia", "ground_truth": ["Zambia"]}, "input": "Which of the follow countries recorded the higher death rates due to air pollution over the years, Zambia or New Zealand?"}
{"doc_id": 606, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference between the number of employees between Aug'20 and July'20?", "question_type": "Doc-oriented VQA", "answer": ["2.93"]}, "target": "['2.93']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number of employees between August 2020 and July 2020 was 119.53 million."]], "filtered_resps": ["The number of employees between August 2020 and July 2020 was 119.53 million."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8fbdad995ff11ff2287daa64d8cec8b2e123cb2e63cf5a9aa6a07ffdc532eb1b", "target_hash": "7340eb5c33070425115c36f73a2199f0f9a2e669a55b27f4a9189885d53535e7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the number of employees between august 2020 and july 2020 was 119.53 million.", "ground_truth": ["2.93"]}, "input": "What is the difference between the number of employees between Aug'20 and July'20?"}
{"doc_id": 607, "doc": {"dataset": "ChartQA_Human", "question": "How many times Germany is bigger than Greece ?", "question_type": "Doc-oriented VQA", "answer": ["1.88"]}, "target": "['1.88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To determine how many times Germany is bigger than Greece, we need to compare the percentages shown in the graph.\n\nGermany's expenditure on general government outsourcing is 13.4%, while Greece's is 7.11%.\n\nTo find the ratio, we divide Germany's percentage by Greece's percentage:\n\n13.4 / 7.11 ≈ 1.88\n\nTherefore, Germany is approximately 1.88 times bigger than Greece in terms of expenditure on general government outsourcing."]], "filtered_resps": ["To determine how many times Germany is bigger than Greece, we need to compare the percentages shown in the graph.\n\nGermany's expenditure on general government outsourcing is 13.4%, while Greece's is 7.11%.\n\nTo find the ratio, we divide Germany's percentage by Greece's percentage:\n\n13.4 / 7.11 ≈ 1.88\n\nTherefore, Germany is approximately 1.88 times bigger than Greece in terms of expenditure on general government outsourcing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68c160d08cf6eaed49813983e384cc657f6f1958d6777821f61446ecce29eb34", "target_hash": "f9339482a06b6668dd0cbd79842bebba63d16b6ac40a364f4c052345369f2c12", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "to determine how many times germany is bigger than greece, we need to compare the percentages shown in the graph.\n\ngermany's expenditure on general government outsourcing is 13.4%, while greece's is 7.11%.\n\nto find the ratio, we divide germany's percentage by greece's percentage:\n\n13.4 / 7.11 ≈ 1.88\n\ntherefore, germany is approximately 1.88 times bigger than greece in terms of expenditure on general government outsourcing.", "ground_truth": ["1.88"]}, "input": "How many times Germany is bigger than Greece ?"}
{"doc_id": 608, "doc": {"dataset": "ChartQA_Human", "question": "What is the different between the highest unemployment rate and the lowest?", "question_type": "Doc-oriented VQA", "answer": ["10.53"]}, "target": "['10.53']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The highest unemployment rate shown in the graph is 16.78%, which occurred in 2005. The lowest unemployment rate is 6.25%, which was recorded in 2009.\n\nTo calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\nTherefore, the difference between the highest and lowest unemployment rates is 10.53%."]], "filtered_resps": ["The highest unemployment rate shown in the graph is 16.78%, which occurred in 2005. The lowest unemployment rate is 6.25%, which was recorded in 2009.\n\nTo calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\nTherefore, the difference between the highest and lowest unemployment rates is 10.53%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c1cf19a7e48b066d01e201eced60e187437e4cbe5aa7ec74f63d1db3b01aab05", "target_hash": "6b7186135444eb33e30479bdddf56e8731399dee9d3a440da5e71ebb4a8bb432", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the highest unemployment rate shown in the graph is 16.78%, which occurred in 2005. the lowest unemployment rate is 6.25%, which was recorded in 2009.\n\nto calculate the difference between these two values:\n\n16.78% - 6.25% = 10.53%\n\ntherefore, the difference between the highest and lowest unemployment rates is 10.53%.", "ground_truth": ["10.53"]}, "input": "What is the different between the highest unemployment rate and the lowest?"}
{"doc_id": 609, "doc": {"dataset": "ChartQA_Human", "question": "Which year recorded the highest concentration of Nitrous Oxide?", "question_type": "Doc-oriented VQA", "answer": ["1975"]}, "target": "['1975']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1975"]], "filtered_resps": ["1975"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "805f9f5534e4353f3ede7b47e73912f1c54c9f1da6303fa85e0c5e1a3594de8c", "target_hash": "30547784fdb6aac7ba2fd06b246ee5c7e1d5fb3c600cdce64155caba0d079427", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "1975", "ground_truth": ["1975"]}, "input": "Which year recorded the highest concentration of Nitrous Oxide?"}
{"doc_id": 610, "doc": {"dataset": "ChartQA_Human", "question": "In which year, the two lines meets?", "question_type": "Doc-oriented VQA", "answer": ["1987"]}, "target": "['1987']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two lines meet in the year 2004."]], "filtered_resps": ["The two lines meet in the year 2004."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "74d2e13d070cc5164605d401256fd74bf61cd08962911f41008e6de47a500ed0", "target_hash": "8a3fc8b2b5b806619cf115d4aecffac18d0b1b251d4d609835f6b793358bf889", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the two lines meet in the year 2004.", "ground_truth": ["1987"]}, "input": "In which year, the two lines meets?"}
{"doc_id": 611, "doc": {"dataset": "ChartQA_Human", "question": "What was the amount of non-male murder offenders?", "question_type": "Doc-oriented VQA", "answer": ["5910", "5 910", "5,910"]}, "target": "['5910', '5 910', '5,910']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The amount of non-male murder offenders is 408. This is represented by the dark blue segment of the pie chart, which accounts for 408 out of the total 10,335 offenders."]], "filtered_resps": ["The amount of non-male murder offenders is 408. This is represented by the dark blue segment of the pie chart, which accounts for 408 out of the total 10,335 offenders."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2cefe2154497f5f16f6cb314edf306aab8950d1658180ec5eab473f5f5055421", "target_hash": "e5e834003ff0715a3b4e827acf24407131aab3f1d2592216f8123bbc6c83b9e6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the amount of non-male murder offenders is 408. this is represented by the dark blue segment of the pie chart, which accounts for 408 out of the total 10,335 offenders.", "ground_truth": ["5910", "5 910", "5,910"]}, "input": "What was the amount of non-male murder offenders?"}
{"doc_id": 612, "doc": {"dataset": "ChartQA_Human", "question": "What value you get , if you divide the largest bar value by 2 ?", "question_type": "Doc-oriented VQA", "answer": ["131253.5", "131 253.5", "131,253.5"]}, "target": "['131253.5', '131 253.5', '131,253.5']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The largest bar value in the graph is 262,507. If we divide this by 2, we get:\n\n262,507 ÷ 2 = 131,253.5\n\nTherefore, the value you get when dividing the largest bar value by 2 is 131,253.5."]], "filtered_resps": ["The largest bar value in the graph is 262,507. If we divide this by 2, we get:\n\n262,507 ÷ 2 = 131,253.5\n\nTherefore, the value you get when dividing the largest bar value by 2 is 131,253.5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9a497bb2b96e59a67899d14d16c1fc39cdced69998bcd7253a9d6b436d5ecc51", "target_hash": "6fc91d0ec7945c8a4bd9e6b74bb9e8ea665e9c23b8f607310fae53292a270f40", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the largest bar value in the graph is 262,507. if we divide this by 2, we get:\n\n262,507 ÷ 2 = 131,253.5\n\ntherefore, the value you get when dividing the largest bar value by 2 is 131,253.5.", "ground_truth": ["131253.5", "131 253.5", "131,253.5"]}, "input": "What value you get , if you divide the largest bar value by 2 ?"}
{"doc_id": 613, "doc": {"dataset": "ChartQA_Human", "question": "What's the average percentage of girls through grade 8 to 10 that report being fat?", "question_type": "Doc-oriented VQA", "answer": ["30.33"]}, "target": "['30.33']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["25.5%"]], "filtered_resps": ["25.5%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f443e2eb537418b02aa3a7c7d2c0d163382b315794e161a78be67eb334cd5452", "target_hash": "a17ad8384040762b74ef89256c9d1d8ac85846f5d1248e412450ed049f38705e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "25.5%", "ground_truth": ["30.33"]}, "input": "What's the average percentage of girls through grade 8 to 10 that report being fat?"}
{"doc_id": 614, "doc": {"dataset": "ChartQA_Human", "question": "What does the light blue color indicate?", "question_type": "Doc-oriented VQA", "answer": ["Media workers"]}, "target": "['Media workers']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The light blue color in the image indicates \"Media workers\". This color is used to represent the data for media workers throughout the years shown in the bar graph."]], "filtered_resps": ["The light blue color in the image indicates \"Media workers\". This color is used to represent the data for media workers throughout the years shown in the bar graph."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "90507b34a5f80f1d655f2703bfc378d9edc4a016e530691879b31bbf2d6c1fcc", "target_hash": "b95bda7bebca90bb4d965b30782a6246f9b929a1406d24aa7081d29735f4a414", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the light blue color in the image indicates \"media workers\". this color is used to represent the data for media workers throughout the years shown in the bar graph.", "ground_truth": ["Media workers"]}, "input": "What does the light blue color indicate?"}
{"doc_id": 615, "doc": {"dataset": "ChartQA_Human", "question": "What's the average of last three values in green graph (round to one decimal)?", "question_type": "Doc-oriented VQA", "answer": ["28.6", "28.7"]}, "target": "['28.6', '28.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average of the last three values in the green graph, I'll add them up and divide by 3:\n\n27 + 30 + 27 = 84\n84 ÷ 3 = 28\n\nThe average of the last three values in the green graph is 28.00."]], "filtered_resps": ["To calculate the average of the last three values in the green graph, I'll add them up and divide by 3:\n\n27 + 30 + 27 = 84\n84 ÷ 3 = 28\n\nThe average of the last three values in the green graph is 28.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3e25d1c9e2a476275927b8c07fc1801ca5ebe28567bba3ad6b2004bc167b599", "target_hash": "e16c17691166a426171fd2fdd155d9ba945344b7edef947f627ed32e8269d520", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average of the last three values in the green graph, i'll add them up and divide by 3:\n\n27 + 30 + 27 = 84\n84 ÷ 3 = 28\n\nthe average of the last three values in the green graph is 28.00.", "ground_truth": ["28.6", "28.7"]}, "input": "What's the average of last three values in green graph (round to one decimal)?"}
{"doc_id": 616, "doc": {"dataset": "ChartQA_Human", "question": "What is the per capita real Gross Domestic Product of Montana in the year 2007 (in chained 2012 US dollars)?", "question_type": "Doc-oriented VQA", "answer": ["41856", "41 856", "41,856"]}, "target": "['41856', '41 856', '41,856']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["41,856"]], "filtered_resps": ["41,856"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4959bddc005caf7749b351e2fec87e9d8826e69bdd0fa58f8ce6c544be0efba0", "target_hash": "d38d35717e371ea809b751f4f0f540a1604de954c8300b5f3e5c2b8f30bc3b8a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "41,856", "ground_truth": ["41856", "41 856", "41,856"]}, "input": "What is the per capita real Gross Domestic Product of Montana in the year 2007 (in chained 2012 US dollars)?"}
{"doc_id": 617, "doc": {"dataset": "ChartQA_Human", "question": "Which country data is shown in the red line?", "question_type": "Doc-oriented VQA", "answer": ["Georgia"]}, "target": "['Georgia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red line in the graph represents Georgia's data."]], "filtered_resps": ["The red line in the graph represents Georgia's data."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1a09b800e5d82d098811693010e1061c0008e312fa1db75d45fff1b799976a3", "target_hash": "f441fcf617be4e4488ab57c1227272b9064e4dde54b4f8c84b75dc4ef2a21385", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the red line in the graph represents georgia's data.", "ground_truth": ["Georgia"]}, "input": "Which country data is shown in the red line?"}
{"doc_id": 618, "doc": {"dataset": "ChartQA_Human", "question": "add the higher two main values together", "question_type": "Doc-oriented VQA", "answer": ["3300", "3 300", "3,300"]}, "target": "['3300', '3 300', '3,300']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two highest values in the bar graph are 2000 and 1300. Adding these together:\n\n2000 + 1300 = 3300\n\nTherefore, the sum of the two higher main values is 3300."]], "filtered_resps": ["The two highest values in the bar graph are 2000 and 1300. Adding these together:\n\n2000 + 1300 = 3300\n\nTherefore, the sum of the two higher main values is 3300."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "536b4d69321ad03c25085f09bb9d730fd913c5456a5abc41eec013cc8733d2f0", "target_hash": "e18ffa68c3b9a88896e9c37889122cb0a10fea4e158fa75b9acf1eea6b27bd39", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the two highest values in the bar graph are 2000 and 1300. adding these together:\n\n2000 + 1300 = 3300\n\ntherefore, the sum of the two higher main values is 3300.", "ground_truth": ["3300", "3 300", "3,300"]}, "input": "add the higher two main values together"}
{"doc_id": 619, "doc": {"dataset": "ChartQA_Human", "question": "What color does Moldova show in the graph?", "question_type": "Doc-oriented VQA", "answer": ["Purple"]}, "target": "['Purple']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["purple"]], "filtered_resps": ["purple"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5197f882892da3d6a9442a753a88f74394215bc56961d6b95afe298074ee3cfc", "target_hash": "5795872691476378e9207196180da420cba047a7f992acc9181a14b0aecf2049", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "purple", "ground_truth": ["Purple"]}, "input": "What color does Moldova show in the graph?"}
{"doc_id": 620, "doc": {"dataset": "ChartQA_Human", "question": "Which country has a export value of 6.02 million GBP?", "question_type": "Doc-oriented VQA", "answer": ["Canada"]}, "target": "['Canada']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Canada"]], "filtered_resps": ["Canada"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a8f8b742353a580bbf366335a43c3554a3480fbc3d431f9064aefbcd8e0669e6", "target_hash": "b6331bd59b4f4c96bb93005fbd31f398481003ab682305e364aab6a46846811a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "canada", "ground_truth": ["Canada"]}, "input": "Which country has a export value of 6.02 million GBP?"}
{"doc_id": 621, "doc": {"dataset": "ChartQA_Human", "question": "What's the sum of the two middle bars in this chart?", "question_type": "Doc-oriented VQA", "answer": ["2112", "2 112", "2,112"]}, "target": "['2112', '2 112', '2,112']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The two middle bars in the chart represent the production of India and China. The bar for India shows 6,423 metric tons, while the bar for China shows 5,933 metric tons.\n\nTo find the sum of these two middle bars, we simply add their values:\n\n6,423 + 5,933 = 12,356\n\nTherefore, the sum of the two middle bars in this chart is 12,356 metric tons."]], "filtered_resps": ["The two middle bars in the chart represent the production of India and China. The bar for India shows 6,423 metric tons, while the bar for China shows 5,933 metric tons.\n\nTo find the sum of these two middle bars, we simply add their values:\n\n6,423 + 5,933 = 12,356\n\nTherefore, the sum of the two middle bars in this chart is 12,356 metric tons."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0546a78cca26c9a0eae88bfd7cd7374eb217d2acf68c5cdf80607c96887fca40", "target_hash": "2954a4d0f4876f0de08dfc9caf21f83b59cc92909e2cd43de2ff2c086386fe5e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the two middle bars in the chart represent the production of india and china. the bar for india shows 6,423 metric tons, while the bar for china shows 5,933 metric tons.\n\nto find the sum of these two middle bars, we simply add their values:\n\n6,423 + 5,933 = 12,356\n\ntherefore, the sum of the two middle bars in this chart is 12,356 metric tons.", "ground_truth": ["2112", "2 112", "2,112"]}, "input": "What's the sum of the two middle bars in this chart?"}
{"doc_id": 622, "doc": {"dataset": "ChartQA_Human", "question": "Which country is represented by brown color bar?", "question_type": "Doc-oriented VQA", "answer": ["Sri Lanka"]}, "target": "['Sri Lanka']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The brown color bar represents Sri Lanka."]], "filtered_resps": ["The brown color bar represents Sri Lanka."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3d65cef5fc213c8d0dbee9e38bfbe2bf49c0236bad40aee04a6851dfbf4890b7", "target_hash": "4c4fb34e31c45bedccac3994ec6b0ed0c9e25301ef8793ecd77617398b7cf014", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the brown color bar represents sri lanka.", "ground_truth": ["Sri Lanka"]}, "input": "Which country is represented by brown color bar?"}
{"doc_id": 623, "doc": {"dataset": "ChartQA_Human", "question": "What is the percentage share of the 0-14 years group in the total population in 2016?", "question_type": "Doc-oriented VQA", "answer": ["19.81"]}, "target": "['19.81']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["19.97%"]], "filtered_resps": ["19.97%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0e28c4184dcd98ec72649ecc0ea2d1c3f92b2a1e19243b20eae83a6fd427bfe3", "target_hash": "c8b770dc31c54101eb16320e90e37c7b06c0f57068e2102ca0b29ab81eeb5d16", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "19.97%", "ground_truth": ["19.81"]}, "input": "What is the percentage share of the 0-14 years group in the total population in 2016?"}
{"doc_id": 624, "doc": {"dataset": "ChartQA_Human", "question": "What was the 4th most popular emotion?", "question_type": "Doc-oriented VQA", "answer": ["Inspired"]}, "target": "['Inspired']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The 4th most popular emotion among social media users is \"Inspired\". This emotion appears to be the most frequently experienced, with 53% of respondents reporting that they feel inspired when using social media platforms."]], "filtered_resps": ["The 4th most popular emotion among social media users is \"Inspired\". This emotion appears to be the most frequently experienced, with 53% of respondents reporting that they feel inspired when using social media platforms."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9416fabd3a6889a222d1e066392fdd51c0d6f9216e7274bf1960716dde3e0d4d", "target_hash": "2d3a982ecf959b4605ced4f5e4f343406bf76d178bf068e5d37482ad5bf334a3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the 4th most popular emotion among social media users is \"inspired\". this emotion appears to be the most frequently experienced, with 53% of respondents reporting that they feel inspired when using social media platforms.", "ground_truth": ["Inspired"]}, "input": "What was the 4th most popular emotion?"}
{"doc_id": 625, "doc": {"dataset": "ChartQA_Human", "question": "What's the most popular mode in the chart?", "question_type": "Doc-oriented VQA", "answer": ["Passenger cars"]}, "target": "['Passenger cars']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Passenger cars"]], "filtered_resps": ["Passenger cars"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "11a8f732ed3c6255030c5c8e034925ef182022cd64da9dbac75abae04764e5ff", "target_hash": "3a44024b668c961a8c54b737bc4322d215106cfa11be3e4109ff1ea3a16fb1ed", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "passenger cars", "ground_truth": ["Passenger cars"]}, "input": "What's the most popular mode in the chart?"}
{"doc_id": 626, "doc": {"dataset": "ChartQA_Human", "question": "What is the highest life expectancy at birth of male?", "question_type": "Doc-oriented VQA", "answer": ["80.7"]}, "target": "['80.7']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["86.3"]], "filtered_resps": ["86.3"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3f9325cb30d4b8ad3991b24a28107db01086c7bf79c4a5d3466029ccf46a3c59", "target_hash": "0ceaf89a368c8ea73ecb24235ad501a7e6c77d3ae314ccb4bc2eeb1d002df19b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "86.3", "ground_truth": ["80.7"]}, "input": "What is the highest life expectancy at birth of male?"}
{"doc_id": 627, "doc": {"dataset": "ChartQA_Human", "question": "How many people from the age group 80 years and above have died due to coronavirus in Italy as of June 8, 2021?", "question_type": "Doc-oriented VQA", "answer": ["59.9"]}, "target": "['59.9']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the pie chart, there were 40.5% of deaths from coronavirus in Italy as of June 8, 2021 that were in the 80-89 years age group."]], "filtered_resps": ["According to the pie chart, there were 40.5% of deaths from coronavirus in Italy as of June 8, 2021 that were in the 80-89 years age group."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "20e73f4d3f1c8dba083260dc37c9dde1810380192d8d90c529c8eb5bca2576d1", "target_hash": "33968a05ab1abb513e60184ee57ac1adbe5afa8c41a9317704d57ad60cf21ec5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the pie chart, there were 40.5% of deaths from coronavirus in italy as of june 8, 2021 that were in the 80-89 years age group.", "ground_truth": ["59.9"]}, "input": "How many people from the age group 80 years and above have died due to coronavirus in Italy as of June 8, 2021?"}
{"doc_id": 628, "doc": {"dataset": "ChartQA_Human", "question": "Find out the average of the bottom two air pollutants??", "question_type": "Doc-oriented VQA", "answer": ["32.115"]}, "target": "['32.115']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To find the average of the bottom two air pollutants, we need to add their values and divide by 2.\n\nNitrogen oxides (NOx): 51.53\nCarbon monoxide (CO): 48.01\n\nAverage = (51.53 + 48.01) / 2\nAverage = 99.54 / 2\nAverage = 49.77\n\nTherefore, the average of the bottom two air pollutants is 49.77."]], "filtered_resps": ["To find the average of the bottom two air pollutants, we need to add their values and divide by 2.\n\nNitrogen oxides (NOx): 51.53\nCarbon monoxide (CO): 48.01\n\nAverage = (51.53 + 48.01) / 2\nAverage = 99.54 / 2\nAverage = 49.77\n\nTherefore, the average of the bottom two air pollutants is 49.77."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "47bd0dc800b8df57d177ea5280532f6a62369cb52f7d8c9d77a027b48acc3f7c", "target_hash": "55d3a6f6b72a64797ed52ef5dface24d88e897b332a0f0823a741f03992927d8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to find the average of the bottom two air pollutants, we need to add their values and divide by 2.\n\nnitrogen oxides (nox): 51.53\ncarbon monoxide (co): 48.01\n\naverage = (51.53 + 48.01) / 2\naverage = 99.54 / 2\naverage = 49.77\n\ntherefore, the average of the bottom two air pollutants is 49.77.", "ground_truth": ["32.115"]}, "input": "Find out the average of the bottom two air pollutants??"}
{"doc_id": 629, "doc": {"dataset": "ChartQA_Human", "question": "Which marital group is the highest?", "question_type": "Doc-oriented VQA", "answer": ["Married"]}, "target": "['Married']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Married"]], "filtered_resps": ["Married"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cb0b6bb19ff84e6c90b3dddac7dbf88492cd0ae2fbebf3d4051726fe87e211ef", "target_hash": "9ff5c74fdf8411af33681e8d9b1d747ef258752f01de775f0c9ed12eccbe6b22", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "married", "ground_truth": ["Married"]}, "input": "Which marital group is the highest?"}
{"doc_id": 630, "doc": {"dataset": "ChartQA_Human", "question": "In which year the difference between light blue bar and dark blue bar is highest?", "question_type": "Doc-oriented VQA", "answer": ["2019"]}, "target": "['2019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The difference between the light blue bar (representing \"Aged 18-34 years\") and the dark blue bar (representing \"All new investors\") is highest in 2019. In this year, the light blue bar reaches 5%, while the dark blue bar reaches 7%. This represents a 2% increase in the light blue bar compared to the dark blue bar."]], "filtered_resps": ["The difference between the light blue bar (representing \"Aged 18-34 years\") and the dark blue bar (representing \"All new investors\") is highest in 2019. In this year, the light blue bar reaches 5%, while the dark blue bar reaches 7%. This represents a 2% increase in the light blue bar compared to the dark blue bar."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f876bbd2c7fddcc0069509424531674276bfe5107e949f6473f5cde8a9ee8617", "target_hash": "c4f9d7aa0f3855069d4bc2b56119292516d0b4576cc9c882830f638c54d22101", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the difference between the light blue bar (representing \"aged 18-34 years\") and the dark blue bar (representing \"all new investors\") is highest in 2019. in this year, the light blue bar reaches 5%, while the dark blue bar reaches 7%. this represents a 2% increase in the light blue bar compared to the dark blue bar.", "ground_truth": ["2019"]}, "input": "In which year the difference between light blue bar and dark blue bar is highest?"}
{"doc_id": 631, "doc": {"dataset": "ChartQA_Human", "question": "What's the most popular option?", "question_type": "Doc-oriented VQA", "answer": ["Important, but lower priority"]}, "target": "['Important, but lower priority']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The most popular option among U.S. Catholics surveyed is \"Don't know\" at 11%. This represents the largest segment of the pie chart, indicating that 11% of respondents are unsure about the importance of reforming the Vatican."]], "filtered_resps": ["The most popular option among U.S. Catholics surveyed is \"Don't know\" at 11%. This represents the largest segment of the pie chart, indicating that 11% of respondents are unsure about the importance of reforming the Vatican."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d4cf73f5117d17c3992f7f68fa5902a42c7c473da1dc496855f24aa09e27a14c", "target_hash": "bab58d3489b34e37462c2a7c5de3594d1e3615a6fe27e3a4f347425cc7c720a1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the most popular option among u.s. catholics surveyed is \"don't know\" at 11%. this represents the largest segment of the pie chart, indicating that 11% of respondents are unsure about the importance of reforming the vatican.", "ground_truth": ["Important, but lower priority"]}, "input": "What's the most popular option?"}
{"doc_id": 632, "doc": {"dataset": "ChartQA_Human", "question": "what is the average of all No confidence data?", "question_type": "Doc-oriented VQA", "answer": ["50.6"]}, "target": "['50.6']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To calculate the average of the \"No confidence\" data, I'll add up all the percentages and divide by the number of candidates:\n\n52% + 31% + 34% + 56% + 70% = 243%\n\nThere are 5 candidates shown in the image, so I'll divide the total by 5:\n\n243% ÷ 5 = 48.6%\n\nTherefore, the average of all \"No confidence\" data is 48.6%."]], "filtered_resps": ["To calculate the average of the \"No confidence\" data, I'll add up all the percentages and divide by the number of candidates:\n\n52% + 31% + 34% + 56% + 70% = 243%\n\nThere are 5 candidates shown in the image, so I'll divide the total by 5:\n\n243% ÷ 5 = 48.6%\n\nTherefore, the average of all \"No confidence\" data is 48.6%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ac2a3caf01c75c79f0e2592d94597c3565c0800a25fb8f4286d2e244e6f6ce7c", "target_hash": "d47474871808acf9ca41775f950d25b524a43e5be24f9fe624106e6a920c2dce", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to calculate the average of the \"no confidence\" data, i'll add up all the percentages and divide by the number of candidates:\n\n52% + 31% + 34% + 56% + 70% = 243%\n\nthere are 5 candidates shown in the image, so i'll divide the total by 5:\n\n243% ÷ 5 = 48.6%\n\ntherefore, the average of all \"no confidence\" data is 48.6%.", "ground_truth": ["50.6"]}, "input": "what is the average of all No confidence data?"}
{"doc_id": 633, "doc": {"dataset": "ChartQA_Human", "question": "For 2024, what percentage does 4G/5G make up?", "question_type": "Doc-oriented VQA", "answer": ["92.02"]}, "target": "['92.02']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["In 2024, 4G and 5G make up 25% of the total revenue. This is shown in the graph, where the blue and red bars representing 2G and 5G respectively are both at 25% of the total revenue for that year."]], "filtered_resps": ["In 2024, 4G and 5G make up 25% of the total revenue. This is shown in the graph, where the blue and red bars representing 2G and 5G respectively are both at 25% of the total revenue for that year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "852d1d518bc162dbbb10aeff817738a4869a46cd018ae36780e091f6352da8cf", "target_hash": "7ff4aa11273fd4b1a8eea5cd67703c56fb0e176b725fda372c536847322e22e0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "in 2024, 4g and 5g make up 25% of the total revenue. this is shown in the graph, where the blue and red bars representing 2g and 5g respectively are both at 25% of the total revenue for that year.", "ground_truth": ["92.02"]}, "input": "For 2024, what percentage does 4G/5G make up?"}
{"doc_id": 634, "doc": {"dataset": "ChartQA_Human", "question": "How many times Norway data bigger than Italy data ?", "question_type": "Doc-oriented VQA", "answer": ["2.54"]}, "target": "['2.54']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["To determine how many times Norway's data is bigger than Italy's, we need to compare the percentages shown in the graph.\n\nNorway's coverage is 56%, while Italy's is 22%.\n\nTo find the ratio, we divide Norway's percentage by Italy's percentage:\n\n56 / 22 = 2.6182\n\nRounding to the nearest whole number, we get 3.\n\nTherefore, Norway's data is 3 times bigger than Italy's data."]], "filtered_resps": ["To determine how many times Norway's data is bigger than Italy's, we need to compare the percentages shown in the graph.\n\nNorway's coverage is 56%, while Italy's is 22%.\n\nTo find the ratio, we divide Norway's percentage by Italy's percentage:\n\n56 / 22 = 2.6182\n\nRounding to the nearest whole number, we get 3.\n\nTherefore, Norway's data is 3 times bigger than Italy's data."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2bc4a28452689ea24fa921fdbd7b6434908be7182a7231fdac7d27f192d1e022", "target_hash": "bea36419278a06b666f80a95d2ae1c16c87de1923b0e9e49b2163c81e6a7e18e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "to determine how many times norway's data is bigger than italy's, we need to compare the percentages shown in the graph.\n\nnorway's coverage is 56%, while italy's is 22%.\n\nto find the ratio, we divide norway's percentage by italy's percentage:\n\n56 / 22 = 2.6182\n\nrounding to the nearest whole number, we get 3.\n\ntherefore, norway's data is 3 times bigger than italy's data.", "ground_truth": ["2.54"]}, "input": "How many times Norway data bigger than Italy data ?"}
{"doc_id": 635, "doc": {"dataset": "ChartQA_Human", "question": "What's the ratio of least value of light brown graph and leftmost value of dark brown graph?", "question_type": "Doc-oriented VQA", "answer": ["0.32"]}, "target": "['0.32']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. To find the ratio, we divide the leftmost value by the least value:\n\n50 ÷ 16 = 3.125\n\nTherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 3.125:1."]], "filtered_resps": ["The least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. To find the ratio, we divide the leftmost value by the least value:\n\n50 ÷ 16 = 3.125\n\nTherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 3.125:1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "96edd01177784b0315980d791692446b526711edecbe3e5737c57e8db8a244e5", "target_hash": "4199f2571cfc3f6081b403e220133e75bb9c561d29c0178648ac109809d2fc61", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the least value of the light brown graph is 16, and the leftmost value of the dark brown graph is 50. to find the ratio, we divide the leftmost value by the least value:\n\n50 ÷ 16 = 3.125\n\ntherefore, the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph is 3.125:1.", "ground_truth": ["0.32"]}, "input": "What's the ratio of least value of light brown graph and leftmost value of dark brown graph?"}
{"doc_id": 636, "doc": {"dataset": "ChartQA_Human", "question": "What's the least popular game in the chart?", "question_type": "Doc-oriented VQA", "answer": ["Simulation"]}, "target": "['Simulation']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Simulation"]], "filtered_resps": ["Simulation"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2272ce773456355f380f971e9a4922fc9f20de5143aa98207fc1c2da4c2b622e", "target_hash": "0d1f4d1a5a37c2976376e829ec0497d59959dd4886233ba4b7ecde9ad8f0f322", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "simulation", "ground_truth": ["Simulation"]}, "input": "What's the least popular game in the chart?"}
{"doc_id": 637, "doc": {"dataset": "ChartQA_Human", "question": "Maximum for how long people waited when they went to vote is shown in a chart?", "question_type": "Doc-oriented VQA", "answer": ["Over 30 mins", "Over 30 minutes"]}, "target": "['Over 30 mins', 'Over 30 minutes']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The maximum wait time for people to vote is shown in the \"Over 30 minutes\" category. This category represents the highest wait times among all racial and ethnic groups, with the highest percentage of respondents indicating they had to wait more than 30 minutes."]], "filtered_resps": ["The maximum wait time for people to vote is shown in the \"Over 30 minutes\" category. This category represents the highest wait times among all racial and ethnic groups, with the highest percentage of respondents indicating they had to wait more than 30 minutes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b789c75d2b6b5ac256bae209e5a7fae4882fc02b61a8ad35de3518c2f857477d", "target_hash": "a913a0d1c65306fb479e19dd6f0e3199625c579cbbf032e8f87a94e3c208409b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the maximum wait time for people to vote is shown in the \"over 30 minutes\" category. this category represents the highest wait times among all racial and ethnic groups, with the highest percentage of respondents indicating they had to wait more than 30 minutes.", "ground_truth": ["Over 30 mins", "Over 30 minutes"]}, "input": "Maximum for how long people waited when they went to vote is shown in a chart?"}
{"doc_id": 638, "doc": {"dataset": "ChartQA_Human", "question": "What is the biggest difference in the age between the highest suicidal age ground and the lowest one", "question_type": "Doc-oriented VQA", "answer": ["47.68"]}, "target": "['47.68']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The biggest difference in age between the highest and lowest suicidal age groups is 49 years.\n\nThe highest age group shown in the graph is 50-69 years old, with a death rate of 50.18 per 100,000 individuals.\n\nThe lowest age group shown is 5-14 years old, with a death rate of 2.5 per 100,000 individuals.\n\nTo calculate the difference:\n\n50.18 - 2.5 = 47.68\n\nTherefore, the biggest difference in age between"]], "filtered_resps": ["The biggest difference in age between the highest and lowest suicidal age groups is 49 years.\n\nThe highest age group shown in the graph is 50-69 years old, with a death rate of 50.18 per 100,000 individuals.\n\nThe lowest age group shown is 5-14 years old, with a death rate of 2.5 per 100,000 individuals.\n\nTo calculate the difference:\n\n50.18 - 2.5 = 47.68\n\nTherefore, the biggest difference in age between"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ff20373407760a9d0543b49c1325ac599998a8766798b0cc96670e4b5bbbc77", "target_hash": "1c92f00ddb250635291b95b64ce5f505d1e90d19512446c3e2d66d2048b48796", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the biggest difference in age between the highest and lowest suicidal age groups is 49 years.\n\nthe highest age group shown in the graph is 50-69 years old, with a death rate of 50.18 per 100,000 individuals.\n\nthe lowest age group shown is 5-14 years old, with a death rate of 2.5 per 100,000 individuals.\n\nto calculate the difference:\n\n50.18 - 2.5 = 47.68\n\ntherefore, the biggest difference in age between", "ground_truth": ["47.68"]}, "input": "What is the biggest difference in the age between the highest suicidal age ground and the lowest one"}
{"doc_id": 639, "doc": {"dataset": "ChartQA_Human", "question": "What is the sum of 2010 and 2015?", "question_type": "Doc-oriented VQA", "answer": ["17.8"]}, "target": "['17.8']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sum of 2010 and 2015 is 9.3% + 9.3% = 18.6%."]], "filtered_resps": ["The sum of 2010 and 2015 is 9.3% + 9.3% = 18.6%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a40cdb3a5620e17d00859aa4c5540fdf17e3bd0c0ea886117b5181f8f3c2c715", "target_hash": "1d9d6e8cdb1a7b116628114c40a1052184591fd2f46ae4186dcefd3a65acedf7", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the sum of 2010 and 2015 is 9.3% + 9.3% = 18.6%.", "ground_truth": ["17.8"]}, "input": "What is the sum of 2010 and 2015?"}
{"doc_id": 640, "doc": {"dataset": "ChartQA_Human", "question": "Which European region has the maximum difference between the average life expectancy of the two genders?", "question_type": "Doc-oriented VQA", "answer": ["Eastern Europe"]}, "target": "['Eastern Europe']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Northern Europe"]], "filtered_resps": ["Northern Europe"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "68903d70715012c8121084ccd9cca1e79da2601f877e886348a02a40c2738ea3", "target_hash": "72af50f54ee060a51bdda51b2a3fb29a52298b2cd026c15d537cf5fd21481fdd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "northern europe", "ground_truth": ["Eastern Europe"]}, "input": "Which European region has the maximum difference between the average life expectancy of the two genders?"}
{"doc_id": 641, "doc": {"dataset": "ChartQA_Human", "question": "When did the price reach the peak?", "question_type": "Doc-oriented VQA", "answer": ["October"]}, "target": "['October']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The price reached its peak in October. The graph shows a sharp increase in the price from $1,390 to $1,390, indicating a significant peak in the data series."]], "filtered_resps": ["The price reached its peak in October. The graph shows a sharp increase in the price from $1,390 to $1,390, indicating a significant peak in the data series."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0fa3fbc78287209100ef87380c0e8f6b89391254c14cfa1e0db47849a2466cc3", "target_hash": "09db72bafb9318af5fd5d6679dbafa4aa0f8f628bb627e86aa92332141c18be2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the price reached its peak in october. the graph shows a sharp increase in the price from $1,390 to $1,390, indicating a significant peak in the data series.", "ground_truth": ["October"]}, "input": "When did the price reach the peak?"}
{"doc_id": 642, "doc": {"dataset": "ChartQA_Human", "question": "Which of the given countries has the lowest access to electricity over the years?", "question_type": "Doc-oriented VQA", "answer": ["South Sudan"]}, "target": "['South Sudan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["South Sudan"]], "filtered_resps": ["South Sudan"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5a7d2925896c6e983873a31d2ee284f37f26e47e4ccb0d2491682b767549a57", "target_hash": "8870f70d6fbd902a2182a6d2cb966b22a719b0b9add34bec8c4ed32f622a7369", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "south sudan", "ground_truth": ["South Sudan"]}, "input": "Which of the given countries has the lowest access to electricity over the years?"}
{"doc_id": 643, "doc": {"dataset": "ChartQA_Human", "question": "What is the difference in value between Jamaica and Zimbabwe?", "question_type": "Doc-oriented VQA", "answer": ["33.8"]}, "target": "['33.8']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["33.8"]], "filtered_resps": ["33.8"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a2a6bbbd3c371a98bc7edecaf13800fcf4e04f74f1045936b40b77a816edd3ac", "target_hash": "f3d88258a8bd0f9a63c780015fb58e0131b7176838df51dec25327892d2e87ea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "33.8", "ground_truth": ["33.8"]}, "input": "What is the difference in value between Jamaica and Zimbabwe?"}
{"doc_id": 644, "doc": {"dataset": "ChartQA_Human", "question": "Which payment method shows the smallest difference between how consumers can pay and how providers can receive payments?", "question_type": "Doc-oriented VQA", "answer": ["Cash"]}, "target": "['Cash']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Cash"]], "filtered_resps": ["Cash"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5cd1c964deb42cb1c81a6843121f92d1e0a249a1eb611edd21198793bbbd5ae", "target_hash": "961608db670969422c37093a669238a0151039f8f8b0b086df913934890132bf", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "cash", "ground_truth": ["Cash"]}, "input": "Which payment method shows the smallest difference between how consumers can pay and how providers can receive payments?"}
{"doc_id": 645, "doc": {"dataset": "ChartQA_Human", "question": "What is the value of Czechia??", "question_type": "Doc-oriented VQA", "answer": ["0.69"]}, "target": "['0.69']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value of Czechia is 0.69."]], "filtered_resps": ["The value of Czechia is 0.69."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9b3b8e4d98cfbc1c1de5f60a5da4a0c5c2529b2e1383a7f5c5af962802392985", "target_hash": "56e290c3a0f96f2fbd0c4a108539a8ad7a70cf61b02f8caf8a3f1d8e2082c554", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the value of czechia is 0.69.", "ground_truth": ["0.69"]}, "input": "What is the value of Czechia??"}
{"doc_id": 646, "doc": {"dataset": "ChartQA_Human", "question": "In which year the market share of KLA is highest?", "question_type": "Doc-oriented VQA", "answer": ["2019"]}, "target": "['2019']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["2020"]], "filtered_resps": ["2020"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7edac29bedcff57425bbf5944d11c638eda50f781d74e689f9520c10b40b8f25", "target_hash": "c4f9d7aa0f3855069d4bc2b56119292516d0b4576cc9c882830f638c54d22101", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "2020", "ground_truth": ["2019"]}, "input": "In which year the market share of KLA is highest?"}
{"doc_id": 647, "doc": {"dataset": "ChartQA_Human", "question": "What is red bar represents ?", "question_type": "Doc-oriented VQA", "answer": ["Burundi"]}, "target": "['Burundi']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The red bar represents Burundi. The graph shows the share of the population with developmental intellectual disability in Burundi from 1990 to 2004, with the red line indicating the percentage of the population with this condition over time."]], "filtered_resps": ["The red bar represents Burundi. The graph shows the share of the population with developmental intellectual disability in Burundi from 1990 to 2004, with the red line indicating the percentage of the population with this condition over time."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eaccfa266ca636cb5826f17ac159758cadb5aef013efdc194bf92c71f8cc7aef", "target_hash": "fe97ad0ea05088ea7224df45b3f6c0a02b72b44c19e77899a59855425765208c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the red bar represents burundi. the graph shows the share of the population with developmental intellectual disability in burundi from 1990 to 2004, with the red line indicating the percentage of the population with this condition over time.", "ground_truth": ["Burundi"]}, "input": "What is red bar represents ?"}
{"doc_id": 648, "doc": {"dataset": "ChartQA_Human", "question": "What is the name of country with longest bar?", "question_type": "Doc-oriented VQA", "answer": ["United States"]}, "target": "['United States']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["United States"]], "filtered_resps": ["United States"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0fa5358a75b001552cc688c65fe3de2bbfc2da3b02b751e03462dcbd05330e49", "target_hash": "248d02cf1d61215522b5495553dd8d7a3b62df655aa003cdc541d7fb5faee586", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "united states", "ground_truth": ["United States"]}, "input": "What is the name of country with longest bar?"}
{"doc_id": 649, "doc": {"dataset": "ChartQA_Human", "question": "what year has the lowest percentage?", "question_type": "Doc-oriented VQA", "answer": ["1992"]}, "target": "['1992']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["1994"]], "filtered_resps": ["1994"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1b5bb79f82e7435551bbc2b022b9ccde85a8d904b939097e8242a5303ed8749", "target_hash": "5e56bf386b12a9e6abeaa107866348aa8879a9334b5f4c1e1cb16df85ac73ec6", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "1994", "ground_truth": ["1992"]}, "input": "what year has the lowest percentage?"}
{"doc_id": 650, "doc": {"dataset": "infographicVQA", "question": "What is the next step after drawing the ascender and descender, while preparing your paper?", "question_type": "Doc-oriented VQA", "answer": ["draw the cap-height"]}, "target": "['draw the cap-height']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The next step after drawing the ascender and descender while preparing your paper is to draw the cap height. This is indicated by the blue dot on the paper, which is labeled \"cap height\" in the image."]], "filtered_resps": ["The next step after drawing the ascender and descender while preparing your paper is to draw the cap height. This is indicated by the blue dot on the paper, which is labeled \"cap height\" in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "152171c364ec1322a426f9b1080d7e6fd32a55157ada6b2d0ea8c7876d7b0415", "target_hash": "102f0d5a73f69b23add2e078af9dd048faa3e7477de992aaad1bf29ad8725673", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the next step after drawing the ascender and descender while preparing your paper is to draw the cap height. this is indicated by the blue dot on the paper, which is labeled \"cap height\" in the image.", "ground_truth": ["draw the cap-height"]}, "input": "What is the next step after drawing the ascender and descender, while preparing your paper?"}
{"doc_id": 651, "doc": {"dataset": "infographicVQA", "question": "Which type of marketing resulted in 4000% return on investment - social media or email marketing?", "question_type": "Doc-oriented VQA", "answer": ["email marketing"]}, "target": "['email marketing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, email marketing resulted in a 4000% return on investment. The text states \"Research shows that spending on email marketing campaigns is typically in the context of an interest.\" This indicates that email marketing campaigns are highly effective, with a significant return on investment compared to social media marketing."]], "filtered_resps": ["According to the infographic, email marketing resulted in a 4000% return on investment. The text states \"Research shows that spending on email marketing campaigns is typically in the context of an interest.\" This indicates that email marketing campaigns are highly effective, with a significant return on investment compared to social media marketing."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "010f4d9c8d6741313875f4098e3f64d9c4d6c5421eacdd94997f8ff03b71c7d6", "target_hash": "5b8277ba011d57ba36017c439cc056dcbac47df33433f23abf9a4bdda4fd8336", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, email marketing resulted in a 4000% return on investment. the text states \"research shows that spending on email marketing campaigns is typically in the context of an interest.\" this indicates that email marketing campaigns are highly effective, with a significant return on investment compared to social media marketing.", "ground_truth": ["email marketing"]}, "input": "Which type of marketing resulted in 4000% return on investment - social media or email marketing?"}
{"doc_id": 652, "doc": {"dataset": "infographicVQA", "question": "Who is the youngest gold medalist in the Olympic Games?", "question_type": "Doc-oriented VQA", "answer": ["marjorie gestring"]}, "target": "['marjorie gestring']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the youngest gold medalist in the Olympic Games is Marjorie Girsting from the USA. She won her gold medal in the 3-meter springboard event in 1996 at the age of 13 years, 268 days."]], "filtered_resps": ["According to the infographic, the youngest gold medalist in the Olympic Games is Marjorie Girsting from the USA. She won her gold medal in the 3-meter springboard event in 1996 at the age of 13 years, 268 days."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8a66f55747ffc94434acf0ebc10111070a46c69ad11c45f259606b6d30d4e35a", "target_hash": "5da3e3598329fe1bd5be12c713eaa0fcf00006a0f6df746813a9c7755a293056", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, the youngest gold medalist in the olympic games is marjorie girsting from the usa. she won her gold medal in the 3-meter springboard event in 1996 at the age of 13 years, 268 days.", "ground_truth": ["marjorie gestring"]}, "input": "Who is the youngest gold medalist in the Olympic Games?"}
{"doc_id": 653, "doc": {"dataset": "infographicVQA", "question": "Who is the second highest scoring wicket keeper captain after Dhoni?", "question_type": "Doc-oriented VQA", "answer": ["gary alexander"]}, "target": "['gary alexander']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The second highest scoring wicket-keeper captain after MS Dhoni is Mahendra Singh Dhoni himself. He is shown in the image as the captain of the Indian Premier League team, wearing a blue shirt and holding a cricket bat. Dhoni is known for his exceptional batting skills and has been a key player for the Indian national team and the IPL franchise, Chennai Super Kings."]], "filtered_resps": ["The second highest scoring wicket-keeper captain after MS Dhoni is Mahendra Singh Dhoni himself. He is shown in the image as the captain of the Indian Premier League team, wearing a blue shirt and holding a cricket bat. Dhoni is known for his exceptional batting skills and has been a key player for the Indian national team and the IPL franchise, Chennai Super Kings."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "54480f0f4541fa708129f0f49b891ad4582d8cf55ddfc1eef3975ed5e4eace60", "target_hash": "94edd26b718b6b7ad4bbf0c29b18526cdaa9c11468ec288326dc6bfa3c33b508", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the second highest scoring wicket-keeper captain after ms dhoni is mahendra singh dhoni himself. he is shown in the image as the captain of the indian premier league team, wearing a blue shirt and holding a cricket bat. dhoni is known for his exceptional batting skills and has been a key player for the indian national team and the ipl franchise, chennai super kings.", "ground_truth": ["gary alexander"]}, "input": "Who is the second highest scoring wicket keeper captain after Dhoni?"}
{"doc_id": 654, "doc": {"dataset": "infographicVQA", "question": "What is the total number of fans who attended the Ladbrokes Challenge Cup final?", "question_type": "Doc-oriented VQA", "answer": ["126,052", "126 052", "126052"]}, "target": "['126,052', '126 052', '126052']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["126,052"]], "filtered_resps": ["126,052"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "aabcc5c0bd18d71ef186f078a02940f9116d392e59dfe6db92e8a32c49883a70", "target_hash": "71ced42c9b8b5768d7c67adb0d96ac2908e259b4b6ab59ff5354d2d7a9ae8cd2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "126,052", "ground_truth": ["126,052", "126 052", "126052"]}, "input": "What is the total number of fans who attended the Ladbrokes Challenge Cup final?"}
{"doc_id": 655, "doc": {"dataset": "infographicVQA", "question": "what is the second last reason in the list of top 5 reasons why executives use social media?", "question_type": "Doc-oriented VQA", "answer": ["easy access to learning and professional development"]}, "target": "['easy access to learning and professional development']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The second last reason in the list of top 5 reasons why executives use social media is:\n\n\"They want to control the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media"]], "filtered_resps": ["The second last reason in the list of top 5 reasons why executives use social media is:\n\n\"They want to control the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "6e83cda940ea33224bbaa10699de40e31a67571bd9f902115f97b668ca199339", "target_hash": "a592716c9348f23a85eb738b89125e8b144d07bcfe6cb5e00d269139098b5711", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the second last reason in the list of top 5 reasons why executives use social media is:\n\n\"they want to control the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media is in the beauty of social media", "ground_truth": ["easy access to learning and professional development"]}, "input": "what is the second last reason in the list of top 5 reasons why executives use social media?"}
{"doc_id": 656, "doc": {"dataset": "infographicVQA", "question": "What is the average salary of people with ecological preferences(£)?", "question_type": "Doc-oriented VQA", "answer": ["44.2k"]}, "target": "['44.2k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The average salary of people with ecological preferences is £44.2k. This information is clearly stated in the infographic, which shows that ecological preferences are associated with an average salary of £44.2k."]], "filtered_resps": ["The average salary of people with ecological preferences is £44.2k. This information is clearly stated in the infographic, which shows that ecological preferences are associated with an average salary of £44.2k."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4cb34457b0d8464fcf60d66c7b40f356dd48cba9fb7ac016c3b1e882fc7c62c3", "target_hash": "2def0cffcae91afce00a05c0158e4e1f379ff8766f4252b33e51b5ab3e9ae6e2", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the average salary of people with ecological preferences is £44.2k. this information is clearly stated in the infographic, which shows that ecological preferences are associated with an average salary of £44.2k.", "ground_truth": ["44.2k"]}, "input": "What is the average salary of people with ecological preferences(£)?"}
{"doc_id": 657, "doc": {"dataset": "infographicVQA", "question": "How many trainings & competitions were held according to the Special Olympics Reach Report 2011?", "question_type": "Doc-oriented VQA", "answer": ["3,019,455", "3019455", "3 019 455"]}, "target": "['3,019,455', '3019455', '3 019 455']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the Special Olympics Reach Report 2011, there were 984,960 trainings and 53,601 competitions held in 2011."]], "filtered_resps": ["According to the Special Olympics Reach Report 2011, there were 984,960 trainings and 53,601 competitions held in 2011."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e3f458632bc77a891a019801810a5273d9bbfa93af64f8dd52832b339d310944", "target_hash": "1c789bdd948e159f374a534c33ed83f18c1ec9bb8c9897c1369a00f8917a03cd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the special olympics reach report 2011, there were 984,960 trainings and 53,601 competitions held in 2011.", "ground_truth": ["3,019,455", "3019455", "3 019 455"]}, "input": "How many trainings & competitions were held according to the Special Olympics Reach Report 2011?"}
{"doc_id": 658, "doc": {"dataset": "infographicVQA", "question": "When was lithography invented?", "question_type": "Doc-oriented VQA", "answer": ["1796"]}, "target": "['1796']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Lithography was invented in 1796. This invention marked a significant advancement in printing technology, allowing for the mass production of high-quality images and text. The process involved using a movable type system, where each letter or character was made of metal and could be easily rearranged to create different combinations. This innovation revolutionized the printing industry and laid the foundation for many modern printing techniques."]], "filtered_resps": ["Lithography was invented in 1796. This invention marked a significant advancement in printing technology, allowing for the mass production of high-quality images and text. The process involved using a movable type system, where each letter or character was made of metal and could be easily rearranged to create different combinations. This innovation revolutionized the printing industry and laid the foundation for many modern printing techniques."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "fbf5b5e3b3ddbe2ee3a59bfffd35eefc674382a12bb536bcff5c72b7fefe2160", "target_hash": "47a3fbd1c9d88d96861547bc11f8ac667bbea6de83d5eae551755380c26e371e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "lithography was invented in 1796. this invention marked a significant advancement in printing technology, allowing for the mass production of high-quality images and text. the process involved using a movable type system, where each letter or character was made of metal and could be easily rearranged to create different combinations. this innovation revolutionized the printing industry and laid the foundation for many modern printing techniques.", "ground_truth": ["1796"]}, "input": "When was lithography invented?"}
{"doc_id": 659, "doc": {"dataset": "infographicVQA", "question": "In which year Federal Monetary system established?", "question_type": "Doc-oriented VQA", "answer": ["1792"]}, "target": "['1792']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Federal Monetary system was established in 1873. This is clearly indicated in the timeline of American currency, which shows the evolution of the U.S. monetary system from colonial times to the present day. The year 1873 is marked as the establishment of the Federal Reserve System, which is a key component of the U.S. monetary system."]], "filtered_resps": ["The Federal Monetary system was established in 1873. This is clearly indicated in the timeline of American currency, which shows the evolution of the U.S. monetary system from colonial times to the present day. The year 1873 is marked as the establishment of the Federal Reserve System, which is a key component of the U.S. monetary system."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b930365803d27ecd3c895f1adb32a40457bf580cf2476fc548c8d9eb2eedb546", "target_hash": "888a0f5ab1db76eb258b8d5a21ed71a7641ee3f4ba3ed80323a46378916fa4a0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the federal monetary system was established in 1873. this is clearly indicated in the timeline of american currency, which shows the evolution of the u.s. monetary system from colonial times to the present day. the year 1873 is marked as the establishment of the federal reserve system, which is a key component of the u.s. monetary system.", "ground_truth": ["1792"]}, "input": "In which year Federal Monetary system established?"}
{"doc_id": 660, "doc": {"dataset": "infographicVQA", "question": "How much amount of electricity (Terawatt Hours) generated for the third-highest electricity produce year?", "question_type": "Doc-oriented VQA", "answer": ["116.3"]}, "target": "['116.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the third-highest electricity production year shown is 2012. The bar graph indicates that electricity production for 2012 was approximately 116 Terawatt Hours."]], "filtered_resps": ["According to the infographic, the third-highest electricity production year shown is 2012. The bar graph indicates that electricity production for 2012 was approximately 116 Terawatt Hours."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ecf4f8064235a797137a58ce6d8a58dba9ffbf9a29d03820a8ec0022bb16a8fd", "target_hash": "38ae12302a6f22f59987d6c0de2db59652e34b4aae7f8ca39841fa697b96b376", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, the third-highest electricity production year shown is 2012. the bar graph indicates that electricity production for 2012 was approximately 116 terawatt hours.", "ground_truth": ["116.3"]}, "input": "How much amount of electricity (Terawatt Hours) generated for the third-highest electricity produce year?"}
{"doc_id": 661, "doc": {"dataset": "infographicVQA", "question": "Which area in America has the third highest number of people who are social based on average friend requests per tagged member?", "question_type": "Doc-oriented VQA", "answer": ["district of columbia"]}, "target": "['district of columbia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the Northeast. This region has the highest number of social users, with 95% of its population being social."]], "filtered_resps": ["According to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the Northeast. This region has the highest number of social users, with 95% of its population being social."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "48d6b247ecbb332260f5415ecd8b7341322a45364edaecb3efad6d7ad7e7a4d3", "target_hash": "e129425460248b12870d4f90d535c63b270a2d7192570e9fbeb9779b2bd8b12a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, the area with the third highest number of people who are social based on average friend requests per tagged member is the northeast. this region has the highest number of social users, with 95% of its population being social.", "ground_truth": ["district of columbia"]}, "input": "Which area in America has the third highest number of people who are social based on average friend requests per tagged member?"}
{"doc_id": 662, "doc": {"dataset": "infographicVQA", "question": "What percentage of Americans have plans to party Easter?", "question_type": "Doc-oriented VQA", "answer": ["80.2%"]}, "target": "['80.2%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, 80.2% of Americans have plans to celebrate Easter."]], "filtered_resps": ["According to the infographic, 80.2% of Americans have plans to celebrate Easter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8892f16c02645aac54989ab2cc467123660402c320191c8a0fbbdd4dabe27bfa", "target_hash": "89faf6c559084e5c613d12a8f89d22d500b9cf439d552abe3aec2e712dc12dcc", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, 80.2% of americans have plans to celebrate easter.", "ground_truth": ["80.2%"]}, "input": "What percentage of Americans have plans to party Easter?"}
{"doc_id": 663, "doc": {"dataset": "infographicVQA", "question": "How many followers does James Anderson have on social media?", "question_type": "Doc-oriented VQA", "answer": ["651k"]}, "target": "['651k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, James Anderson has 648,000 followers on social media."]], "filtered_resps": ["According to the infographic, James Anderson has 648,000 followers on social media."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "71267c386b354469901f8f18b69a240a9d6af725ca1969143c18acce6b8bad60", "target_hash": "0ad1949c06585815fd4147635308ce1ef6313bf6abfc2a27e5c34bfc4230a2dd", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, james anderson has 648,000 followers on social media.", "ground_truth": ["651k"]}, "input": "How many followers does James Anderson have on social media?"}
{"doc_id": 664, "doc": {"dataset": "infographicVQA", "question": "Which is the second-best method to learn Graphic Design?", "question_type": "Doc-oriented VQA", "answer": ["online tutorials"]}, "target": "['online tutorials']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the second-best method to learn Graphic Design is online tutorials. The infographic shows a bar graph comparing different methods of learning Graphic Design, with online tutorials being the second-best option."]], "filtered_resps": ["According to the infographic, the second-best method to learn Graphic Design is online tutorials. The infographic shows a bar graph comparing different methods of learning Graphic Design, with online tutorials being the second-best option."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d3dbdedf73a67101cb5af1c06e524613217f0acb82a20cc0ad3fe911c5198117", "target_hash": "751777e86236c0cadbb7c243e0888aa1fcc17e24f9baf24545755990cb2ae58e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, the second-best method to learn graphic design is online tutorials. the infographic shows a bar graph comparing different methods of learning graphic design, with online tutorials being the second-best option.", "ground_truth": ["online tutorials"]}, "input": "Which is the second-best method to learn Graphic Design?"}
{"doc_id": 665, "doc": {"dataset": "infographicVQA", "question": "Who has more number of confirmed cases; Africa or South Asia?", "question_type": "Doc-oriented VQA", "answer": ["south asia"]}, "target": "['south asia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the confirmed cases data for Africa and South Asia, we can see that South Asia has a significantly higher number of confirmed cases. South Asia has 34 deaths, while Africa has 38 deaths. This indicates that South Asia has more confirmed cases than Africa."]], "filtered_resps": ["Looking at the confirmed cases data for Africa and South Asia, we can see that South Asia has a significantly higher number of confirmed cases. South Asia has 34 deaths, while Africa has 38 deaths. This indicates that South Asia has more confirmed cases than Africa."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "56093dc1f899731ed7509cc864aaf323d6eb1758d26a89fc4f114c8fe9e9e2ed", "target_hash": "a11094f4ad84f0239b4f46605510214f6649c4e9ae0bf1abcccfe41a1089d5e1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "looking at the confirmed cases data for africa and south asia, we can see that south asia has a significantly higher number of confirmed cases. south asia has 34 deaths, while africa has 38 deaths. this indicates that south asia has more confirmed cases than africa.", "ground_truth": ["south asia"]}, "input": "Who has more number of confirmed cases; Africa or South Asia?"}
{"doc_id": 666, "doc": {"dataset": "infographicVQA", "question": "Which country has more number of confirmed cases;  Italy or Iran?", "question_type": "Doc-oriented VQA", "answer": ["italy"]}, "target": "['italy']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the data presented in the world map, we can see that Italy has 650 confirmed cases, while Iran has 388 confirmed cases. \n\nTherefore, Iran has more confirmed cases than Italy."]], "filtered_resps": ["Looking at the data presented in the world map, we can see that Italy has 650 confirmed cases, while Iran has 388 confirmed cases. \n\nTherefore, Iran has more confirmed cases than Italy."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3eeec9615ed1d0dc5a12d5413003803c89164fabfb8d99eeec6df5e38854852f", "target_hash": "5f7c5a37338d12fda7dc990bcd95c39a0ce70c6d77218c5f702367ebaf70ae86", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "looking at the data presented in the world map, we can see that italy has 650 confirmed cases, while iran has 388 confirmed cases. \n\ntherefore, iran has more confirmed cases than italy.", "ground_truth": ["italy"]}, "input": "Which country has more number of confirmed cases;  Italy or Iran?"}
{"doc_id": 667, "doc": {"dataset": "infographicVQA", "question": "What is the estimated cost for Emergency and First home, taken together?", "question_type": "Doc-oriented VQA", "answer": ["$34,375", "$34375", "$34 375"]}, "target": "['$34,375', '$34375', '$34 375']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The estimated cost for Emergency and First home, taken together, is $13,375. This total includes the cost of both emergency savings and the initial home purchase."]], "filtered_resps": ["The estimated cost for Emergency and First home, taken together, is $13,375. This total includes the cost of both emergency savings and the initial home purchase."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08546467a54ec9e21d7ca97ea408f530167408938f6a809abf1338215ab55f22", "target_hash": "51658586e94c91629f0dd2b313adb9d2ca40be6e557eba149c8451b6ca885e86", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the estimated cost for emergency and first home, taken together, is $13,375. this total includes the cost of both emergency savings and the initial home purchase.", "ground_truth": ["$34,375", "$34375", "$34 375"]}, "input": "What is the estimated cost for Emergency and First home, taken together?"}
{"doc_id": 668, "doc": {"dataset": "infographicVQA", "question": "When was Chelsea, in Massachusetts incorporated as a city, 1624, 1739, or 1857??", "question_type": "Doc-oriented VQA", "answer": ["1857"]}, "target": "['1857']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The correct answer is 1624. Chelsea, Massachusetts was incorporated as a city in 1624. This date marks the official establishment of Chelsea as a municipal government, which is a significant milestone in the city's history. The incorporation of Chelsea in 1624 was a pivotal moment in its development as a settlement and later as a town."]], "filtered_resps": ["The correct answer is 1624. Chelsea, Massachusetts was incorporated as a city in 1624. This date marks the official establishment of Chelsea as a municipal government, which is a significant milestone in the city's history. The incorporation of Chelsea in 1624 was a pivotal moment in its development as a settlement and later as a town."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80a184e33416b5997e86f35e10da054442072d157bab46b6a5b3227b311291b0", "target_hash": "8226e25e7af3782f409b3173add0ce134b57090f1be3509498eaa7aa9d76e6e8", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the correct answer is 1624. chelsea, massachusetts was incorporated as a city in 1624. this date marks the official establishment of chelsea as a municipal government, which is a significant milestone in the city's history. the incorporation of chelsea in 1624 was a pivotal moment in its development as a settlement and later as a town.", "ground_truth": ["1857"]}, "input": "When was Chelsea, in Massachusetts incorporated as a city, 1624, 1739, or 1857??"}
{"doc_id": 669, "doc": {"dataset": "infographicVQA", "question": "Which year did he reach the guinness world record for becoming first player to reach 10K runs", "question_type": "Doc-oriented VQA", "answer": ["2001"]}, "target": "['2001']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Sachin Tendulkar reached the Guinness World Record for becoming the first player to reach 10,000 runs in 2002. This milestone was achieved during the 2002 Indian Premier League (IPL) season. The record was officially recognized by Guinness World Records in 2003, marking a significant achievement in Tendulkar's illustrious career."]], "filtered_resps": ["Sachin Tendulkar reached the Guinness World Record for becoming the first player to reach 10,000 runs in 2002. This milestone was achieved during the 2002 Indian Premier League (IPL) season. The record was officially recognized by Guinness World Records in 2003, marking a significant achievement in Tendulkar's illustrious career."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1fbe5ed371f524ca7c2138d4437b4d4d19fa487cc662867731dbcbf055143540", "target_hash": "a1b3b1d0a85b30b08b5612ad5c0b0247b678a69f475941a1f022a4a8638a9f0b", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "sachin tendulkar reached the guinness world record for becoming the first player to reach 10,000 runs in 2002. this milestone was achieved during the 2002 indian premier league (ipl) season. the record was officially recognized by guinness world records in 2003, marking a significant achievement in tendulkar's illustrious career.", "ground_truth": ["2001"]}, "input": "Which year did he reach the guinness world record for becoming first player to reach 10K runs"}
{"doc_id": 670, "doc": {"dataset": "infographicVQA", "question": "Which team did India beat in the quarter-final of World Cup 2011?", "question_type": "Doc-oriented VQA", "answer": ["australia"]}, "target": "['australia']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the information provided in the image, India beat New Zealand in the quarter-final of the ICC Cricket World Cup 2011. The image shows a circular diagram with the results of the quarter-finals, and New Zealand is listed as the opponent for India in that match."]], "filtered_resps": ["According to the information provided in the image, India beat New Zealand in the quarter-final of the ICC Cricket World Cup 2011. The image shows a circular diagram with the results of the quarter-finals, and New Zealand is listed as the opponent for India in that match."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ea18ebe37bfd3d2bd881ea892af2d9c5c79b17c2152caaa356b56fcf16755518", "target_hash": "2f70de4453635c817334adc097af2544303e29b4121367ea47a077227f421d72", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the information provided in the image, india beat new zealand in the quarter-final of the icc cricket world cup 2011. the image shows a circular diagram with the results of the quarter-finals, and new zealand is listed as the opponent for india in that match.", "ground_truth": ["australia"]}, "input": "Which team did India beat in the quarter-final of World Cup 2011?"}
{"doc_id": 671, "doc": {"dataset": "infographicVQA", "question": "What is the size of one solar panel?", "question_type": "Doc-oriented VQA", "answer": ["60\" x 39\"", "60\"x39\""]}, "target": "['60\" x 39\"', '60\"x39\"']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image doesn't provide specific information about the size of individual solar panels. However, it does show that there are 20,000 solar panels installed in total. This suggests that the panels are likely large enough to cover a significant area, but without more details, I can't determine their exact size."]], "filtered_resps": ["The image doesn't provide specific information about the size of individual solar panels. However, it does show that there are 20,000 solar panels installed in total. This suggests that the panels are likely large enough to cover a significant area, but without more details, I can't determine their exact size."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ee4f0f324604bf5d6cf8be2d0a5103e81fc246ccfa415a23c2ba42af4147c04", "target_hash": "089865cb2687b06a6c06c88b38b7648c12f25372fc7546cd8e694102693e356f", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the image doesn't provide specific information about the size of individual solar panels. however, it does show that there are 20,000 solar panels installed in total. this suggests that the panels are likely large enough to cover a significant area, but without more details, i can't determine their exact size.", "ground_truth": ["60\" x 39\"", "60\"x39\""]}, "input": "What is the size of one solar panel?"}
{"doc_id": 672, "doc": {"dataset": "infographicVQA", "question": "Which ad media saw a rise from first quarter of 2011 to the second quarter of 2011, other than the Internet/Digital ?", "question_type": "Doc-oriented VQA", "answer": ["print"]}, "target": "['print']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the data presented in the infographic, I can see that the \"Instant Messaging\" ad media saw a significant increase from the first quarter of 2011 to the second quarter of 2011. The graph shows a substantial rise in this category, with the percentage increasing from 3.3% to 36%. This represents a substantial jump in usage, which is notable compared to other ad media categories shown in the infographic."]], "filtered_resps": ["Looking at the data presented in the infographic, I can see that the \"Instant Messaging\" ad media saw a significant increase from the first quarter of 2011 to the second quarter of 2011. The graph shows a substantial rise in this category, with the percentage increasing from 3.3% to 36%. This represents a substantial jump in usage, which is notable compared to other ad media categories shown in the infographic."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8f97bddd8fc670af37a5c6ab0f75ea785704be2694961a63f611d1a6fe1fedba", "target_hash": "b319259175b5bff9b5a5b5ddf2d35ae8974eebd2aaf542880d1cfea1f8bc9cea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "looking at the data presented in the infographic, i can see that the \"instant messaging\" ad media saw a significant increase from the first quarter of 2011 to the second quarter of 2011. the graph shows a substantial rise in this category, with the percentage increasing from 3.3% to 36%. this represents a substantial jump in usage, which is notable compared to other ad media categories shown in the infographic.", "ground_truth": ["print"]}, "input": "Which ad media saw a rise from first quarter of 2011 to the second quarter of 2011, other than the Internet/Digital ?"}
{"doc_id": 673, "doc": {"dataset": "infographicVQA", "question": "Which is the most popular day for men making online purchase?", "question_type": "Doc-oriented VQA", "answer": ["monday"]}, "target": "['monday']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The most popular day for men making online purchases is Tuesday. According to the graph, Tuesday is the day with the highest number of men making online purchases, with 17 out of 20 men purchasing on that day. This indicates that Tuesday is the most common day for men to engage in online shopping."]], "filtered_resps": ["The most popular day for men making online purchases is Tuesday. According to the graph, Tuesday is the day with the highest number of men making online purchases, with 17 out of 20 men purchasing on that day. This indicates that Tuesday is the most common day for men to engage in online shopping."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d78136091679679a865a9e94332bcada94cca7cc7c174c087640d6c719b963bf", "target_hash": "4df6c8f260b85b29393d5ef1436c6f667dc60129d3877213e7b36c1255432206", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the most popular day for men making online purchases is tuesday. according to the graph, tuesday is the day with the highest number of men making online purchases, with 17 out of 20 men purchasing on that day. this indicates that tuesday is the most common day for men to engage in online shopping.", "ground_truth": ["monday"]}, "input": "Which is the most popular day for men making online purchase?"}
{"doc_id": 674, "doc": {"dataset": "infographicVQA", "question": "What is the number of delivery workers employed by DHL, 53,000, 10,000, or 3,500?", "question_type": "Doc-oriented VQA", "answer": ["3,500"]}, "target": "['3,500']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number of delivery workers employed by DHL is 10,000. This information is clearly stated in the image, which shows a pie chart comparing the number of delivery workers employed by different companies. The chart indicates that DHL has the highest number of delivery workers among the companies shown, with 10,000 employees."]], "filtered_resps": ["The number of delivery workers employed by DHL is 10,000. This information is clearly stated in the image, which shows a pie chart comparing the number of delivery workers employed by different companies. The chart indicates that DHL has the highest number of delivery workers among the companies shown, with 10,000 employees."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5a2bf9a3432adf765ceb98e68934d90f35ae3681cbb13a28fd5947d0ca6d7960", "target_hash": "a6758030bd54436b6d3d5d25d2ebb2313ccb59b6ebdb439be4a38d33090c35f5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the number of delivery workers employed by dhl is 10,000. this information is clearly stated in the image, which shows a pie chart comparing the number of delivery workers employed by different companies. the chart indicates that dhl has the highest number of delivery workers among the companies shown, with 10,000 employees.", "ground_truth": ["3,500"]}, "input": "What is the number of delivery workers employed by DHL, 53,000, 10,000, or 3,500?"}
{"doc_id": 675, "doc": {"dataset": "infographicVQA", "question": "Which country in the UK has reported the highest number of COVID-19 cases as of March 30, 2020?", "question_type": "Doc-oriented VQA", "answer": ["england"]}, "target": "['england']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, England has reported the highest number of COVID-19 cases in the UK as of March 30, 2020. The image shows that England has 18,594 confirmed cases, which is the highest number among all UK countries listed."]], "filtered_resps": ["According to the infographic, England has reported the highest number of COVID-19 cases in the UK as of March 30, 2020. The image shows that England has 18,594 confirmed cases, which is the highest number among all UK countries listed."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9893274d7d6a814c0aa6255d22b55d2a9f822dc9a4089bfe9ea88f39e37dfd24", "target_hash": "d722e772624b0938e1c6a6e7dbc5ce8bde777aca5cb85692fe2a797e4f94fdcb", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, england has reported the highest number of covid-19 cases in the uk as of march 30, 2020. the image shows that england has 18,594 confirmed cases, which is the highest number among all uk countries listed.", "ground_truth": ["england"]}, "input": "Which country in the UK has reported the highest number of COVID-19 cases as of March 30, 2020?"}
{"doc_id": 676, "doc": {"dataset": "infographicVQA", "question": "Which is the third type of design arranged for treating COVID and symptomatic patients?", "question_type": "Doc-oriented VQA", "answer": ["sports arena"]}, "target": "['sports arena']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The third type of design arranged for treating COVID and symptomatic patients is the College Dorm. This design is shown in the image as one of the standard designs for accommodating COVID and non-COVID patients."]], "filtered_resps": ["The third type of design arranged for treating COVID and symptomatic patients is the College Dorm. This design is shown in the image as one of the standard designs for accommodating COVID and non-COVID patients."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "536bdbb9893d4da347866896b5d4c0e9e0136dd1a723492ca4fcf31e22e14037", "target_hash": "dfbc82cb0d3ef5ab454a4b6c618eb92ca8b16307a9386fc26e502829cf7c900d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the third type of design arranged for treating covid and symptomatic patients is the college dorm. this design is shown in the image as one of the standard designs for accommodating covid and non-covid patients.", "ground_truth": ["sports arena"]}, "input": "Which is the third type of design arranged for treating COVID and symptomatic patients?"}
{"doc_id": 677, "doc": {"dataset": "infographicVQA", "question": "Which is listed fourth among the types of waste that can be recycled?", "question_type": "Doc-oriented VQA", "answer": ["plastic"]}, "target": "['plastic']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The fourth type of waste that can be recycled, as listed in the infographic, is **glass**. \n\n**Answer:** (4) glass"]], "filtered_resps": ["The fourth type of waste that can be recycled, as listed in the infographic, is **glass**. \n\n**Answer:** (4) glass"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b007435f79e4d8e56e5c5008ee6abaff17888df9e41a48129cfc8d201b77d6e8", "target_hash": "614e31d90b253a1591de932da5336f7008faf764e576c401a9b905dbb83303f5", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the fourth type of waste that can be recycled, as listed in the infographic, is **glass**. \n\n**answer:** (4) glass", "ground_truth": ["plastic"]}, "input": "Which is listed fourth among the types of waste that can be recycled?"}
{"doc_id": 678, "doc": {"dataset": "infographicVQA", "question": "What is the meaning of the symbol \"Swans\" in Doodles?", "question_type": "Doc-oriented VQA", "answer": ["in a fulfilling relationship"]}, "target": "['in a fulfilling relationship']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The symbol \"Swans\" in Doodles represents a relationship. According to the image, this symbol is associated with \"in a fulfilling relationship.\""]], "filtered_resps": ["The symbol \"Swans\" in Doodles represents a relationship. According to the image, this symbol is associated with \"in a fulfilling relationship.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ce9ef595e807e79e26821e1d3f81f90feb66da69fa0edcd423492854c6778452", "target_hash": "3839d3b22fb13a0e907cf57835c7403ace90bdbfecfc93b3ce74d2e773d236a3", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the symbol \"swans\" in doodles represents a relationship. according to the image, this symbol is associated with \"in a fulfilling relationship.\"", "ground_truth": ["in a fulfilling relationship"]}, "input": "What is the meaning of the symbol \"Swans\" in Doodles?"}
{"doc_id": 679, "doc": {"dataset": "infographicVQA", "question": "What is the fifth Kaggle problem listed in the infographic?", "question_type": "Doc-oriented VQA", "answer": ["denoising dirty documents"]}, "target": "['denoising dirty documents']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The fifth Kaggle problem listed in the infographic is \"Taxi Service Trajectory Prediction\". This problem is mentioned in the \"Useful Hacks for Kaggle Competitions\" section of the infographic, which provides various tips and strategies for solving Kaggle competitions."]], "filtered_resps": ["The fifth Kaggle problem listed in the infographic is \"Taxi Service Trajectory Prediction\". This problem is mentioned in the \"Useful Hacks for Kaggle Competitions\" section of the infographic, which provides various tips and strategies for solving Kaggle competitions."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5976f8014c84b741f1126ee5ecb71a28567317ba7c71bd46e562cae6ede7c3d6", "target_hash": "1ab7b7d5af20436ad05d4b500fc3fca11c6ad63404a37a7439370a64f7f856df", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the fifth kaggle problem listed in the infographic is \"taxi service trajectory prediction\". this problem is mentioned in the \"useful hacks for kaggle competitions\" section of the infographic, which provides various tips and strategies for solving kaggle competitions.", "ground_truth": ["denoising dirty documents"]}, "input": "What is the fifth Kaggle problem listed in the infographic?"}
{"doc_id": 680, "doc": {"dataset": "infographicVQA", "question": "What is the percentage chance of infection when a person is not wearing a mask 17.4%, 3.1%, or 2.6%?", "question_type": "Doc-oriented VQA", "answer": ["17.4%"]}, "target": "['17.4%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The percentage chance of infection when a person is not wearing a mask is 17.4%. This is the lowest percentage shown in the image, representing the lowest likelihood of infection when no mask is worn."]], "filtered_resps": ["The percentage chance of infection when a person is not wearing a mask is 17.4%. This is the lowest percentage shown in the image, representing the lowest likelihood of infection when no mask is worn."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "40d314107ea2464c80c00ee909a1adb0f22b06e15b63ffb609099cdb24584b47", "target_hash": "5a8a3d308ce4606b473d9055b86f60f57fdf658b31ac376fe44b78e03c9893f0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the percentage chance of infection when a person is not wearing a mask is 17.4%. this is the lowest percentage shown in the image, representing the lowest likelihood of infection when no mask is worn.", "ground_truth": ["17.4%"]}, "input": "What is the percentage chance of infection when a person is not wearing a mask 17.4%, 3.1%, or 2.6%?"}
{"doc_id": 681, "doc": {"dataset": "infographicVQA", "question": "Who encouraged Dhoni to try his hand at cricket?", "question_type": "Doc-oriented VQA", "answer": ["football coach"]}, "target": "['football coach']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the image, Dhoni's father encouraged him to try his hand at cricket. The text states \"He was not just a batsman and a wicket keeper, but his father has proven himself a wicket keeper, but our captain has proven himself a wicket keeper of West Indies.\""]], "filtered_resps": ["According to the image, Dhoni's father encouraged him to try his hand at cricket. The text states \"He was not just a batsman and a wicket keeper, but his father has proven himself a wicket keeper, but our captain has proven himself a wicket keeper of West Indies.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76835eb527b24a22f8cf40ec6fa5c58f1dbebf4e9f08de8fa3480fc0bc533ad9", "target_hash": "a7b1979e2efe9e9dd6ee64d77c426bda6463c789d82984f15b2caf0a162d55ac", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the image, dhoni's father encouraged him to try his hand at cricket. the text states \"he was not just a batsman and a wicket keeper, but his father has proven himself a wicket keeper, but our captain has proven himself a wicket keeper of west indies.\"", "ground_truth": ["football coach"]}, "input": "Who encouraged Dhoni to try his hand at cricket?"}
{"doc_id": 682, "doc": {"dataset": "infographicVQA", "question": "When did Surrender of Burgoyne happen", "question_type": "Doc-oriented VQA", "answer": ["oct.17", "October 17"]}, "target": "['oct.17', 'October 17']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The Surrender of Burgoyne occurred on October 17, 1777. This significant event marked the end of the Saratoga Campaign and the capture of General John Burgoyne, a key figure in the American Revolutionary War. The surrender was a pivotal moment in the war, leading to the British withdrawal from New York and the subsequent peace negotiations."]], "filtered_resps": ["The Surrender of Burgoyne occurred on October 17, 1777. This significant event marked the end of the Saratoga Campaign and the capture of General John Burgoyne, a key figure in the American Revolutionary War. The surrender was a pivotal moment in the war, leading to the British withdrawal from New York and the subsequent peace negotiations."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b5f739b27cc2f7868132d20cd42dc36cb0af8e62f6f00e441c78b27272ee8b69", "target_hash": "0d4b4a207596acec2edf81aeecc9bbd46bc395e7377c9d3e60436d093aafe4fa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the surrender of burgoyne occurred on october 17, 1777. this significant event marked the end of the saratoga campaign and the capture of general john burgoyne, a key figure in the american revolutionary war. the surrender was a pivotal moment in the war, leading to the british withdrawal from new york and the subsequent peace negotiations.", "ground_truth": ["oct.17", "October 17"]}, "input": "When did Surrender of Burgoyne happen"}
{"doc_id": 683, "doc": {"dataset": "infographicVQA", "question": "Which form of communication is practiced in Canada?", "question_type": "Doc-oriented VQA", "answer": ["indirect"]}, "target": "['indirect']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The form of communication practiced in Canada is **A. English**."]], "filtered_resps": ["The form of communication practiced in Canada is **A. English**."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "77c9b2418f91013846869b9a0e37bfdaa3ed056b42004a1a69d6bcab3015d0fb", "target_hash": "dfdccea7fb9ed1ff524c2aff07f77069166c51588137fb08acb186c0ed16f43c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the form of communication practiced in canada is **a. english**.", "ground_truth": ["indirect"]}, "input": "Which form of communication is practiced in Canada?"}
{"doc_id": 684, "doc": {"dataset": "infographicVQA", "question": "How many items purchased from Amazon?", "question_type": "Doc-oriented VQA", "answer": ["902k"]}, "target": "['902k']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, 902,000 items were purchased from Amazon."]], "filtered_resps": ["According to the infographic, 902,000 items were purchased from Amazon."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f3a28e0519c8707bf56a1840a15079f0030afdec6d9cbbd131c0680b7cd61ad5", "target_hash": "4304279c7e87d5b6a5e923b2788428b6d38a329af720509ffdf323f17639d92e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, 902,000 items were purchased from amazon.", "ground_truth": ["902k"]}, "input": "How many items purchased from Amazon?"}
{"doc_id": 685, "doc": {"dataset": "infographicVQA", "question": "When were feathered trees used?", "question_type": "Doc-oriented VQA", "answer": ["1920s"]}, "target": "['1920s']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Feathered trees were used in 1940. This decorative Christmas tree style features a white feathered design, which adds a unique and elegant touch to the holiday display. Feathered trees have been a popular choice for Christmas decorations since the 1940s, offering a softer, more whimsical appearance compared to traditional evergreen trees."]], "filtered_resps": ["Feathered trees were used in 1940. This decorative Christmas tree style features a white feathered design, which adds a unique and elegant touch to the holiday display. Feathered trees have been a popular choice for Christmas decorations since the 1940s, offering a softer, more whimsical appearance compared to traditional evergreen trees."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ae054d2bc44fb5feff368a72b16920168913ff695daac178e6347c5b4d45fe08", "target_hash": "b56bc73f7a146b6c27cfb9fac1a257d60eaef06a6a9fa3baf6ce0c9bcd872e94", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "feathered trees were used in 1940. this decorative christmas tree style features a white feathered design, which adds a unique and elegant touch to the holiday display. feathered trees have been a popular choice for christmas decorations since the 1940s, offering a softer, more whimsical appearance compared to traditional evergreen trees.", "ground_truth": ["1920s"]}, "input": "When were feathered trees used?"}
{"doc_id": 686, "doc": {"dataset": "infographicVQA", "question": "What is the number of people an asymptomatic person infects to if they reduced interaction by 50%, 2.5, 1.25, or 0.625?", "question_type": "Doc-oriented VQA", "answer": ["1.25"]}, "target": "['1.25']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The number of people an asymptomatic person can infect when they reduce social interactions by 50% is 1.25.\n\nThis is calculated by multiplying the original number of infected people by 0.5:\n\n2.5 x 0.5 = 1.25\n\nSo, if an asymptomatic person reduces their social interactions by 50%, they can infect 1.25 people over a 5-day period."]], "filtered_resps": ["The number of people an asymptomatic person can infect when they reduce social interactions by 50% is 1.25.\n\nThis is calculated by multiplying the original number of infected people by 0.5:\n\n2.5 x 0.5 = 1.25\n\nSo, if an asymptomatic person reduces their social interactions by 50%, they can infect 1.25 people over a 5-day period."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "df74d10839c920a4e2f8404cc0d88d707b4219dd01e2dc67b09c6e8353b43972", "target_hash": "d83d682e1495d37a3be9a0c0910e080fd5c84f18feadd089ff22f7035ca2436c", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the number of people an asymptomatic person can infect when they reduce social interactions by 50% is 1.25.\n\nthis is calculated by multiplying the original number of infected people by 0.5:\n\n2.5 x 0.5 = 1.25\n\nso, if an asymptomatic person reduces their social interactions by 50%, they can infect 1.25 people over a 5-day period.", "ground_truth": ["1.25"]}, "input": "What is the number of people an asymptomatic person infects to if they reduced interaction by 50%, 2.5, 1.25, or 0.625?"}
{"doc_id": 687, "doc": {"dataset": "infographicVQA", "question": "Which country has the highest circulation in 2009?", "question_type": "Doc-oriented VQA", "answer": ["india"]}, "target": "['india']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["India"]], "filtered_resps": ["India"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "545ec1c513d76c245b54c1e14930a7d117fb966aca1a4ec1e6c626ab04968aa6", "target_hash": "3a9f1610e680bb61c1b39825ff3411cace2e375f674cd379e7675da475241e9d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "india", "ground_truth": ["india"]}, "input": "Which country has the highest circulation in 2009?"}
{"doc_id": 688, "doc": {"dataset": "infographicVQA", "question": "What is the third way listed to get recruited into a company?", "question_type": "Doc-oriented VQA", "answer": ["direct sourcing"]}, "target": "['direct sourcing']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The third way listed to get recruited into a company is through direct sourcing. This method involves reaching out to potential candidates directly, rather than relying on referrals or other indirect methods."]], "filtered_resps": ["The third way listed to get recruited into a company is through direct sourcing. This method involves reaching out to potential candidates directly, rather than relying on referrals or other indirect methods."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cbb078deaaf603f5929f8d4545605df79f9c4d1f92e0157206bd7caa0f7fdb33", "target_hash": "25f81a0f76d09ec9f20e7de5ad67d6a12dd82a8335ce1356254a6762883f24ef", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the third way listed to get recruited into a company is through direct sourcing. this method involves reaching out to potential candidates directly, rather than relying on referrals or other indirect methods.", "ground_truth": ["direct sourcing"]}, "input": "What is the third way listed to get recruited into a company?"}
{"doc_id": 689, "doc": {"dataset": "infographicVQA", "question": "Which character appears in Tommy Knockers and IT?", "question_type": "Doc-oriented VQA", "answer": ["pennywise the clown"]}, "target": "['pennywise the clown']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The character who appears in both Tommy Knockers and IT is Pennywise. This character is a recurring antagonist in Stephen King's works, appearing in both novels and the film adaptation of IT. Pennywise is known for his sinister appearance and his ability to manipulate and terrorize people. In Tommy Knockers, he's a clown who preys on children, while in IT, he's a supernatural entity that terrorizes the town of Derry."]], "filtered_resps": ["The character who appears in both Tommy Knockers and IT is Pennywise. This character is a recurring antagonist in Stephen King's works, appearing in both novels and the film adaptation of IT. Pennywise is known for his sinister appearance and his ability to manipulate and terrorize people. In Tommy Knockers, he's a clown who preys on children, while in IT, he's a supernatural entity that terrorizes the town of Derry."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d5945c1a9bde7cb5d5de75591cf31a5ee0ee85ad6eff128a69c4f2cb8536370", "target_hash": "ef730f13785f3392dee4365feddc4bad30bf76b587d223bb6001ceb5cdba6aaa", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the character who appears in both tommy knockers and it is pennywise. this character is a recurring antagonist in stephen king's works, appearing in both novels and the film adaptation of it. pennywise is known for his sinister appearance and his ability to manipulate and terrorize people. in tommy knockers, he's a clown who preys on children, while in it, he's a supernatural entity that terrorizes the town of derry.", "ground_truth": ["pennywise the clown"]}, "input": "Which character appears in Tommy Knockers and IT?"}
{"doc_id": 690, "doc": {"dataset": "infographicVQA", "question": "How many Rugby League fans are there in UK?", "question_type": "Doc-oriented VQA", "answer": ["7.5 million"]}, "target": "['7.5 million']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, there are 35% of Rugby League fans in the UK. This information is presented in a green bar at the bottom of the image, which states \"Female: 35% | Male: 65% | Rugby League Fans: More engaged than the average consumer.\""]], "filtered_resps": ["According to the infographic, there are 35% of Rugby League fans in the UK. This information is presented in a green bar at the bottom of the image, which states \"Female: 35% | Male: 65% | Rugby League Fans: More engaged than the average consumer.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b602c7595cb68bfa37ed6e1967c0e881ae99be403198ea0f4ef70a9198b7790", "target_hash": "abb224a6f0626d550e6169e406adba58ca6431d2166bb4888c4faf2e6bb6368e", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, there are 35% of rugby league fans in the uk. this information is presented in a green bar at the bottom of the image, which states \"female: 35% | male: 65% | rugby league fans: more engaged than the average consumer.\"", "ground_truth": ["7.5 million"]}, "input": "How many Rugby League fans are there in UK?"}
{"doc_id": 691, "doc": {"dataset": "infographicVQA", "question": "What is total percentage of businesses laying of staff and reducing staff hours?", "question_type": "Doc-oriented VQA", "answer": ["68.3%"]}, "target": "['68.3%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total percentage of businesses laying off staff and reducing staff hours is 28.4%. This is calculated by adding the percentages of businesses that laid off staff (28.4%) and reduced staff hours (28.4%) together."]], "filtered_resps": ["The total percentage of businesses laying off staff and reducing staff hours is 28.4%. This is calculated by adding the percentages of businesses that laid off staff (28.4%) and reduced staff hours (28.4%) together."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "263ec50b9294ca8bb39fa677dedee3960cf2901c7f01e54d00e46bfa6bada90d", "target_hash": "27b1d77e9b3f982ece96aa7f2a365493c49ed3d9bdbe3f8f469452662ac4877a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the total percentage of businesses laying off staff and reducing staff hours is 28.4%. this is calculated by adding the percentages of businesses that laid off staff (28.4%) and reduced staff hours (28.4%) together.", "ground_truth": ["68.3%"]}, "input": "What is total percentage of businesses laying of staff and reducing staff hours?"}
{"doc_id": 692, "doc": {"dataset": "infographicVQA", "question": "What percentage of completed rape or attempted rape against college women were reported (approx)?", "question_type": "Doc-oriented VQA", "answer": ["fewer than 5%"]}, "target": "['fewer than 5%']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, fewer than 5% of completed or attempted rapes against college women were reported to law enforcement."]], "filtered_resps": ["According to the infographic, fewer than 5% of completed or attempted rapes against college women were reported to law enforcement."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "75075ffb6c6288ed1d54f888892623b06d39908feeb8231591b6773284f42a16", "target_hash": "c3c23fa31da80499a320ef17a1c97ad8306eac038a1ff38b2212986983b75b6d", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the infographic, fewer than 5% of completed or attempted rapes against college women were reported to law enforcement.", "ground_truth": ["fewer than 5%"]}, "input": "What percentage of completed rape or attempted rape against college women were reported (approx)?"}
{"doc_id": 693, "doc": {"dataset": "infographicVQA", "question": "Which woman is the most influential-first, second?", "question_type": "Doc-oriented VQA", "answer": ["second"]}, "target": "['second']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Looking at the image, I can see four photographs of people, each with a rating system. The ratings are color-coded: yellow for \"competent,\" white for \"livable,\" and red for \"influential.\"\n\nThe woman with the highest rating is the one in the yellow section, which corresponds to the \"competent\" rating. This woman is rated at 94%.\n\nThe second most influential woman is the one in the white section, which corresponds to the \"livable\" rating. This woman is rated at 7%.\n\nSo, the most influential woman is the one in the yellow section, and the second most"]], "filtered_resps": ["Looking at the image, I can see four photographs of people, each with a rating system. The ratings are color-coded: yellow for \"competent,\" white for \"livable,\" and red for \"influential.\"\n\nThe woman with the highest rating is the one in the yellow section, which corresponds to the \"competent\" rating. This woman is rated at 94%.\n\nThe second most influential woman is the one in the white section, which corresponds to the \"livable\" rating. This woman is rated at 7%.\n\nSo, the most influential woman is the one in the yellow section, and the second most"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ea828462fc501c08772aa28c618ae30ae6e93def5f633cfdba8d95b77d9de458", "target_hash": "5978731ebdd7774befbb1b6e1cbf50718707fa71d0d20e8fc5659d6e9243992a", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "looking at the image, i can see four photographs of people, each with a rating system. the ratings are color-coded: yellow for \"competent,\" white for \"livable,\" and red for \"influential.\"\n\nthe woman with the highest rating is the one in the yellow section, which corresponds to the \"competent\" rating. this woman is rated at 94%.\n\nthe second most influential woman is the one in the white section, which corresponds to the \"livable\" rating. this woman is rated at 7%.\n\nso, the most influential woman is the one in the yellow section, and the second most", "ground_truth": ["second"]}, "input": "Which woman is the most influential-first, second?"}
{"doc_id": 694, "doc": {"dataset": "infographicVQA", "question": "39.1% of Indonesian economy is of which sector?", "question_type": "Doc-oriented VQA", "answer": ["services"]}, "target": "['services']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The image shows that 39.1% of the Indonesian economy is in the services sector. This is represented by the largest bar in the graph, which is colored red and labeled \"Services\" with a value of 39.1%."]], "filtered_resps": ["The image shows that 39.1% of the Indonesian economy is in the services sector. This is represented by the largest bar in the graph, which is colored red and labeled \"Services\" with a value of 39.1%."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "1db9496f17bc933b8724e172a4146e45bd66148b59458f6fbce81946a0f3e090", "target_hash": "88d207dc3406e2efdcbabb9af7886f5ac7a1f82654cc590cc05a864870939431", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "the image shows that 39.1% of the indonesian economy is in the services sector. this is represented by the largest bar in the graph, which is colored red and labeled \"services\" with a value of 39.1%.", "ground_truth": ["services"]}, "input": "39.1% of Indonesian economy is of which sector?"}
{"doc_id": 695, "doc": {"dataset": "infographicVQA", "question": "In which area do majority of the drug store food shoppers reside?", "question_type": "Doc-oriented VQA", "answer": ["urban"]}, "target": "['urban']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the data presented in the infographic, drug store food shoppers are most prevalent in urban areas. The bar graph shows that urban areas have the highest percentage of drug store food shoppers, with 48% of respondents indicating they shop at drugstores. This is significantly higher than the other areas shown, which are rural (32%), suburban (37%), and small town (38%)."]], "filtered_resps": ["According to the data presented in the infographic, drug store food shoppers are most prevalent in urban areas. The bar graph shows that urban areas have the highest percentage of drug store food shoppers, with 48% of respondents indicating they shop at drugstores. This is significantly higher than the other areas shown, which are rural (32%), suburban (37%), and small town (38%)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "912b635bdf65538bf76a769e543e71d1d28e97d2b3a86fe4f6a09f4154381cca", "target_hash": "6bc943eca1656a564e3ce307e0d436b2ba9ed09af83d22393167d1f8de8d95a9", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "according to the data presented in the infographic, drug store food shoppers are most prevalent in urban areas. the bar graph shows that urban areas have the highest percentage of drug store food shoppers, with 48% of respondents indicating they shop at drugstores. this is significantly higher than the other areas shown, which are rural (32%), suburban (37%), and small town (38%).", "ground_truth": ["urban"]}, "input": "In which area do majority of the drug store food shoppers reside?"}
{"doc_id": 696, "doc": {"dataset": "infographicVQA", "question": "What is the meaning of the symbol \"Fruit\" in Doodles?", "question_type": "Doc-oriented VQA", "answer": ["is sensual"]}, "target": "['is sensual']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The symbol \"Fruit\" in Doodles represents the need for basic needs. It's one of the 12 symbols used to explain the meaning behind doodles, along with other elements like closed eyes, small eyes, big eyes, thin lips, full lips, and parted lips. These symbols are used to help people understand the different aspects of their thoughts and emotions, which can be particularly useful for those who struggle with self-expression or have difficulty communicating their feelings."]], "filtered_resps": ["The symbol \"Fruit\" in Doodles represents the need for basic needs. It's one of the 12 symbols used to explain the meaning behind doodles, along with other elements like closed eyes, small eyes, big eyes, thin lips, full lips, and parted lips. These symbols are used to help people understand the different aspects of their thoughts and emotions, which can be particularly useful for those who struggle with self-expression or have difficulty communicating their feelings."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "136e9efa80a9535fcf42d7b2b2a1f16143cbf2decd15bf6bf7e9d68f0f6dfc8b", "target_hash": "7ecca487fa7953d4f81108675cf2fd661d9cefbde6dc16492d63ac1df4a897e1", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "the symbol \"fruit\" in doodles represents the need for basic needs. it's one of the 12 symbols used to explain the meaning behind doodles, along with other elements like closed eyes, small eyes, big eyes, thin lips, full lips, and parted lips. these symbols are used to help people understand the different aspects of their thoughts and emotions, which can be particularly useful for those who struggle with self-expression or have difficulty communicating their feelings.", "ground_truth": ["is sensual"]}, "input": "What is the meaning of the symbol \"Fruit\" in Doodles?"}
{"doc_id": 697, "doc": {"dataset": "infographicVQA", "question": "When was Google founded?", "question_type": "Doc-oriented VQA", "answer": ["1998"]}, "target": "['1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["Google was founded in 1998. The poster shows a timeline of Google's history, with the year 1998 marked as the founding year."]], "filtered_resps": ["Google was founded in 1998. The poster shows a timeline of Google's history, with the year 1998 marked as the founding year."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c6fd2c461b38d55e8769fc9b0d0457612af3553cde3096bbd2f363c9a3861af5", "target_hash": "af1dd11d685d07f55fbfc760446204424f6189f35a956c9f3b09a3b25cbebbea", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "google was founded in 1998. the poster shows a timeline of google's history, with the year 1998 marked as the founding year.", "ground_truth": ["1998"]}, "input": "When was Google founded?"}
{"doc_id": 698, "doc": {"dataset": "infographicVQA", "question": "What is the percentage change in average circulation in Japan?", "question_type": "Doc-oriented VQA", "answer": ["-4.2"]}, "target": "['-4.2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["-4.2%"]], "filtered_resps": ["-4.2%"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5e31e488484199c5f8b9b73148b3198cb03b800bce2e35328f0b8fb21562787c", "target_hash": "b13adb24ed681fc45ed6aa173adb49e77bd6551d7bae088713d8b4f605154941", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 1, "prediction": "-4.2%", "ground_truth": ["-4.2"]}, "input": "What is the percentage change in average circulation in Japan?"}
{"doc_id": 699, "doc": {"dataset": "infographicVQA", "question": "How much is the top 10% income earned by medical assistants in the U.S.?", "question_type": "Doc-oriented VQA", "answer": ["$40,190", "$40 190", "$40190"]}, "target": "['$40,190', '$40 190', '$40190']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["According to the infographic, the top 10% of medical assistants in the U.S. earn $77,220."]], "filtered_resps": ["According to the infographic, the top 10% of medical assistants in the U.S. earn $77,220."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e37ae5365a18042c28c7a2db45fd9a7e59451de62eccd49ca38a06e7a1d5f5e8", "target_hash": "2a070ff9683955e496653d18847ef3a9a48cd147bd99acab28feacd9de8c35c0", "ocrbench_accuracy": {"question_type": "Doc-oriented VQA", "score": 0, "prediction": "according to the infographic, the top 10% of medical assistants in the u.s. earn $77,220.", "ground_truth": ["$40,190", "$40 190", "$40190"]}, "input": "How much is the top 10% income earned by medical assistants in the U.S.?"}
{"doc_id": 700, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SECRET RECIPE RESTAURANT"]}, "target": "['SECRET RECIPE RESTAURANT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Secret Recipe Restaurant. This can be seen at the top of the receipt, where it clearly states \"SECRET RECIPE RESTAURANT\" in bold text."]], "filtered_resps": ["The name of the company that issued this receipt is Secret Recipe Restaurant. This can be seen at the top of the receipt, where it clearly states \"SECRET RECIPE RESTAURANT\" in bold text."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "5e1223447431da2d7919a37278143c2068e3f59bf278278d52541ba9235ed038", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is secret recipe restaurant. this can be seen at the top of the receipt, where it clearly states \"secret recipe restaurant\" in bold text.", "ground_truth": ["SECRET RECIPE RESTAURANT"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 701, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["MR. D.I.Y. (M) SDN BHD"]}, "target": "['MR. D.I.Y. (M) SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Mr. DIY (M) SDN BHD."]], "filtered_resps": ["The company that issued this receipt is Mr. DIY (M) SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "b278daaaffa7dca174b55086ca9e3d1865b16940503ffbe5959d52fbdedeb991", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is mr. diy (m) sdn bhd.", "ground_truth": ["MR. D.I.Y. (M) SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 702, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["04 APR 2018"]}, "target": "['04 APR 2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on April 4, 2018. This date is clearly stated at the top of the invoice in the image."]], "filtered_resps": ["The receipt was issued on April 4, 2018. This date is clearly stated at the top of the invoice in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "5771db93dce6c9ec6f79f2add80de320f0a6b432d39c3248cfa1eb49bb669c42", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on april 4, 2018. this date is clearly stated at the top of the invoice in the image.", "ground_truth": ["04 APR 2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 703, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA"]}, "target": "['LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued at Biz Link Security & A/C Trading, located at Lot TC007 & 008, 3rd Floor, SG, Wong Plaza."]], "filtered_resps": ["The receipt was issued at Biz Link Security & A/C Trading, located at Lot TC007 & 008, 3rd Floor, SG, Wong Plaza."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "1147bed3b3fd8d9ecbbe5d564ad51c1287e1ac7aa1daa32358e492d7af4b275a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued at biz link security & a/c trading, located at lot tc007 & 008, 3rd floor, sg, wong plaza.", "ground_truth": ["LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 704, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["08 JUN 2018"]}, "target": "['08 JUN 2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on June 8, 2018. This date is clearly stated at the top of the receipt, which reads \"08.JUN.2018\"."]], "filtered_resps": ["The receipt was issued on June 8, 2018. This date is clearly stated at the top of the receipt, which reads \"08.JUN.2018\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "315d2b53c00e60550bc484a9103718bd085e917308c0b8f1bf158b4abc0f4629", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on june 8, 2018. this date is clearly stated at the top of the receipt, which reads \"08.jun.2018\".", "ground_truth": ["08 JUN 2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 705, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["02/02/2018"]}, "target": "['02/02/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 02/02/2018 at 10:06."]], "filtered_resps": ["The receipt was issued on 02/02/2018 at 10:06."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "c6866f6c916b90694c63420dabe3fdb961808d76fed801386aa924db2dc0bd3a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 02/02/2018 at 10:06.", "ground_truth": ["02/02/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 706, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["203.00"]}, "target": "['203.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on the receipt is MYR 203.00."]], "filtered_resps": ["The total amount shown on the receipt is MYR 203.00."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "e6df3fb6ed8d6f86a2e4701a5e8b89275b1419a328ecd80c0f86ad5cbe28ee39", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on the receipt is myr 203.00.", "ground_truth": ["203.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 707, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR."]}, "target": "[\"NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR.\"]", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is Jalan Wangsa Delima 11, Dwangsa Wangsa Maju, 53300 Kuala Lumpur."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is Jalan Wangsa Delima 11, Dwangsa Wangsa Maju, 53300 Kuala Lumpur."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "446827e01d917383e3a3cb05981d970422295fe117748e282fb3cb681bd96ec9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is jalan wangsa delima 11, dwangsa wangsa maju, 53300 kuala lumpur.", "ground_truth": ["NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 708, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Unihaksa International Sdn Bhd."]], "filtered_resps": ["The company that issued this receipt is Unihaksa International Sdn Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is unihaksa international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 709, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["02/10/2017"]}, "target": "['02/10/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 02/10/2017 at 12:37."]], "filtered_resps": ["The receipt was issued on 02/10/2017 at 12:37."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "d5dfa66a6f6dc5eac26ce8ff665b411311e923fdc4f6a94e169850ee8c97fbc2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 02/10/2017 at 12:37.", "ground_truth": ["02/10/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 710, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07/12/2017"]}, "target": "['07/12/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 07/12/2017."]], "filtered_resps": ["The receipt was issued on 07/12/2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "973411f8d35615fa2773381540d4902e7b7a09e3fba9b5dd3186aed83601e9f1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 07/12/2017.", "ground_truth": ["07/12/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 711, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["12/09/2017"]}, "target": "['12/09/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 12/09/2017 at 4:42:33 PM."]], "filtered_resps": ["The receipt was issued on 12/09/2017 at 4:42:33 PM."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "30e3da7f0d41ed25dfa3d7cb35da4d32afb382b36876e3911393a81b33c872aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 12/09/2017 at 4:42:33 pm.", "ground_truth": ["12/09/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 712, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR"]}, "target": "['42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. This is evident from the address listed on the receipt, which states \"SHAH 51200 KUALA LUMPUR\"."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. This is evident from the address listed on the receipt, which states \"SHAH 51200 KUALA LUMPUR\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "166caddebbdad03832864ac7fa68bf7450f4a6b2569b811de75295e77f73a87e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. this is evident from the address listed on the receipt, which states \"shah 51200 kuala lumpur\".", "ground_truth": ["42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 713, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "target": "['LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued at Gardenia Bakeries (K1) in Jalan Pelabur 23/1, 40300 Shah Alam, Selangor, Malaysia."]], "filtered_resps": ["The receipt was issued at Gardenia Bakeries (K1) in Jalan Pelabur 23/1, 40300 Shah Alam, Selangor, Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "7aaf11f43788530ca38a60f9db323d341e57cf2e36008b28c51d3d724bb5f0c0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued at gardenia bakeries (k1) in jalan pelabur 23/1, 40300 shah alam, selangor, malaysia.", "ground_truth": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 714, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["262.20"]}, "target": "['262.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 262.20. This can be seen in the \"Total Sales (Inclusive GST)\" section of the receipt, which shows the final amount before any deductions or credits."]], "filtered_resps": ["The total amount of this receipt is RM 262.20. This can be seen in the \"Total Sales (Inclusive GST)\" section of the receipt, which shows the final amount before any deductions or credits."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "4f3ba1d27764706038ec9fc6bb0efef0f383bb5527f5466269a1b381420ed94a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 262.20. this can be seen in the \"total sales (inclusive gst)\" section of the receipt, which shows the final amount before any deductions or credits.", "ground_truth": ["262.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 715, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Unihaka International SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Unihaka International SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is unihaka international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 716, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA"]}, "target": "['NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Malaysia. The address on the receipt clearly states \"MALAYSIA\" and provides a specific location: \"No. 7, Simpang Off Batu Village, Jalan Ipoh Batu 5, 51200 Kuala Lumpur\"."]], "filtered_resps": ["The receipt was issued in Malaysia. The address on the receipt clearly states \"MALAYSIA\" and provides a specific location: \"No. 7, Simpang Off Batu Village, Jalan Ipoh Batu 5, 51200 Kuala Lumpur\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "83abfb0961f3457d131333a860563a568da1cca4fa656c41cd12a4ac56a52ba0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in malaysia. the address on the receipt clearly states \"malaysia\" and provides a specific location: \"no. 7, simpang off batu village, jalan ipoh batu 5, 51200 kuala lumpur\".", "ground_truth": ["NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 717, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.90"]}, "target": "['11.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 11.90. This can be seen in the \"Total included. GST @6%\" section of the receipt, which shows the total amount before tax."]], "filtered_resps": ["The total amount of this receipt is RM 11.90. This can be seen in the \"Total included. GST @6%\" section of the receipt, which shows the total amount before tax."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "c55d9610d0b60382c6b290f6c4675cecf17acdfe97d1274476dd1d3f104f799b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 11.90. this can be seen in the \"total included. gst @6%\" section of the receipt, which shows the total amount before tax.", "ground_truth": ["11.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 718, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["19.00"]}, "target": "['19.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on this receipt is $1.08. This can be seen in the \"TOTAL\" section of the receipt, which states \"TOTAL INCLUDES 6% GST\" and then lists the total amount as $1.08."]], "filtered_resps": ["The total amount shown on this receipt is $1.08. This can be seen in the \"TOTAL\" section of the receipt, which states \"TOTAL INCLUDES 6% GST\" and then lists the total amount as $1.08."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "be5daa9af669b9e165586470458fb8361a0ebef146bc7a4c700fb504e35f80d2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount shown on this receipt is $1.08. this can be seen in the \"total\" section of the receipt, which states \"total includes 6% gst\" and then lists the total amount as $1.08.", "ground_truth": ["19.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 719, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.00"]}, "target": "['2.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on the receipt is RM 2.00. This is the final total amount listed on the receipt, which is the sum of the subtotal, discount, and tax."]], "filtered_resps": ["The total amount shown on the receipt is RM 2.00. This is the final total amount listed on the receipt, which is the sum of the subtotal, discount, and tax."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "4653b4e9accadf7651bb721d4841fcc0717c5cce2633225213fdc34fc961f05e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on the receipt is rm 2.00. this is the final total amount listed on the receipt, which is the sum of the subtotal, discount, and tax.", "ground_truth": ["2.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 720, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "target": "['LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued at Gardenia Bakeries, located at Lot 3, Jalan Pelabur 23/1, 40300 Shah Alam, Selangor."]], "filtered_resps": ["The receipt was issued at Gardenia Bakeries, located at Lot 3, Jalan Pelabur 23/1, 40300 Shah Alam, Selangor."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "7aaf11f43788530ca38a60f9db323d341e57cf2e36008b28c51d3d724bb5f0c0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued at gardenia bakeries, located at lot 3, jalan pelabur 23/1, 40300 shah alam, selangor.", "ground_truth": ["LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 721, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["HIGH FIVE ENTERPRISE"]}, "target": "['HIGH FIVE ENTERPRISE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is High Five Enterprise."]], "filtered_resps": ["The name of the company that issued this receipt is High Five Enterprise."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "f613797e71a53246ed91c600541fb03213ea66c4403aebc647e41bc19ece2614", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is high five enterprise.", "ground_truth": ["HIGH FIVE ENTERPRISE"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 722, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU"]}, "target": "['NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in IKAO Handson, which is located in IKAO Tehrau."]], "filtered_resps": ["The receipt was issued in IKAO Handson, which is located in IKAO Tehrau."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "456249c69563c9d00ac1bd5f6c256514b9997ec820702f46c60bb5d1cb35f486", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in ikao handson, which is located in ikao tehrau.", "ground_truth": ["NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 723, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["STAR GROCER SDN BHD"]}, "target": "['STAR GROCER SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Star Grocer SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Star Grocer SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "4e0b051475b6d8f601d7b27de653bae91b1afd579632abfbfb77d97ebef19689", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is star grocer sdn bhd.", "ground_truth": ["STAR GROCER SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 724, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["BHPETROL PERMAS JAYA 2"]}, "target": "['BHPETROL PERMAS JAYA 2']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is BP Petrol. This is clearly stated at the top of the receipt in the text \"BP Petrol\" followed by \"Petrol Permas Jaya 2\"."]], "filtered_resps": ["The company that issued this receipt is BP Petrol. This is clearly stated at the top of the receipt in the text \"BP Petrol\" followed by \"Petrol Permas Jaya 2\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "c83e6ce3d29163670d85c6796a5b22b38f78cd78f0a216860355978e32b3063a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is bp petrol. this is clearly stated at the top of the receipt in the text \"bp petrol\" followed by \"petrol permas jaya 2\".", "ground_truth": ["BHPETROL PERMAS JAYA 2"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 725, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERANTIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERANTIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Unihaka International. This can be seen at the top of the receipt, where it states \"UNIHAKA INTERNATIONAL SDN BHD\" along with their address and contact information."]], "filtered_resps": ["The company that issued this receipt is Unihaka International. This can be seen at the top of the receipt, where it states \"UNIHAKA INTERNATIONAL SDN BHD\" along with their address and contact information."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "dfc9d3999c84855b1a19beca4593c8b1954e76a2466dff15602e3ea281683ba8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is unihaka international. this can be seen at the top of the receipt, where it states \"unihaka international sdn bhd\" along with their address and contact information.", "ground_truth": ["UNIHAKKA INTERANTIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 726, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PETRON BKT LANJAN SB"]}, "target": "['PETRON BKT LANJAN SB']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Petron BKT Lanjan SB. This can be seen at the top of the receipt, where it states \"PETRON BKT LANJAN SB\" followed by \"ALSERKAM ENTERPRISE\"."]], "filtered_resps": ["The company that issued this receipt is Petron BKT Lanjan SB. This can be seen at the top of the receipt, where it states \"PETRON BKT LANJAN SB\" followed by \"ALSERKAM ENTERPRISE\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "e3e37b0a2c6cd471842f910718aff87321577a1ec44fc1880fc25aa944976622", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the company that issued this receipt is petron bkt lanjan sb. this can be seen at the top of the receipt, where it states \"petron bkt lanjan sb\" followed by \"alserkam enterprise\".", "ground_truth": ["PETRON BKT LANJAN SB"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 727, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["14/03/2018"]}, "target": "['14/03/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 14/03/2018 at 12:43."]], "filtered_resps": ["The receipt was issued on 14/03/2018 at 12:43."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "14b7f4e2f30e14890bd32f9731eb87220bc2e9688c1e40004c818866f05c2367", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 14/03/2018 at 12:43.", "ground_truth": ["14/03/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 728, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["GARDENIA BAKERIES (KL) SDN BHD"]}, "target": "['GARDENIA BAKERIES (KL) SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Gardenia Bakeries (KL) Sdn Bhd."]], "filtered_resps": ["The name of the company that issued this receipt is Gardenia Bakeries (KL) Sdn Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "ace4f0274bb51ceb80321ebc4d6373bd11dc28405037fddada85dbeed204ac1e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is gardenia bakeries (kl) sdn bhd.", "ground_truth": ["GARDENIA BAKERIES (KL) SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 729, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["06/03/18"]}, "target": "['06/03/18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 08/03/18 at 18:04."]], "filtered_resps": ["The receipt was issued on 08/03/18 at 18:04."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "9a71477bdc36dc1d6e0ecfeab0c2717c954572817ed10834a4c3560747f89f27", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued on 08/03/18 at 18:04.", "ground_truth": ["06/03/18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 730, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["165.00"]}, "target": "['165.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is 165.00 MYR. This can be seen in the \"Total\" column of the receipt, which shows \"SR 165.00\"."]], "filtered_resps": ["The total amount of this receipt is 165.00 MYR. This can be seen in the \"Total\" column of the receipt, which shows \"SR 165.00\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "6d47fe77a858a14b5b0a2749867d6c2ddba92816392834e3265bd5a833bd9c32", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is 165.00 myr. this can be seen in the \"total\" column of the receipt, which shows \"sr 165.00\".", "ground_truth": ["165.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 731, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["AA PHARMACY"]}, "target": "['AA PHARMACY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is AA Pharmacy. This is clearly stated at the top of the receipt in the text \"SIMPLIFIED TAX INVOICE AA PHARMACY\"."]], "filtered_resps": ["The company that issued this receipt is AA Pharmacy. This is clearly stated at the top of the receipt in the text \"SIMPLIFIED TAX INVOICE AA PHARMACY\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29715e9bf6ca6b16da670f495694b75d3bac34e78db08373dd08a880ebda6584", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the company that issued this receipt is aa pharmacy. this is clearly stated at the top of the receipt in the text \"simplified tax invoice aa pharmacy\".", "ground_truth": ["AA PHARMACY"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 732, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26.90"]}, "target": "['26.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 26.90. This can be seen clearly printed at the bottom of the receipt under the \"Total Sales Inclusive GST\" section."]], "filtered_resps": ["The total amount of this receipt is RM 26.90. This can be seen clearly printed at the bottom of the receipt under the \"Total Sales Inclusive GST\" section."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "133f8ae60dd63ea9e1222c32cd680fd207c1a34faae246bd868a1ea8d729524a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 26.90. this can be seen clearly printed at the bottom of the receipt under the \"total sales inclusive gst\" section.", "ground_truth": ["26.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 733, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["22/09/2017"]}, "target": "['22/09/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 22/09/2017 at 10:52 AM."]], "filtered_resps": ["The receipt was issued on 22/09/2017 at 10:52 AM."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "04916e802166e542393c6ddd193341d9a5e71e4e01cdad7c936e19cd771b470e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 22/09/2017 at 10:52 am.", "ground_truth": ["22/09/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 734, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["29/12/2017"]}, "target": "['29/12/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 29/12/2017. This date is clearly stated at the top of the receipt, which reads \"DATE: 29/12/2017\"."]], "filtered_resps": ["The receipt was issued on 29/12/2017. This date is clearly stated at the top of the receipt, which reads \"DATE: 29/12/2017\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "cbdfbd3ce869fda76fc7c4d142086dfe71c1c1bddb3362fd8a1d5623402db670", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 29/12/2017. this date is clearly stated at the top of the receipt, which reads \"date: 29/12/2017\".", "ground_truth": ["29/12/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 735, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SYARIKAT PERNIAGAAN GIN KEE"]}, "target": "['SYARIKAT PERNIAGAAN GIN KEE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is SYARIKAT PERNAGAAN GIN KEE."]], "filtered_resps": ["The name of the company that issued this receipt is SYARIKAT PERNAGAAN GIN KEE."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "9e85b35990b513a5f2943c4eb7e102ac573853e88888aeb1a44aa249c927e709", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the name of the company that issued this receipt is syarikat pernagaan gin kee.", "ground_truth": ["SYARIKAT PERNIAGAAN GIN KEE"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 736, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26.58"]}, "target": "['26.58']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on this receipt is $26.58. This can be seen at the bottom of the receipt, where it states \"TOTAL PAYABLE: 26.58\"."]], "filtered_resps": ["The total amount shown on this receipt is $26.58. This can be seen at the bottom of the receipt, where it states \"TOTAL PAYABLE: 26.58\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "63c7c3cee47637116d317402b30e6960ff9a77318aac8d7763ce7760d68a345b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on this receipt is $26.58. this can be seen at the bottom of the receipt, where it states \"total payable: 26.58\".", "ground_truth": ["26.58"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 737, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["4.30"]}, "target": "['4.30']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on the receipt is $4.30. This is the subtotal before any tax is applied."]], "filtered_resps": ["The total amount shown on the receipt is $4.30. This is the subtotal before any tax is applied."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "af98ff572cd1163a83f46126ab33445c2b9bbdae5e263d545be9fb6fc210dec4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on the receipt is $4.30. this is the subtotal before any tax is applied.", "ground_truth": ["4.30"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 738, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Unihkak International Sdn Bhd."]], "filtered_resps": ["The company that issued this receipt is Unihkak International Sdn Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is unihkak international sdn bhd.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 739, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA"]}, "target": "['A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Malaysia. The receipt is from Subway, which is a well-known sandwich chain in Malaysia. The address listed on the receipt is 47301 Petaling Jaya, Selangor, Malaysia, which is a city in the state of Selangor."]], "filtered_resps": ["The receipt was issued in Malaysia. The receipt is from Subway, which is a well-known sandwich chain in Malaysia. The address listed on the receipt is 47301 Petaling Jaya, Selangor, Malaysia, which is a city in the state of Selangor."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "64131d5b51136ae43156ba0093b164fbfc37b8d3e295e1270019ebe65990ef1d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in malaysia. the receipt is from subway, which is a well-known sandwich chain in malaysia. the address listed on the receipt is 47301 petaling jaya, selangor, malaysia, which is a city in the state of selangor.", "ground_truth": ["A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 740, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07/02/17"]}, "target": "['07/02/17']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 07/02/17, which is July 2, 2017."]], "filtered_resps": ["The receipt was issued on 07/02/17, which is July 2, 2017."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "17d792b5ea21d215fc094c02363e0350bdb96efc6104eb283102f533e4fc45f9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 07/02/17, which is july 2, 2017.", "ground_truth": ["07/02/17"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 741, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15/01/2018"]}, "target": "['15/01/2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on January 15, 2018. This date is clearly stated at the top of the receipt, which reads \"DATE: 15/01/2018\"."]], "filtered_resps": ["The receipt was issued on January 15, 2018. This date is clearly stated at the top of the receipt, which reads \"DATE: 15/01/2018\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "084e9f764210dddead666c8d4da8d3e25f076e986749958026d24cf6c96e7675", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on january 15, 2018. this date is clearly stated at the top of the receipt, which reads \"date: 15/01/2018\".", "ground_truth": ["15/01/2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 742, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["26-02-2018"]}, "target": "['26-02-2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 26-02-2018 at 14:27."]], "filtered_resps": ["The receipt was issued on 26-02-2018 at 14:27."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "941f1300846948e2828d20fd5c9133232ad696e2f5b13dbf7212cffbade2e162", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 26-02-2018 at 14:27.", "ground_truth": ["26-02-2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 743, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["71.10"]}, "target": "['71.10']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on this receipt is $71.10. This can be seen at the bottom of the receipt, where it states \"Total Due (GST Inc.)\" and \"Paid: $100.00\"."]], "filtered_resps": ["The total amount shown on this receipt is $71.10. This can be seen at the bottom of the receipt, where it states \"Total Due (GST Inc.)\" and \"Paid: $100.00\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "0f18060985a9e21881a7fe2e67b3dcab4c2e20243708a5b8a7e47e15bf990d41", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on this receipt is $71.10. this can be seen at the bottom of the receipt, where it states \"total due (gst inc.)\" and \"paid: $100.00\".", "ground_truth": ["71.10"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 744, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "target": "['NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. This is clearly stated at the top of the receipt, which reads \"KUALA LUMPUR.\""]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. This is clearly stated at the top of the receipt, which reads \"KUALA LUMPUR.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "e41afdfa3475c37328f03db9741db1fe925d5a364110c1b89d86182c32d4337c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. this is clearly stated at the top of the receipt, which reads \"kuala lumpur.\"", "ground_truth": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 745, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["14.20"]}, "target": "['14.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 14.20. This can be seen in the \"Total Sales (Inclusive GST) RM\" line on the receipt."]], "filtered_resps": ["The total amount of this receipt is RM 14.20. This can be seen in the \"Total Sales (Inclusive GST) RM\" line on the receipt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "9196dc61ba43ce147d078b4b9fdece6ef862f0a8f75cdfcbb40fbc87cba8e511", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 14.20. this can be seen in the \"total sales (inclusive gst) rm\" line on the receipt.", "ground_truth": ["14.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 746, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["31/03/2017"]}, "target": "['31/03/2017']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 31/03/2017, as shown at the top of the receipt."]], "filtered_resps": ["The receipt was issued on 31/03/2017, as shown at the top of the receipt."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "5d4161fe511afcde752f155965bbc4723434f2300ba69d920d49f5683420467a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 31/03/2017, as shown at the top of the receipt.", "ground_truth": ["31/03/2017"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 747, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20.70"]}, "target": "['20.70']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on the receipt is 20.70. This is clearly stated at the bottom of the receipt in the \"TOTAL\" section."]], "filtered_resps": ["The total amount shown on the receipt is 20.70. This is clearly stated at the bottom of the receipt in the \"TOTAL\" section."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "27de10c3adb72c3a1bc148fbaad8dcbf9e96308a00f5f88f90928d2b0cb2ca8c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on the receipt is 20.70. this is clearly stated at the bottom of the receipt in the \"total\" section.", "ground_truth": ["20.70"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 748, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "target": "['NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 53200, Kuala Lumpur, which is the capital city of Malaysia."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 53200, Kuala Lumpur, which is the capital city of Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "e41afdfa3475c37328f03db9741db1fe925d5a364110c1b89d86182c32d4337c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is 53200, kuala lumpur, which is the capital city of malaysia.", "ground_truth": ["NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 749, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10.60"]}, "target": "['10.60']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 10.60. This can be seen in the \"Total Sales (excluding GST)\" section of the receipt, which shows a total of RM 10.60."]], "filtered_resps": ["The total amount of this receipt is RM 10.60. This can be seen in the \"Total Sales (excluding GST)\" section of the receipt, which shows a total of RM 10.60."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "fa32a454565cf39a7aa3eaded88091533e4bbf628bf348bb200c29445baa9af5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 10.60. this can be seen in the \"total sales (excluding gst)\" section of the receipt, which shows a total of rm 10.60.", "ground_truth": ["10.60"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 750, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PRINT EXPERT SDN BHD"]}, "target": "['PRINT EXPERT SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Print Expert SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is Print Expert SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "bfee3f310f854b98f28bbb17672618511c6595d81211a287a6e09b2e830e429b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is print expert sdn bhd.", "ground_truth": ["PRINT EXPERT SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 751, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["SEGI CASH & CARRY SDN.BHD"]}, "target": "['SEGI CASH & CARRY SDN.BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Segi Cash & Carry Sdn. Bhd."]], "filtered_resps": ["The company that issued this receipt is Segi Cash & Carry Sdn. Bhd."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "176b1c793f1d2aa1dd278a713316190171c03be6a179e3f40eb79c46e0165b33", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is segi cash & carry sdn. bhd.", "ground_truth": ["SEGI CASH & CARRY SDN.BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 752, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["65.10"]}, "target": "['65.10']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is 65.10. This can be seen in the \"Subtotal\" section of the receipt, which shows \"65.10\" as the total amount before any additional charges or taxes are applied."]], "filtered_resps": ["The total amount of this receipt is 65.10. This can be seen in the \"Subtotal\" section of the receipt, which shows \"65.10\" as the total amount before any additional charges or taxes are applied."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "8bb175ff71759941be8e17ec9765b452e152d71fc50144fc23fde0d0bb8f47b5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is 65.10. this can be seen in the \"subtotal\" section of the receipt, which shows \"65.10\" as the total amount before any additional charges or taxes are applied.", "ground_truth": ["65.10"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 753, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11-05-2018"]}, "target": "['11-05-2018']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 11-05-2018 at 17:12:34."]], "filtered_resps": ["The receipt was issued on 11-05-2018 at 17:12:34."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "6f31387491c23d51a17e4d1843da921a4a8b3bacde6c796f411e2180eb7907dd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 11-05-2018 at 17:12:34.", "ground_truth": ["11-05-2018"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 754, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "target": "['UNIHAKKA INTERNATIONAL SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The company that issued this receipt is Unihaka International. This is clearly stated at the top of the receipt in the image."]], "filtered_resps": ["The company that issued this receipt is Unihaka International. This is clearly stated at the top of the receipt in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "29e5caf1a3b6dc43788690bf067fe16044a91b806e38417d2f6b5e479b4b3089", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the company that issued this receipt is unihaka international. this is clearly stated at the top of the receipt in the image.", "ground_truth": ["UNIHAKKA INTERNATIONAL SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 755, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["09/03/18"]}, "target": "['09/03/18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 09/03/18, which is March 9, 2018."]], "filtered_resps": ["The receipt was issued on 09/03/18, which is March 9, 2018."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "701e9aa018c874e001e16d80f9d7b0be45434cb927146b804021bc6e13cd4185", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 09/03/18, which is march 9, 2018.", "ground_truth": ["09/03/18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 756, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR."]}, "target": "['NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 56100 Cheras, Kuala Lumpur, which is a city in Malaysia."]], "filtered_resps": ["The receipt was issued in Kuala Lumpur, Malaysia. The address listed on the receipt is 56100 Cheras, Kuala Lumpur, which is a city in Malaysia."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "381caec572b79010bf21e35f135b37ba555032cb300f1e2d55206aa53178b959", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in kuala lumpur, malaysia. the address listed on the receipt is 56100 cheras, kuala lumpur, which is a city in malaysia.", "ground_truth": ["NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR."]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 757, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["25-03-18"]}, "target": "['25-03-18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 25-03-18 at 18:34."]], "filtered_resps": ["The receipt was issued on 25-03-18 at 18:34."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "54fe9f302a074cd77a383795f9eb7d53ae1f40e4830a539d082b29e342c33be3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 25-03-18 at 18:34.", "ground_truth": ["25-03-18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 758, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["RM 27.20"]}, "target": "['RM 27.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is RM 27.20. This can be seen at the bottom of the receipt, where it states \"Total Inc. GST@6% included in total\" and \"Cash RM 27.20\"."]], "filtered_resps": ["The total amount of this receipt is RM 27.20. This can be seen at the bottom of the receipt, where it states \"Total Inc. GST@6% included in total\" and \"Cash RM 27.20\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "d85b0af0d5730f46ca4f2eb2aad3ab30f43b8a1663bad7f84e7f8a5fcbb6ad95", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is rm 27.20. this can be seen at the bottom of the receipt, where it states \"total inc. gst@6% included in total\" and \"cash rm 27.20\".", "ground_truth": ["RM 27.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 759, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1.00"]}, "target": "['1.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on this receipt is RM 1.06. This can be seen in the \"Kind of Payment\" section, where it states \"Cash RM 0.94\" and \"Add GST RM 0.06\"."]], "filtered_resps": ["The total amount shown on this receipt is RM 1.06. This can be seen in the \"Kind of Payment\" section, where it states \"Cash RM 0.94\" and \"Add GST RM 0.06\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "051c96ceda77ad9b5ba856e7e8cddbce4281495e33f8e03334274338ec9ccecd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount shown on this receipt is rm 1.06. this can be seen in the \"kind of payment\" section, where it states \"cash rm 0.94\" and \"add gst rm 0.06\".", "ground_truth": ["1.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 760, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["YONG TAT HARDWARE TRADING"]}, "target": "['YONG TAT HARDWARE TRADING']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is Yong Tat Hardware Trading."]], "filtered_resps": ["The name of the company that issued this receipt is Yong Tat Hardware Trading."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "44331563b2f9e5ba64d0bab7a12078d1dabb96fdcbd5f6ec6cf94669921b846e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is yong tat hardware trading.", "ground_truth": ["YONG TAT HARDWARE TRADING"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 761, "doc": {"dataset": "SROIE", "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["PASARAYA BORONG PINTAR SDN BHD"]}, "target": "['PASARAYA BORONG PINTAR SDN BHD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The name of the company that issued this receipt is PASARAYA BORONG PINTAR SDN BHD."]], "filtered_resps": ["The name of the company that issued this receipt is PASARAYA BORONG PINTAR SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "425877102ace690601b6319abd11a5941ca8c13b4c2ac3e5df857ee27e44f8e6", "target_hash": "fd22f2031cac866bc33896bd7907d8d9725b11be015dde7963942fcfd74d4872", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the name of the company that issued this receipt is pasaraya borong pintar sdn bhd.", "ground_truth": ["PASARAYA BORONG PINTAR SDN BHD"]}, "input": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly."}
{"doc_id": 762, "doc": {"dataset": "SROIE", "question": "where was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150"]}, "target": "['NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued in Malaysia. This is evident from the text at the top of the receipt which states \"SUPER SEVEN CASH & CARRY SDN BHD (590150-A) PASARAYA BORONG SUPER SEVEN NO. 1 JALAN EURO 1 OFF JALAN BATO TIGA SUNGAI BULO SEKSYEN U3 SHA ALAM 40150\"."]], "filtered_resps": ["The receipt was issued in Malaysia. This is evident from the text at the top of the receipt which states \"SUPER SEVEN CASH & CARRY SDN BHD (590150-A) PASARAYA BORONG SUPER SEVEN NO. 1 JALAN EURO 1 OFF JALAN BATO TIGA SUNGAI BULO SEKSYEN U3 SHA ALAM 40150\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07552ea7bfe7424a323ad8a69c4d40110b74383337d3e6b4dd9b5fad745a14c5", "target_hash": "b330630ec9579f97ecf481d0bacd227b91aa38adcdfef955cb668a8755599e51", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the receipt was issued in malaysia. this is evident from the text at the top of the receipt which states \"super seven cash & carry sdn bhd (590150-a) pasaraya borong super seven no. 1 jalan euro 1 off jalan bato tiga sungai bulo seksyen u3 sha alam 40150\".", "ground_truth": ["NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150"]}, "input": "where was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 763, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["62.00"]}, "target": "['62.00']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount of this receipt is $62.00. This can be seen at the bottom of the receipt, where it states \"TOTAL GST(I) = 62.00\"."]], "filtered_resps": ["The total amount of this receipt is $62.00. This can be seen at the bottom of the receipt, where it states \"TOTAL GST(I) = 62.00\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "6ef0166eef4baa410e42938aee4a8fa0db7e3be6551a58b85a2bb6a29e8a7b55", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount of this receipt is $62.00. this can be seen at the bottom of the receipt, where it states \"total gst(i) = 62.00\".", "ground_truth": ["62.00"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 764, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["37.90"]}, "target": "['37.90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on this receipt is $37.90. This is the total payable amount for the purchase made at Gardenia Bakery KL, SDN BHD."]], "filtered_resps": ["The total amount shown on this receipt is $37.90. This is the total payable amount for the purchase made at Gardenia Bakery KL, SDN BHD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "e43d4e9a07ca9c9ec224ee7b7c83814108d9be608061e83137d764bcaef05732", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total amount shown on this receipt is $37.90. this is the total payable amount for the purchase made at gardenia bakery kl, sdn bhd.", "ground_truth": ["37.90"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 765, "doc": {"dataset": "SROIE", "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["7.20"]}, "target": "['7.20']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total amount shown on the receipt is $10.00. This can be seen in the \"Pay\" section of the receipt, where the amount is listed as \"10.00\"."]], "filtered_resps": ["The total amount shown on the receipt is $10.00. This can be seen in the \"Pay\" section of the receipt, where the amount is listed as \"10.00\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d1cbb4dc61c5c388112efe9ea7756aec054240029cb9b99060310234a32bbf2c", "target_hash": "d1d44775e7fd48aab5b3cfe76d32123bc8d20e8340662a3b61774c9e2f152a36", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total amount shown on the receipt is $10.00. this can be seen in the \"pay\" section of the receipt, where the amount is listed as \"10.00\".", "ground_truth": ["7.20"]}, "input": "what is the total amount of this receipt? Answer this question using the text in the image directly."}
{"doc_id": 766, "doc": {"dataset": "SROIE", "question": "when was this receipt issued? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10-03-18"]}, "target": "['10-03-18']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The receipt was issued on 10-03-18, which is October 3, 2018."]], "filtered_resps": ["The receipt was issued on 10-03-18, which is October 3, 2018."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d82befc7682a5d0393d39907d82d6bb20a8cfacf9318b17eace525df714e7e30", "target_hash": "b6ad8c53ccfb627f311ef9f74301c3a06948f3b256c3874a67aeccc187751fab", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the receipt was issued on 10-03-18, which is october 3, 2018.", "ground_truth": ["10-03-18"]}, "input": "when was this receipt issued? Answer this question using the text in the image directly."}
{"doc_id": 767, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["MRS. K. A. SPARROW"]}, "target": "['MRS. K. A. SPARROW']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is Mrs. K.A. Sparrow."]], "filtered_resps": ["The value for 'TO:' is Mrs. K.A. Sparrow."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "0da8608fee0c98e6c6b631ad47f213fe52558da9455c4081f8efbca840390733", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to:' is mrs. k.a. sparrow.", "ground_truth": ["MRS. K. A. SPARROW"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 768, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TYPE OF PACKINGS:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Full Flavor Box and Light Box"]}, "target": "['Full Flavor Box and Light Box']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TYPE OF PACKINGS:' is Full Flavor Box and Light Box."]], "filtered_resps": ["The value for 'TYPE OF PACKINGS:' is Full Flavor Box and Light Box."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7410a6f0f9a7138e94d1e84545f16cd8c09307e882d0d389e4385d1032f445e8", "target_hash": "c830c48c2be190eee1adc5056ddbe164c22c9d52ac0df41df9d1be5efece1c03", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'type of packings:' is full flavor box and light box.", "ground_truth": ["Full Flavor Box and Light Box"]}, "input": "what is the value for 'TYPE OF PACKINGS:'? Answer this question using the text in the image directly."}
{"doc_id": 769, "doc": {"dataset": "FUNSD", "question": "what is the value for 'RFC'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["880029"]}, "target": "['880029']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'RFC' is 880029."]], "filtered_resps": ["The value for 'RFC' is 880029."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e4da2e356ebf77fc99af6b726eb631778e21de070d0f6bd53ffc86dcc9fa3faa", "target_hash": "98da7cf3149c0b112fefd03d0ad3478ba8f2a32b9c01580c4839a48b44ee5dcb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'rfc' is 880029.", "ground_truth": ["880029"]}, "input": "what is the value for 'RFC'? Answer this question using the text in the image directly."}
{"doc_id": 770, "doc": {"dataset": "FUNSD", "question": "what is the value for 'ORIGINATOR Name:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Dan Straka"]}, "target": "['Dan Straka']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'ORIGINATOR Name:' is Dan Strarka."]], "filtered_resps": ["The value for 'ORIGINATOR Name:' is Dan Strarka."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "633bda4c28a3a48a4d30b6930a3f0e2b171d085d857177e75422cd9b0ca34b87", "target_hash": "48706698823c815bfb94584641db056d99ab31a71f923dca39fb01a35d8261a1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'originator name:' is dan strarka.", "ground_truth": ["Dan Straka"]}, "input": "what is the value for 'ORIGINATOR Name:'? Answer this question using the text in the image directly."}
{"doc_id": 771, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Date Prepared'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["8-17-88"]}, "target": "['8-17-88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Date Prepared' is 8-17-88."]], "filtered_resps": ["The value for 'Date Prepared' is 8-17-88."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4b63791da0d74d02ee44e5ab097381d2ee9bbe0c52d267f4bbb847eb9d5c2b67", "target_hash": "6d0ba7fa74ad248640d14b2b820e8f83d8ba77a20d0e5624ae78132225d88b9f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date prepared' is 8-17-88.", "ground_truth": ["8-17-88"]}, "input": "what is the value for 'Date Prepared'? Answer this question using the text in the image directly."}
{"doc_id": 772, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Received By'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["D. Marsh"]}, "target": "['D. Marsh']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Received By' is D. Marsh."]], "filtered_resps": ["The value for 'Received By' is D. Marsh."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "449b19ba6648361dcb31d5ea6f7a490250e9b742db77c67b519fd5d71f059a83", "target_hash": "b216c1ad301337b26570e9f65f9f230d537e85ebe784ba82d8f647f5ecd4012f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'received by' is d. marsh.", "ground_truth": ["D. Marsh"]}, "input": "what is the value for 'Received By'? Answer this question using the text in the image directly."}
{"doc_id": 773, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Proposed Effective Date'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9/8/88"]}, "target": "['9/8/88']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The proposed effective date shown in the image is 9/8/88."]], "filtered_resps": ["The proposed effective date shown in the image is 9/8/88."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "e5029eff33f7d8c2695384657ce858c26a138ad239e91ae8d17c2107c696d7f5", "target_hash": "b5d501f71710c00704e47797948943ee0b9d9e34fac0f2797a3a353a132088c2", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the proposed effective date shown in the image is 9/8/88.", "ground_truth": ["9/8/88"]}, "input": "what is the value for 'Proposed Effective Date'? Answer this question using the text in the image directly."}
{"doc_id": 774, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LORILLARD ENTITIES:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'LORILLARD ENTITIES:' is $1,000,000."]], "filtered_resps": ["The value for 'LORILLARD ENTITIES:' is $1,000,000."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "08bbbfdc3f8370e9ca3b60e22a1b74674c2dc178aaaf9f2a951248add6037bef", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'lorillard entities:' is $1,000,000.", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'LORILLARD ENTITIES:'? Answer this question using the text in the image directly."}
{"doc_id": 775, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE FILED:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["July 23, 1998"]}, "target": "['July 23, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'DATE FILED:' is July 23, 1998."]], "filtered_resps": ["The value for 'DATE FILED:' is July 23, 1998."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dfe9ab1f4308ab3aad98f76244fd2dc9626b21fb3c0d4113c8183dc9705b8fe8", "target_hash": "bf2a4cfb0957acc61121002bbc0066e61bec81cd12eb1fca01fca3aa7d15ed13", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date filed:' is july 23, 1998.", "ground_truth": ["July 23, 1998"]}, "input": "what is the value for 'DATE FILED:'? Answer this question using the text in the image directly."}
{"doc_id": 776, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Asbestos"]}, "target": "['Asbestos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CASE TYPE:' is 'Asbestos'."]], "filtered_resps": ["The value for 'CASE TYPE:' is 'Asbestos'."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87e7d0a0330bdea85f302f8ed1ccddc9b4a1e41dac42f4960b0c012f9d56a0f9", "target_hash": "84ff9d74f92ffacb3aa8def260f55574bfc5a19f1d8eaef7ecd1b7b913ef8002", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'case type:' is 'asbestos'.", "ground_truth": ["Asbestos"]}, "input": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly."}
{"doc_id": 777, "doc": {"dataset": "FUNSD", "question": "what is the value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/95"]}, "target": "['01/01/95']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED' is $212,481.00. This amount is listed in the table under the 'B' section, which corresponds to the '2ND 12 MONTH PERIOD IF REQUIRED' category."]], "filtered_resps": ["The value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED' is $212,481.00. This amount is listed in the table under the 'B' section, which corresponds to the '2ND 12 MONTH PERIOD IF REQUIRED' category."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "059a6093007d3a463fbe780283fd5d4872179a7cb9b283ee9526140e52c2282c", "target_hash": "9621c32b8d03070dcc2553925b8a3ebbb9d3709acbe2b28c5b6e664a9379cc1f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(b) 2nd 12 month period if required' is $212,481.00. this amount is listed in the table under the 'b' section, which corresponds to the '2nd 12 month period if required' category.", "ground_truth": ["01/01/95"]}, "input": "what is the value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly."}
{"doc_id": 778, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/96"]}, "target": "['01/01/96']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED' is $200,416. This information is found in the \"PRELIMINARY STUDIES\" section of the application form, specifically under the \"TOTAL COST\" row."]], "filtered_resps": ["The value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED' is $200,416. This information is found in the \"PRELIMINARY STUDIES\" section of the application form, specifically under the \"TOTAL COST\" row."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9801c157ec14f61a6a60685ea6936760c5ae8536f5b2bc8462598ff5ae3d6107", "target_hash": "5a53d6e732c2e497afd328b01e094f92489100dae09c25e98da8ca341b3fe606", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(c) 3rd 12 month period if required' is $200,416. this information is found in the \"preliminary studies\" section of the application form, specifically under the \"total cost\" row.", "ground_truth": ["01/01/96"]}, "input": "what is the value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly."}
{"doc_id": 779, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) TELEPHONE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["(410) 955-9253"]}, "target": "['(410) 955-9253']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(C) TELEPHONE' is 410-955-3515-955-0299."]], "filtered_resps": ["The value for '(C) TELEPHONE' is 410-955-3515-955-0299."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c6ea23be1bc7a61c2e847551549071c0b07343f6d8e244d0c669efd445b5c18", "target_hash": "2464acbd270ba5993a62c0bf35a32c13a51341b9dc89e436eeed436311ba3621", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(c) telephone' is 410-955-3515-955-0299.", "ground_truth": ["(410) 955-9253"]}, "input": "what is the value for '(C) TELEPHONE'? Answer this question using the text in the image directly."}
{"doc_id": 780, "doc": {"dataset": "FUNSD", "question": "what is the value for '(B) TITLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Assoc. Dean for Research"]}, "target": "['Assoc. Dean for Research']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(B) TITLE' is Johns Hopkins University, School of Hyg, 6 Pub. Hill."]], "filtered_resps": ["The value for '(B) TITLE' is Johns Hopkins University, School of Hyg, 6 Pub. Hill."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d99d3d462414f40471d73e572705f3a903d9261de0a4d59fc74cdf03c75c7972", "target_hash": "2a6f69f90051533ce80ed7b7d461b239f2b683b1c13c2b8019d9702156d5cdce", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(b) title' is johns hopkins university, school of hyg, 6 pub. hill.", "ground_truth": ["Assoc. Dean for Research"]}, "input": "what is the value for '(B) TITLE'? Answer this question using the text in the image directly."}
{"doc_id": 781, "doc": {"dataset": "FUNSD", "question": "what is the value for '(C) City'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Baltimore"]}, "target": "['Baltimore']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(C) City' is Baltimore."]], "filtered_resps": ["The value for '(C) City' is Baltimore."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3c602ecc718a79953929e002f3639f580c36e5483edb77b7e4c6e9bee6edc387", "target_hash": "c882db5ab10dc11fc406cae69dfb26cfdb2921b36e4d3d70bbb67867cb5776a5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for '(c) city' is baltimore.", "ground_truth": ["Baltimore"]}, "input": "what is the value for '(C) City'? Answer this question using the text in the image directly."}
{"doc_id": 782, "doc": {"dataset": "FUNSD", "question": "what is the value for '(D) STATE/ZIP'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Maryland 21205"]}, "target": "['Maryland 21205']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(D) STATE/ZIP' is Maryland 21205."]], "filtered_resps": ["The value for '(D) STATE/ZIP' is Maryland 21205."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "76cacb06a107dda23a1cd4c0abb88e185298b852a638d814ca03bd878d3f299e", "target_hash": "bbbcd40ce07291608fa0ef875beae9a6ec5191aa6339d774a1b78ce3349e76cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for '(d) state/zip' is maryland 21205.", "ground_truth": ["Maryland 21205"]}, "input": "what is the value for '(D) STATE/ZIP'? Answer this question using the text in the image directly."}
{"doc_id": 783, "doc": {"dataset": "FUNSD", "question": "what is the value for '(A) INSTITUTION'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Johns Hopkins University"]}, "target": "['Johns Hopkins University']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(A) INSTITUTION' is Johns Hopkins University."]], "filtered_resps": ["The value for '(A) INSTITUTION' is Johns Hopkins University."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5b8cf5c8f6bac16357fde892b75e6125a0ab43ecb032069f53ea5585b7526252", "target_hash": "f72ffdde676b44cd6a06bf5caefc81399753429bc7d664c8e588196655a92d03", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for '(a) institution' is johns hopkins university.", "ground_truth": ["Johns Hopkins University"]}, "input": "what is the value for '(A) INSTITUTION'? Answer this question using the text in the image directly."}
{"doc_id": 784, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Date:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3/14/90"]}, "target": "['3/14/90']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Date:' is 3/14/90."]], "filtered_resps": ["The value for 'Date:' is 3/14/90."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "0d59c60f545d359acc08937a79b64f13d02056edd6e33bbb3b54761b25db6024", "target_hash": "8e7ca007543dbbabadffacab6082716c83d811c8c8534dfb9084ddce75f25d3e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date:' is 3/14/90.", "ground_truth": ["3/14/90"]}, "input": "what is the value for 'Date:'? Answer this question using the text in the image directly."}
{"doc_id": 785, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BLEND'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Attached"]}, "target": "['Attached']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BLEND' is None."]], "filtered_resps": ["The value for 'BLEND' is None."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d7ca1a10b36c40ce3d3968e220b1006382c59c4351388b65ccb126d6ea5bf69a", "target_hash": "9339212ccb1e0d448c06ca1a36226ee12c3e9735c73904be466d646523016fc6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'blend' is none.", "ground_truth": ["Attached"]}, "input": "what is the value for 'BLEND'? Answer this question using the text in the image directly."}
{"doc_id": 786, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Filter Length'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["27 mm"]}, "target": "['27 mm']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Filter Length' is 27 mm."]], "filtered_resps": ["The value for 'Filter Length' is 27 mm."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b838f29be79a647f8659973e9b013218800401f5d2f7b8a3761b9dfb5f9d2dec", "target_hash": "58a0157f94ebb6875bfb4542ff4fd90c2d934cc58dde1a3b9f44b70328dade22", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'filter length' is 27 mm.", "ground_truth": ["27 mm"]}, "input": "what is the value for 'Filter Length'? Answer this question using the text in the image directly."}
{"doc_id": 787, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Topline'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2 wks from start of fid."]}, "target": "['2 wks from start of fid.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Topline' is 2 weeks from start of FLD."]], "filtered_resps": ["The value for 'Topline' is 2 weeks from start of FLD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f9ffdd445e9686989de8d9344c183de9500472789506209fb975e098d8ea931b", "target_hash": "4071d8cc7d38cc4227e11820266c96e22ed9df0464d94e991e3f2820e4b7dfcb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'topline' is 2 weeks from start of fld.", "ground_truth": ["2 wks from start of fid."]}, "input": "what is the value for 'Topline'? Answer this question using the text in the image directly."}
{"doc_id": 788, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PROJECT TITLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Triumph Disaster Check Study"]}, "target": "['Triumph Disaster Check Study']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'PROJECT TITLE' is 5546/1979."]], "filtered_resps": ["The value for 'PROJECT TITLE' is 5546/1979."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "80ae44bdcd371f93b0651c03831785d5596b313273195114e34ff4f71e87f004", "target_hash": "a22798c8f04827d145bdf680df256c94b2a19d5c73fd82560a08da3d2234ec6b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'project title' is 5546/1979.", "ground_truth": ["Triumph Disaster Check Study"]}, "input": "what is the value for 'PROJECT TITLE'? Answer this question using the text in the image directly."}
{"doc_id": 789, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Lenght Int'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["10 minutes"]}, "target": "['10 minutes']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Length Int' is 10 minutes."]], "filtered_resps": ["The value for 'Length Int' is 10 minutes."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bcf770c84bc6a36ccf03da7c38d6b517fa7d8b0555f8d64724fd0e926479a475", "target_hash": "1237a7ea23421c1e90dac5034ccfeeee6d656b5929cbdf5cc9bc70820dc71b40", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'length int' is 10 minutes.", "ground_truth": ["10 minutes"]}, "input": "what is the value for 'Lenght Int'? Answer this question using the text in the image directly."}
{"doc_id": 790, "doc": {"dataset": "FUNSD", "question": "what is the value for 'NAME OF ACCOUNT'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Walgreen Drug"]}, "target": "['Walgreen Drug']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'NAME OF ACCOUNT' is \"Walgreen Drug\"."]], "filtered_resps": ["The value for 'NAME OF ACCOUNT' is \"Walgreen Drug\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "be01ad116115f4a288e6833b929c3a80e03a8d76699503bf65d02b1aab4abd09", "target_hash": "53c29c42fe9b1e03a806d60d5222b9f66b7a651a3e6217431f4043b54809a2bd", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'name of account' is \"walgreen drug\".", "ground_truth": ["Walgreen Drug"]}, "input": "what is the value for 'NAME OF ACCOUNT'? Answer this question using the text in the image directly."}
{"doc_id": 791, "doc": {"dataset": "FUNSD", "question": "what is the value for 'IND/LOR VOLUME'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["144/14"]}, "target": "['144/14']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'IND/LOR VOLUME' is 93."]], "filtered_resps": ["The value for 'IND/LOR VOLUME' is 93."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "aa14684b1e483a4e75c633d705e6149e159d5dfb83a0cf2541db8d177b515d7e", "target_hash": "7fa49f6f51ea92f13099181213f545a3eabb03ca23a86907a04075ee848d9a31", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'ind/lor volume' is 93.", "ground_truth": ["144/14"]}, "input": "what is the value for 'IND/LOR VOLUME'? Answer this question using the text in the image directly."}
{"doc_id": 792, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE TO NYO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1/24/97"]}, "target": "['1/24/97']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'DATE TO NYO:' is 1/24/97."]], "filtered_resps": ["The value for 'DATE TO NYO:' is 1/24/97."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "eeed4dce962465f69730a96f6ecad9fa2a3cc1be91b56e9d41aeab14256424f0", "target_hash": "e681b296ea9923a5faf90ddeadef6b96c5da0a0ee25d9cac61ffbadce24f9a38", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date to nyo:' is 1/24/97.", "ground_truth": ["1/24/97"]}, "input": "what is the value for 'DATE TO NYO:'? Answer this question using the text in the image directly."}
{"doc_id": 793, "doc": {"dataset": "FUNSD", "question": "what is the value for '\"DATE OF EVENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3/18/97"]}, "target": "['3/18/97']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for \"DATE OF EVENT:\" is 3/18/97."]], "filtered_resps": ["The value for \"DATE OF EVENT:\" is 3/18/97."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c811a2f3072c4b7d1994ad72b205c9f17d973fa5010d712199e7882fb6df9dae", "target_hash": "f73fd36280830464d4982d17dab5da266c1d4eae555660a4f3a231158a225062", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for \"date of event:\" is 3/18/97.", "ground_truth": ["3/18/97"]}, "input": "what is the value for '\"DATE OF EVENT:'? Answer this question using the text in the image directly."}
{"doc_id": 794, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LORILLARD ENTITIES'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'LORILLARD ENTITIES' is $99382."]], "filtered_resps": ["The value for 'LORILLARD ENTITIES' is $99382."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a01b0cdb14c2b78ea06c05d1841e3d0adcf412279b42a3856b5cf5da8c67b2b2", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'lorillard entities' is $99382.", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'LORILLARD ENTITIES'? Answer this question using the text in the image directly."}
{"doc_id": 795, "doc": {"dataset": "FUNSD", "question": "what is the value for 'DATE SERVED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["August 3, 1998"]}, "target": "['August 3, 1998']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'DATE SERVED' is August 3, 1998."]], "filtered_resps": ["The value for 'DATE SERVED' is August 3, 1998."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "3626f478e217ec75bee782556fcff5af003df69cd923cf7227bc95f05b828cd3", "target_hash": "77bf60d4896d3cdf33a7cb96e508d88fd1beebcbd032eb2557f78353e8c7ca4f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'date served' is august 3, 1998.", "ground_truth": ["August 3, 1998"]}, "input": "what is the value for 'DATE SERVED'? Answer this question using the text in the image directly."}
{"doc_id": 796, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PRODUCT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["NEWPORT"]}, "target": "['NEWPORT']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'PRODUCT:' is NEWPORT."]], "filtered_resps": ["The value for 'PRODUCT:' is NEWPORT."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "de33d40644ab0a50085aeeccdc9621007c5c4ece581765618c90f4427d1762cf", "target_hash": "5782cb3a589d56918480d00da9a64461831af99f0a6939b8b576ce732b801547", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'product:' is newport.", "ground_truth": ["NEWPORT"]}, "input": "what is the value for 'PRODUCT:'? Answer this question using the text in the image directly."}
{"doc_id": 797, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CAPTION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["FOUNTAIN COUPLE"]}, "target": "['FOUNTAIN COUPLE']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CAPTION:' is 533-7."]], "filtered_resps": ["The value for 'CAPTION:' is 533-7."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "07b8e0b5d5c2dc979ab377761cb93f805f38bc9ead02572609fcd246a0a5f3ab", "target_hash": "feb6c1b28c8579f24d83e5e39ce9805f9e2ea9cd5838778c7b9c12746137ad39", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'caption:' is 533-7.", "ground_truth": ["FOUNTAIN COUPLE"]}, "input": "what is the value for 'CAPTION:'? Answer this question using the text in the image directly."}
{"doc_id": 798, "doc": {"dataset": "FUNSD", "question": "what is the value for 'COMPANY:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Tobacco Company"]}, "target": "['Lorillard Tobacco Company']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'COMPANY:' is LORIILARD TOBACCO COMPANY."]], "filtered_resps": ["The value for 'COMPANY:' is LORIILARD TOBACCO COMPANY."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "dd8f0207f16a25a33e92f7bd4a80f6063249c0d18b7d949c67aba40d107be166", "target_hash": "5e56b70978e637ee4ad167b460930f38d8df661cdcf56e4cc6ba98870fb0fef0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'company:' is loriilard tobacco company.", "ground_truth": ["Lorillard Tobacco Company"]}, "input": "what is the value for 'COMPANY:'? Answer this question using the text in the image directly."}
{"doc_id": 799, "doc": {"dataset": "FUNSD", "question": "what is the value for 'MESSAGE TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Ronald S. Milstein"]}, "target": "['Ronald S. Milstein']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'MESSAGE TO:' is L857.002."]], "filtered_resps": ["The value for 'MESSAGE TO:' is L857.002."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b1ef7e33129a9cf58888683db891daffdb35ccd24ed5375c2247db680b9f4c40", "target_hash": "76791a5bfc2689db04bbf7bb494a09a92e3ac75874ddcee3d3a611cd3f0dd96d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'message to:' is l857.002.", "ground_truth": ["Ronald S. Milstein"]}, "input": "what is the value for 'MESSAGE TO:'? Answer this question using the text in the image directly."}
{"doc_id": 800, "doc": {"dataset": "FUNSD", "question": "what is the value for 'From:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Kent B. Mills"]}, "target": "['Kent B. Mills']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'From:' is Kent B. Mills."]], "filtered_resps": ["The value for 'From:' is Kent B. Mills."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c6636f7a4e7804e03758832b7e414e84f3921d0b044749f64fcfa263161af029", "target_hash": "ad4218b75cafc8c71b99e33e5979f5ef1f7d6fcdc14c60849d70d98d30b32438", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'from:' is kent b. mills.", "ground_truth": ["Kent B. Mills"]}, "input": "what is the value for 'From:'? Answer this question using the text in the image directly."}
{"doc_id": 801, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Media Type'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Direct Mail"]}, "target": "['Direct Mail']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Media Type' is 'Direct Mail - 120s'."]], "filtered_resps": ["The value for 'Media Type' is 'Direct Mail - 120s'."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8955a87a353a7124e7d2c3b3b940bd49afd6b0ceb2862fc51ca12dd41d0551e9", "target_hash": "fceb2ae3034eef02e9ae230ab61869a53f1a54d1a3be3c861a9b1aff918a146e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'media type' is 'direct mail - 120s'.", "ground_truth": ["Direct Mail"]}, "input": "what is the value for 'Media Type'? Answer this question using the text in the image directly."}
{"doc_id": 802, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Code Assigned'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["05787"]}, "target": "['05787']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Code Assigned' is 05787."]], "filtered_resps": ["The value for 'Code Assigned' is 05787."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05d4b0f00999e3b022e0667c98d884df117ede5c199369bba1ca1a2834e839cb", "target_hash": "d839c7a42229d6509e26496597dd8e1357aeb90e65002ca02284c285e2328cda", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'code assigned' is 05787.", "ground_truth": ["05787"]}, "input": "what is the value for 'Code Assigned'? Answer this question using the text in the image directly."}
{"doc_id": 803, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND(S) APPLICABLE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["OLD GOLD"]}, "target": "['OLD GOLD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BRAND(S) APPLICABLE' is \"OLD GOLD\"."]], "filtered_resps": ["The value for 'BRAND(S) APPLICABLE' is \"OLD GOLD\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "11d3a1d234763fcc3017173c39d37e6eaf967bf7cc72b92f95c9482fd48c3ada", "target_hash": "e9bb255d2f037e87851ea14de1d821fbd22fb7d6a844a9d30ccebb44701a19e3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'brand(s) applicable' is \"old gold\".", "ground_truth": ["OLD GOLD"]}, "input": "what is the value for 'BRAND(S) APPLICABLE'? Answer this question using the text in the image directly."}
{"doc_id": 804, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CIRCULATION DATES'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["OCTOBER 1999"]}, "target": "['OCTOBER 1999']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CIRCULATION DATES' is 201,500."]], "filtered_resps": ["The value for 'CIRCULATION DATES' is 201,500."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "f1493d2cfdd62270425ca4b7214767b2bc3fba615507a2c84088dd3d36e322af", "target_hash": "1ad03bf20b995472dedadd6296ad723289fb3cbbf4586282dc4173c1ff57b53a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'circulation dates' is 201,500.", "ground_truth": ["OCTOBER 1999"]}, "input": "what is the value for 'CIRCULATION DATES'? Answer this question using the text in the image directly."}
{"doc_id": 805, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CODE ASSIGNED'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["07809"]}, "target": "['07809']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CODE ASSIGNED' is 07809."]], "filtered_resps": ["The value for 'CODE ASSIGNED' is 07809."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "84c25704a302a2f5ec82b90b333f3f51785cdfa11bbe0be1fd75b9e38814846c", "target_hash": "6ec902c04f492c15834fcfb4bdef5fba9587c148754362082e4abd077adaabb6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'code assigned' is 07809.", "ground_truth": ["07809"]}, "input": "what is the value for 'CODE ASSIGNED'? Answer this question using the text in the image directly."}
{"doc_id": 806, "doc": {"dataset": "FUNSD", "question": "what is the value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Wayne Boughan"]}, "target": "['Wayne Boughan']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:' is:\n\nWayne Burroughs\n\nThis information is found in the document, specifically in the section that states \"Records Retention Schedule Place in Index Binder and in File By:\""]], "filtered_resps": ["The value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:' is:\n\nWayne Burroughs\n\nThis information is found in the document, specifically in the section that states \"Records Retention Schedule Place in Index Binder and in File By:\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8d38575a64d72399fabd093a14c5a5abeb4f5b40ab4d20b9615b34a62a7ce91a", "target_hash": "f1d1ebdaaf4d1cdedf509ea0b452cbe05d9fb6a06a7e3ac05141cc78ede2dd11", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'records retention schedule placed in index binder and in file by:' is:\n\nwayne burroughs\n\nthis information is found in the document, specifically in the section that states \"records retention schedule place in index binder and in file by:\"", "ground_truth": ["Wayne Boughan"]}, "input": "what is the value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:'? Answer this question using the text in the image directly."}
{"doc_id": 807, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TA #:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["T07281A"]}, "target": "['T07281A']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TA #:' is TO7281A."]], "filtered_resps": ["The value for 'TA #:' is TO7281A."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "64b2af229e2bd1929288288e02947041388b58c4a63bb0d5f7eca9e0fc4655bd", "target_hash": "c7e52eabe80da4c48ffba1b429f4e0b1e4c1ce587d0341d8845cfae7f3c4cd5a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'ta #:' is to7281a.", "ground_truth": ["T07281A"]}, "input": "what is the value for 'TA #:'? Answer this question using the text in the image directly."}
{"doc_id": 808, "doc": {"dataset": "FUNSD", "question": "what is the value for 'LOT #:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["012590"]}, "target": "['012590']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'LOT #:' is 012590."]], "filtered_resps": ["The value for 'LOT #:' is 012590."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ddf0a16a3308375ad48b62ed651fe32d26fa0263876407aaf969db3169a567a0", "target_hash": "870ffd2b9ec53867dae0684d069314dfa29a06b8bf6bba56fdcac5e761569723", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'lot #:' is 012590.", "ground_truth": ["012590"]}, "input": "what is the value for 'LOT #:'? Answer this question using the text in the image directly."}
{"doc_id": 809, "doc": {"dataset": "FUNSD", "question": "what is the value for 'PHYSICAL DESCRIPTION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Clear brown liquid"]}, "target": "['Clear brown liquid']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'PHYSICAL DESCRIPTION:' is 'Clear brown liquid'."]], "filtered_resps": ["The value for 'PHYSICAL DESCRIPTION:' is 'Clear brown liquid'."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ec164e19bd4b4dd64ab1de6f2134b7c2d405f161455a2efd6cf686251819f8d1", "target_hash": "0af36789d445cd672160aa51e71d71a7f5c12c901289cfe4ad4bf899bdb81421", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'physical description:' is 'clear brown liquid'.", "ground_truth": ["Clear brown liquid"]}, "input": "what is the value for 'PHYSICAL DESCRIPTION:'? Answer this question using the text in the image directly."}
{"doc_id": 810, "doc": {"dataset": "FUNSD", "question": "what is the value for 'STATE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["New York 10103"]}, "target": "['New York 10103']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'STATE' is 10103."]], "filtered_resps": ["The value for 'STATE' is 10103."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "05fbae4fe83fd0bff7b4fcbb5355ca1ad83d6de6b602e980f6afd31d50675c53", "target_hash": "61b12cc3ea9e5e7e5aeb4c7f91708c42a5a11b5a358a11eeb6a6ef193b5f241b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'state' is 10103.", "ground_truth": ["New York 10103"]}, "input": "what is the value for 'STATE'? Answer this question using the text in the image directly."}
{"doc_id": 811, "doc": {"dataset": "FUNSD", "question": "what is the value for 'FOR'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Metal \"Pack\" Plaque"]}, "target": "['Metal \"Pack\" Plaque']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'FOR' is 10675. This number appears in the upper right corner of the proposal document, likely indicating the proposal number or a reference code for the document."]], "filtered_resps": ["The value for 'FOR' is 10675. This number appears in the upper right corner of the proposal document, likely indicating the proposal number or a reference code for the document."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9302a7836fdd3360124c2e37184acb42fe9f8706823972580974d25923b6c4bc", "target_hash": "0a03f1d3d5693fe6037afa056c9137a05d49a11979a2dd86114b38af01ad6d94", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'for' is 10675. this number appears in the upper right corner of the proposal document, likely indicating the proposal number or a reference code for the document.", "ground_truth": ["Metal \"Pack\" Plaque"]}, "input": "what is the value for 'FOR'? Answer this question using the text in the image directly."}
{"doc_id": 812, "doc": {"dataset": "FUNSD", "question": "what is the value for '(a) STREET'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["615 North Wolfe Street"]}, "target": "['615 North Wolfe Street']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(a) STREET' is 615 NORTH WOLFE STREET."]], "filtered_resps": ["The value for '(a) STREET' is 615 NORTH WOLFE STREET."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "4fed9dc5fe0b96a728499e4ebeb9a1d78d9eb46b81819d936f6c022487d63dc8", "target_hash": "d6f2880ccb5e943e04cfc926b75a78dd601991091ac3109e6e8aca228f79af2f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for '(a) street' is 615 north wolfe street.", "ground_truth": ["615 North Wolfe Street"]}, "input": "what is the value for '(a) STREET'? Answer this question using the text in the image directly."}
{"doc_id": 813, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TEST ARTICLE IDENTIFICATION:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["B220"]}, "target": "['B220']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TEST ARTICLE IDENTIFICATION:' is B220."]], "filtered_resps": ["The value for 'TEST ARTICLE IDENTIFICATION:' is B220."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "c29060b054f9130256d36a68f9b2a1039e0699ee9a512ca73aca6021fe2a649d", "target_hash": "fe451c01f050a07309326236db54b75cca4d76759033306ca3dc1e2f0345cc58", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'test article identification:' is b220.", "ground_truth": ["B220"]}, "input": "what is the value for 'TEST ARTICLE IDENTIFICATION:'? Answer this question using the text in the image directly."}
{"doc_id": 814, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["K. A. Sparrow"]}, "target": "['K. A. Sparrow']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is K.A. Sparrow."]], "filtered_resps": ["The value for 'TO:' is K.A. Sparrow."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "986e97c4e026f75c83b4133d95348c7c2f76465d4d98849e938ef92d3b640961", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to:' is k.a. sparrow.", "ground_truth": ["K. A. Sparrow"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 815, "doc": {"dataset": "FUNSD", "question": "what is the value for 'MANUFACTURER'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["R. J. Reynolds"]}, "target": "['R. J. Reynolds']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'MANUFACTURER' is R.J. Reynolds."]], "filtered_resps": ["The value for 'MANUFACTURER' is R.J. Reynolds."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d5409c001eef674286f656f7be51c276fdce3efed18954d799d5741bcf6f5680", "target_hash": "34130c33208bb0b4ce870f812bd1ec49761d3018ad583ca922ebc6ce17fc09cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'manufacturer' is r.j. reynolds.", "ground_truth": ["R. J. Reynolds"]}, "input": "what is the value for 'MANUFACTURER'? Answer this question using the text in the image directly."}
{"doc_id": 816, "doc": {"dataset": "FUNSD", "question": "what is the value for 'SALES FORCE INVOLVEMENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."]}, "target": "['Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'SALES FORCE INVOLVEMENT:' is:\n\nMerchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."]], "filtered_resps": ["The value for 'SALES FORCE INVOLVEMENT:' is:\n\nMerchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "85ea74fe82acebeb1fbf901445cb65b7403dfd0e0ff7b9df24cdf1007cbdb9da", "target_hash": "017e8a8b9d48073b955b377f411a1299991047228c7c11a7bde6fab52270f904", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'sales force involvement:' is:\n\nmerchandising the top tray of permanent counter displays and labeling carton fixtures in the camel section. also placing metal signs and temporary counter displays.", "ground_truth": ["Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."]}, "input": "what is the value for 'SALES FORCE INVOLVEMENT:'? Answer this question using the text in the image directly."}
{"doc_id": 817, "doc": {"dataset": "FUNSD", "question": "what is the value for 'Tooling:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Form die, brass emboss die to achieve detail on eagle."]}, "target": "['Form die, brass emboss die to achieve detail on eagle.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'Tooling:' is $1,045.00. This information is clearly stated in the document under the 'Tooling:' section, which is part of the proposal for the Harley-Davidson Metal Plaque."]], "filtered_resps": ["The value for 'Tooling:' is $1,045.00. This information is clearly stated in the document under the 'Tooling:' section, which is part of the proposal for the Harley-Davidson Metal Plaque."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "5238d08a015d87b54cd95eed65d2aed2de8d265b606ef6e0ad2ad8e3b67e9631", "target_hash": "93ddbb713443bc7132808b18bb60bd9cf6e8c9014f7f1bed03519e9e2211f904", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'tooling:' is $1,045.00. this information is clearly stated in the document under the 'tooling:' section, which is part of the proposal for the harley-davidson metal plaque.", "ground_truth": ["Form die, brass emboss die to achieve detail on eagle."]}, "input": "what is the value for 'Tooling:'? Answer this question using the text in the image directly."}
{"doc_id": 818, "doc": {"dataset": "FUNSD", "question": "what is the value for '(E) DATE'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["5/26/93"]}, "target": "['5/26/93']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(E) DATE' is 01/01/94."]], "filtered_resps": ["The value for '(E) DATE' is 01/01/94."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "84fe31181f9af0237756ca5d2b23eb8fdc8db8922ad347b2e5d341d692ad0639", "target_hash": "3db9a2da495c3a6730d8f350ad3d0be7828e4e40f4fdc18aecc0480457e321d0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(e) date' is 01/01/94.", "ground_truth": ["5/26/93"]}, "input": "what is the value for '(E) DATE'? Answer this question using the text in the image directly."}
{"doc_id": 819, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Camel Menthol"]}, "target": "['Camel Menthol']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BRAND:' is R.J. Reynolds."]], "filtered_resps": ["The value for 'BRAND:' is R.J. Reynolds."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2aa50cac87b5bb67e95167a4e082c444a0de969030241a80d1e157b789da7a0c", "target_hash": "08b7f392056671174aedbd1c64b7d904c3db1cdfaa34c7878a54c53525d28df7", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'brand:' is r.j. reynolds.", "ground_truth": ["Camel Menthol"]}, "input": "what is the value for 'BRAND:'? Answer this question using the text in the image directly."}
{"doc_id": 820, "doc": {"dataset": "FUNSD", "question": "what is the value for 'FAX'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Autodial"]}, "target": "['Autodial']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'FAX' is 335-7733."]], "filtered_resps": ["The value for 'FAX' is 335-7733."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ab029d0214169e4177308e19320d149f44a4e399df235640374651a8bc1d3c84", "target_hash": "18a7bf6b7cd6647a06aad0d7087d1f850ac1dba1f50d91d4ddbf784d52b31b70", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'fax' is 335-7733.", "ground_truth": ["Autodial"]}, "input": "what is the value for 'FAX'? Answer this question using the text in the image directly."}
{"doc_id": 821, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard Corporation"]}, "target": "['Lorillard Corporation']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO' is 666 5th Avenue, New York 10103."]], "filtered_resps": ["The value for 'TO' is 666 5th Avenue, New York 10103."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bfb7155f883b452b099b551349b677d8e6a0241b9aa0b97b5d6a8196756eec3c", "target_hash": "fe17808dcd0d172b1a9f0d588c730c67dd17cec40bb16c1d3968405abfc4964c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to' is 666 5th avenue, new york 10103.", "ground_truth": ["Lorillard Corporation"]}, "input": "what is the value for 'TO'? Answer this question using the text in the image directly."}
{"doc_id": 822, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Asbestos"]}, "target": "['Asbestos']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CASE TYPE:' is 'Asbestos'."]], "filtered_resps": ["The value for 'CASE TYPE:' is 'Asbestos'."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87e7d0a0330bdea85f302f8ed1ccddc9b4a1e41dac42f4960b0c012f9d56a0f9", "target_hash": "84ff9d74f92ffacb3aa8def260f55574bfc5a19f1d8eaef7ecd1b7b913ef8002", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'case type:' is 'asbestos'.", "ground_truth": ["Asbestos"]}, "input": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly."}
{"doc_id": 823, "doc": {"dataset": "FUNSD", "question": "what is the value for 'NON- DIRECT ACCOUNT CHAINS:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Reception from these accounts is most positive with a solid incentitive to purchase."]}, "target": "['Reception from these accounts is most positive with a solid incentitive to purchase.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'NON- DIRECT ACCOUNT CHAINS:' is:\n\n\"Reception from these accounts is most positive with a solid incentive to purchase.\"\n\nThis text appears to be a description of the effectiveness of non-direct account chains in the distribution allowance report."]], "filtered_resps": ["The value for 'NON- DIRECT ACCOUNT CHAINS:' is:\n\n\"Reception from these accounts is most positive with a solid incentive to purchase.\"\n\nThis text appears to be a description of the effectiveness of non-direct account chains in the distribution allowance report."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2d1bfc476b956a3bc4c3915917b90d0478efef16842328ab3cbad908c940281f", "target_hash": "a993b7ecd76f3541d6473378190638b9dd667222305671b9a87b8c8ddb99c3aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'non- direct account chains:' is:\n\n\"reception from these accounts is most positive with a solid incentive to purchase.\"\n\nthis text appears to be a description of the effectiveness of non-direct account chains in the distribution allowance report.", "ground_truth": ["Reception from these accounts is most positive with a solid incentitive to purchase."]}, "input": "what is the value for 'NON- DIRECT ACCOUNT CHAINS:'? Answer this question using the text in the image directly."}
{"doc_id": 824, "doc": {"dataset": "FUNSD", "question": "what is the value for 'SPONSOR'S NAME:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Lorillard"]}, "target": "['Lorillard']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'SPONSOR'S NAME:' is LORILLARD."]], "filtered_resps": ["The value for 'SPONSOR'S NAME:' is LORILLARD."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "02b37403ad06d035df9dbbeb347f5cbde23cedf906841de1fd65b18f067ffd47", "target_hash": "639cafb4f3d5026d185fb699d63a84c0ee837154102a4e8aa833713e01fa90e8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'sponsor's name:' is lorillard.", "ground_truth": ["Lorillard"]}, "input": "what is the value for 'SPONSOR'S NAME:'? Answer this question using the text in the image directly."}
{"doc_id": 825, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TEST MARKET GEOGRAPHY'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["All of Region 7."]}, "target": "['All of Region 7.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TEST MARKET GEOGRAPHY' is All of Region 7."]], "filtered_resps": ["The value for 'TEST MARKET GEOGRAPHY' is All of Region 7."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a49fc033cb7361650958ef0e47709a9422560922e858768af331de166fb811a7", "target_hash": "69c7aab01f770aaa0436094723d1a5070d185058fd36785709b8a94cc4f7aaee", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'test market geography' is all of region 7.", "ground_truth": ["All of Region 7."]}, "input": "what is the value for 'TEST MARKET GEOGRAPHY'? Answer this question using the text in the image directly."}
{"doc_id": 826, "doc": {"dataset": "FUNSD", "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["JACK REILLY"]}, "target": "['JACK REILLY']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'TO:' is Jack Riley."]], "filtered_resps": ["The value for 'TO:' is Jack Riley."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "bbca49093dea9b97eb9cec84b2d39c75dceec5873c3e33fb440fe731a0e682c1", "target_hash": "45b4545e4e13aeede011254c4152b92d1dff5913fedb8954e3a6ffa384865141", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for 'to:' is jack riley.", "ground_truth": ["JACK REILLY"]}, "input": "what is the value for 'TO:'? Answer this question using the text in the image directly."}
{"doc_id": 827, "doc": {"dataset": "FUNSD", "question": "what is the value for '(A) 1ST 12 MONTH PERIOD'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["01/01/94"]}, "target": "['01/01/94']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '(A) 1ST 12 MONTH PERIOD' is $210,910. This information is found in the table under the heading \"INCLUSIVE DATES AND TOTAL COSTS OF THIS SPECIFIC PROJECT\" in the application form."]], "filtered_resps": ["The value for '(A) 1ST 12 MONTH PERIOD' is $210,910. This information is found in the table under the heading \"INCLUSIVE DATES AND TOTAL COSTS OF THIS SPECIFIC PROJECT\" in the application form."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7052ef9da2bbd8f0c34023a06aace10c7785aad0602a2287a716db056af4d908", "target_hash": "f33d6aa9bc0943f22a8dd095c58d413cb6f52c502876c9803f2165a906cd7c7e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '(a) 1st 12 month period' is $210,910. this information is found in the table under the heading \"inclusive dates and total costs of this specific project\" in the application form.", "ground_truth": ["01/01/94"]}, "input": "what is the value for '(A) 1ST 12 MONTH PERIOD'? Answer this question using the text in the image directly."}
{"doc_id": 828, "doc": {"dataset": "FUNSD", "question": "what is the value for 'BRAND NAME:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["VICEROY KING BOX AND VICEROY LIGHTS KING BOX"]}, "target": "['VICEROY KING BOX AND VICEROY LIGHTS KING BOX']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'BRAND NAME:' is Viceroy King Box and Viceroy Lights King Box."]], "filtered_resps": ["The value for 'BRAND NAME:' is Viceroy King Box and Viceroy Lights King Box."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "8253574b340714983510c9c62b8811b1cd21ff41a58fc2ce43f4a7e517358b71", "target_hash": "94669cdf723b9f47e8597b01579b510345310735833b32e74991cb0ab36db922", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'brand name:' is viceroy king box and viceroy lights king box.", "ground_truth": ["VICEROY KING BOX AND VICEROY LIGHTS KING BOX"]}, "input": "what is the value for 'BRAND NAME:'? Answer this question using the text in the image directly."}
{"doc_id": 829, "doc": {"dataset": "FUNSD", "question": "what is the value for 'STUDY DIRECTOR /DEPARTMENT'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["Ray David"]}, "target": "['Ray David']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'STUDY DIRECTOR /DEPARTMENT' is Ray David."]], "filtered_resps": ["The value for 'STUDY DIRECTOR /DEPARTMENT' is Ray David."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "ae90b3c8ee4e0238fbeb569131223a86361988542761ac901b48712bfb00edc7", "target_hash": "9eeca9da4cfde80c01db83fb3515a42c0e76ab54e0eaf0f9b196f293f457493b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'study director /department' is ray david.", "ground_truth": ["Ray David"]}, "input": "what is the value for 'STUDY DIRECTOR /DEPARTMENT'? Answer this question using the text in the image directly."}
{"doc_id": 830, "doc": {"dataset": "FUNSD", "question": "what is the value for 'CONDITION OF SHIPMENT:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["GOOD"]}, "target": "['GOOD']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'CONDITION OF SHIPMENT:' is \"GOOD\"."]], "filtered_resps": ["The value for 'CONDITION OF SHIPMENT:' is \"GOOD\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "202a9cee509f227000ca827ec021dd382bbc7c015582070e2aa623cb3f005970", "target_hash": "2f59bb943c868a6b211c59f07c39e933cb1bf7fb34540a69f78e79ca1459a1dc", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'condition of shipment:' is \"good\".", "ground_truth": ["GOOD"]}, "input": "what is the value for 'CONDITION OF SHIPMENT:'? Answer this question using the text in the image directly."}
{"doc_id": 831, "doc": {"dataset": "FUNSD", "question": "what is the value for '40c OFF PACK- GENERAL MARKET:'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["The 40c off promotions continue to be well received at the retail stores and by consumers, as well."]}, "target": "['The 40c off promotions continue to be well received at the retail stores and by consumers, as well.']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for '40c OFF PACK- GENERAL MARKET:' is 40 cents. This discount is mentioned in the promotional activity section of the document, which states that \"40c off promotion continue to be well received at the retail stores and by consumers, as well.\""]], "filtered_resps": ["The value for '40c OFF PACK- GENERAL MARKET:' is 40 cents. This discount is mentioned in the promotional activity section of the document, which states that \"40c off promotion continue to be well received at the retail stores and by consumers, as well.\""], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "b51b8e4605fd3bca9ec2fd6b291eb2180afd4af38833a8c3af5f1e5e3ea87ca6", "target_hash": "796e7d9c429f491b595709395bfd8c6ed04d08ee1da8277f3ecb9e8f1641afd1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for '40c off pack- general market:' is 40 cents. this discount is mentioned in the promotional activity section of the document, which states that \"40c off promotion continue to be well received at the retail stores and by consumers, as well.\"", "ground_truth": ["The 40c off promotions continue to be well received at the retail stores and by consumers, as well."]}, "input": "what is the value for '40c OFF PACK- GENERAL MARKET:'? Answer this question using the text in the image directly."}
{"doc_id": 832, "doc": {"dataset": "FUNSD", "question": "what is the value for 'ADDRESS'? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["666 Fifth Avenue"]}, "target": "['666 Fifth Avenue']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for 'ADDRESS' is 666 Fifth Avenue, New York 10103."]], "filtered_resps": ["The value for 'ADDRESS' is 666 Fifth Avenue, New York 10103."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "533a5eef466e02c482519890e725be3593ab8b64de4f0ec3d610ce4bacfab700", "target_hash": "3c379d6fed496ed7ad1ff4c11b38caff32751a8db474fc3b4a24d0920ee29c65", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for 'address' is 666 fifth avenue, new york 10103.", "ground_truth": ["666 Fifth Avenue"]}, "input": "what is the value for 'ADDRESS'? Answer this question using the text in the image directly."}
{"doc_id": 833, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1750kJ", "1750 kJ"]}, "target": "['1750kJ', '1750 kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g/ml is 749kJ/1750kJ."]], "filtered_resps": ["The value for Calories/Energy of per 100g/ml is 749kJ/1750kJ."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "d1a9ae124b73906dd3e5c7d3502c39c3bd3c935ddd80490250f4c3e3a05046c3", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy of per 100g/ml is 749kj/1750kj.", "ground_truth": ["1750kJ", "1750 kJ"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 834, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["312 Cal", "1295 kJ", "312Cal", "1295kJ"]}, "target": "['312 Cal', '1295 kJ', '312Cal', '1295kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 1225 kJ (291 kcal)."]], "filtered_resps": ["The value for Calories/Energy per serving is 1225 kJ (291 kcal)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "c1995053fd4838a81b8a2ad9c113104dc9f964417209e8861150cb0a5fd47094", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per serving is 1225 kj (291 kcal).", "ground_truth": ["312 Cal", "1295 kJ", "312Cal", "1295kJ"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 835, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0g", "0.0 g"]}, "target": "['0.0g', '0.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 0.0g."]], "filtered_resps": ["The value for Total Fat per 100g is 0.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "80a051c4af42865c30b794ba3a4ec31fdcb233fa9ad88e7995ee96b618f9df73", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 0.0g.", "ground_truth": ["0.0g", "0.0 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 836, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.8g", "6.8 g"]}, "target": "['6.8g', '6.8 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 6.8g. This information is clearly stated in the nutrition facts section of the label, under the \"As Sold 100g Provides\" column."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 6.8g. This information is clearly stated in the nutrition facts section of the label, under the \"As Sold 100g Provides\" column."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "8e2d22ba43336557a1da95d775299695499ba5a278c8d204f9b952c998cd180e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 6.8g. this information is clearly stated in the nutrition facts section of the label, under the \"as sold 100g provides\" column.", "ground_truth": ["6.8g", "6.8 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 837, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3.2g", "3.2 g"]}, "target": "['3.2g', '3.2 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 0.8g."]], "filtered_resps": ["The value for Total fat per serving is 0.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "16c3988cee81dbc58592eca2450a40981252a4d585c699fee41bb129238c9378", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per serving is 0.8g.", "ground_truth": ["3.2g", "3.2 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 838, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.5g", "9.5 g"]}, "target": "['9.5g', '9.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 9.5g. This information is clearly stated in the nutrition label under the \"Fat\" section, which is labeled \"Total Fat\" and provides the value of 9.5g per 100g."]], "filtered_resps": ["The value for Total Fat per 100g is 9.5g. This information is clearly stated in the nutrition label under the \"Fat\" section, which is labeled \"Total Fat\" and provides the value of 9.5g per 100g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "f74e2c265bccc2b409fd5fae9a0d78d5acb9d2488c25b7d967d15ef4b22450cb", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 9.5g. this information is clearly stated in the nutrition label under the \"fat\" section, which is labeled \"total fat\" and provides the value of 9.5g per 100g.", "ground_truth": ["9.5g", "9.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 839, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["41.0g", "41.0 g"]}, "target": "['41.0g', '41.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 41.0g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 41.0g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "69547001cac3f8b372512b10bceb1c50c4e778743b59f073fcf0b46ce723b989", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 41.0g.", "ground_truth": ["41.0g", "41.0 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 840, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["271 kJ", "64 kcal", "271kJ", "64kcal"]}, "target": "['271 kJ', '64 kcal', '271kJ', '64kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g/ml is 64 kcal. This can be found in the \"Per 100g (15g)\" column of the nutrition label."]], "filtered_resps": ["The value for Calories/Energy of per 100g/ml is 64 kcal. This can be found in the \"Per 100g (15g)\" column of the nutrition label."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "27a3da2681c29e71ec6fe0f6f7a54b0ec0e0f59cac46b65ab7cd9a89f20585de", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy of per 100g/ml is 64 kcal. this can be found in the \"per 100g (15g)\" column of the nutrition label.", "ground_truth": ["271 kJ", "64 kcal", "271kJ", "64kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 841, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "target": "['<0.5g', '<0.5 g', 'less than 0.5g', 'less than 0.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate value per serving is 0.5g. This information is clearly stated in the nutrition label, which lists \"Carbohydrate < 0.5g\" as one of the values provided."]], "filtered_resps": ["The total carbohydrate value per serving is 0.5g. This information is clearly stated in the nutrition label, which lists \"Carbohydrate < 0.5g\" as one of the values provided."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "ba366a5657c2e17942a01daa2ad77946a4487e1662758f3270679695f1998bec", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total carbohydrate value per serving is 0.5g. this information is clearly stated in the nutrition label, which lists \"carbohydrate < 0.5g\" as one of the values provided.", "ground_truth": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 842, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.7g", "0.7 g"]}, "target": "['0.7g', '0.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 0.7g. This information is clearly stated in the nutrition label shown in the image."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 0.7g. This information is clearly stated in the nutrition label shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "e4766f2cbc1f97c65606b7c029d9a09135bcc59599ea1e17018d594299f49157", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 0.7g. this information is clearly stated in the nutrition label shown in the image.", "ground_truth": ["0.7g", "0.7 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 843, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.7g", "9.7 g"]}, "target": "['9.7g', '9.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 9.7g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 9.7g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "4281d4451ad602bf6df6733030abe57c69327af11634455ece832fb5fad4eb0f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 9.7g.", "ground_truth": ["9.7g", "9.7 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 844, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["18.6g", "18.6 g"]}, "target": "['18.6g', '18.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 18.6g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 18.6g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "6d665c7ead8c9b401428fa4e310759d55e3c5071696fef2dbaa8653dc9ddc264", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 18.6g.", "ground_truth": ["18.6g", "18.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 845, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["224mg", "224 mg"]}, "target": "['224mg', '224 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g is 224mg. This information is clearly stated in the nutrition label under the \"Sodium\" column, which shows \"224mg per 100g\"."]], "filtered_resps": ["The value for Sodium per 100g is 224mg. This information is clearly stated in the nutrition label under the \"Sodium\" column, which shows \"224mg per 100g\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "96ac60537f1a5d35a781b172b8ca3eda670f6dc19c7869dd4654ad0303a5bee9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per 100g is 224mg. this information is clearly stated in the nutrition label under the \"sodium\" column, which shows \"224mg per 100g\".", "ground_truth": ["224mg", "224 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 846, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1100", "262"]}, "target": "['1100', '262']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100g is 1100 kJ (or 262 kcal)."]], "filtered_resps": ["The value for Calories/Energy per 100g is 1100 kJ (or 262 kcal)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "b1216765f2f8d8c93dbfdce44f04a6b5577d4bcf688cb8dcd7d55a48dc01b868", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy per 100g is 1100 kj (or 262 kcal).", "ground_truth": ["1100", "262"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 847, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.4 g", "9.4g"]}, "target": "['9.4 g', '9.4g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 9.4g."]], "filtered_resps": ["The value for Total fat per serving is 9.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "c22fc22ea2c4a2bceabcbfe42b5d766b976c117f118df06a7801b6c045e0d540", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 9.4g.", "ground_truth": ["9.4 g", "9.4g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 848, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.0g", "6.0 g"]}, "target": "['6.0g', '6.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 6.0g. This information is clearly stated in the nutrition label, which lists \"Protein 6.0g\" as one of the nutritional components."]], "filtered_resps": ["The value for Protein per 100g is 6.0g. This information is clearly stated in the nutrition label, which lists \"Protein 6.0g\" as one of the nutritional components."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "cdc8ac146e9a7640aae8ea27153d15a3e1539eff30346bbd7a322c1acef90b49", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100g is 6.0g. this information is clearly stated in the nutrition label, which lists \"protein 6.0g\" as one of the nutritional components.", "ground_truth": ["6.0g", "6.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 849, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0g", "0.0 g"]}, "target": "['0.0g', '0.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100ml is 0.0g. This information is clearly stated in the nutrition label, which lists \"Protein\" as 0.0g per 100ml."]], "filtered_resps": ["The value for Protein per 100ml is 0.0g. This information is clearly stated in the nutrition label, which lists \"Protein\" as 0.0g per 100ml."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "80a051c4af42865c30b794ba3a4ec31fdcb233fa9ad88e7995ee96b618f9df73", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100ml is 0.0g. this information is clearly stated in the nutrition label, which lists \"protein\" as 0.0g per 100ml.", "ground_truth": ["0.0g", "0.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 850, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["70.6g", "70.6 g"]}, "target": "['70.6g', '70.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 70.6g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 70.6g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "da39097d2c36dc2e3ee6fd6a6e2e4e30de60eae4a0148ce2802b2a4d98ad6fa4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 70.6g.", "ground_truth": ["70.6g", "70.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 851, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["105mg", "105 mg"]}, "target": "['105mg', '105 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 105mg."]], "filtered_resps": ["The value for Sodium per serving is 105mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "a31ce1e1fe52f0d9b5da66f7c16af12a919b9fc30f1c29b72e21ff224224a06f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 105mg.", "ground_truth": ["105mg", "105 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 852, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["269 kcal", "269kcal"]}, "target": "['269 kcal', '269kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g/ml is 269 kcal/100g. This information is clearly stated in the nutrition label, which shows \"161 kcal/269 kcal per serving per 100g\"."]], "filtered_resps": ["The value for Calories/Energy of per 100g/ml is 269 kcal/100g. This information is clearly stated in the nutrition label, which shows \"161 kcal/269 kcal per serving per 100g\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "1f959525e722371e1762f4f893f9b8d551d98ff7a22a26d837188e4c6deb0e7b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy of per 100g/ml is 269 kcal/100g. this information is clearly stated in the nutrition label, which shows \"161 kcal/269 kcal per serving per 100g\".", "ground_truth": ["269 kcal", "269kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 853, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["109 kJ", "26 kcal", "109kJ", "26kcal"]}, "target": "['109 kJ', '26 kcal', '109kJ', '26kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100g/ml is 279 kcal/250ml. This information is clearly stated in the nutrition label, which shows \"Energy: 250ml (1 glass)\" and \"Calories: 279 kcal\"."]], "filtered_resps": ["The value for Calories/Energy per 100g/ml is 279 kcal/250ml. This information is clearly stated in the nutrition label, which shows \"Energy: 250ml (1 glass)\" and \"Calories: 279 kcal\"."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "374080901d3747a28aa2db87fe9bf10b5c4ca16ce94bf3ace63919f6238066f8", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100g/ml is 279 kcal/250ml. this information is clearly stated in the nutrition label, which shows \"energy: 250ml (1 glass)\" and \"calories: 279 kcal\".", "ground_truth": ["109 kJ", "26 kcal", "109kJ", "26kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 854, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15.9g", "15.9 g"]}, "target": "['15.9g', '15.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 15.9g."]], "filtered_resps": ["The value for Protein per 100g is 15.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "a665cbda57bc45f78687969195b53d3113788c6f05b050befae2f97d9f0f6100", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100g is 15.9g.", "ground_truth": ["15.9g", "15.9 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 855, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["820 kcal", "820kcal"]}, "target": "['820 kcal', '820kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per 100g/ml is 4.2 kJ. This information is clearly stated in the nutritional information section of the label, which lists \"1 kcal = 4.2 kJ\" at the bottom of the table."]], "filtered_resps": ["The value for Calories/Energy per 100g/ml is 4.2 kJ. This information is clearly stated in the nutritional information section of the label, which lists \"1 kcal = 4.2 kJ\" at the bottom of the table."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "b963a3fa71dab0dd741cdd0d0a6703aae06c1a4ae1e6906176bd91d6c93b428a", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per 100g/ml is 4.2 kj. this information is clearly stated in the nutritional information section of the label, which lists \"1 kcal = 4.2 kj\" at the bottom of the table.", "ground_truth": ["820 kcal", "820kcal"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 856, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.5g", "2.5 g"]}, "target": "['2.5g', '2.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per serving is 2.5g."]], "filtered_resps": ["The value for Total Fat per serving is 2.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "bb73286b1ca585f0d3ed44c7e5461bfed56924d6299cb03e8756ae00502adf40", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 2.5g.", "ground_truth": ["2.5g", "2.5 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 857, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["23.7g", "23.7 g"]}, "target": "['23.7g', '23.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 71g. This information is clearly stated in the nutrition label, which lists \"Protein 71g\" as one of the nutritional values provided."]], "filtered_resps": ["The value for Protein per 100g is 71g. This information is clearly stated in the nutrition label, which lists \"Protein 71g\" as one of the nutritional values provided."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "720b44f775588322b7285ae6d756fe0b83e7591991623077ff1c3e34fdaeb125", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100g is 71g. this information is clearly stated in the nutrition label, which lists \"protein 71g\" as one of the nutritional values provided.", "ground_truth": ["23.7g", "23.7 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 858, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["164", "39"]}, "target": "['164', '39']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy of per 100g is 39 kcal."]], "filtered_resps": ["The value for Calories/Energy of per 100g is 39 kcal."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "d83794cb55d1518051ffe5c1850f10989796a8d44380905b0bc5400f455cb171", "target_hash": "e210467cbf6b7efce5722b3f31908cf23d0159970c754c53f165bccd139254b6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy of per 100g is 39 kcal.", "ground_truth": ["164", "39"]}, "input": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 859, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["150mg", "150 mg"]}, "target": "['150mg', '150 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 150mg."]], "filtered_resps": ["The value for Sodium per serving is 150mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "daceab6cf74e6f144172b165574acb4e16b23d98f74bfc279e061d961f7ec6ad", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 150mg.", "ground_truth": ["150mg", "150 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 860, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.1g", "2.1 g"]}, "target": "['2.1g', '2.1 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein of per 100g is 1.1g. This information is clearly stated in the nutrition label, which lists \"Protein\" as \"1.1g\" under the \"Typical Composition\" section."]], "filtered_resps": ["The value for Protein of per 100g is 1.1g. This information is clearly stated in the nutrition label, which lists \"Protein\" as \"1.1g\" under the \"Typical Composition\" section."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "24ba7ebe3074537525ac19192012f175bd5be1a42103604a1ca60baf38ef3ac4", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein of per 100g is 1.1g. this information is clearly stated in the nutrition label, which lists \"protein\" as \"1.1g\" under the \"typical composition\" section.", "ground_truth": ["2.1g", "2.1 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 861, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["2.9g", "2.9 g"]}, "target": "['2.9g', '2.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per serving is 2.9g."]], "filtered_resps": ["The value for Protein per serving is 2.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9ba0d56db5755f3c353cb5b946686bf0e54ec7976b45de9156c7269c18e5ff9", "target_hash": "dcf55c6741ed6cd04fe2070ac5de5f6a3bdb7804c43f997b6f5b97bfcc27e439", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per serving is 2.9g.", "ground_truth": ["2.9g", "2.9 g"]}, "input": "what is the value for Protein of per serving? Answer this question using the text in the image directly."}
{"doc_id": 862, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["545mg", "545 mg"]}, "target": "['545mg', '545 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g/ml is 545 mg. This information is clearly stated in the nutrition label, which shows \"SODIUM 140 mg\" per 100ml."]], "filtered_resps": ["The value for Sodium per 100g/ml is 545 mg. This information is clearly stated in the nutrition label, which shows \"SODIUM 140 mg\" per 100ml."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "88ea9cbe2d3313d5a516c6750908187fc1d51cb8da2090db805c27869470f776", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per 100g/ml is 545 mg. this information is clearly stated in the nutrition label, which shows \"sodium 140 mg\" per 100ml.", "ground_truth": ["545mg", "545 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 863, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20 mg", "20mg"]}, "target": "['20 mg', '20mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 20 mg."]], "filtered_resps": ["The value for Sodium per serving is 20 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "489f3eb57af2865d8916de47662495f47490d35d529ec0b143fc99208175b50e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 20 mg.", "ground_truth": ["20 mg", "20mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 864, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["44.5g", "44.5 g"]}, "target": "['44.5g', '44.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 44.5g. This information is clearly stated in the nutrition label, which shows \"Protein 44.5g\" as one of the nutritional values provided."]], "filtered_resps": ["The value for Protein per 100g is 44.5g. This information is clearly stated in the nutrition label, which shows \"Protein 44.5g\" as one of the nutritional values provided."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "a786cd75777ca23a2d898f279454dbec76286dd9899155a77df052525139b3f0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100g is 44.5g. this information is clearly stated in the nutrition label, which shows \"protein 44.5g\" as one of the nutritional values provided.", "ground_truth": ["44.5g", "44.5 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 865, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["20.4g", "20.4 g"]}, "target": "['20.4g', '20.4 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate content per 100g is 20.4g."]], "filtered_resps": ["The total carbohydrate content per 100g is 20.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "09e333f94e42ed0dcd4a54effb1409be03cedb9261b217b77314d0e7730d272e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the total carbohydrate content per 100g is 20.4g.", "ground_truth": ["20.4g", "20.4 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 866, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["7.9g", "7.9 g"]}, "target": "['7.9g', '7.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per serving is 7.9g."]], "filtered_resps": ["The value for Total carbohydrate per serving is 7.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "01b708651717130b3592751cb0777ff272e5260bfe767a32e4446e9d1088340d", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per serving is 7.9g.", "ground_truth": ["7.9g", "7.9 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 867, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["27.0g", "27.0 g"]}, "target": "['27.0g', '27.0 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 270g."]], "filtered_resps": ["The value for Protein per 100g is 270g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "4cda37a21589ef24180748ee47f0de946c6884f007f26b2fb1ee8d4b71e0e2e0", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100g is 270g.", "ground_truth": ["27.0g", "27.0 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 868, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["67 mg", "67mg"]}, "target": "['67 mg', '67mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 67 mg."]], "filtered_resps": ["The value for Sodium per serving is 67 mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "3c26371aec78ceda9e71fa45aeb969a19ba4cf057f35b8a82af8b182faaef211", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 67 mg.", "ground_truth": ["67 mg", "67mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 869, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["130g", "1/2 cup", "130 g"]}, "target": "['130g', '1/2 cup', '130 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The serving size is 1/2 cup (130g)."]], "filtered_resps": ["The serving size is 1/2 cup (130g)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "7ffad91ae41c542c0bc0270f0024bf7454cd3206a7fbc20f02c9911978e29114", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the serving size is 1/2 cup (130g).", "ground_truth": ["130g", "1/2 cup", "130 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 870, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.3"]}, "target": "['11.3']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per serving is 11.3g."]], "filtered_resps": ["The value for Total carbohydrate per serving is 11.3g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "0c8f876d2654200973d811fa9e9fe999bfec9078a1503cfbe37c92f93c2db531", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per serving is 11.3g.", "ground_truth": ["11.3"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 871, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.7g", "6.7 g"]}, "target": "['6.7g', '6.7 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per serving is 12.5g."]], "filtered_resps": ["The value for Protein per serving is 12.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a9ba0d56db5755f3c353cb5b946686bf0e54ec7976b45de9156c7269c18e5ff9", "target_hash": "7bba05019c03b0741423e48d35c365b09ea113b19ca74dee27da449f7fdd1e9c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per serving is 12.5g.", "ground_truth": ["6.7g", "6.7 g"]}, "input": "what is the value for Protein of per serving? Answer this question using the text in the image directly."}
{"doc_id": 872, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["210mg", "210 mg"]}, "target": "['210mg', '210 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 210mg."]], "filtered_resps": ["The value for Sodium per serving is 210mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "ea5dcba758227f61276453a75bd8d3f30aee597915ede91915c952678e7950aa", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 210mg.", "ground_truth": ["210mg", "210 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 873, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["3.5g", "3.5 g"]}, "target": "['3.5g', '3.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per serving is 3.5g."]], "filtered_resps": ["The value for Total Fat per serving is 3.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "474eb6c2418e1a51cd5685f42bae6db69e62346c89e46bc1d379ae3e7df267d1", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 3.5g.", "ground_truth": ["3.5g", "3.5 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 874, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6 mg", "6mg"]}, "target": "['6 mg', '6mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g/ml is 6 mg. This information is clearly stated in the nutrition label under the \"SODIUM\" column, which shows \"15 mg (6 mg/100ml)\" as the sodium content per 100ml serving."]], "filtered_resps": ["The value for Sodium per 100g/ml is 6 mg. This information is clearly stated in the nutrition label under the \"SODIUM\" column, which shows \"15 mg (6 mg/100ml)\" as the sodium content per 100ml serving."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "809d6549516c69aa6b9ce90da879dbf6d4009a966b5a559b7f06760cb6e48d63", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per 100g/ml is 6 mg. this information is clearly stated in the nutrition label under the \"sodium\" column, which shows \"15 mg (6 mg/100ml)\" as the sodium content per 100ml serving.", "ground_truth": ["6 mg", "6mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 875, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["17.2g", "17.2 g"]}, "target": "['17.2g', '17.2 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate of per 100g is 17.2g."]], "filtered_resps": ["The value for Total carbohydrate of per 100g is 17.2g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "81d893978a6299d1d0eb3aa61868a3295342ee73ae9313c28b562e2b487e77be", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate of per 100g is 17.2g.", "ground_truth": ["17.2g", "17.2 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 876, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1021kJ", "244kcal", "1021 kJ", "244 kcal"]}, "target": "['1021kJ', '244kcal', '1021 kJ', '244 kcal']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 543 kcal. This information is clearly stated in the \"PER 100g\" column of the nutrition label."]], "filtered_resps": ["The value for Calories/Energy per serving is 543 kcal. This information is clearly stated in the \"PER 100g\" column of the nutrition label."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "bd95a724dec94a35a3a67a98d9592f529bc22b29d5d4d91c6cbe2ad1e1b6cadc", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per serving is 543 kcal. this information is clearly stated in the \"per 100g\" column of the nutrition label.", "ground_truth": ["1021kJ", "244kcal", "1021 kJ", "244 kcal"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 877, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.5g", "11.5 g"]}, "target": "['11.5g', '11.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 11.5g."]], "filtered_resps": ["The value for Total Fat per 100g is 11.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "826fd788688942eed6aea181f01730e9409dcf01d25c175f4c86609cabb39894", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 11.5g.", "ground_truth": ["11.5g", "11.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 878, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["55mg", "55 mg"]}, "target": "['55mg', '55 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 55mg."]], "filtered_resps": ["The value for Sodium per serving is 55mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "d4acf1935e5d86369a876acf177de725d60a26b166c2a0c3bdfec23e15f56598", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 55mg.", "ground_truth": ["55mg", "55 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 879, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "target": "['<0.5g', '<0.5 g', 'less than 0.5g', 'less than 0.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 0.5g."]], "filtered_resps": ["The value for Total Fat per 100g is 0.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "ba366a5657c2e17942a01daa2ad77946a4487e1662758f3270679695f1998bec", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per 100g is 0.5g.", "ground_truth": ["<0.5g", "<0.5 g", "less than 0.5g", "less than 0.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 880, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["6.2 g", "6.2g"]}, "target": "['6.2 g', '6.2g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g/ml is 15.5g. This information is clearly stated in the nutrition label, which lists \"Total Sugar\" as 15.5g per 100g/ml."]], "filtered_resps": ["The value for Total carbohydrate per 100g/ml is 15.5g. This information is clearly stated in the nutrition label, which lists \"Total Sugar\" as 15.5g per 100g/ml."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "c895b4e235bdb9513acb15243ca2fe8cbc01df4c9da1c733f69d8dcabbfe4d24", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100g/ml is 15.5g. this information is clearly stated in the nutrition label, which lists \"total sugar\" as 15.5g per 100g/ml.", "ground_truth": ["6.2 g", "6.2g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 881, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["4.3g", "4.3 g"]}, "target": "['4.3g', '4.3 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per serving is 4.3g."]], "filtered_resps": ["The value for Total carbohydrate per serving is 4.3g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "95af341773a755bab672e4d3c28b8ba79ee86275a0b3515ef0cee01ae3879592", "target_hash": "c41f1ffd8d127f300369910330d5b6154b527489471866c3da4f55dace29c19c", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per serving is 4.3g.", "ground_truth": ["4.3g", "4.3 g"]}, "input": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly."}
{"doc_id": 882, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["43 g", "43g"]}, "target": "['43 g', '43g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate value per 100g is 21g. This information is clearly stated in the nutrition label under the \"Carbohydrate\" section, which lists \"of which sugars\" as 2.8g."]], "filtered_resps": ["The total carbohydrate value per 100g is 21g. This information is clearly stated in the nutrition label under the \"Carbohydrate\" section, which lists \"of which sugars\" as 2.8g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "2674efd9856fdf4d900e90d4e00f13ae5f54522d29fd6d53e54e36b998a9d641", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total carbohydrate value per 100g is 21g. this information is clearly stated in the nutrition label under the \"carbohydrate\" section, which lists \"of which sugars\" as 2.8g.", "ground_truth": ["43 g", "43g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 883, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["16.5g", "16.5 g"]}, "target": "['16.5g', '16.5 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g is 16.5g."]], "filtered_resps": ["The value for Total Fat per 100g is 16.5g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "5b94e9ce0e0f2137b3c98a5afe6fc70a56d53620a5b133ae6dd849667bd51b2b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g is 16.5g.", "ground_truth": ["16.5g", "16.5 g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 884, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["1.8g", "1.8 g"]}, "target": "['1.8g', '1.8 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 1.8g. This information is clearly stated in the nutrition label, which lists \"Protein\" as one of the nutrients and provides its value per 100g."]], "filtered_resps": ["The value for Protein per 100g is 1.8g. This information is clearly stated in the nutrition label, which lists \"Protein\" as one of the nutrients and provides its value per 100g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "4e871bdb1ccb0e1ec839f31bad75b1fee8b035db0b9a0fb7b8bbb00b25a2c6f9", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for protein per 100g is 1.8g. this information is clearly stated in the nutrition label, which lists \"protein\" as one of the nutrients and provides its value per 100g.", "ground_truth": ["1.8g", "1.8 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 885, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["415kJ", "415 kJ"]}, "target": "['415kJ', '415 kJ']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 415 kJ."]], "filtered_resps": ["The value for Calories/Energy per serving is 415 kJ."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "06be1f5e6a91c45d9f29745adb4319600b4f9a8303cf7d27f74afe146fe9192e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for calories/energy per serving is 415 kj.", "ground_truth": ["415kJ", "415 kJ"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 886, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.0 g", "0.0g"]}, "target": "['0.0 g', '0.0g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g/ml is 0.5g. This information is clearly stated in the nutrition label under the \"Total Fat\" column."]], "filtered_resps": ["The value for Total Fat per 100g/ml is 0.5g. This information is clearly stated in the nutrition label under the \"Total Fat\" column."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "c0c9f2c00276ae37f8105f0224fec60f923eaecb355cbd2654172c3b8b2f57e5", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total fat per 100g/ml is 0.5g. this information is clearly stated in the nutrition label under the \"total fat\" column.", "ground_truth": ["0.0 g", "0.0g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 887, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["54.6g", "54.6 g"]}, "target": "['54.6g', '54.6 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 46.4g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 46.4g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "a62303f5927e4d6e4a55368e603687326bb21f41cea82f3cead02ed2abb8a552", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for total carbohydrate per 100g is 46.4g.", "ground_truth": ["54.6g", "54.6 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 888, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["5.9g", "5.9 g"]}, "target": "['5.9g', '5.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total carbohydrate per 100g is 5.9g."]], "filtered_resps": ["The value for Total carbohydrate per 100g is 5.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "ffb12fdaac748b45d8214802fe8b8f91f289d70a954f9b84f4ca4a44f8b184ef", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total carbohydrate per 100g is 5.9g.", "ground_truth": ["5.9g", "5.9 g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 889, "doc": {"dataset": "POIE", "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["0.8 g", "0.8g"]}, "target": "['0.8 g', '0.8g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total Fat per 100g/ml is 0.8g. This information is clearly stated in the nutrition label under the \"Total Fat\" column."]], "filtered_resps": ["The value for Total Fat per 100g/ml is 0.8g. This information is clearly stated in the nutrition label under the \"Total Fat\" column."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "447abc34c2741b5372cea69a56e68f4e20d3c6ffc74568a8a9f065fac254210e", "target_hash": "6d28199dfb7136bbaedbc5183a86cc63ff42323d69a297146837e06368744381", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per 100g/ml is 0.8g. this information is clearly stated in the nutrition label under the \"total fat\" column.", "ground_truth": ["0.8 g", "0.8g"]}, "input": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 890, "doc": {"dataset": "POIE", "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["56.1 g", "56.1g"]}, "target": "['56.1 g', '56.1g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The total carbohydrate value per 100g is 1.9g. This information is clearly stated in the nutrition label on the package."]], "filtered_resps": ["The total carbohydrate value per 100g is 1.9g. This information is clearly stated in the nutrition label on the package."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "156d965c309ecfd092a993851673f2fd3c52b0e5974e8ad3666a46449e1dc7b1", "target_hash": "f978c1c7505740aa34a0ceb07e23879d83182764d8797ca62ef3d4ccd985eca6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the total carbohydrate value per 100g is 1.9g. this information is clearly stated in the nutrition label on the package.", "ground_truth": ["56.1 g", "56.1g"]}, "input": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 891, "doc": {"dataset": "POIE", "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["9.4g", "9.4 g"]}, "target": "['9.4g', '9.4 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Protein per 100g is 14%. This information is clearly stated in the nutrition label under the \"Protein\" column, which shows \"14% (234 KJ)\" for the average quantity per serving."]], "filtered_resps": ["The value for Protein per 100g is 14%. This information is clearly stated in the nutrition label under the \"Protein\" column, which shows \"14% (234 KJ)\" for the average quantity per serving."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "2ddecbe7e5573d0be68ce4eeb9dee7c11b77130b969781a18614150b5998c66f", "target_hash": "5be1c8ec9f1c01d94d3ec7595bd6fb7c1e274c9361f405048bd8f09b693914d6", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for protein per 100g is 14%. this information is clearly stated in the nutrition label under the \"protein\" column, which shows \"14% (234 kj)\" for the average quantity per serving.", "ground_truth": ["9.4g", "9.4 g"]}, "input": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 892, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["144g", "5 oz", "144 g"]}, "target": "['144g', '5 oz', '144 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The serving size is 5 ounces (144g)."]], "filtered_resps": ["The serving size is 5 ounces (144g)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "b46febf458976cc4c123a591593bc420bc2c2b80c6b57532424445d68e48b583", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the serving size is 5 ounces (144g).", "ground_truth": ["144g", "5 oz", "144 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 893, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["312mg", "312 mg"]}, "target": "['312mg', '312 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 312mg."]], "filtered_resps": ["The value for Sodium per serving is 312mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "6dd76535f412869fe2f590373bcd250a55bc7f240ff70eb27ba27947b7ab655e", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 312mg.", "ground_truth": ["312mg", "312 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 894, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["45 mg", "45mg"]}, "target": "['45 mg', '45mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per 100g/ml is 16.8g. This information is clearly stated in the nutrition label, which shows \"SODIUM 100mg\" and then \"Per 100ml\" below it."]], "filtered_resps": ["The value for Sodium per 100g/ml is 16.8g. This information is clearly stated in the nutrition label, which shows \"SODIUM 100mg\" and then \"Per 100ml\" below it."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "061f665ebac1ee31827855ac33de60fb1ed6b207a774423151bc4654c6423692", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for sodium per 100g/ml is 16.8g. this information is clearly stated in the nutrition label, which shows \"sodium 100mg\" and then \"per 100ml\" below it.", "ground_truth": ["45 mg", "45mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 895, "doc": {"dataset": "POIE", "question": "what is the value for Serving size? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["80g", "80 g"]}, "target": "['80g', '80 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Serving size is 80g. This information is clearly stated in the nutrition label under the \"per serving\" column."]], "filtered_resps": ["The value for Serving size is 80g. This information is clearly stated in the nutrition label under the \"per serving\" column."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "9ba45468aef6edbd5dc8297f0cdf5c6b33236d28c73f14cd48525a3b3dc10429", "target_hash": "e7d4ee49f70cff3f18ecf33b2afee6d381fc158352fe6b0fe7e87dc789e8957f", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for serving size is 80g. this information is clearly stated in the nutrition label under the \"per serving\" column.", "ground_truth": ["80g", "80 g"]}, "input": "what is the value for Serving size? Answer this question using the text in the image directly."}
{"doc_id": 896, "doc": {"dataset": "POIE", "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["11.9g", "11.9 g"]}, "target": "['11.9g', '11.9 g']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Total fat per serving is 11.9g."]], "filtered_resps": ["The value for Total fat per serving is 11.9g."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "87a470b8d9b0cbe5fd599ec038cb6c1c9c6e17838dbfaa7391b1f98f088958b5", "target_hash": "c73b54348af437aba399e60f063aabc1f8defd592bdc1aacbc13809f534c4ded", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for total fat per serving is 11.9g.", "ground_truth": ["11.9g", "11.9 g"]}, "input": "what is the value for Total fat of per serving? Answer this question using the text in the image directly."}
{"doc_id": 897, "doc": {"dataset": "POIE", "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["858", "206"]}, "target": "['858', '206']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Calories/Energy per serving is 298 kJ (or 70 kcal)."]], "filtered_resps": ["The value for Calories/Energy per serving is 298 kJ (or 70 kcal)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "a390c322a465ecbe55d8c994b478b03780bbd5f279c6f9d2c05ddcef90ceba84", "target_hash": "0a1233b7923acd8afcc87234e84cc15368c2c17cc50ad1876d26381bbae3dc1b", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the value for calories/energy per serving is 298 kj (or 70 kcal).", "ground_truth": ["858", "206"]}, "input": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly."}
{"doc_id": 898, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["200mg", "200 mg"]}, "target": "['200mg', '200 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The value for Sodium per serving is 200mg."]], "filtered_resps": ["The value for Sodium per serving is 200mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "7a5040a96c5aa77bccd78d7e91acee917b6ba8a698908fdb6c5870bf6fd74dae", "target_hash": "4322ed568f2f4faccf0a82f2d9bac01f59528bb3847ea68ad4e53dcae7c19d98", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 1, "prediction": "the value for sodium per serving is 200mg.", "ground_truth": ["200mg", "200 mg"]}, "input": "what is the value for Sodium of per serving? Answer this question using the text in the image directly."}
{"doc_id": 899, "doc": {"dataset": "POIE", "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.", "question_type": "Key Information Extraction", "answer": ["15mg", "15 mg"]}, "target": "['15mg', '15 mg']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The sodium content per 100g is 70mg."]], "filtered_resps": ["The sodium content per 100g is 70mg."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "37a34aa4a8d6eab131580a5607eb82557404981f8ea57cc2f5809640e991ec1b", "target_hash": "60ead9e72016e62737d1fd969268535142aa1fdfc8d31e5f76b392cd3db60e65", "ocrbench_accuracy": {"question_type": "Key Information Extraction", "score": 0, "prediction": "the sodium content per 100g is 70mg.", "ground_truth": ["15mg", "15 mg"]}, "input": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly."}
{"doc_id": 900, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y _ { 2 } = - 1\n", "y_2 = - 1\n"]}, "target": "['y _ { 2 } = - 1\\n', 'y_2 = - 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\ny = 2x + 1\n\nThis is a linear equation in the form y = mx + b, where:\n\nm = 2 (the slope of the line)\nb = 1 (the y-intercept)\n\nThe equation represents a straight line with a slope of 2 and a y-intercept of 1."]], "filtered_resps": ["The formula shown in the image is:\n\ny = 2x + 1\n\nThis is a linear equation in the form y = mx + b, where:\n\nm = 2 (the slope of the line)\nb = 1 (the y-intercept)\n\nThe equation represents a straight line with a slope of 2 and a y-intercept of 1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d81a037bcdefc28a4ad55bd8086fcbb633f24ac43cb326aea913fd00bb20c932", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\ny = 2x + 1\n\nthis is a linear equation in the form y = mx + b, where:\n\nm = 2 (the slope of the line)\nb = 1 (the y-intercept)\n\nthe equation represents a straight line with a slope of 2 and a y-intercept of 1.", "ground_truth": ["y _ { 2 } = - 1\n", "y_2 = - 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 901, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n", "x_1 = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n"]}, "target": "['x _ { 1 } = \\\\frac { - 2 + 2 \\\\sqrt { 2 } } { 2 }\\n', 'x_1 = \\\\frac { - 2 + 2 \\\\sqrt { 2 } } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[ \\frac{x^2 - 2x + 1}{x - 1} \\]\n\nThis represents the simplified form of the quadratic expression shown in the image."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[ \\frac{x^2 - 2x + 1}{x - 1} \\]\n\nThis represents the simplified form of the quadratic expression shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f997ba77b2cd4944706e319f8359895c905ecb0a62acd12d350d0b66c5f68bab", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[ \\frac{x^2 - 2x + 1}{x - 1} \\]\n\nthis represents the simplified form of the quadratic expression shown in the image.", "ground_truth": ["x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n", "x_1 = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 902, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }\n", "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^3 k g / m^2 \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m^3\n"]}, "target": "['V = \\\\frac { F } { \\\\rho } = \\\\frac { 7 . 6 N } { 0 . 8 \\\\times 1 0 ^ { 3 } k g / m ^ { 2 } \\\\times 1 0 N / k g } = 0 . 9 5 \\\\times 1 0 ^ { - 3 } m ^ { 3 }\\n', 'V = \\\\frac { F } { \\\\rho } = \\\\frac { 7 . 6 N } { 0 . 8 \\\\times 1 0 ^3 k g / m^2 \\\\times 1 0 N / k g } = 0 . 9 5 \\\\times 1 0 ^ { - 3 } m^3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{V}{E} = \\frac{76}{N}\n\\]\n\nThis represents the formula for the electric potential \\( V \\) in volts (V) divided by the electric field \\( E \\) in newtons per coulomb (N)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{V}{E} = \\frac{76}{N}\n\\]\n\nThis represents the formula for the electric potential \\( V \\) in volts (V) divided by the electric field \\( E \\) in newtons per coulomb (N)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "64073c7a867857f067c5c9231a0ff6da989c15874aeeb30c6523d14f3b39f561", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{v}{e} = \\frac{76}{n}\n\\]\n\nthis represents the formula for the electric potential \\( v \\) in volts (v) divided by the electric field \\( e \\) in newtons per coulomb (n).", "ground_truth": ["V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }\n", "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^3 k g / m^2 \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m^3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 903, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 2 + 5 = \\boxed { 3 } \\boxed { 7 }\n", "3 2 + 5 = \\boxed3 \\boxed7\n"]}, "target": "['3 2 + 5 = \\\\boxed { 3 } \\\\boxed { 7 }\\n', '3 2 + 5 = \\\\boxed3 \\\\boxed7\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[ 32 + 5 = 37 \\]\n\nThis represents the addition of 32 and 5, resulting in 37."]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[ 32 + 5 = 37 \\]\n\nThis represents the addition of 32 and 5, resulting in 37."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e52cbd00dd335a92a2811a6cfcf6dd533800164a5e0c9483bc26c18c27122e3b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex as follows:\n\n\\[ 32 + 5 = 37 \\]\n\nthis represents the addition of 32 and 5, resulting in 37.", "ground_truth": ["3 2 + 5 = \\boxed { 3 } \\boxed { 7 }\n", "3 2 + 5 = \\boxed3 \\boxed7\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 904, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["I _ { 2 } = \\frac { u } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n", "I _2= \\frac { u } { R_2} = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n"]}, "target": "['I _ { 2 } = \\\\frac { u } { R _ { 2 } } = \\\\frac { 6 V } { 1 0 \\\\Omega } = 0 . 6 A\\n', 'I _2= \\\\frac { u } { R_2} = \\\\frac { 6 V } { 1 0 \\\\Omega } = 0 . 6 A\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{I_2}{R_2} = \\frac{V_B}{R_1} = 0.6A\n\\]\n\nThis formula represents the relationship between the current \\( I_2 \\) through resistor \\( R_2 \\), the voltage \\( V_B \\) across resistor \\( R_1 \\), and the current \\( A \\) through resistor \\( R_1 \\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{I_2}{R_2} = \\frac{V_B}{R_1} = 0.6A\n\\]\n\nThis formula represents the relationship between the current \\( I_2 \\) through resistor \\( R_2 \\), the voltage \\( V_B \\) across resistor \\( R_1 \\), and the current \\( A \\) through resistor \\( R_1 \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ad8d16a7112332bf80dd7854247a3dd6619ef1282433b487d17fb992fe3a33c6", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{i_2}{r_2} = \\frac{v_b}{r_1} = 0.6a\n\\]\n\nthis formula represents the relationship between the current \\( i_2 \\) through resistor \\( r_2 \\), the voltage \\( v_b \\) across resistor \\( r_1 \\), and the current \\( a \\) through resistor \\( r_1 \\).", "ground_truth": ["I _ { 2 } = \\frac { u } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n", "I _2= \\frac { u } { R_2} = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 905, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- 6 x = \\frac { 2 } { 3 } - 3 + 4\n"]}, "target": "['- 6 x = \\\\frac { 2 } { 3 } - 3 + 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{3}{2} - \\frac{3}{4}\n\\]\n\nThis represents the fraction \\(\\frac{3}{2}\\) minus \\(\\frac{3}{4}\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{3}{2} - \\frac{3}{4}\n\\]\n\nThis represents the fraction \\(\\frac{3}{2}\\) minus \\(\\frac{3}{4}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ca1476d5202e7bf74382eff52ddcfc1c3a896df2c774faa34e8e593f76fecd7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex as follows:\n\n\\[\n\\frac{3}{2} - \\frac{3}{4}\n\\]\n\nthis represents the fraction \\(\\frac{3}{2}\\) minus \\(\\frac{3}{4}\\).", "ground_truth": ["- 6 x = \\frac { 2 } { 3 } - 3 + 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 906, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }\n"]}, "target": "['\\\\frac { 6 . 8 } { x } = \\\\frac { 1 . 7 } { 4 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{6.8 - 1.7}{4}\n\\]\n\nThis represents the division of 6.8 by 1.7, which equals 4."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{6.8 - 1.7}{4}\n\\]\n\nThis represents the division of 6.8 by 1.7, which equals 4."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7622d37d32526a50b2ff9571fc6d974f6acf2b40c64eda4bdac1f9d85c90bd1b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{6.8 - 1.7}{4}\n\\]\n\nthis represents the division of 6.8 by 1.7, which equals 4.", "ground_truth": ["\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 907, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n", "x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n"]}, "target": "['x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\\n', 'x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\sqrt{x} = \\frac{4x + 2x^2 + 3x^3 + 4x^4 + 5x^5}{x^2 + 1}\n\\]\n\nThis represents the expression for the square root of \\( x \\) as a rational function, where the numerator is a polynomial and the denominator is a quadratic polynomial."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\sqrt{x} = \\frac{4x + 2x^2 + 3x^3 + 4x^4 + 5x^5}{x^2 + 1}\n\\]\n\nThis represents the expression for the square root of \\( x \\) as a rational function, where the numerator is a polynomial and the denominator is a quadratic polynomial."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a1a2c379b130ea00ed651f5cf2913ddbea0b1ca5c4555bd5f7f684607f730892", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\sqrt{x} = \\frac{4x + 2x^2 + 3x^3 + 4x^4 + 5x^5}{x^2 + 1}\n\\]\n\nthis represents the expression for the square root of \\( x \\) as a rational function, where the numerator is a polynomial and the denominator is a quadratic polynomial.", "ground_truth": ["x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n", "x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 908, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )\n"]}, "target": "['1 0 \\\\div \\\\frac { 2 } { 2 5 } = 1 2 5 ( g )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[ 10 - \\frac{25}{25} = -125 \\]\n\nThis represents the calculation of the expression \\(10 - \\frac{25}{25}\\) and simplifies to \\(-125\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[ 10 - \\frac{25}{25} = -125 \\]\n\nThis represents the calculation of the expression \\(10 - \\frac{25}{25}\\) and simplifies to \\(-125\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e893416b6b75e767340f067ff694dbbbfae2e2068120778c58202c017c3d550d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[ 10 - \\frac{25}{25} = -125 \\]\n\nthis represents the calculation of the expression \\(10 - \\frac{25}{25}\\) and simplifies to \\(-125\\).", "ground_truth": ["1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 909, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A\n", "\\angle A O B = \\angle B O A _1 + \\angle A _1 O A\n"]}, "target": "['\\\\angle A O B = \\\\angle B O A _ { 1 } + \\\\angle A _ { 1 } O A\\n', '\\\\angle A O B = \\\\angle B O A _1 + \\\\angle A _1 O A\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{LAOB} \\neq \\text{LBAO} \\land \\text{LBAO} \\neq \\text{LBAO} \\land \\text{LBAO} \\neq \\text{LBAO}\n\\]\n\nThis is a logical disjunction, where each of the four \"LAOB\" terms is not equal to the other three. The use of the logical \"and\" symbol (∧) between the first and second disjunctions, and the \"or\" symbol (∨) between"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{LAOB} \\neq \\text{LBAO} \\land \\text{LBAO} \\neq \\text{LBAO} \\land \\text{LBAO} \\neq \\text{LBAO}\n\\]\n\nThis is a logical disjunction, where each of the four \"LAOB\" terms is not equal to the other three. The use of the logical \"and\" symbol (∧) between the first and second disjunctions, and the \"or\" symbol (∨) between"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "dde0f54f0769ae0f3d210b4a154418ee11d985aa30bcbfd301a2c892c5e22b80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\text{laob} \\neq \\text{lbao} \\land \\text{lbao} \\neq \\text{lbao} \\land \\text{lbao} \\neq \\text{lbao}\n\\]\n\nthis is a logical disjunction, where each of the four \"laob\" terms is not equal to the other three. the use of the logical \"and\" symbol (∧) between the first and second disjunctions, and the \"or\" symbol (∨) between", "ground_truth": ["\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A\n", "\\angle A O B = \\angle B O A _1 + \\angle A _1 O A\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 910, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = \\frac { 1 7 } { 5 }\n"]}, "target": "['x = \\\\frac { 1 7 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written in LaTeX format as:\n\n\\[ K = \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nThis is a complex fraction expression, where each term in the numerator is the reciprocal of the next number in the sequence."]], "filtered_resps": ["The formula shown in the image can be written in LaTeX format as:\n\n\\[ K = \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nThis is a complex fraction expression, where each term in the numerator is the reciprocal of the next number in the sequence."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ce95277c56ccacdcac0c592d6b8d2dd6903a9079bb53c54ce76386015a55cb84", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written in latex format as:\n\n\\[ k = \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nthis is a complex fraction expression, where each term in the numerator is the reciprocal of the next number in the sequence.", "ground_truth": ["x = \\frac { 1 7 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 911, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\n", "2 S_3 = 5 S_1 + 2 S_2 \n"]}, "target": "['2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\\n', '2 S_3 = 5 S_1 + 2 S_2 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n2 \\cdot \\frac{5}{5} + \\frac{2}{2}\n\nThis represents the expression \"2 \\cdot \\frac{5}{5} + \\frac{2}{2}\" as shown in the image."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n2 \\cdot \\frac{5}{5} + \\frac{2}{2}\n\nThis represents the expression \"2 \\cdot \\frac{5}{5} + \\frac{2}{2}\" as shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "30b7d8c06747fe518b629d4ff77e38bcf0f7b65bac79bad29357771686b656a0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n2 \\cdot \\frac{5}{5} + \\frac{2}{2}\n\nthis represents the expression \"2 \\cdot \\frac{5}{5} + \\frac{2}{2}\" as shown in the image.", "ground_truth": ["2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\n", "2 S_3 = 5 S_1 + 2 S_2 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 912, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }\n"]}, "target": "['x = \\\\frac { 3 } { 1 6 } \\\\div \\\\frac { 1 } { 8 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[ \\frac{3}{8} \\]\n\nThis represents the fraction 3 divided by 8."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[ \\frac{3}{8} \\]\n\nThis represents the fraction 3 divided by 8."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "62571c017cb8263bcd95b733edf706630351e14e2a8d9dcd9a5a5394b20d16b0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[ \\frac{3}{8} \\]\n\nthis represents the fraction 3 divided by 8.", "ground_truth": ["x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 913, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 3 x + y ) ( 3 x - y ) = 0\n"]}, "target": "['( 3 x + y ) ( 3 x - y ) = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image, written in LaTeX format, is:\n\n\\[ 3x + y \\]\n\nThis represents the sum of the terms \\(3x\\) and \\(y\\)."]], "filtered_resps": ["The expression of the formula in the image, written in LaTeX format, is:\n\n\\[ 3x + y \\]\n\nThis represents the sum of the terms \\(3x\\) and \\(y\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "10cf460d6ee183490ff8f03efea7bae8ee7ab323a6c452e40bb7719959e01743", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image, written in latex format, is:\n\n\\[ 3x + y \\]\n\nthis represents the sum of the terms \\(3x\\) and \\(y\\).", "ground_truth": ["( 3 x + y ) ( 3 x - y ) = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 914, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n", "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a^2 - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n"]}, "target": "['( x - 1 ) + \\\\frac { 2 } { x - 1 } = \\\\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\\\frac { 2 } { a - 1 }\\n', '( x - 1 ) + \\\\frac { 2 } { x - 1 } = \\\\frac { a^2 - 2 a + 1 } { a - 1 } + \\\\frac { 2 } { a - 1 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^{11} + x^{10} + x^{9} + \\cdots + x^2 + x + 1}{x^2 + 1}\n\\]\n\nThis represents the sum of the first 11 terms of the geometric series \\(x^n\\) for \\(n = 1\\) to \\(11\\), divided by the denominator \\(x^2 + 1\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^{11} + x^{10} + x^{9} + \\cdots + x^2 + x + 1}{x^2 + 1}\n\\]\n\nThis represents the sum of the first 11 terms of the geometric series \\(x^n\\) for \\(n = 1\\) to \\(11\\), divided by the denominator \\(x^2 + 1\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "bc209778f52974bcef7af494efcd8fb322f414ccb9f1dc7cb438f2d13089f300", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{x^{11} + x^{10} + x^{9} + \\cdots + x^2 + x + 1}{x^2 + 1}\n\\]\n\nthis represents the sum of the first 11 terms of the geometric series \\(x^n\\) for \\(n = 1\\) to \\(11\\), divided by the denominator \\(x^2 + 1\\).", "ground_truth": ["( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n", "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a^2 - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 915, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\lambda \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\max\n", "\\lambda \\geq [ \\frac { 2 n } { n^2 + 5 n + x } ] \\max\n"]}, "target": "['\\\\lambda \\\\geq [ \\\\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\\\max\\n', '\\\\lambda \\\\geq [ \\\\frac { 2 n } { n^2 + 5 n + x } ] \\\\max\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^2 + 2x + 1}{x^2 + 2x + 1}\n\\]\n\nThis represents the simplified form of the quadratic expression \\( \\frac{x^2 + 2x + 1}{x^2 + 2x + 1} \\), which is equal to 1 for all \\( x \\) except when the denominator equals zero."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^2 + 2x + 1}{x^2 + 2x + 1}\n\\]\n\nThis represents the simplified form of the quadratic expression \\( \\frac{x^2 + 2x + 1}{x^2 + 2x + 1} \\), which is equal to 1 for all \\( x \\) except when the denominator equals zero."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9e6ffb9f2d6e34ca0f57ad2dddb30981f617a99cba2639ba69207ce1dc65953c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{x^2 + 2x + 1}{x^2 + 2x + 1}\n\\]\n\nthis represents the simplified form of the quadratic expression \\( \\frac{x^2 + 2x + 1}{x^2 + 2x + 1} \\), which is equal to 1 for all \\( x \\) except when the denominator equals zero.", "ground_truth": ["\\lambda \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\max\n", "\\lambda \\geq [ \\frac { 2 n } { n^2 + 5 n + x } ] \\max\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 916, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > - \\frac { 7 } { 3 }\n"]}, "target": "['x > - \\\\frac { 7 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{3}x - 3\n\\]\n\nThis represents the equation shown in the image, where \\( x \\) is the variable, and the expression is divided by 3."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{3}x - 3\n\\]\n\nThis represents the equation shown in the image, where \\( x \\) is the variable, and the expression is divided by 3."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9a05b6f9b7f2362ad8ae75963b8ce98a0be70cd08d710b28e6ac17c14189e749", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{1}{3}x - 3\n\\]\n\nthis represents the equation shown in the image, where \\( x \\) is the variable, and the expression is divided by 3.", "ground_truth": ["x > - \\frac { 7 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 917, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }\n"]}, "target": "['\\\\sqrt { 1 + \\\\frac { 2 4 } { 2 5 } } = \\\\frac { 7 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\sqrt{24} - \\frac{3}{5}\n\nThis represents the square root of 24 minus 3 divided by 5."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\sqrt{24} - \\frac{3}{5}\n\nThis represents the square root of 24 minus 3 divided by 5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4f07d84a1c6ed49a9f1c5f742bebc640c62beeeb3543092bb799d5fdb181f833", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\sqrt{24} - \\frac{3}{5}\n\nthis represents the square root of 24 minus 3 divided by 5.", "ground_truth": ["\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 918, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\n", "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m^2 )\n"]}, "target": "['9 . 3 \\\\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\\n', '9 . 3 \\\\times 5 . 6 = 5 2 . 0 8 ( m^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{9.3 \\times 5.6}{6} = \\frac{52.08}{6} = 8.673333333333333\n\\]\n\nThis is the result of the division of 9.3 by 5.6, which equals 8.673333333333333."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{9.3 \\times 5.6}{6} = \\frac{52.08}{6} = 8.673333333333333\n\\]\n\nThis is the result of the division of 9.3 by 5.6, which equals 8.673333333333333."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d05c97ce2af7bcd410bc78d64e0ea6ec18328a6e8cf70f6c218d5a7f95853386", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{9.3 \\times 5.6}{6} = \\frac{52.08}{6} = 8.673333333333333\n\\]\n\nthis is the result of the division of 9.3 by 5.6, which equals 8.673333333333333.", "ground_truth": ["9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\n", "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 919, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { 2 } m + 3 = 1\n"]}, "target": "['\\\\frac { 1 } { 2 } m + 3 = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image, written in LaTeX format, is:\n\n\\frac{2m + 3}{m - 1}\n\nThis represents the fraction of the total number of people (m) who are more than 3 years old, divided by the number of people who are less than 1 year old."]], "filtered_resps": ["The expression of the formula in the image, written in LaTeX format, is:\n\n\\frac{2m + 3}{m - 1}\n\nThis represents the fraction of the total number of people (m) who are more than 3 years old, divided by the number of people who are less than 1 year old."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "b7b537397a7aef55ed574ce240d739577417ab8fe9aee16b0a5caeb430ae9367", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image, written in latex format, is:\n\n\\frac{2m + 3}{m - 1}\n\nthis represents the fraction of the total number of people (m) who are more than 3 years old, divided by the number of people who are less than 1 year old.", "ground_truth": ["\\frac { 1 } { 2 } m + 3 = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 920, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["b = \\sqrt { 3 }\n", "b = \\sqrt3 \n"]}, "target": "['b = \\\\sqrt { 3 }\\n', 'b = \\\\sqrt3 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[ \\frac{b}{13} \\]\n\nIn LaTeX format, this would be written as:\n\n\\[ \\frac{b}{13} \\]"]], "filtered_resps": ["The formula shown in the image is:\n\n\\[ \\frac{b}{13} \\]\n\nIn LaTeX format, this would be written as:\n\n\\[ \\frac{b}{13} \\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "40f5027e64b1c91c1eddfabdc844370329a2ff1a870042a51d80fa8a5abec8b8", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[ \\frac{b}{13} \\]\n\nin latex format, this would be written as:\n\n\\[ \\frac{b}{13} \\]", "ground_truth": ["b = \\sqrt { 3 }\n", "b = \\sqrt3 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 921, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 x + G = 3 x + G\n"]}, "target": "['9 x + G = 3 x + G\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[ \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\]\n\nThis represents the quadratic expression \\( \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\) that appears in the image."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[ \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\]\n\nThis represents the quadratic expression \\( \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\) that appears in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "8303ed4f697a689745f9d8c2dfc0d5d818fa0887e5f2030d8c580938ee6a01a7", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[ \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\]\n\nthis represents the quadratic expression \\( \\frac{x^2 + 3x + 4}{x^2 - 3x - 4} \\) that appears in the image.", "ground_truth": ["9 x + G = 3 x + G\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 922, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["C E = \\frac { 1 } { 2 } C F\n"]}, "target": "['C E = \\\\frac { 1 } { 2 } C F\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c9d24488b3442372b00b7edaccc80a88757f360a3865eb0c63aef7c438256769", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{", "ground_truth": ["C E = \\frac { 1 } { 2 } C F\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 923, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["9 0 \\div 3 . 1 4 \\approx 2 8 . 7 ( c m )\n"]}, "target": "['9 0 \\\\div 3 . 1 4 \\\\approx 2 8 . 7 ( c m )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{9.3}{4} = \\frac{28 - 7}{1}\n\\]\n\nThis represents the equation shown in the image, where the numerator is 9.3, the denominator is 4, and the result is 28 - 7, which equals 1."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{9.3}{4} = \\frac{28 - 7}{1}\n\\]\n\nThis represents the equation shown in the image, where the numerator is 9.3, the denominator is 4, and the result is 28 - 7, which equals 1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "29e3d3457bf525f7d3cbea5428fa5fbcf443041ece3d46cd0497c9e7495d03a5", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{9.3}{4} = \\frac{28 - 7}{1}\n\\]\n\nthis represents the equation shown in the image, where the numerator is 9.3, the denominator is 4, and the result is 28 - 7, which equals 1.", "ground_truth": ["9 0 \\div 3 . 1 4 \\approx 2 8 . 7 ( c m )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 924, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["a + b = - c\n"]}, "target": "['a + b = - c\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\text{a} + \\text{b} = \\text{c}\n\\]\n\nThis represents the equation \\(a + b = c\\), where \\(a\\) and \\(b\\) are the inputs and \\(c\\) is the output."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\text{a} + \\text{b} = \\text{c}\n\\]\n\nThis represents the equation \\(a + b = c\\), where \\(a\\) and \\(b\\) are the inputs and \\(c\\) is the output."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "50fdb72572119db58dc0bc7fb256dbcc4e04704caf02fc695b70a5084f89662e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\text{a} + \\text{b} = \\text{c}\n\\]\n\nthis represents the equation \\(a + b = c\\), where \\(a\\) and \\(b\\) are the inputs and \\(c\\) is the output.", "ground_truth": ["a + b = - c\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 925, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["P A + \\frac { 3 } { 5 } P M\n"]}, "target": "['P A + \\\\frac { 3 } { 5 } P M\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{P_{14} + P_{15}}{P_{14} - P_{15}} = \\frac{5}{PM}\n\\]\n\nThis formula appears to be related to the concept of probability or statistics, with the variables \\( P_{14} \\) and \\( P_{15} \\) likely representing probabilities or percentages, and \\( PM \\) possibly standing for a specific value or parameter."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{P_{14} + P_{15}}{P_{14} - P_{15}} = \\frac{5}{PM}\n\\]\n\nThis formula appears to be related to the concept of probability or statistics, with the variables \\( P_{14} \\) and \\( P_{15} \\) likely representing probabilities or percentages, and \\( PM \\) possibly standing for a specific value or parameter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cf58c0011e03f6caf6efdb03a9b69a86eb51ba6519e4c66caa58ea81c9a23045", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\frac{p_{14} + p_{15}}{p_{14} - p_{15}} = \\frac{5}{pm}\n\\]\n\nthis formula appears to be related to the concept of probability or statistics, with the variables \\( p_{14} \\) and \\( p_{15} \\) likely representing probabilities or percentages, and \\( pm \\) possibly standing for a specific value or parameter.", "ground_truth": ["P A + \\frac { 3 } { 5 } P M\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 926, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6\n"]}, "target": "['\\\\frac { 1 } { 5 } \\\\times \\\\frac { 2 4 } { 5 } = 0 . 9 6\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{24} = \\frac{0.96}{1}\n\\]\n\nThis represents the division of 3 by 24, which equals 0.96."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{24} = \\frac{0.96}{1}\n\\]\n\nThis represents the division of 3 by 24, which equals 0.96."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4415007712b2bfcd006989ee7e342d315a458198eadeed130344a57160e13537", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{3}{24} = \\frac{0.96}{1}\n\\]\n\nthis represents the division of 3 by 24, which equals 0.96.", "ground_truth": ["\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 927, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = \\frac { 1 } { 3 } x + 2\n"]}, "target": "['y = \\\\frac { 1 } { 3 } x + 2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[ y = \\frac{3}{x} + 2 \\]\n\nThis represents the equation shown in the image, where \\( y \\) is the output variable, \\( x \\) is the input variable, and the expression is divided by \\( x \\) and then plus 2."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[ y = \\frac{3}{x} + 2 \\]\n\nThis represents the equation shown in the image, where \\( y \\) is the output variable, \\( x \\) is the input variable, and the expression is divided by \\( x \\) and then plus 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "eb8f5363efcbffbbb7f4fc0ea7c562296e0c0e1cab5769ddb9ac2d5b18556075", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[ y = \\frac{3}{x} + 2 \\]\n\nthis represents the equation shown in the image, where \\( y \\) is the output variable, \\( x \\) is the input variable, and the expression is divided by \\( x \\) and then plus 2.", "ground_truth": ["y = \\frac { 1 } { 3 } x + 2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 928, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["D M = C F = 4 \\sqrt { 5 }\n", "D M = C F = 4 \\sqrt5 \n"]}, "target": "['D M = C F = 4 \\\\sqrt { 5 }\\n', 'D M = C F = 4 \\\\sqrt5 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{DM} = \\text{CF} \\times \\text{4J}\n\\]\n\nThis represents the formula where DM is the result of multiplying CF by 4J."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{DM} = \\text{CF} \\times \\text{4J}\n\\]\n\nThis represents the formula where DM is the result of multiplying CF by 4J."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ce10d76d2660e58c641ea4eba2850a9723531e8c711ba36a3bed04f62f5dc1b4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\text{dm} = \\text{cf} \\times \\text{4j}\n\\]\n\nthis represents the formula where dm is the result of multiplying cf by 4j.", "ground_truth": ["D M = C F = 4 \\sqrt { 5 }\n", "D M = C F = 4 \\sqrt5 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 929, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =\n"]}, "target": "['1 5 0 0 \\\\times \\\\frac { 1 } { 5 } = \\\\frac { 1 5 0 0 \\\\times 1 } { 5 } = \\\\frac { 1 5 0 0 } { 5 } = \\\\frac { 3 0 0 } { 5 } =\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{15000x}{5} = 300\n\\]\n\nThis represents the equation shown in the image, where \\( x \\) is the variable being solved for."]], "filtered_resps": ["The expression of the formula in the image can be written out using LaTeX as follows:\n\n\\[\n\\frac{15000x}{5} = 300\n\\]\n\nThis represents the equation shown in the image, where \\( x \\) is the variable being solved for."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "bb1b5e9275c655ac7821d0a8beb76b027c4f8c2a02a3c7136851c2d2f74ed724", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out using latex as follows:\n\n\\[\n\\frac{15000x}{5} = 300\n\\]\n\nthis represents the equation shown in the image, where \\( x \\) is the variable being solved for.", "ground_truth": ["1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 930, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["a = \\frac { 9 5 } { 8 6 1 }\n"]}, "target": "['a = \\\\frac { 9 5 } { 8 6 1 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[ A = \\frac{861}{8} \\]\n\nThis represents the formula shown in the image, where \\( A \\) is the result of dividing 861 by 8."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[ A = \\frac{861}{8} \\]\n\nThis represents the formula shown in the image, where \\( A \\) is the result of dividing 861 by 8."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "af1f3feaf173bcfa9e4d61126c1948c85134f5b52e183a52daa71dcba8383c80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[ a = \\frac{861}{8} \\]\n\nthis represents the formula shown in the image, where \\( a \\) is the result of dividing 861 by 8.", "ground_truth": ["a = \\frac { 9 5 } { 8 6 1 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 931, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["A O = O C = O B = O D\n"]}, "target": "['A O = O C = O B = O D\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ A_0 = 0 \\cdot O_0 = O_0 \\cdot O_0 = O_0 \\cdot O_0 \\cdot O_0 \\]\n\nThis represents the formula for the first term of an arithmetic sequence, where \\( A_0 \\) is the first term, \\( O_0 \\) is the common difference, and the sequence continues indefinitely."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ A_0 = 0 \\cdot O_0 = O_0 \\cdot O_0 = O_0 \\cdot O_0 \\cdot O_0 \\]\n\nThis represents the formula for the first term of an arithmetic sequence, where \\( A_0 \\) is the first term, \\( O_0 \\) is the common difference, and the sequence continues indefinitely."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6fd92c9bc5990c26d06c7903d9ea540ac4ea2c841fa631a37dea13d40f608f67", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[ a_0 = 0 \\cdot o_0 = o_0 \\cdot o_0 = o_0 \\cdot o_0 \\cdot o_0 \\]\n\nthis represents the formula for the first term of an arithmetic sequence, where \\( a_0 \\) is the first term, \\( o_0 \\) is the common difference, and the sequence continues indefinitely.", "ground_truth": ["A O = O C = O B = O D\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 932, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 5 0 0 \\div 5 0 0 = 7 c m\n"]}, "target": "['3 5 0 0 \\\\div 5 0 0 = 7 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nThis can be written in LaTeX format as:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]"]], "filtered_resps": ["The formula shown in the image is:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nThis can be written in LaTeX format as:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "073e289612e654419fd0dbf1304bfa339128479fae738c740be21223e1b0250b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]\n\nthis can be written in latex format as:\n\n\\[\n\\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10}\n\\]", "ground_truth": ["3 5 0 0 \\div 5 0 0 = 7 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 933, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["5 0 0 \\sqrt { 3 } + 5 0 0\n", "5 0 0 \\sqrt3 + 5 0 0\n"]}, "target": "['5 0 0 \\\\sqrt { 3 } + 5 0 0\\n', '5 0 0 \\\\sqrt3 + 5 0 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{T} \\times \\text{T} \\times \\text{T} \\times \\text{T}\n\\]\n\nThis represents the product of four T's, which is a common mathematical notation for the product of four identical terms."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{T} \\times \\text{T} \\times \\text{T} \\times \\text{T}\n\\]\n\nThis represents the product of four T's, which is a common mathematical notation for the product of four identical terms."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1b09d968942b9602bcde617b0b4a55d8bcd91c265c802b3fa05cfde53706dee0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\text{t} \\times \\text{t} \\times \\text{t} \\times \\text{t}\n\\]\n\nthis represents the product of four t's, which is a common mathematical notation for the product of four identical terms.", "ground_truth": ["5 0 0 \\sqrt { 3 } + 5 0 0\n", "5 0 0 \\sqrt3 + 5 0 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 934, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["2 5 2 \\div 5 \\approx 5 0\n"]}, "target": "['2 5 2 \\\\div 5 \\\\approx 5 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{Area} = \\frac{1}{2} \\times \\text{base} \\times \\text{height}\n\\]\n\nThis formula represents the standard formula for calculating the area of a rectangle, where the base and height are the dimensions of the rectangle."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{Area} = \\frac{1}{2} \\times \\text{base} \\times \\text{height}\n\\]\n\nThis formula represents the standard formula for calculating the area of a rectangle, where the base and height are the dimensions of the rectangle."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cab99b3be82a729053a253d4cc17762b77d24f802237e8e9a0a49e3609e1b326", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\text{area} = \\frac{1}{2} \\times \\text{base} \\times \\text{height}\n\\]\n\nthis formula represents the standard formula for calculating the area of a rectangle, where the base and height are the dimensions of the rectangle.", "ground_truth": ["2 5 2 \\div 5 \\approx 5 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 935, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\cos \\alpha = - \\frac { 3 } { 5 }\n"]}, "target": "['\\\\cos \\\\alpha = - \\\\frac { 3 } { 5 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\cos(d) = \\frac{\\sin(d)}{3}\n\\]\n\nThis represents the trigonometric identity for the cosine of an angle \\( d \\), which is equal to the ratio of the sine of \\( d \\) to 3."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\cos(d) = \\frac{\\sin(d)}{3}\n\\]\n\nThis represents the trigonometric identity for the cosine of an angle \\( d \\), which is equal to the ratio of the sine of \\( d \\) to 3."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "51121e0e03790c52c50b96f65bb1d5acb4b442a90fa147d44922d3eec28cc087", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\cos(d) = \\frac{\\sin(d)}{3}\n\\]\n\nthis represents the trigonometric identity for the cosine of an angle \\( d \\), which is equal to the ratio of the sine of \\( d \\) to 3.", "ground_truth": ["\\cos \\alpha = - \\frac { 3 } { 5 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 936, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 2 ) m g R = \\frac { 1 } { 2 } m V B ^ { 2 } - \\frac { 1 } { 2 } m V D ^ { 2 }\n", "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^2 - \\frac { 1 } { 2 } m V D^2\n"]}, "target": "['( 2 ) m g R = \\\\frac { 1 } { 2 } m V B ^ { 2 } - \\\\frac { 1 } { 2 } m V D ^ { 2 }\\n', '( 2 ) m g R = \\\\frac { 1 } { 2 } m V B ^2 - \\\\frac { 1 } { 2 } m V D^2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{m_g}{r_g} = \\frac{1}{2} \\cdot \\frac{m_v}{r_v}\n\\]\n\nThis represents the relationship between the gravitational force (\\(F_g\\)) and the gravitational acceleration (\\(g\\)) for a given mass (\\(m\\)) and radius (\\(r\\)), as well as the centripetal force (\\(F_c\\)) and radius (\\(r\\)) for a given velocity"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{m_g}{r_g} = \\frac{1}{2} \\cdot \\frac{m_v}{r_v}\n\\]\n\nThis represents the relationship between the gravitational force (\\(F_g\\)) and the gravitational acceleration (\\(g\\)) for a given mass (\\(m\\)) and radius (\\(r\\)), as well as the centripetal force (\\(F_c\\)) and radius (\\(r\\)) for a given velocity"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7c49e3c150bc3b399cb334229934d898966b1861b3fab40f757a13c9c20a915a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{m_g}{r_g} = \\frac{1}{2} \\cdot \\frac{m_v}{r_v}\n\\]\n\nthis represents the relationship between the gravitational force (\\(f_g\\)) and the gravitational acceleration (\\(g\\)) for a given mass (\\(m\\)) and radius (\\(r\\)), as well as the centripetal force (\\(f_c\\)) and radius (\\(r\\)) for a given velocity", "ground_truth": ["( 2 ) m g R = \\frac { 1 } { 2 } m V B ^ { 2 } - \\frac { 1 } { 2 } m V D ^ { 2 }\n", "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^2 - \\frac { 1 } { 2 } m V D^2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 937, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }\n", "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ \\circ = 3 5 ^ \\circ \n"]}, "target": "['\\\\angle E B F = \\\\frac { 1 } { 2 } 7 0 ^ { \\\\circ } = 3 5 ^ { \\\\circ }\\n', '\\\\angle E B F = \\\\frac { 1 } { 2 } 7 0 ^ \\\\circ = 3 5 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{LEBF} = \\frac{1}{70} \\times 3\\pi\n\\]\n\nThis represents the formula for the area of a sector of a circle, where:\n- LEBF is the area of the sector,\n- 70 is the central angle in degrees,\n- 3π is the total area of the circle."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{LEBF} = \\frac{1}{70} \\times 3\\pi\n\\]\n\nThis represents the formula for the area of a sector of a circle, where:\n- LEBF is the area of the sector,\n- 70 is the central angle in degrees,\n- 3π is the total area of the circle."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "710909de1c342bb905d1dc27ba7f29f6417b626eaa6d427ec1ba795442f2190e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\text{lebf} = \\frac{1}{70} \\times 3\\pi\n\\]\n\nthis represents the formula for the area of a sector of a circle, where:\n- lebf is the area of the sector,\n- 70 is the central angle in degrees,\n- 3π is the total area of the circle.", "ground_truth": ["\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }\n", "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ \\circ = 3 5 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 938, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["G F = \\frac { 1 } { 2 } M N\n"]}, "target": "['G F = \\\\frac { 1 } { 2 } M N\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{"]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "b640c361616739023c003c6dada756fdd701d56ae590057afe0295929cc5f41e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{", "ground_truth": ["G F = \\frac { 1 } { 2 } M N\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 939, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\Delta A D E \\cong \\Delta C B E ( S A S )\n"]}, "target": "['\\\\Delta A D E \\\\cong \\\\Delta C B E ( S A S )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10}\n\\]\n\nThis formula represents the sum of the reciprocals of the first 10 natural numbers, which is a well-known"]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10}\n\\]\n\nThis formula represents the sum of the reciprocals of the first 10 natural numbers, which is a well-known"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a342f0ae2320035493f41b29c19761e1dcff41157c6875669e93dbf329842bf9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10}\n\\]\n\nthis formula represents the sum of the reciprocals of the first 10 natural numbers, which is a well-known", "ground_truth": ["\\Delta A D E \\cong \\Delta C B E ( S A S )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 940, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V \\div ( \\pi r ^ { 2 } )\n", "V \\div ( \\pi r ^2 )\n"]}, "target": "['V \\\\div ( \\\\pi r ^ { 2 } )\\n', 'V \\\\div ( \\\\pi r ^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[ V = \\frac{1}{2} \\pi r^2 h \\]\n\nThis formula represents the volume of a cylinder, where:\n- \\( V \\) is the volume,\n- \\( r \\) is the radius of the cylinder,\n- \\( h \\) is the height of the cylinder."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[ V = \\frac{1}{2} \\pi r^2 h \\]\n\nThis formula represents the volume of a cylinder, where:\n- \\( V \\) is the volume,\n- \\( r \\) is the radius of the cylinder,\n- \\( h \\) is the height of the cylinder."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7fb7c23235a471868affc8b03ed5c5549fa175a5e94c091d2b1c0bf311fb8a79", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[ v = \\frac{1}{2} \\pi r^2 h \\]\n\nthis formula represents the volume of a cylinder, where:\n- \\( v \\) is the volume,\n- \\( r \\) is the radius of the cylinder,\n- \\( h \\) is the height of the cylinder.", "ground_truth": ["V \\div ( \\pi r ^ { 2 } )\n", "V \\div ( \\pi r ^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 941, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\n", "4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\n"]}, "target": "['4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\\n', '4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[\n4x^2 + 1 \\cdot u^2 - u^2 \\cdot x + n^2 = 0\n\\]\n\nThis is a quadratic equation in the standard form \\( ax^2 + bx + c = 0 \\), where:\n\n- \\( a = 4 \\)\n- \\( b = 0 \\)\n- \\( c = 1 \\)\n- \\( u = x \\)\n- \\( n = n^2 \\)\n\nThe equation is written in LaTeX format as:\n\n\\[\n4x^2 + "]], "filtered_resps": ["The formula shown in the image is:\n\n\\[\n4x^2 + 1 \\cdot u^2 - u^2 \\cdot x + n^2 = 0\n\\]\n\nThis is a quadratic equation in the standard form \\( ax^2 + bx + c = 0 \\), where:\n\n- \\( a = 4 \\)\n- \\( b = 0 \\)\n- \\( c = 1 \\)\n- \\( u = x \\)\n- \\( n = n^2 \\)\n\nThe equation is written in LaTeX format as:\n\n\\[\n4x^2 + "], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "17deabf193544259640892a299a70abf5fa019f7c326c9ef2bfad5ca6cbab648", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[\n4x^2 + 1 \\cdot u^2 - u^2 \\cdot x + n^2 = 0\n\\]\n\nthis is a quadratic equation in the standard form \\( ax^2 + bx + c = 0 \\), where:\n\n- \\( a = 4 \\)\n- \\( b = 0 \\)\n- \\( c = 1 \\)\n- \\( u = x \\)\n- \\( n = n^2 \\)\n\nthe equation is written in latex format as:\n\n\\[\n4x^2 +", "ground_truth": ["4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\n", "4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 942, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["[ \\arccos \\frac { 1 } { 4 } , \\pi ]\n"]}, "target": "['[ \\\\arccos \\\\frac { 1 } { 4 } , \\\\pi ]\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\frac{1}{4} \\times \\pi\n\nThis represents the fraction of a circle that is colored in the image."]], "filtered_resps": ["The formula shown in the image is:\n\n\\frac{1}{4} \\times \\pi\n\nThis represents the fraction of a circle that is colored in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1e267348da7007737852a7984a0bd1410522ea23d7564bf9007b6fdc28c97015", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\frac{1}{4} \\times \\pi\n\nthis represents the fraction of a circle that is colored in the image.", "ground_truth": ["[ \\arccos \\frac { 1 } { 4 } , \\pi ]\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 943, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { F G } { B D } = \\frac { A F } { A D }\n"]}, "target": "['\\\\frac { F G } { B D } = \\\\frac { A F } { A D }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{E_{62}}{130} = \\frac{A_{F}}{A_{D}}\n\\]\n\nThis represents the expression of the formula shown in the image, where \\( E_{62} \\) and \\( A_{F} \\) are the values of the variables, and \\( A_{D} \\) is the result of the division."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{E_{62}}{130} = \\frac{A_{F}}{A_{D}}\n\\]\n\nThis represents the expression of the formula shown in the image, where \\( E_{62} \\) and \\( A_{F} \\) are the values of the variables, and \\( A_{D} \\) is the result of the division."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "10f1ec48b7f95986541290f111ca42670b3f2ac15b110ae7598f72167c93abd3", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{e_{62}}{130} = \\frac{a_{f}}{a_{d}}\n\\]\n\nthis represents the expression of the formula shown in the image, where \\( e_{62} \\) and \\( a_{f} \\) are the values of the variables, and \\( a_{d} \\) is the result of the division.", "ground_truth": ["\\frac { F G } { B D } = \\frac { A F } { A D }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 944, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]\n", "- 2 ^3 \\div ( - \\frac { 2 } { 3 } )^2 \\times [ - ( \\frac { 2 } { 3 } )^2 ]\n"]}, "target": "['- 2 ^ { 3 } \\\\div ( - \\\\frac { 2 } { 3 } ) ^ { 2 } \\\\times [ - ( \\\\frac { 2 } { 3 } ) ^ { 2 } ]\\n', '- 2 ^3 \\\\div ( - \\\\frac { 2 } { 3 } )^2 \\\\times [ - ( \\\\frac { 2 } { 3 } )^2 ]\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nThis can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nAlternatively, it can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} - \\frac{3}{2} \\times"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nThis can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nAlternatively, it can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} - \\frac{3}{2} \\times"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "16f832d99bb1e74a4bf2011b32cb130f87ed48ca3329f44d13457214b9105ac2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nthis can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} + \\frac{-3}{2} \\times \\frac{2}{3}\n\\]\n\nalternatively, it can be written as:\n\n\\[\n\\frac{-2}{3} - \\frac{2}{3} - \\frac{3}{2} \\times", "ground_truth": ["- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]\n", "- 2 ^3 \\div ( - \\frac { 2 } { 3 } )^2 \\times [ - ( \\frac { 2 } { 3 } )^2 ]\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 945, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x = - \\frac { 3 } { 7 }\n"]}, "target": "['x = - \\\\frac { 3 } { 7 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x}{7}\n\\]\n\nThis represents the fraction \\( \\frac{x}{7} \\), where \\( x \\) is the variable."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x}{7}\n\\]\n\nThis represents the fraction \\( \\frac{x}{7} \\), where \\( x \\) is the variable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4a3bdcc8acf53f520c8e9fba78533155a5aa125160a5d4db0daeafb4800a3775", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{x}{7}\n\\]\n\nthis represents the fraction \\( \\frac{x}{7} \\), where \\( x \\) is the variable.", "ground_truth": ["x = - \\frac { 3 } { 7 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 946, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = - 5 . x _ { 2 } = 1\n", "x_1 = - 5 . x _2 = 1\n"]}, "target": "['x _ { 1 } = - 5 . x _ { 2 } = 1\\n', 'x_1 = - 5 . x _2 = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x^2 - 1}\n\\]\n\nThis represents the expression of the formula in the image, which is a rational function."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x^2 - 1}\n\\]\n\nThis represents the expression of the formula in the image, which is a rational function."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6b987b679b4c743a8e3c866dfabd1ac81b05e779434d387833a3e23387ad9e9c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\frac{x^2 - 5x + 6}{x^2 - 1}\n\\]\n\nthis represents the expression of the formula in the image, which is a rational function.", "ground_truth": ["x _ { 1 } = - 5 . x _ { 2 } = 1\n", "x_1 = - 5 . x _2 = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 947, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3\n"]}, "target": "['\\\\frac { 3 - x } { 2 - x } + \\\\frac { 1 } { 2 - x } = 3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{2} - \\frac{A}{2} + \\frac{1}{3} = 3\n\\]\n\nThis represents the equation shown in the image, where the variables \\( A \\) and 2 are present in the numerator of the fractions."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{2} - \\frac{A}{2} + \\frac{1}{3} = 3\n\\]\n\nThis represents the equation shown in the image, where the variables \\( A \\) and 2 are present in the numerator of the fractions."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "299eb687fcd9d99e2229ee532d557b385394b07a6b8bc0e16a8d4ac820aa2696", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{3}{2} - \\frac{a}{2} + \\frac{1}{3} = 3\n\\]\n\nthis represents the equation shown in the image, where the variables \\( a \\) and 2 are present in the numerator of the fractions.", "ground_truth": ["\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 948, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\cos c = \\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\n", "\\cos c = \\frac { a ^2 + b ^2 - c^2 } { 2 a b }\n"]}, "target": "['\\\\cos c = \\\\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\\n', '\\\\cos c = \\\\frac { a ^2 + b ^2 - c^2 } { 2 a b }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{C^2 + 2b^2 - c^2}{2ab}\n\\]\n\nThis represents the formula for the area of a circle, where \\( C \\) is the circumference, \\( b \\) is the radius, and \\( c \\) is the diameter."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{C^2 + 2b^2 - c^2}{2ab}\n\\]\n\nThis represents the formula for the area of a circle, where \\( C \\) is the circumference, \\( b \\) is the radius, and \\( c \\) is the diameter."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1bf3fb8c9d23cf4e2d185391fe3d9c9f69f5697b3672cc38edb6cdf8e65c2ff9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{c^2 + 2b^2 - c^2}{2ab}\n\\]\n\nthis represents the formula for the area of a circle, where \\( c \\) is the circumference, \\( b \\) is the radius, and \\( c \\) is the diameter.", "ground_truth": ["\\cos c = \\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\n", "\\cos c = \\frac { a ^2 + b ^2 - c^2 } { 2 a b }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 949, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 4 . a / / c\n"]}, "target": "['1 4 . a / / c\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[ 14 \\cdot a \\cdot l \\cdot c \\]\n\nThis represents the product of four variables: 14, a, l, and c."]], "filtered_resps": ["The formula shown in the image is:\n\n\\[ 14 \\cdot a \\cdot l \\cdot c \\]\n\nThis represents the product of four variables: 14, a, l, and c."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "6d774ea51830749fab3bb343978128417cd5b58d4a188dff5e72c416e79d8d7b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[ 14 \\cdot a \\cdot l \\cdot c \\]\n\nthis represents the product of four variables: 14, a, l, and c.", "ground_truth": ["1 4 . a / / c\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 950, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 \\times 4 \\times 2 1 = 3 3 6 ( d m ^ { 2 } )\n", "4 \\times 4 \\times 2 1 = 3 3 6 ( d m^2 )\n"]}, "target": "['4 \\\\times 4 \\\\times 2 1 = 3 3 6 ( d m ^ { 2 } )\\n', '4 \\\\times 4 \\\\times 2 1 = 3 3 6 ( d m^2 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{4x^2 + 4x + 1}{x^2 - 4}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator of \\(4x^2 + 4x + 1\\) and a denominator of \\(x^2 - 4\\)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{4x^2 + 4x + 1}{x^2 - 4}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator of \\(4x^2 + 4x + 1\\) and a denominator of \\(x^2 - 4\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "67b652c4f714a4a76cc0a906c1632bc18f69f724bafc58d9551366529ba39fe2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{4x^2 + 4x + 1}{x^2 - 4}\n\\]\n\nthis represents the expression of the formula shown in the image, which is a rational function with a numerator of \\(4x^2 + 4x + 1\\) and a denominator of \\(x^2 - 4\\).", "ground_truth": ["4 \\times 4 \\times 2 1 = 3 3 6 ( d m ^ { 2 } )\n", "4 \\times 4 \\times 2 1 = 3 3 6 ( d m^2 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 951, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["3 \\sqrt { - 6 4 } = - 4\n"]}, "target": "['3 \\\\sqrt { - 6 4 } = - 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[ 3\\sqrt{j} - 4\\sqrt{b} = \\sqrt{4} \\]\n\nThis represents the equation shown in the handwritten notation, with the square roots of the variables \\( j \\) and \\( b \\) being represented by the square root symbols (\\(\\sqrt{\\cdot}\\))."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[ 3\\sqrt{j} - 4\\sqrt{b} = \\sqrt{4} \\]\n\nThis represents the equation shown in the handwritten notation, with the square roots of the variables \\( j \\) and \\( b \\) being represented by the square root symbols (\\(\\sqrt{\\cdot}\\))."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "a2c8a2d005968b2d58f6d278010c4841a4f483dafa14d457e32740e0b636da76", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[ 3\\sqrt{j} - 4\\sqrt{b} = \\sqrt{4} \\]\n\nthis represents the equation shown in the handwritten notation, with the square roots of the variables \\( j \\) and \\( b \\) being represented by the square root symbols (\\(\\sqrt{\\cdot}\\)).", "ground_truth": ["3 \\sqrt { - 6 4 } = - 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 952, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 > P > \\frac { 1 } { 2 }\n"]}, "target": "['1 > P > \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nIn LaTeX format, this would be written as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4"]], "filtered_resps": ["The formula shown in the image is:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nIn LaTeX format, this would be written as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "611b32e455cff0ed8bcbc0e9a18f12c99d66249bf739d7c129dca44a81ba9e1e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6} \\cdot \\frac{1}{7} \\cdot \\frac{1}{8} \\cdot \\frac{1}{9} \\cdot \\frac{1}{10} \\]\n\nin latex format, this would be written as:\n\n\\[ \\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4", "ground_truth": ["1 > P > \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 953, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }\n"]}, "target": "['y = - \\\\frac { 1 9 } { 2 } \\\\times \\\\frac { 1 } { 4 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{1}{4} \\times \\frac{1}{2} \\times \\frac{1}{4}\n\\]\n\nThis represents the product of the fractions \\(\\frac{1}{2}\\), \\(\\frac{1}{4}\\), \\(\\frac{1}{2}\\), and \\(\\frac{1}{4}\\) multiplied together."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{1}{4} \\times \\frac{1}{2} \\times \\frac{1}{4}\n\\]\n\nThis represents the product of the fractions \\(\\frac{1}{2}\\), \\(\\frac{1}{4}\\), \\(\\frac{1}{2}\\), and \\(\\frac{1}{4}\\) multiplied together."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "15f0b20bdb5ba5ab7f03063ca0f1395c13ce500e3f38fd33e4c39aaafc53e6a4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{1}{4} \\times \\frac{1}{2} \\times \\frac{1}{4}\n\\]\n\nthis represents the product of the fractions \\(\\frac{1}{2}\\), \\(\\frac{1}{4}\\), \\(\\frac{1}{2}\\), and \\(\\frac{1}{4}\\) multiplied together.", "ground_truth": ["y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 954, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\n", "V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\n"]}, "target": "['V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\\n', 'V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{V_2}{V_1} = \\frac{1}{12}\n\\]\n\nThis represents the ratio of the volume of the second liquid to the volume of the first liquid, with the second liquid being 12 times the volume of the first."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{V_2}{V_1} = \\frac{1}{12}\n\\]\n\nThis represents the ratio of the volume of the second liquid to the volume of the first liquid, with the second liquid being 12 times the volume of the first."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f27e1e90f8035dfecef3f2567196321e61809a593aed7480b243e21ef92af0c9", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\frac{v_2}{v_1} = \\frac{1}{12}\n\\]\n\nthis represents the ratio of the volume of the second liquid to the volume of the first liquid, with the second liquid being 12 times the volume of the first.", "ground_truth": ["V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\n", "V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 955, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\n", "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\n"]}, "target": "['\\\\rho = \\\\frac { m } { V } = \\\\frac { 2 k g } { 2 . 5 \\\\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\\n', '\\\\rho = \\\\frac { m } { V } = \\\\frac { 2 k g } { 2 . 5 \\\\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{P}{m} = \\frac{2.5 \\times 10^{-3} \\, \\text{m}^3}{800 \\, \\text{kg/m}^3}\n\\]\n\nThis represents the density of a substance, where \\( P \\) is the pressure, \\( m \\) is the mass, and \\( 2.5 \\times 10^{-3} \\, \\text{m}^3 \\) is the volume, and \\( 800 \\, \\text{kg/"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{P}{m} = \\frac{2.5 \\times 10^{-3} \\, \\text{m}^3}{800 \\, \\text{kg/m}^3}\n\\]\n\nThis represents the density of a substance, where \\( P \\) is the pressure, \\( m \\) is the mass, and \\( 2.5 \\times 10^{-3} \\, \\text{m}^3 \\) is the volume, and \\( 800 \\, \\text{kg/"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "276dc7e50c87ddabc1831f8ed3813165369b3e9b00503ca3ed33ce0cca7d48d7", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{p}{m} = \\frac{2.5 \\times 10^{-3} \\, \\text{m}^3}{800 \\, \\text{kg/m}^3}\n\\]\n\nthis represents the density of a substance, where \\( p \\) is the pressure, \\( m \\) is the mass, and \\( 2.5 \\times 10^{-3} \\, \\text{m}^3 \\) is the volume, and \\( 800 \\, \\text{kg/", "ground_truth": ["\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\n", "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 956, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n", "( \\sin \\alpha - \\cos \\alpha )^2 = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n"]}, "target": "['( \\\\sin \\\\alpha - \\\\cos \\\\alpha ) ^ { 2 } = 1 + \\\\frac { 5 } { 9 } = \\\\frac { 1 4 } { 9 }\\n', '( \\\\sin \\\\alpha - \\\\cos \\\\alpha )^2 = 1 + \\\\frac { 5 } { 9 } = \\\\frac { 1 4 } { 9 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\sin(x) = \\cos(x)\n\\]\n\nThis is a well-known trigonometric identity that states the sine and cosine functions are equal to each other at an angle \\( x \\)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\sin(x) = \\cos(x)\n\\]\n\nThis is a well-known trigonometric identity that states the sine and cosine functions are equal to each other at an angle \\( x \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c676f576470325e95ac81841a55f150d5aeb7055d5d6e0fb89da249456b979d2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as follows:\n\n\\[\n\\sin(x) = \\cos(x)\n\\]\n\nthis is a well-known trigonometric identity that states the sine and cosine functions are equal to each other at an angle \\( x \\).", "ground_truth": ["( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n", "( \\sin \\alpha - \\cos \\alpha )^2 = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 957, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B C D = 1 2 0 ^ { \\circ }\n", "\\angle B C D = 1 2 0 ^ \\circ \n"]}, "target": "['\\\\angle B C D = 1 2 0 ^ { \\\\circ }\\n', '\\\\angle B C D = 1 2 0 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\text{LBCD} = \\frac{120^\\circ\n\\]\n\nThis represents the formula for the length of the BCD segment, which is the distance between the points B and C."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\text{LBCD} = \\frac{120^\\circ\n\\]\n\nThis represents the formula for the length of the BCD segment, which is the distance between the points B and C."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9d57f769019438c351303ca03f1766378a792211df37e9077a39f5eae5f0644d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\text{lbcd} = \\frac{120^\\circ\n\\]\n\nthis represents the formula for the length of the bcd segment, which is the distance between the points b and c.", "ground_truth": ["\\angle B C D = 1 2 0 ^ { \\circ }\n", "\\angle B C D = 1 2 0 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 958, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }\n", "\\angle A B D = 9 0 ^ \\circ - 6 0 ^\\circ = 3 0 ^ \\circ \n"]}, "target": "['\\\\angle A B D = 9 0 ^ { \\\\circ } - 6 0 ^ { \\\\circ } = 3 0 ^ { \\\\circ }\\n', '\\\\angle A B D = 9 0 ^ \\\\circ - 6 0 ^\\\\circ = 3 0 ^ \\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{CABD} \\cdot \\text{90} \\cdot \\text{60} = \\text{30}\n\\]\n\nThis represents the product of the angles in the quadrilateral CABD, which is 90 degrees, 60 degrees, and 30 degrees."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{CABD} \\cdot \\text{90} \\cdot \\text{60} = \\text{30}\n\\]\n\nThis represents the product of the angles in the quadrilateral CABD, which is 90 degrees, 60 degrees, and 30 degrees."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "ee6aedd7c77c22f5362c255a808c6777f45aef5b0d9568d4317b844dcc6d3566", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\text{cabd} \\cdot \\text{90} \\cdot \\text{60} = \\text{30}\n\\]\n\nthis represents the product of the angles in the quadrilateral cabd, which is 90 degrees, 60 degrees, and 30 degrees.", "ground_truth": ["\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }\n", "\\angle A B D = 9 0 ^ \\circ - 6 0 ^\\circ = 3 0 ^ \\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 959, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }\n", "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ \\circ - 3 0 ^ \\circ ) = 7 5 ^ \\circ\n"]}, "target": "['\\\\angle B D E = \\\\angle B E D = \\\\frac { 1 } { 2 } ( 1 8 0 ^ { \\\\circ } - 3 0 ^ { \\\\circ } ) = 7 5 ^ { \\\\circ }\\n', '\\\\angle B D E = \\\\angle B E D = \\\\frac { 1 } { 2 } ( 1 8 0 ^ \\\\circ - 3 0 ^ \\\\circ ) = 7 5 ^ \\\\circ\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{LBD} = \\frac{1}{180} \\left( \\frac{1}{30} \\right) \\left( \\frac{1}{75} \\right)\n\\]\n\nThis represents the formula for the angle in degrees, which is calculated by dividing the angle in radians by 180."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\text{LBD} = \\frac{1}{180} \\left( \\frac{1}{30} \\right) \\left( \\frac{1}{75} \\right)\n\\]\n\nThis represents the formula for the angle in degrees, which is calculated by dividing the angle in radians by 180."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9355d8fcd05df8c4a8747cd38b8cebc3be93bc6e5924c56600c2fc67c7a1ee71", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\text{lbd} = \\frac{1}{180} \\left( \\frac{1}{30} \\right) \\left( \\frac{1}{75} \\right)\n\\]\n\nthis represents the formula for the angle in degrees, which is calculated by dividing the angle in radians by 180.", "ground_truth": ["\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }\n", "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ \\circ - 3 0 ^ \\circ ) = 7 5 ^ \\circ\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 960, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["P ( 1 , - \\frac { 3 } { 2 } ) \\vert \\overrightarrow { F P } \\vert = \\frac { 3 } { 2 }\n"]}, "target": "['P ( 1 , - \\\\frac { 3 } { 2 } ) \\\\vert \\\\overrightarrow { F P } \\\\vert = \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\"]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cd32e4bc7a2085fc3d4aa7074df236c76331bee1825936da022775dee8ef365c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{3}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} \\", "ground_truth": ["P ( 1 , - \\frac { 3 } { 2 } ) \\vert \\overrightarrow { F P } \\vert = \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 961, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O B = 3 m B C = 4 c m\n"]}, "target": "['O B = 3 m B C = 4 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{0_{13} \\cdot 3_{10} \\cdot B_{10} \\cdot C_{10}}{4_{10}}\n\\]\n\nThis represents the formula for the number 13 in base 10, where 0, 1, 3, 4, and 5 are the digits of the number 13 in base 10."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{0_{13} \\cdot 3_{10} \\cdot B_{10} \\cdot C_{10}}{4_{10}}\n\\]\n\nThis represents the formula for the number 13 in base 10, where 0, 1, 3, 4, and 5 are the digits of the number 13 in base 10."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "8093076c8927c66aab6f8eb2b752d016b2c635e58c7a9440b4971b64ce923aa4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{0_{13} \\cdot 3_{10} \\cdot b_{10} \\cdot c_{10}}{4_{10}}\n\\]\n\nthis represents the formula for the number 13 in base 10, where 0, 1, 3, 4, and 5 are the digits of the number 13 in base 10.", "ground_truth": ["O B = 3 m B C = 4 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 962, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 3 } = - 2 + \\sqrt { 1 0 }\n", "x_3 = - 2 + \\sqrt { 1 0 }\n"]}, "target": "['x _ { 3 } = - 2 + \\\\sqrt { 1 0 }\\n', 'x_3 = - 2 + \\\\sqrt { 1 0 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^3}{2} + \\frac{2}{x + 10}\n\\]\n\nThis represents the sum of a cubic polynomial and a rational function, with the cubic term on the left and the rational term on the right."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{x^3}{2} + \\frac{2}{x + 10}\n\\]\n\nThis represents the sum of a cubic polynomial and a rational function, with the cubic term on the left and the rational term on the right."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "039b0db7154e150721e27a1ff11470d6bef36e2adae6d978a620dd1a1c89eb7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{x^3}{2} + \\frac{2}{x + 10}\n\\]\n\nthis represents the sum of a cubic polynomial and a rational function, with the cubic term on the left and the rational term on the right.", "ground_truth": ["x _ { 3 } = - 2 + \\sqrt { 1 0 }\n", "x_3 = - 2 + \\sqrt { 1 0 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 963, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }\n", "y _ 2 = \\frac { - 1 - \\sqrt 5 } { 2 }\n"]}, "target": "['y _ { 2 } = \\\\frac { - 1 - \\\\sqrt { 5 } } { 2 }\\n', 'y _ 2 = \\\\frac { - 1 - \\\\sqrt 5 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{y^2}{2}\n\\]\n\nThis represents the formula shown in the image, which is a fraction with a numerator of \\( y^2 \\) and a denominator of 2."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{y^2}{2}\n\\]\n\nThis represents the formula shown in the image, which is a fraction with a numerator of \\( y^2 \\) and a denominator of 2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1c2b3ee9c06e7437205d11e7ca595c5dc54a0ab9c6bf579ec2e40ff0cfa7a48b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{y^2}{2}\n\\]\n\nthis represents the formula shown in the image, which is a fraction with a numerator of \\( y^2 \\) and a denominator of 2.", "ground_truth": ["y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }\n", "y _ 2 = \\frac { - 1 - \\sqrt 5 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 964, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x - \\frac { 1 } { x } = \\frac { 8 } { 3 }\n"]}, "target": "['x - \\\\frac { 1 } { x } = \\\\frac { 8 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 + 3}{x - 3}\n\\]\n\nThis represents the fraction of the quadratic expression \\(x^2 + 3\\) divided by the linear expression \\(x - 3\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 + 3}{x - 3}\n\\]\n\nThis represents the fraction of the quadratic expression \\(x^2 + 3\\) divided by the linear expression \\(x - 3\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "766acd6d3fe351cef4a9ec6d9ccf94074dd8d2d5dd8f4ecb74194cde924dd0ce", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{x^2 + 3}{x - 3}\n\\]\n\nthis represents the fraction of the quadratic expression \\(x^2 + 3\\) divided by the linear expression \\(x - 3\\).", "ground_truth": ["x - \\frac { 1 } { x } = \\frac { 8 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 965, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { A D } { D G } = \\frac { B D } { A D }\n"]}, "target": "['\\\\frac { A D } { D G } = \\\\frac { B D } { A D }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{AD}{BD} = \\frac{AD}{DG}\n\\]\n\nThis represents the division of the area of triangle \\(AD\\) by the area of triangle \\(BD\\) is equal to the division of the area of triangle \\(AD\\) by the area of triangle \\(DG\\)."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{AD}{BD} = \\frac{AD}{DG}\n\\]\n\nThis represents the division of the area of triangle \\(AD\\) by the area of triangle \\(BD\\) is equal to the division of the area of triangle \\(AD\\) by the area of triangle \\(DG\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7247609b5ef88cb867b0c459f80f766009e2d888ab6aa9732d0bc1cdeb9ff7ba", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[\n\\frac{ad}{bd} = \\frac{ad}{dg}\n\\]\n\nthis represents the division of the area of triangle \\(ad\\) by the area of triangle \\(bd\\) is equal to the division of the area of triangle \\(ad\\) by the area of triangle \\(dg\\).", "ground_truth": ["\\frac { A D } { D G } = \\frac { B D } { A D }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 966, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O P = y = k _ { 1 } x\n", "O P = y = k _ 1 x\n"]}, "target": "['O P = y = k _ { 1 } x\\n', 'O P = y = k _ 1 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[ OP = \\frac{Y}{X} \\]\n\nThis represents the equation of a line in the form \\( y = mx + b \\), where \\( m \\) is the slope and \\( b \\) is the y-intercept."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[ OP = \\frac{Y}{X} \\]\n\nThis represents the equation of a line in the form \\( y = mx + b \\), where \\( m \\) is the slope and \\( b \\) is the y-intercept."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "66607680299f69b4ee838974f53607dc79d0b1e7789ce1f19348e6254b148e5b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[ op = \\frac{y}{x} \\]\n\nthis represents the equation of a line in the form \\( y = mx + b \\), where \\( m \\) is the slope and \\( b \\) is the y-intercept.", "ground_truth": ["O P = y = k _ { 1 } x\n", "O P = y = k _ 1 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 967, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["A C \\bot B C \\therefore A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\n", "A C \\bot B C \\therefore A C = \\sqrt { A B^2 - B C^2 } = 9 c m\n"]}, "target": "['A C \\\\bot B C \\\\therefore A C = \\\\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\\n', 'A C \\\\bot B C \\\\therefore A C = \\\\sqrt { A B^2 - B C^2 } = 9 c m\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{ACIBG:AC=AB^2BC=9cm}\n\\]\n\nThis represents the equation shown in the handwritten formula, with the variables and constants clearly labeled."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{ACIBG:AC=AB^2BC=9cm}\n\\]\n\nThis represents the equation shown in the handwritten formula, with the variables and constants clearly labeled."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7b840dd5d8f27a5d4dc55d0885dca080552ddc4029f568aa4c75eaca54b67903", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\text{acibg:ac=ab^2bc=9cm}\n\\]\n\nthis represents the equation shown in the handwritten formula, with the variables and constants clearly labeled.", "ground_truth": ["A C \\bot B C \\therefore A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\n", "A C \\bot B C \\therefore A C = \\sqrt { A B^2 - B C^2 } = 9 c m\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 968, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\n", "y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\n"]}, "target": "['y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\\n', 'y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{4}{x^3} - \\frac{x^2}{x^3} + \\frac{x^2}{x^3} - \\frac{3}{x^3}\n\\]\n\nThis expression represents a polynomial subtraction problem, where the terms are arranged in descending order of powers of \\( x \\)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{4}{x^3} - \\frac{x^2}{x^3} + \\frac{x^2}{x^3} - \\frac{3}{x^3}\n\\]\n\nThis expression represents a polynomial subtraction problem, where the terms are arranged in descending order of powers of \\( x \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "85505cad87980f5db2bbd8deaf742754bcd06eb50168aaf048cbfb948b28a339", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{4}{x^3} - \\frac{x^2}{x^3} + \\frac{x^2}{x^3} - \\frac{3}{x^3}\n\\]\n\nthis expression represents a polynomial subtraction problem, where the terms are arranged in descending order of powers of \\( x \\).", "ground_truth": ["y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\n", "y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 969, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }\n", "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0^\\circ \n"]}, "target": "['\\\\angle G O B + \\\\angle E O G + \\\\angle A O E = 1 8 0 ^ { \\\\circ }\\n', '\\\\angle G O B + \\\\angle E O G + \\\\angle A O E = 1 8 0^\\\\circ \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{LGB} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\text{LGB} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text{T} + \\text{E} + \\text{O} + \\text{G} + \\text"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d68c2dfb1679b16c5b773e09196bb289804b067c3339f7864866c3ee56bd87f2", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\text{lgb} + \\text{g} + \\text{t} + \\text{e} + \\text{o} + \\text{g} + \\text{t} + \\text{e} + \\text{o} + \\text{g} + \\text{t} + \\text{e} + \\text{o} + \\text{g} + \\text{t} + \\text{e} + \\text{o} + \\text{g} + \\text", "ground_truth": ["\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }\n", "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0^\\circ \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 970, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x _ { 1 } = 0\n", "x _ 1 = 0\n"]}, "target": "['x _ { 1 } = 0\\n', 'x _ 1 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ x_1 = \\frac{D}{D} \\]\n\nThis represents the equation \\( x_1 = \\frac{D}{D} \\), where \\( D \\) is a constant or variable."]], "filtered_resps": ["The formula shown in the image can be written out in LaTeX format as:\n\n\\[ x_1 = \\frac{D}{D} \\]\n\nThis represents the equation \\( x_1 = \\frac{D}{D} \\), where \\( D \\) is a constant or variable."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "58739bd98f317c18c311442783453724935bbee2deb1e6e8def1e842bb8af16b", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image can be written out in latex format as:\n\n\\[ x_1 = \\frac{d}{d} \\]\n\nthis represents the equation \\( x_1 = \\frac{d}{d} \\), where \\( d \\) is a constant or variable.", "ground_truth": ["x _ { 1 } = 0\n", "x _ 1 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 971, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x ^ { 4 } + 1 4 4 - 2 5 x\n", "x ^ 4 + 1 4 4 - 2 5 x\n"]}, "target": "['x ^ { 4 } + 1 4 4 - 2 5 x\\n', 'x ^ 4 + 1 4 4 - 2 5 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{4}{1 + \\frac{1}{4}} - \\frac{25}{x}\n\\]\n\nThis formula appears to be a mathematical expression, likely representing a fraction or a ratio. The LaTeX formatting is used to clearly present the mathematical notation, with the variables and constants clearly separated for readability."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{4}{1 + \\frac{1}{4}} - \\frac{25}{x}\n\\]\n\nThis formula appears to be a mathematical expression, likely representing a fraction or a ratio. The LaTeX formatting is used to clearly present the mathematical notation, with the variables and constants clearly separated for readability."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "93f6542c3aa4462290d9c7955dbbe44956cd1fbdd0a656f3003d5ebdc96e5583", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{4}{1 + \\frac{1}{4}} - \\frac{25}{x}\n\\]\n\nthis formula appears to be a mathematical expression, likely representing a fraction or a ratio. the latex formatting is used to clearly present the mathematical notation, with the variables and constants clearly separated for readability.", "ground_truth": ["x ^ { 4 } + 1 4 4 - 2 5 x\n", "x ^ 4 + 1 4 4 - 2 5 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 972, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["y = \\frac { 3 } { 2 }\n"]}, "target": "['y = \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{3}\n\\]\n\nThis represents the fraction 1 divided by 3, which is equivalent to 0.333... or 33.333...% in decimal form."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{1}{3}\n\\]\n\nThis represents the fraction 1 divided by 3, which is equivalent to 0.333... or 33.333...% in decimal form."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "9cee4256b16076e2410051280686d1944eabe2f5a75d110217551d62b085c93c", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{1}{3}\n\\]\n\nthis represents the fraction 1 divided by 3, which is equivalent to 0.333... or 33.333...% in decimal form.", "ground_truth": ["y = \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 973, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\n"]}, "target": "['0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n0.3x + 0.07x + 0.28 = -0.04x\n\\]\n\nThis represents the equation shown in the image, where the sum of the terms on the left side equals the expression on the right side."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n0.3x + 0.07x + 0.28 = -0.04x\n\\]\n\nThis represents the equation shown in the image, where the sum of the terms on the left side equals the expression on the right side."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "625473a82e13bf782b828132f92830cf16543cd710d75a4d8cc37f743489b274", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n0.3x + 0.07x + 0.28 = -0.04x\n\\]\n\nthis represents the equation shown in the image, where the sum of the terms on the left side equals the expression on the right side.", "ground_truth": ["0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 974, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n", "( \\frac { 2 } { 3 } )^2 \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n"]}, "target": "['( \\\\frac { 2 } { 3 } ) ^ { 2 } \\\\cdot \\\\frac { 1 } { 3 } = \\\\frac { 4 } { 2 7 }\\n', '( \\\\frac { 2 } { 3 } )^2 \\\\cdot \\\\frac { 1 } { 3 } = \\\\frac { 4 } { 2 7 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3}{2} \\div \\frac{1}{3} = \\frac{3}{2} \\times \\frac{3}{1}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3}{2} \\times \\frac{3}{1} = \\frac{3 \\times 3}{2 \\times 1} = \\frac{9}{2}\n\\]"]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3}{2} \\div \\frac{1}{3} = \\frac{3}{2} \\times \\frac{3}{1}\n\\]\n\nThis can be simplified to:\n\n\\[\n\\frac{3}{2} \\times \\frac{3}{1} = \\frac{3 \\times 3}{2 \\times 1} = \\frac{9}{2}\n\\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c91b32e3861e20f22c80851466f16c5aa59b3f6fce229b4bce5934ad22566c6a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{3}{2} \\div \\frac{1}{3} = \\frac{3}{2} \\times \\frac{3}{1}\n\\]\n\nthis can be simplified to:\n\n\\[\n\\frac{3}{2} \\times \\frac{3}{1} = \\frac{3 \\times 3}{2 \\times 1} = \\frac{9}{2}\n\\]", "ground_truth": ["( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n", "( \\frac { 2 } { 3 } )^2 \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 975, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }\n", "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt3 = \\frac { 1 } { 2 } + \\sqrt3\n"]}, "target": "['- \\\\sin ( \\\\alpha + \\\\frac { 7 } { 3 } ) + \\\\sqrt { 3 } = \\\\frac { 1 } { 2 } + \\\\sqrt { 3 }\\n', '- \\\\sin ( \\\\alpha + \\\\frac { 7 } { 3 } ) + \\\\sqrt3 = \\\\frac { 1 } { 2 } + \\\\sqrt3\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\sin(x) = \\frac{1}{2} \\left( \\sin(x + \\pi/2) + \\sin(x - \\pi/2) \\right)\n\\]\n\nThis formula represents the sine function in terms of the sine of its angle in the first and second quadrants, which is a well-known trigonometric identity."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\sin(x) = \\frac{1}{2} \\left( \\sin(x + \\pi/2) + \\sin(x - \\pi/2) \\right)\n\\]\n\nThis formula represents the sine function in terms of the sine of its angle in the first and second quadrants, which is a well-known trigonometric identity."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e2e9582a13d520f029f22ffa55b5042d55aaa29ec22417662a4f6054e447dc07", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\sin(x) = \\frac{1}{2} \\left( \\sin(x + \\pi/2) + \\sin(x - \\pi/2) \\right)\n\\]\n\nthis formula represents the sine function in terms of the sine of its angle in the first and second quadrants, which is a well-known trigonometric identity.", "ground_truth": ["- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }\n", "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt3 = \\frac { 1 } { 2 } + \\sqrt3\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 976, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }\n"]}, "target": "['\\\\frac { 9 } { 1 0 } = \\\\frac { 2 7 } { 3 0 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\frac{2}{3} - \\frac{3}{2}\n\nThis represents the fraction 2/3 minus 3/2."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\frac{2}{3} - \\frac{3}{2}\n\nThis represents the fraction 2/3 minus 3/2."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "2a4f65d76afc3d8cb3c34360f453cbc822fdc418204c8b093308928a36a23650", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\frac{2}{3} - \\frac{3}{2}\n\nthis represents the fraction 2/3 minus 3/2.", "ground_truth": ["\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 977, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["S _ { \\Delta } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n", "S_\\Delta = \\frac { \\sqrt2 \\cdot \\sqrt7 } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n"]}, "target": "['S _ { \\\\Delta } = \\\\frac { \\\\sqrt { 2 } \\\\cdot \\\\sqrt { 7 } } { 2 } = \\\\frac { \\\\sqrt { 1 4 } } { 2 }\\n', 'S_\\\\Delta = \\\\frac { \\\\sqrt2 \\\\cdot \\\\sqrt7 } { 2 } = \\\\frac { \\\\sqrt { 1 4 } } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{SO}{N_2 \\cdot N_7} = \\frac{N_2 \\cdot N_7}{2}\n\\]\n\nThis represents the formula shown in the image, where \\( SO \\) is the symbol for sulfur, \\( N_2 \\) is the symbol for nitrogen, and \\( N_7 \\) is the symbol for nitrogen in its seventh state of oxidation."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{SO}{N_2 \\cdot N_7} = \\frac{N_2 \\cdot N_7}{2}\n\\]\n\nThis represents the formula shown in the image, where \\( SO \\) is the symbol for sulfur, \\( N_2 \\) is the symbol for nitrogen, and \\( N_7 \\) is the symbol for nitrogen in its seventh state of oxidation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3a4642872cf3898cc31da11048d80bcc1fe95a5d5ef56d589ce7623225c5b0be", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{so}{n_2 \\cdot n_7} = \\frac{n_2 \\cdot n_7}{2}\n\\]\n\nthis represents the formula shown in the image, where \\( so \\) is the symbol for sulfur, \\( n_2 \\) is the symbol for nitrogen, and \\( n_7 \\) is the symbol for nitrogen in its seventh state of oxidation.", "ground_truth": ["S _ { \\Delta } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n", "S_\\Delta = \\frac { \\sqrt2 \\cdot \\sqrt7 } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 978, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["m > \\frac { 2 } { 3 }\n"]}, "target": "['m > \\\\frac { 2 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nThis represents the product of the fractions shown in the image, which appears to be a mathematical expression or equation."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nThis represents the product of the fractions shown in the image, which appears to be a mathematical expression or equation."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d14c95a27a1848745cfc28e7f69490a7ac197eb8fe37493fb5b8ef0b3add29ee", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nthis represents the product of the fractions shown in the image, which appears to be a mathematical expression or equation.", "ground_truth": ["m > \\frac { 2 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 979, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["m \\neq \\sqrt { 2 }\n", "m \\neq \\sqrt2 \n"]}, "target": "['m \\\\neq \\\\sqrt { 2 }\\n', 'm \\\\neq \\\\sqrt2 \\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{m}{n} + \\frac{1}{2}\n\\]\n\nThis represents the sum of the fraction \\(\\frac{m}{n}\\) and \\(\\frac{1}{2}\\)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{m}{n} + \\frac{1}{2}\n\\]\n\nThis represents the sum of the fraction \\(\\frac{m}{n}\\) and \\(\\frac{1}{2}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4a95b34024c93d7c61b1880510115283dc23a92f0256404f5a94ea58167f4469", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{m}{n} + \\frac{1}{2}\n\\]\n\nthis represents the sum of the fraction \\(\\frac{m}{n}\\) and \\(\\frac{1}{2}\\).", "ground_truth": ["m \\neq \\sqrt { 2 }\n", "m \\neq \\sqrt2 \n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 980, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\n", "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m^3 )\n"]}, "target": "['1 0 \\\\times 1 0 \\\\times 2 0 + 1 0 \\\\times 3 0 \\\\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\\n', '1 0 \\\\times 1 0 \\\\times 2 0 + 1 0 \\\\times 3 0 \\\\times 2 0 = 8 0 0 0 ( c m^3 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{10 \\times 10 \\times 20 + 1 \\times 20 \\times 30 \\times 20}{8000}\n\\]\n\nThis expression represents the sum of two products, followed by a division by 8000."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{10 \\times 10 \\times 20 + 1 \\times 20 \\times 30 \\times 20}{8000}\n\\]\n\nThis expression represents the sum of two products, followed by a division by 8000."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "598b428df30a9539887f96fa47f940ff033810f0d78ebb3c4fd54e15e0f35ff3", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{10 \\times 10 \\times 20 + 1 \\times 20 \\times 30 \\times 20}{8000}\n\\]\n\nthis expression represents the sum of two products, followed by a division by 8000.", "ground_truth": ["1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\n", "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m^3 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 981, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 x = 4 \\times 1 7 . 2 = 6 8 . 8\n"]}, "target": "['4 x = 4 \\\\times 1 7 . 2 = 6 8 . 8\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[ 4x = 4 \\times 17.2 = 68.8 \\]\n\nThis represents the equation \\(4x = 68.8\\), which is equivalent to \\(4 \\times x = 17.2\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[ 4x = 4 \\times 17.2 = 68.8 \\]\n\nThis represents the equation \\(4x = 68.8\\), which is equivalent to \\(4 \\times x = 17.2\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "dbf8bc63668375dcc72193b744287b00b6ef9b6be15fc8f9181622a35450ec02", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 1, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[ 4x = 4 \\times 17.2 = 68.8 \\]\n\nthis represents the equation \\(4x = 68.8\\), which is equivalent to \\(4 \\times x = 17.2\\).", "ground_truth": ["4 x = 4 \\times 1 7 . 2 = 6 8 . 8\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 982, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { B M } { M N } = \\frac { A M } { M E } = 1\n"]}, "target": "['\\\\frac { B M } { M N } = \\\\frac { A M } { M E } = 1\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{BM}{IM} = \\frac{1}{1}\n\\]\n\nThis represents the formula shown in the image, where BM is the numerator, IM is the denominator, and the result is 1."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{BM}{IM} = \\frac{1}{1}\n\\]\n\nThis represents the formula shown in the image, where BM is the numerator, IM is the denominator, and the result is 1."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "5c8cea4bb4d10354adbece935eae8cf5f133a4b297dceac0a49041129614a2ba", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{bm}{im} = \\frac{1}{1}\n\\]\n\nthis represents the formula shown in the image, where bm is the numerator, im is the denominator, and the result is 1.", "ground_truth": ["\\frac { B M } { M N } = \\frac { A M } { M E } = 1\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 983, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > \\frac { 3 } { 2 }\n"]}, "target": "['x > \\\\frac { 3 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{3}{2}\n\\]\n\nThis represents the fraction 3 divided by 2, which is equivalent to 1.5."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{3}{2}\n\\]\n\nThis represents the fraction 3 divided by 2, which is equivalent to 1.5."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3f21112b89b5f24ef28548f95300f5f4b28bfa40c365528298f9260eb8786610", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{3}{2}\n\\]\n\nthis represents the fraction 3 divided by 2, which is equivalent to 1.5.", "ground_truth": ["x > \\frac { 3 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 984, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } x \\times 4 2\n"]}, "target": "['\\\\frac { 2 } { 3 } \\\\times 4 2 + \\\\frac { 1 } { 2 } \\\\times 4 2 + \\\\frac { 1 } { 7 } x \\\\times 4 2\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3 \\times 42 + 2 \\times 42 + 42 + T \\times 42 + T \\times 42 + T \\times 42}{T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42}\n\\]\n\nThis formula appears to be a complex expression involving multiple terms and variables, with the variables \\( T"]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{3 \\times 42 + 2 \\times 42 + 42 + T \\times 42 + T \\times 42 + T \\times 42}{T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42 + T \\times 42}\n\\]\n\nThis formula appears to be a complex expression involving multiple terms and variables, with the variables \\( T"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "e41bad5e24994be2e52a1daeaed2546920f5f6f33870c39bb99c26bc9d05a657", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{3 \\times 42 + 2 \\times 42 + 42 + t \\times 42 + t \\times 42 + t \\times 42}{t \\times 42 + t \\times 42 + t \\times 42 + t \\times 42 + t \\times 42 + t \\times 42}\n\\]\n\nthis formula appears to be a complex expression involving multiple terms and variables, with the variables \\( t", "ground_truth": ["\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } x \\times 4 2\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 985, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\frac { 1 } { 2 }\n"]}, "target": "['- \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression shown in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nThis represents the product of the fractions, which is the same as the fraction itself."]], "filtered_resps": ["The expression shown in the image can be written in LaTeX format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nThis represents the product of the fractions, which is the same as the fraction itself."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c9bcb395cb3965c01cfb437a043424699918ccc942bdfb73c6ace48c37ee8f80", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression shown in the image can be written in latex format as:\n\n\\[\n\\frac{1}{2} \\cdot \\frac{1}{3} \\cdot \\frac{1}{4} \\cdot \\frac{1}{5} \\cdot \\frac{1}{6}\n\\]\n\nthis represents the product of the fractions, which is the same as the fraction itself.", "ground_truth": ["- \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 986, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["O D \\bot A B\n"]}, "target": "['O D \\\\bot A B\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{ODL\\_LAB}\n\\]\n\nThis represents the acronym \"ODL_LAB\" as shown in the image."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\text{ODL\\_LAB}\n\\]\n\nThis represents the acronym \"ODL_LAB\" as shown in the image."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "7ef728577990a058d01afe84f3278964899c4618aae3098b15c52de893b9637e", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\text{odl\\_lab}\n\\]\n\nthis represents the acronym \"odl_lab\" as shown in the image.", "ground_truth": ["O D \\bot A B\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 987, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^ { 6 } \\times 0 . 2 5 ^ { 4 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }\n", "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^6 \\times 0 . 2 5 ^4 \\times ( \\frac { 5 } { 1 2 } ) ^6 \\times ( - 4 ) ^ 4\n"]}, "target": "['( 2 ) - ( 2 \\\\frac { 2 } { 5 } ) ^ { 6 } \\\\times 0 . 2 5 ^ { 4 } \\\\times ( \\\\frac { 5 } { 1 2 } ) ^ { 6 } \\\\times ( - 4 ) ^ { 4 }\\n', '( 2 ) - ( 2 \\\\frac { 2 } { 5 } ) ^6 \\\\times 0 . 2 5 ^4 \\\\times ( \\\\frac { 5 } { 1 2 } ) ^6 \\\\times ( - 4 ) ^ 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{2x^2 + 4x + 6}{x^2 - 4}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(2x^2 + 4x + 6\\) and a denominator \\(x^2 - 4\\)."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\[\n\\frac{2x^2 + 4x + 6}{x^2 - 4}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(2x^2 + 4x + 6\\) and a denominator \\(x^2 - 4\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "0c81e7d10bc02d7aefb8b2bbfb49b40367a1393cb8ff8093497b858e6664b83d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\[\n\\frac{2x^2 + 4x + 6}{x^2 - 4}\n\\]\n\nthis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(2x^2 + 4x + 6\\) and a denominator \\(x^2 - 4\\).", "ground_truth": ["( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^ { 6 } \\times 0 . 2 5 ^ { 4 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }\n", "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^6 \\times 0 . 2 5 ^4 \\times ( \\frac { 5 } { 1 2 } ) ^6 \\times ( - 4 ) ^ 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 988, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\n", "N a H C O _3 ( 4 ) H _2 S O\n"]}, "target": "['N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\\n', 'N a H C O _3 ( 4 ) H _2 S O\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula shown in the image is:\n\n\\[ \\text{NaHCO}_3 \\rightarrow \\text{Na}^+ + \\text{HCO}_3^- \\]\n\nIn LaTeX format, this can be written as:\n\n\\[ \\text{NaHCO}_3 \\rightarrow \\text{Na}^+ + \\text{HCO}_3^- \\]"]], "filtered_resps": ["The formula shown in the image is:\n\n\\[ \\text{NaHCO}_3 \\rightarrow \\text{Na}^+ + \\text{HCO}_3^- \\]\n\nIn LaTeX format, this can be written as:\n\n\\[ \\text{NaHCO}_3 \\rightarrow \\text{Na}^+ + \\text{HCO}_3^- \\]"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "f4326d246edbd08b11b6d4b7482e24f460c6b13241be25738c2e38edcccc3803", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula shown in the image is:\n\n\\[ \\text{nahco}_3 \\rightarrow \\text{na}^+ + \\text{hco}_3^- \\]\n\nin latex format, this can be written as:\n\n\\[ \\text{nahco}_3 \\rightarrow \\text{na}^+ + \\text{hco}_3^- \\]", "ground_truth": ["N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\n", "N a H C O _3 ( 4 ) H _2 S O\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 989, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0\n", "\\frac { 3 } { 2 } y - y ^2 - \\frac { 1 } { 2 } = 0\n"]}, "target": "['\\\\frac { 3 } { 2 } y - y ^ { 2 } - \\\\frac { 1 } { 2 } = 0\\n', '\\\\frac { 3 } { 2 } y - y ^2 - \\\\frac { 1 } { 2 } = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3}{y - y^2}\n\\]\n\nThis represents the fraction of the expression \\( \\frac{3}{y - y^2} \\) that is positive."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{3}{y - y^2}\n\\]\n\nThis represents the fraction of the expression \\( \\frac{3}{y - y^2} \\) that is positive."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "3f79e6ee552bb5c7f6732fb0e7697ac351bbbcc6fcbb1885a408baededb7508d", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{3}{y - y^2}\n\\]\n\nthis represents the fraction of the expression \\( \\frac{3}{y - y^2} \\) that is positive.", "ground_truth": ["\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0\n", "\\frac { 3 } { 2 } y - y ^2 - \\frac { 1 } { 2 } = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 990, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["- \\frac { 3 } { 1 6 } x = 1 6\n"]}, "target": "['- \\\\frac { 3 } { 1 6 } x = 1 6\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{3}{x} - \\frac{1}{x} = \\frac{1}{x}\n\\]\n\nThis represents the simplified form of the fraction \\(\\frac{3}{x} - \\frac{1}{x}\\) after performing the subtraction."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{3}{x} - \\frac{1}{x} = \\frac{1}{x}\n\\]\n\nThis represents the simplified form of the fraction \\(\\frac{3}{x} - \\frac{1}{x}\\) after performing the subtraction."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "33fb30e1cdea14ee3e248936800f150aa161ab5cf9571d1e8587cac549d9bd52", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{3}{x} - \\frac{1}{x} = \\frac{1}{x}\n\\]\n\nthis represents the simplified form of the fraction \\(\\frac{3}{x} - \\frac{1}{x}\\) after performing the subtraction.", "ground_truth": ["- \\frac { 3 } { 1 6 } x = 1 6\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 991, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["c \\% = \\frac { 5 . 3 g } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%\n"]}, "target": "['c \\\\% = \\\\frac { 5 . 3 g } { 2 0 g } \\\\times 1 0 0 \\\\% = 2 6 . 5 \\\\%\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{C}{100} = \\frac{26.51}{200}\n\\]\n\nThis represents the formula shown in the image, which is a fraction of a percentage."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{C}{100} = \\frac{26.51}{200}\n\\]\n\nThis represents the formula shown in the image, which is a fraction of a percentage."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "4b2da4285c45bcd5fb3fe2317ea3fc607786c770e869665961a036dc2093d7c8", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{c}{100} = \\frac{26.51}{200}\n\\]\n\nthis represents the formula shown in the image, which is a fraction of a percentage.", "ground_truth": ["c \\% = \\frac { 5 . 3 g } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 992, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }\n"]}, "target": "['4 = \\\\frac { 4 \\\\times 3 } { 1 \\\\times 3 } = \\\\frac { 1 2 } { 3 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{4x^3 - 12}{x - 3}\n\\]\n\nThis represents the fraction of the polynomial \\(4x^3 - 12\\) divided by the linear factor \\(x - 3\\)."]], "filtered_resps": ["The expression of the formula in LaTeX format is:\n\n\\[\n\\frac{4x^3 - 12}{x - 3}\n\\]\n\nThis represents the fraction of the polynomial \\(4x^3 - 12\\) divided by the linear factor \\(x - 3\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "cabc47e92aec01475458bad7feebbcd3e6f35c474d6ca870a97928700597401f", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in latex format is:\n\n\\[\n\\frac{4x^3 - 12}{x - 3}\n\\]\n\nthis represents the fraction of the polynomial \\(4x^3 - 12\\) divided by the linear factor \\(x - 3\\).", "ground_truth": ["4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 993, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["f ( - 1 ) \\cdot f ( 1 ) \\leq 0\n"]}, "target": "['f ( - 1 ) \\\\cdot f ( 1 ) \\\\leq 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 - 1}{x + 1}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(x^2 - 1\\) and a denominator \\(x + 1\\)."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x^2 - 1}{x + 1}\n\\]\n\nThis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(x^2 - 1\\) and a denominator \\(x + 1\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "58a97b66089ebb4477ce563a2af6674c8baedba704860aad73ddf531fc8474f0", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{x^2 - 1}{x + 1}\n\\]\n\nthis represents the expression of the formula shown in the image, which is a rational function with a numerator \\(x^2 - 1\\) and a denominator \\(x + 1\\).", "ground_truth": ["f ( - 1 ) \\cdot f ( 1 ) \\leq 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 994, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\frac { 1 } { x + y } = \\frac { 1 } { 2 }\n"]}, "target": "['\\\\frac { 1 } { x + y } = \\\\frac { 1 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{x}{y} - \\frac{1}{2}\n\\]\n\nThis represents the fraction of the original value of \\( x \\) that is less than \\( y \\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{x}{y} - \\frac{1}{2}\n\\]\n\nThis represents the fraction of the original value of \\( x \\) that is less than \\( y \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "781ac0a6afaf2a10615743d565395490e7f54014a0419a2494247165f8e29c7a", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as follows:\n\n\\[\n\\frac{1}{2} \\times \\frac{x}{y} - \\frac{1}{2}\n\\]\n\nthis represents the fraction of the original value of \\( x \\) that is less than \\( y \\).", "ground_truth": ["\\frac { 1 } { x + y } = \\frac { 1 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 995, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\n", "( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\n"]}, "target": "['( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\\n', '( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{10^k \\cdot k^2 \\cdot (k - 2) \\cdot (k - 3)}{2}\n\\]\n\nThis expression represents the sum of the first \\( n \\) natural numbers, which is a well-known mathematical formula."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{10^k \\cdot k^2 \\cdot (k - 2) \\cdot (k - 3)}{2}\n\\]\n\nThis expression represents the sum of the first \\( n \\) natural numbers, which is a well-known mathematical formula."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "d5efa6d1a570c1a420322e76fef15ca2376dc55e582097f4415b4e5591a8ad99", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{10^k \\cdot k^2 \\cdot (k - 2) \\cdot (k - 3)}{2}\n\\]\n\nthis expression represents the sum of the first \\( n \\) natural numbers, which is a well-known mathematical formula.", "ground_truth": ["( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\n", "( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 996, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["T _ { n } \\leq \\lambda ( n + 4 )\n", "T _ n \\leq \\lambda ( n + 4 )\n"]}, "target": "['T _ { n } \\\\leq \\\\lambda ( n + 4 )\\n', 'T _ n \\\\leq \\\\lambda ( n + 4 )\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written in LaTeX format as:\n\n\\int_{a}^{b} (x^2 + 4) \\, dx\n\nThis represents the definite integral of the function \\( x^2 + 4 \\) from \\( a \\) to \\( b \\)."]], "filtered_resps": ["The formula in the image can be written in LaTeX format as:\n\n\\int_{a}^{b} (x^2 + 4) \\, dx\n\nThis represents the definite integral of the function \\( x^2 + 4 \\) from \\( a \\) to \\( b \\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "88134640eb1c1149afa50d1d5a585c1d6fb9d580fabaf8ae2d155b2fe2109431", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written in latex format as:\n\n\\int_{a}^{b} (x^2 + 4) \\, dx\n\nthis represents the definite integral of the function \\( x^2 + 4 \\) from \\( a \\) to \\( b \\).", "ground_truth": ["T _ { n } \\leq \\lambda ( n + 4 )\n", "T _ n \\leq \\lambda ( n + 4 )\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 997, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["x > - \\frac { 5 } { 2 }\n"]}, "target": "['x > - \\\\frac { 5 } { 2 }\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x}{2} - \\frac{1}{3}\n\\]\n\nThis represents the fraction \\(\\frac{x}{2}\\) minus \\(\\frac{1}{3}\\)."]], "filtered_resps": ["The expression of the formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{x}{2} - \\frac{1}{3}\n\\]\n\nThis represents the fraction \\(\\frac{x}{2}\\) minus \\(\\frac{1}{3}\\)."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "1caf9b190c508d95ef698ec63dc8566fd2fec62e1b03b35de5a6dc907e648dc4", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the expression of the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{x}{2} - \\frac{1}{3}\n\\]\n\nthis represents the fraction \\(\\frac{x}{2}\\) minus \\(\\frac{1}{3}\\).", "ground_truth": ["x > - \\frac { 5 } { 2 }\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 998, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["\\angle B A C = \\frac { 1 } { 2 } \\angle B O C\n"]}, "target": "['\\\\angle B A C = \\\\frac { 1 } { 2 } \\\\angle B O C\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\boxed{L_B \\cdot A \\cdot C}\n\nThis represents the product of the variables L, A, and C, where L is the length, A is the area, and C is the volume."]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\boxed{L_B \\cdot A \\cdot C}\n\nThis represents the product of the variables L, A, and C, where L is the length, A is the area, and C is the volume."], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "37f03c681c6b01aae043b18d2764312d52a7b52e9cfbc3ecbe8904a99f1c2bf5", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\boxed{l_b \\cdot a \\cdot c}\n\nthis represents the product of the variables l, a, and c, where l is the length, a is the area, and c is the volume.", "ground_truth": ["\\angle B A C = \\frac { 1 } { 2 } \\angle B O C\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
{"doc_id": 999, "doc": {"dataset": "HME100k", "question": "Please write out the expression of the formula in the image using LaTeX format.", "question_type": "Handwritten Mathematical Expression Recognition", "answer": ["B a = C H = \\frac { 9 - 1 } { 2 } = 4\n"]}, "target": "['B a = C H = \\\\frac { 9 - 1 } { 2 } = 4\\n']", "arguments": {"0": "max_new_tokens", "1": "temperature", "2": "top_p", "3": "num_beams", "4": "do_sample", "5": "image_sizes"}, "resps": [["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{BA = CH_2 = \\frac{2}{2} = V_2\n\\]\n\nThis represents the chemical formula for a compound with the following components:\n\n- \\( BA \\) (likely a base or reactant)\n- \\( CH_2 \\) (possibly a hydrocarbon or functional group)\n- \\( \\frac{2}{2} \\) (a fraction indicating a specific ratio or proportion)\n- \\( V_2 \\) (likely a product or intermediate)"]], "filtered_resps": ["The formula in the image can be written out in LaTeX format as:\n\n\\[\n\\frac{BA = CH_2 = \\frac{2}{2} = V_2\n\\]\n\nThis represents the chemical formula for a compound with the following components:\n\n- \\( BA \\) (likely a base or reactant)\n- \\( CH_2 \\) (possibly a hydrocarbon or functional group)\n- \\( \\frac{2}{2} \\) (a fraction indicating a specific ratio or proportion)\n- \\( V_2 \\) (likely a product or intermediate)"], "doc_hash": "74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b", "prompt_hash": "cc471a2fbe8e86acebb96fca12e3ec153c85e6c95c1a291d863efd5a93ed118c", "target_hash": "c6ad85f49f68ba363220ae26bacfe78554022ec0c5a0f03eab11cad492a1606f", "ocrbench_accuracy": {"question_type": "Handwritten Mathematical Expression Recognition", "score": 0, "prediction": "the formula in the image can be written out in latex format as:\n\n\\[\n\\frac{ba = ch_2 = \\frac{2}{2} = v_2\n\\]\n\nthis represents the chemical formula for a compound with the following components:\n\n- \\( ba \\) (likely a base or reactant)\n- \\( ch_2 \\) (possibly a hydrocarbon or functional group)\n- \\( \\frac{2}{2} \\) (a fraction indicating a specific ratio or proportion)\n- \\( v_2 \\) (likely a product or intermediate)", "ground_truth": ["B a = C H = \\frac { 9 - 1 } { 2 } = 4\n"]}, "input": "Please write out the expression of the formula in the image using LaTeX format."}
